[
  {
    "mt_id": 1,
    "task_id": "BigCodeBench/13",
    "mt_data": [
      {
        "task_id": "BigCodeBench/13_1",
        "turn": "1",
        "instruct_prompt": "  You should write self-contained code starting with:```python\nimport ftplib\n\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        ftp_obj = ftplib.FTP(ftp_server)\n        ftp_obj.login(ftp_user, ftp_password)\n        return ftp_obj\n    except Exception as e:\n        raise\n```",
        "test": "import unittest\nimport ftplib\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('ftplib.FTP')\n    def test_successful_connection(self, mock_ftp_class):\n        mock_ftp_instance = MagicMock()\n        mock_ftp_class.return_value = mock_ftp_instance\n        \n        ftp_obj = task_func('testserver', 'user', 'pass', '/dir')\n        \n        mock_ftp_class.assert_called_once_with('testserver')\n        mock_ftp_instance.login.assert_called_once_with('user', 'pass')\n        self.assertEqual(ftp_obj, mock_ftp_instance)\n\n    @patch('ftplib.FTP')\n    def test_connection_failure(self, mock_ftp_class):\n        mock_ftp_class.side_effect = ftplib.all_errors\n        \n        with self.assertRaises(Exception):\n            task_func('badserver', 'user', 'pass', '/dir')\n\n    @patch('ftplib.FTP')\n    def test_login_failure(self, mock_ftp_class):\n        mock_ftp_instance = MagicMock()\n        mock_ftp_class.return_value = mock_ftp_instance\n        mock_ftp_instance.login.side_effect = ftplib.error_perm('530 Login incorrect.')\n        \n        with self.assertRaises(Exception):\n            task_func('server', 'wronguser', 'wrongpass', '/dir')\n",
        "code": "import ftplib\n\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        ftp_obj = ftplib.FTP(ftp_server)\n        ftp_obj.login(ftp_user, ftp_password)\n        return ftp_obj\n    except Exception as e:\n        raise\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/13_2",
        "turn": "2",
        "instruct_prompt": "Add functionality to change the directory on the connected FTP server to ftp_dir, raising an exception with message \"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\" if it fails.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport ftplib\n\nclass TestCases(unittest.TestCase):\n    @patch('ftplib.FTP')\n    def test_change_directory_success(self, mock_ftp_class):\n        mock_ftp = MagicMock()\n        mock_ftp_class.return_value = mock_ftp\n        mock_ftp.cwd.return_value = '250 Directory successfully changed.'\n\n        # Should not raise exception\n        ftp_obj = None\n        try:\n            ftp_obj = __import__(__name__).task_func(ftp_dir='/valid/dir')\n        except Exception:\n            self.fail('task_func raised Exception unexpectedly!')\n\n        mock_ftp_class.assert_called_once_with('ftp.dlptest.com')\n        mock_ftp.login.assert_called_once_with('dlpuser', 'rNrKYTX9g7z3RgJRmxWuGHbeu')\n        mock_ftp.cwd.assert_called_once_with('/valid/dir')\n        self.assertEqual(ftp_obj, mock_ftp)\n\n    @patch('ftplib.FTP')\n    def test_change_directory_fail(self, mock_ftp_class):\n        mock_ftp = MagicMock()\n        mock_ftp_class.return_value = mock_ftp\n        # Simulate cwd raising an error\n        mock_ftp.cwd.side_effect = ftplib.error_perm('550 Failed to change directory.')\n\n        with self.assertRaises(Exception) as context:\n            __import__(__name__).task_func(ftp_dir='/invalid/dir')\n\n        self.assertIn('Failed to change to directory /invalid/dir on server ftp.dlptest.com:', str(context.exception))\n\n    @patch('ftplib.FTP')\n    def test_login_fail(self, mock_ftp_class):\n        mock_ftp_class.side_effect = ftplib.error_perm('530 Login incorrect.')\n\n        with self.assertRaises(ftplib.error_perm):\n            __import__(__name__).task_func()\n",
        "code": "import ftplib\n\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        ftp_obj = ftplib.FTP(ftp_server)\n        ftp_obj.login(ftp_user, ftp_password)\n        try:\n            ftp_obj.cwd(ftp_dir)\n        except Exception as e:\n            raise Exception(f\"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n        return ftp_obj\n    except Exception as e:\n        raise\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/13_3",
        "turn": "3",
        "instruct_prompt": "List all filenames in the current directory of the FTP server and store them in a list.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('ftplib.FTP')\n    def test_list_filenames_success(self, mock_ftp_class):\n        mock_ftp = MagicMock()\n        mock_ftp_class.return_value = mock_ftp\n        mock_ftp.nlst.return_value = ['file1.txt', 'file2.jpg', 'file3.pdf']\n\n        filenames = task_func(ftp_server='dummy_server', ftp_user='user', ftp_password='pass', ftp_dir='/dummy_dir')\n\n        mock_ftp_class.assert_called_with('dummy_server')\n        mock_ftp.login.assert_called_with('user', 'pass')\n        mock_ftp.cwd.assert_called_with('/dummy_dir')\n        mock_ftp.nlst.assert_called_once()\n        self.assertEqual(filenames, ['file1.txt', 'file2.jpg', 'file3.pdf'])\n\n    @patch('ftplib.FTP')\n    def test_change_dir_failure(self, mock_ftp_class):\n        mock_ftp = MagicMock()\n        mock_ftp_class.return_value = mock_ftp\n        mock_ftp.cwd.side_effect = Exception('No such directory')\n\n        with self.assertRaises(Exception) as context:\n            task_func(ftp_server='dummy_server', ftp_user='user', ftp_password='pass', ftp_dir='/invalid_dir')\n\n        self.assertIn('Failed to change to directory', str(context.exception))\n\n    @patch('ftplib.FTP')\n    def test_login_failure(self, mock_ftp_class):\n        mock_ftp_class.side_effect = Exception('Connection failed')\n\n        with self.assertRaises(Exception) as context:\n            task_func(ftp_server='dummy_server', ftp_user='user', ftp_password='pass', ftp_dir='/dir')\n\n        self.assertIn('Connection failed', str(context.exception))\n",
        "code": "import ftplib\n\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    try:\n        ftp_obj = ftplib.FTP(ftp_server)\n        ftp_obj.login(ftp_user, ftp_password)\n        try:\n            ftp_obj.cwd(ftp_dir)\n        except Exception as e:\n            raise Exception(f\"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n        filenames = ftp_obj.nlst()\n        return filenames\n    except Exception as e:\n        raise\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/13_4",
        "turn": "4",
        "instruct_prompt": "Download all files from the FTP server directory using wget in a subprocess, saving them to a local directory named 'downloaded_files'. Create the directory if it does not exist. Return the list of filenames attempted to download.",
        "test": "import unittest\nimport os\nimport shutil\nimport subprocess\nfrom unittest import mock\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Remove downloaded_files directory if exists before each test\n        if os.path.exists('downloaded_files'):\n            shutil.rmtree('downloaded_files')\n\n    def tearDown(self):\n        # Clean up after test\n        if os.path.exists('downloaded_files'):\n            shutil.rmtree('downloaded_files')\n\n    @mock.patch('ftplib.FTP')\n    @mock.patch('subprocess.run')\n    def test_task_func_download_files(self, mock_subprocess_run, mock_ftp_class):\n        # Setup mock FTP instance\n        mock_ftp = mock.Mock()\n        mock_ftp_class.return_value = mock_ftp\n        mock_ftp.nlst.return_value = ['file1.txt', 'file2.txt']\n\n        # Call the function\n        result = task_func()\n\n        # Check returned filenames\n        self.assertEqual(result, ['file1.txt', 'file2.txt'])\n\n        # Check directory created\n        self.assertTrue(os.path.exists('downloaded_files'))\n\n        # Check subprocess.run called with correct wget commands\n        expected_calls = [\n            mock.call(['wget', '-P', 'downloaded_files',\n                       f'ftp://dlpuser:rNrKYTX9g7z3RgJRmxWuGHbeu@ftp.dlptest.com/ftp/test/file1.txt'], check=False),\n            mock.call(['wget', '-P', 'downloaded_files',\n                       f'ftp://dlpuser:rNrKYTX9g7z3RgJRmxWuGHbeu@ftp.dlptest.com/ftp/test/file2.txt'], check=False)\n        ]\n        mock_subprocess_run.assert_has_calls(expected_calls, any_order=False)\n\n    @mock.patch('ftplib.FTP')\n    def test_task_func_creates_directory_if_not_exists(self, mock_ftp_class):\n        mock_ftp = mock.Mock()\n        mock_ftp_class.return_value = mock_ftp\n        mock_ftp.nlst.return_value = []\n\n        # Ensure directory does not exist\n        if os.path.exists('downloaded_files'):\n            shutil.rmtree('downloaded_files')\n\n        task_func()\n\n        self.assertTrue(os.path.exists('downloaded_files'))\n\n    @mock.patch('ftplib.FTP')\n    def test_task_func_raises_on_invalid_dir(self, mock_ftp_class):\n        mock_ftp = mock.Mock()\n        mock_ftp_class.return_value = mock_ftp\n        mock_ftp.cwd.side_effect = Exception('No such directory')\n\n        with self.assertRaises(Exception) as context:\n            task_func(ftp_dir='/invalid/dir')\n        self.assertIn('Failed to change to directory', str(context.exception))\n",
        "code": "import os\nimport subprocess\nimport ftplib\n\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    # Connect to FTP and get list of files\n    try:\n        ftp_obj = ftplib.FTP(ftp_server)\n        ftp_obj.login(ftp_user, ftp_password)\n        try:\n            ftp_obj.cwd(ftp_dir)\n        except Exception as e:\n            raise Exception(f\"Failed to change to directory {ftp_dir} on server {ftp_server}: {str(e)}\")\n        filenames = ftp_obj.nlst()\n    except Exception as e:\n        raise\n\n    # Create local directory if not exists\n    local_dir = 'downloaded_files'\n    if not os.path.exists(local_dir):\n        os.makedirs(local_dir)\n\n    # Download each file using wget in a subprocess\n    for filename in filenames:\n        # Compose FTP URL\n        ftp_url = f\"ftp://{ftp_user}:{ftp_password}@{ftp_server}{ftp_dir}/{filename}\"\n        # Run wget to download file into local_dir\n        subprocess.run(['wget', '-P', local_dir, ftp_url], check=False)\n\n    return filenames\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 2,
    "task_id": "BigCodeBench/15",
    "mt_data": [
      {
        "task_id": "BigCodeBench/15_1",
        "turn": "1",
        "instruct_prompt": "Write a function task_func(commands_file_path, output_dir_path) that reads a list of shell commands from a CSV file located at commands_file_path and returns the list of these commands as strings. You should write self-contained code starting with:\n```\nimport csv\nimport os\ndef task_func(commands_file_path, output_dir_path):\n```",
        "test": "import unittest\nimport tempfile\nimport os\nimport csv\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_reads_commands(self):\n        with tempfile.TemporaryDirectory() as temp_dir:\n            csv_path = os.path.join(temp_dir, 'commands.csv')\n            commands_list = ['echo Hello', 'ls -l', 'pwd']\n            with open(csv_path, mode='w', newline='', encoding='utf-8') as f:\n                writer = csv.writer(f)\n                for cmd in commands_list:\n                    writer.writerow([cmd])\n            # output_dir_path is not used in current implementation\n            result = task_func(csv_path, temp_dir)\n            self.assertEqual(result, commands_list)\n\n    def test_task_func_empty_file(self):\n        with tempfile.TemporaryDirectory() as temp_dir:\n            csv_path = os.path.join(temp_dir, 'empty.csv')\n            with open(csv_path, mode='w', newline='', encoding='utf-8') as f:\n                pass  # create empty file\n            result = task_func(csv_path, temp_dir)\n            self.assertEqual(result, [])\n",
        "code": "import csv\nimport os\n\ndef task_func(commands_file_path, output_dir_path):\n    commands = []\n    with open(commands_file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            if row:\n                commands.append(row[0])\n    return commands\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/15_2",
        "turn": "2",
        "instruct_prompt": "Modify the function to raise a FileNotFoundError if the commands_file_path does not exist.",
        "test": "import unittest\nimport tempfile\nimport os\nimport csv\n\nclass TestCases(unittest.TestCase):\n    def test_file_not_found(self):\n        # We test that the FileNotFoundError is raised with the custom message\n        missing_file = 'non_existent_file.csv'\n        with self.assertRaises(FileNotFoundError) as context:\n            task_func(missing_file, 'some_output_dir')\n        self.assertIn(f\"The file {missing_file} does not exist.\", str(context.exception))\n\n    def test_existing_file(self):\n        with tempfile.NamedTemporaryFile(mode='w+', newline='', delete=False, encoding='utf-8') as tmpfile:\n            writer = csv.writer(tmpfile)\n            writer.writerow(['command1'])\n            writer.writerow(['command2'])\n            tmpfile_path = tmpfile.name\n        try:\n            result = task_func(tmpfile_path, 'some_output_dir')\n            self.assertEqual(result, ['command1', 'command2'])\n        finally:\n            os.remove(tmpfile_path)\n",
        "code": "import csv\nimport os\n\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(f\"The file {commands_file_path} does not exist.\")\n    commands = []\n    with open(commands_file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            if row:\n                commands.append(row[0])\n    return commands\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/15_3",
        "turn": "3",
        "instruct_prompt": "Add code to ensure the output directory output_dir_path exists, creating it if necessary.",
        "test": "import unittest\nimport tempfile\nimport os\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def test_output_dir_creation(self):\n        with tempfile.TemporaryDirectory() as temp_dir:\n            # Create a commands file\n            commands_file = os.path.join(temp_dir, 'commands.csv')\n            with open(commands_file, 'w', encoding='utf-8') as f:\n                f.write('cmd1\\ncmd2\\n')\n\n            # Define an output directory that does not exist\n            output_dir = os.path.join(temp_dir, 'output_subdir')\n            self.assertFalse(os.path.exists(output_dir))\n\n            # Call the function\n            commands = task_func(commands_file, output_dir)\n\n            # Check that output directory is created\n            self.assertTrue(os.path.exists(output_dir))\n            # Check commands are read correctly\n            self.assertEqual(commands, ['cmd1', 'cmd2'])\n\n    def test_file_not_found(self):\n        with tempfile.TemporaryDirectory() as temp_dir:\n            commands_file = os.path.join(temp_dir, 'nonexistent.csv')\n            output_dir = os.path.join(temp_dir, 'output')\n            with self.assertRaises(FileNotFoundError):\n                task_func(commands_file, output_dir)\n",
        "code": "import csv\nimport os\n\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(f\"The file {commands_file_path} does not exist.\")\n    if not os.path.exists(output_dir_path):\n        os.makedirs(output_dir_path)\n    commands = []\n    with open(commands_file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            if row:\n                commands.append(row[0])\n    return commands\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/15_4",
        "turn": "4",
        "instruct_prompt": "For each command read from the CSV file, execute it as a shell command and write its standard output and standard error to a separate file named 'command_X_output.txt' in output_dir_path, where X is the command index starting from 1.",
        "test": "import unittest\nimport tempfile\nimport os\nimport csv\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory for output files\n        self.temp_dir = tempfile.TemporaryDirectory()\n        # Create a temporary CSV file for commands\n        self.temp_csv = tempfile.NamedTemporaryFile(mode='w+', newline='', delete=False, encoding='utf-8')\n\n    def tearDown(self):\n        self.temp_csv.close()\n        os.unlink(self.temp_csv.name)\n        self.temp_dir.cleanup()\n\n    def test_execute_commands_and_output_files(self):\n        # Write some shell commands to the CSV file\n        commands = [\n            'echo Hello, World!',\n            'python --version',\n            '>&2 echo error message'\n        ]\n        writer = csv.writer(self.temp_csv)\n        for cmd in commands:\n            writer.writerow([cmd])\n        self.temp_csv.flush()\n\n        # Directly call task_func without import\n        task_func(self.temp_csv.name, self.temp_dir.name)\n\n        # Check if output files are created and contain expected output\n        for i, cmd in enumerate(commands, start=1):\n            output_file = os.path.join(self.temp_dir.name, f'command_{i}_output.txt')\n            self.assertTrue(os.path.exists(output_file))\n            with open(output_file, 'r', encoding='utf-8') as f:\n                content = f.read()\n                if i == 1:\n                    self.assertIn('Hello, World!', content)\n                elif i == 2:\n                    self.assertIn('Python', content)\n                elif i == 3:\n                    self.assertIn('error message', content)\n\n    def test_nonexistent_commands_file(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('nonexistent_file.csv', self.temp_dir.name)\n\n    def test_create_output_dir_if_not_exists(self):\n        # Write one simple command\n        writer = csv.writer(self.temp_csv)\n        writer.writerow(['echo test'])\n        self.temp_csv.flush()\n\n        new_output_dir = os.path.join(self.temp_dir.name, 'new_output')\n        self.assertFalse(os.path.exists(new_output_dir))\n\n        task_func(self.temp_csv.name, new_output_dir)\n\n        self.assertTrue(os.path.exists(new_output_dir))\n        output_file = os.path.join(new_output_dir, 'command_1_output.txt')\n        self.assertTrue(os.path.exists(output_file))\n        with open(output_file, 'r', encoding='utf-8') as f:\n            content = f.read()\n            self.assertIn('test', content)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import csv\nimport os\nimport subprocess\n\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(f\"The file {commands_file_path} does not exist.\")\n    if not os.path.exists(output_dir_path):\n        os.makedirs(output_dir_path)\n\n    commands = []\n    with open(commands_file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            if row:\n                commands.append(row[0])\n\n    for index, command in enumerate(commands, start=1):\n        output_file_path = os.path.join(output_dir_path, f'command_{index}_output.txt')\n        with open(output_file_path, 'w', encoding='utf-8') as outfile:\n            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n            stdout, stderr = process.communicate()\n            if stdout:\n                outfile.write(stdout)\n            if stderr:\n                outfile.write(stderr)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/15_5",
        "turn": "5",
        "instruct_prompt": "If a command execution fails (non-zero exit code), append a descriptive error message including the exit code to the respective output file. The function should return a list of all output file paths created.",
        "test": "import os\nimport tempfile\nimport unittest\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create temporary directory for commands file and output\n        self.temp_dir = tempfile.TemporaryDirectory()\n        self.commands_file = os.path.join(self.temp_dir.name, 'commands.csv')\n        self.output_dir = os.path.join(self.temp_dir.name, 'output')\n\n    def tearDown(self):\n        self.temp_dir.cleanup()\n\n    def test_command_execution_with_success_and_failure(self):\n        # Prepare commands: one valid, one invalid\n        # The valid command prints 'hello'\n        # The invalid command is 'exit 1' which should fail with exit code 1\n        commands = ['echo hello', 'exit 1']\n\n        with open(self.commands_file, 'w', encoding='utf-8') as f:\n            for cmd in commands:\n                f.write(cmd + '\\n')\n\n        output_files = task_func(self.commands_file, self.output_dir)\n\n        # There should be two output files\n        self.assertEqual(len(output_files), 2)\n\n        # Check first output file contains 'hello' and no error message\n        with open(output_files[0], 'r', encoding='utf-8') as f:\n            content1 = f.read()\n        self.assertIn('hello', content1)\n        self.assertNotIn('Error:', content1)\n\n        # Check second output file contains error message with exit code 1\n        with open(output_files[1], 'r', encoding='utf-8') as f:\n            content2 = f.read()\n        self.assertIn('Error: Command exited with non-zero exit code 1.', content2)\n\n    def test_empty_commands_file(self):\n        # Create empty commands file\n        with open(self.commands_file, 'w', encoding='utf-8') as f:\n            pass\n\n        output_files = task_func(self.commands_file, self.output_dir)\n        # No commands, so no output files\n        self.assertEqual(output_files, [])\n\n    def test_nonexistent_commands_file(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('nonexistent.csv', self.output_dir)\n",
        "code": "import csv\nimport os\nimport subprocess\n\ndef task_func(commands_file_path, output_dir_path):\n    if not os.path.exists(commands_file_path):\n        raise FileNotFoundError(f\"The file {commands_file_path} does not exist.\")\n    if not os.path.exists(output_dir_path):\n        os.makedirs(output_dir_path)\n\n    commands = []\n    with open(commands_file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            if row:\n                commands.append(row[0])\n\n    output_files = []\n    for index, command in enumerate(commands, start=1):\n        output_file_path = os.path.join(output_dir_path, f'command_{index}_output.txt')\n        output_files.append(output_file_path)\n        with open(output_file_path, 'w', encoding='utf-8') as outfile:\n            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n            stdout, stderr = process.communicate()\n            if stdout:\n                outfile.write(stdout)\n            if stderr:\n                outfile.write(stderr)\n            if process.returncode != 0:\n                outfile.write(f\"\\nError: Command exited with non-zero exit code {process.returncode}.\\n\")\n\n    return output_files\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 3,
    "task_id": "BigCodeBench/17",
    "mt_data": [
      {
        "task_id": "BigCodeBench/17_1",
        "turn": "1",
        "instruct_prompt": "Check if a process with a given name is running. You should write self-contained code starting with:\n```python\nimport psutil\ndef task_func(process_name: str) -> str:\n```",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport psutil\n\nclass TestCases(unittest.TestCase):\n    @patch('psutil.process_iter')\n    def test_process_running(self, mock_process_iter):\n        mock_proc = MagicMock()\n        mock_proc.info = {'name': 'testproc'}\n        mock_process_iter.return_value = [mock_proc]\n\n        result = task_func('testproc')\n        self.assertEqual(result, 'Running')\n\n    @patch('psutil.process_iter')\n    def test_process_not_running(self, mock_process_iter):\n        mock_proc = MagicMock()\n        mock_proc.info = {'name': 'otherproc'}\n        mock_process_iter.return_value = [mock_proc]\n\n        result = task_func('testproc')\n        self.assertEqual(result, 'Not Running')\n\n    @patch('psutil.process_iter')\n    def test_no_processes(self, mock_process_iter):\n        mock_process_iter.return_value = []\n\n        result = task_func('testproc')\n        self.assertEqual(result, 'Not Running')\n\n    @patch('psutil.process_iter')\n    def test_process_info_access_raises(self, mock_process_iter):\n        # Simulate one process where accessing info raises AccessDenied, and another normal process\n        mock_proc1 = MagicMock()\n        type(mock_proc1).info = property(lambda self: (_ for _ in ()).throw(psutil.AccessDenied()))\n\n        mock_proc2 = MagicMock()\n        mock_proc2.info = {'name': 'testproc'}\n\n        mock_process_iter.return_value = [mock_proc1, mock_proc2]\n\n        result = task_func('testproc')\n        self.assertEqual(result, 'Running')\n\n    @patch('psutil.process_iter')\n    def test_process_iter_raises(self, mock_process_iter):\n        # Simulate process_iter raising AccessDenied exception\n        mock_process_iter.side_effect = psutil.AccessDenied()\n\n        result = task_func('testproc')\n        self.assertEqual(result, 'Not Running')\n",
        "code": "import psutil\n\ndef task_func(process_name: str) -> str:\n    \"\"\"Check if a process with the given name is running.\n\n    Args:\n        process_name (str): The name of the process to check.\n\n    Returns:\n        str: 'Running' if any process with the given name is found, otherwise 'Not Running'.\n    \"\"\"\n    try:\n        for proc in psutil.process_iter(['name']):\n            try:\n                if proc.info['name'] == process_name:\n                    return 'Running'\n            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n                continue\n    except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n        # If iteration itself fails, just treat as not found\n        pass\n    return 'Not Running'\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/17_2",
        "turn": "2",
        "instruct_prompt": "If the process is not running, start it using subprocess.Popen with the process name as the command, and return the message \"Process not found. Starting <process_name>.\"",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('psutil.process_iter')\n    def test_process_running(self, mock_process_iter):\n        # Mock process_iter to have a running process with the given name\n        mock_proc = MagicMock()\n        mock_proc.info = {'name': 'testproc'}\n        mock_process_iter.return_value = [mock_proc]\n\n        result = task_func('testproc')\n        self.assertEqual(result, 'Running')\n\n    @patch('psutil.process_iter')\n    @patch('subprocess.Popen')\n    def test_process_not_running_starts_process(self, mock_popen, mock_process_iter):\n        # Mock process_iter to return no processes\n        mock_process_iter.return_value = []\n\n        result = task_func('testproc')\n\n        # Check that Popen was called with the process name\n        mock_popen.assert_called_once_with(['testproc'])\n        self.assertEqual(result, 'Process not found. Starting testproc.')\n",
        "code": "import psutil\nimport subprocess\n\ndef task_func(process_name: str) -> str:\n    \"\"\"Check if a process with the given name is running.\n\n    If not running, start the process using subprocess.Popen with the process name as command.\n\n    Args:\n        process_name (str): The name of the process to check and start if not running.\n\n    Returns:\n        str: 'Running' if any process with the given name is found,\n             otherwise 'Process not found. Starting <process_name>'.\n    \"\"\"\n    try:\n        for proc in psutil.process_iter(['name']):\n            try:\n                if proc.info['name'] == process_name:\n                    return 'Running'\n            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n                continue\n    except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n        pass\n\n    # If not found, start the process\n    subprocess.Popen([process_name])\n    return f'Process not found. Starting {process_name}.'\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/17_3",
        "turn": "3",
        "instruct_prompt": "If the process is running, terminate all its instances, wait 5 seconds, then restart it using subprocess.Popen with the process name as the command, and return the message \"Process found. Restarting <process_name>.\"",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Patch subprocess.Popen to avoid actually starting processes\n        self.popen_patcher = patch('subprocess.Popen')\n        self.mock_popen = self.popen_patcher.start()\n\n        # Patch time.sleep to speed up tests\n        self.sleep_patcher = patch('time.sleep', return_value=None)\n        self.mock_sleep = self.sleep_patcher.start()\n\n    def tearDown(self):\n        self.popen_patcher.stop()\n        self.sleep_patcher.stop()\n\n    def test_process_found_and_restarted(self):\n        mock_proc = MagicMock()\n        mock_proc.info = {'name': 'testproc'}\n        mock_proc.terminate = MagicMock()\n\n        with patch('psutil.process_iter', return_value=[mock_proc]):\n            with patch('psutil.wait_procs') as mock_wait_procs:\n                result = task_func('testproc')\n\n                mock_proc.terminate.assert_called_once()\n                mock_wait_procs.assert_called_once_with([mock_proc], timeout=5)\n                self.mock_sleep.assert_called_once_with(5)\n                self.mock_popen.assert_called_once_with(['testproc'])\n                self.assertEqual(result, 'Process found. Restarting testproc.')\n\n    def test_process_not_found(self):\n        with patch('psutil.process_iter', return_value=[]):\n            result = task_func('nonexistentproc')\n            self.mock_popen.assert_not_called()\n            self.assertIsNone(result)\n",
        "code": "import psutil\nimport subprocess\nimport time\n\ndef task_func(process_name: str) -> str:\n    \"\"\"If the process is running, terminate all its instances, wait 5 seconds, then restart it.\n\n    Args:\n        process_name (str): The name of the process to check, terminate, and restart.\n\n    Returns:\n        str: 'Process found. Restarting <process_name>.' if process was found and restarted.\n    \"\"\"\n    procs_to_kill = []\n    try:\n        for proc in psutil.process_iter(['name']):\n            try:\n                if proc.info['name'] == process_name:\n                    procs_to_kill.append(proc)\n            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n                continue\n    except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n        pass\n\n    if procs_to_kill:\n        for proc in procs_to_kill:\n            try:\n                proc.terminate()\n            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n                continue\n        psutil.wait_procs(procs_to_kill, timeout=5)\n        time.sleep(5)\n        subprocess.Popen([process_name])\n        return f\"Process found. Restarting {process_name}.\"\n    # If no process found, do nothing and return None\n    return None\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 4,
    "task_id": "BigCodeBench/19",
    "mt_data": [
      {
        "task_id": "BigCodeBench/19_1",
        "turn": "1",
        "instruct_prompt": "Write a function that lists all files (not directories) in the specified directory and returns this list. You should write self-contained code starting with:\n```python\nimport os\nimport glob\ndef task_func(directory):\n```",
        "test": "import unittest\nimport os\nimport tempfile\n\nclass TestCases(unittest.TestCase):\n    def test_only_files(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            # Create some files\n            filenames = ['file1.txt', 'file2.txt', 'file3.log']\n            for fname in filenames:\n                with open(os.path.join(tmpdir, fname), 'w') as f:\n                    f.write('test')\n            # Create a directory\n            os.mkdir(os.path.join(tmpdir, 'subdir'))\n            # Call the function\n            result = task_func(tmpdir)\n            # Check that only files are listed\n            self.assertCountEqual(result, filenames)\n\n    def test_empty_directory(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            result = task_func(tmpdir)\n            self.assertEqual(result, [])\n\n    def test_directory_with_only_subdirs(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            os.mkdir(os.path.join(tmpdir, 'subdir1'))\n            os.mkdir(os.path.join(tmpdir, 'subdir2'))\n            result = task_func(tmpdir)\n            self.assertEqual(result, [])\n",
        "code": "import os\nimport glob\ndef task_func(directory):\n    # List all files (not directories) in the given directory\n    files = []\n    for entry in os.listdir(directory):\n        full_path = os.path.join(directory, entry)\n        if os.path.isfile(full_path):\n            files.append(entry)\n    return files\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/19_2",
        "turn": "2",
        "instruct_prompt": "Modify the function to raise a FileNotFoundError if the specified directory does not exist.",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_existing_directory_with_files(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            filenames = ['file1.txt', 'file2.txt']\n            for fname in filenames:\n                with open(os.path.join(tmpdir, fname), 'w') as f:\n                    f.write('test')\n            os.mkdir(os.path.join(tmpdir, 'subdir'))\n            result = task_func(tmpdir)\n            self.assertCountEqual(result, filenames)\n\n    def test_non_existing_directory_raises(self):\n        non_existing_dir = '/path/to/non/existing/directory'\n        with self.assertRaises(FileNotFoundError):\n            task_func(non_existing_dir)\n\n    def test_path_is_a_file_not_directory(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            file_path = os.path.join(tmpdir, 'afile')\n            with open(file_path, 'w') as f:\n                f.write('content')\n            # Pass the file path instead of directory path\n            with self.assertRaises(FileNotFoundError):\n                task_func(file_path)\n\n    def test_existing_directory_empty(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            result = task_func(tmpdir)\n            self.assertEqual(result, [])\n",
        "code": "import os\n\ndef task_func(directory):\n    if not os.path.exists(directory) or not os.path.isdir(directory):\n        raise FileNotFoundError(f\"Directory '{directory}' does not exist.\")\n    files = []\n    for entry in os.listdir(directory):\n        full_path = os.path.join(directory, entry)\n        if os.path.isfile(full_path):\n            files.append(entry)\n    return files\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/19_3",
        "turn": "3",
        "instruct_prompt": "Add functionality to create a zip file named 'files.zip' inside the specified directory containing all the files found (not including subdirectories). The function should return the path to this zip file.",
        "test": "import unittest\nimport tempfile\nimport os\nimport zipfile\n\nclass TestCases(unittest.TestCase):\n    def test_create_zip_with_files(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            # Create some files\n            file_names = ['a.txt', 'b.txt', 'c.log']\n            for name in file_names:\n                with open(os.path.join(tmpdir, name), 'w') as f:\n                    f.write('content ' + name)\n\n            # Create a subdirectory with a file to check it is excluded\n            os.mkdir(os.path.join(tmpdir, 'subdir'))\n            with open(os.path.join(tmpdir, 'subdir', 'd.txt'), 'w') as f:\n                f.write('should not be included')\n\n            zip_path = task_func(tmpdir)\n            self.assertTrue(os.path.isfile(zip_path))\n            self.assertEqual(os.path.basename(zip_path), 'files.zip')\n\n            with zipfile.ZipFile(zip_path, 'r') as zipf:\n                zipped_files = zipf.namelist()\n                self.assertCountEqual(zipped_files, file_names)\n\n                # Check content\n                for file_name in file_names:\n                    with zipf.open(file_name) as f:\n                        content = f.read().decode('utf-8')\n                        self.assertEqual(content, 'content ' + file_name)\n\n    def test_non_existent_directory(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('/non/existent/directory')\n",
        "code": "import os\nimport zipfile\n\ndef task_func(directory):\n    if not os.path.exists(directory) or not os.path.isdir(directory):\n        raise FileNotFoundError(f\"Directory '{directory}' does not exist.\")\n    files = []\n    for entry in os.listdir(directory):\n        full_path = os.path.join(directory, entry)\n        if os.path.isfile(full_path):\n            files.append(entry)\n    \n    zip_path = os.path.join(directory, 'files.zip')\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file_name in files:\n            file_path = os.path.join(directory, file_name)\n            zipf.write(file_path, arcname=file_name)\n    \n    return zip_path\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/19_4",
        "turn": "4",
        "instruct_prompt": "Update the function to return None if the directory does not contain any files.",
        "test": "import unittest\nimport tempfile\nimport os\nimport zipfile\n\nclass TestCases(unittest.TestCase):\n    def test_directory_with_files(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            # Create some files\n            file1 = os.path.join(tmpdir, 'file1.txt')\n            file2 = os.path.join(tmpdir, 'file2.txt')\n            with open(file1, 'w') as f:\n                f.write('Hello')\n            with open(file2, 'w') as f:\n                f.write('World')\n\n            zip_path = task_func(tmpdir)\n            self.assertIsNotNone(zip_path)\n            self.assertTrue(os.path.isfile(zip_path))\n\n            # Check contents of the zip\n            with zipfile.ZipFile(zip_path, 'r') as zipf:\n                self.assertIn('file1.txt', zipf.namelist())\n                self.assertIn('file2.txt', zipf.namelist())\n\n    def test_directory_with_no_files(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            # Create a subdirectory but no files\n            os.mkdir(os.path.join(tmpdir, 'subdir'))\n            result = task_func(tmpdir)\n            self.assertIsNone(result)\n\n    def test_directory_does_not_exist(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('/path/to/nonexistent/directory')\n",
        "code": "import os\nimport zipfile\n\ndef task_func(directory):\n    if not os.path.exists(directory) or not os.path.isdir(directory):\n        raise FileNotFoundError(f\"Directory '{directory}' does not exist.\")\n    files = []\n    for entry in os.listdir(directory):\n        full_path = os.path.join(directory, entry)\n        if os.path.isfile(full_path):\n            files.append(entry)\n    \n    if not files:\n        return None\n\n    zip_path = os.path.join(directory, 'files.zip')\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file_name in files:\n            file_path = os.path.join(directory, file_name)\n            zipf.write(file_path, arcname=file_name)\n    \n    return zip_path\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 5,
    "task_id": "BigCodeBench/34",
    "mt_data": [
      {
        "task_id": "BigCodeBench/34_1",
        "turn": "1",
        "instruct_prompt": "Create a function that takes a text input and returns a WordCloud object generated from the text.\nYou should write self-contained code starting with:\n```\nimport re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ndef task_func(text):\n```",
        "test": "import unittest\nfrom wordcloud import WordCloud\n\nclass TestCases(unittest.TestCase):\n    def test_wordcloud_type(self):\n        text = \"hello world hello\"\n        wc = task_func(text)\n        self.assertIsInstance(wc, WordCloud)\n\n    def test_wordcloud_contains_words(self):\n        text = \"apple apple banana\"\n        wc = task_func(text)\n        words = list(wc.words_.keys())\n        self.assertIn('apple', words)\n        self.assertIn('banana', words)\n\n    def test_wordcloud_empty_text(self):\n        text = \"\"\n        wc = task_func(text)\n        self.assertIsInstance(wc, WordCloud)\n        # Since we use 'empty' as dummy word, it should appear in words_\n        self.assertIn('empty', wc.words_)\n\n    def test_wordcloud_whitespace_text(self):\n        text = \"   \\t\\n  \"\n        wc = task_func(text)\n        self.assertIsInstance(wc, WordCloud)\n        self.assertIn('empty', wc.words_)\n",
        "code": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # If text is empty or only whitespace, use a dummy word to avoid ValueError\n    if not text or not text.strip():\n        text = 'empty'\n    wordcloud = WordCloud().generate(text)\n    return wordcloud\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/34_2",
        "turn": "2",
        "instruct_prompt": "Remove all URLs from the input text before generating the word cloud.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_url_removal(self):\n        input_text = 'Check this link http://example.com and also https://www.test.com/page'\n        wordcloud = task_func(input_text)\n        # URLs should not appear as words\n        self.assertNotIn('http://example.com', wordcloud.words_)\n        self.assertNotIn('https://www.test.com/page', wordcloud.words_)\n        # Words from non-url parts should appear (using non-stopwords)\n        self.assertIn('Check', wordcloud.words_)\n        self.assertIn('link', wordcloud.words_)\n\n    def test_text_with_only_url(self):\n        input_text = 'http://onlyurl.com'\n        wordcloud = task_func(input_text)\n        # Since all text is removed, the wordcloud should contain the dummy word 'empty'\n        self.assertIn('empty', wordcloud.words_)\n\n    def test_text_without_url(self):\n        input_text = 'Hello world this is a test'\n        wordcloud = task_func(input_text)\n        # Words should be present as usual (non-stopwords)\n        self.assertIn('Hello', wordcloud.words_)\n        self.assertIn('world', wordcloud.words_)\n\n    def test_empty_string(self):\n        input_text = ''\n        wordcloud = task_func(input_text)\n        self.assertIn('empty', wordcloud.words_)\n\n    def test_text_with_url_and_words(self):\n        input_text = 'Visit https://example.com for more info'\n        wordcloud = task_func(input_text)\n        # URL should be removed\n        self.assertNotIn('https://example.com', wordcloud.words_)\n        # Non-stopword words should appear\n        self.assertIn('Visit', wordcloud.words_)\n        self.assertIn('info', wordcloud.words_)\n",
        "code": "import re\nfrom wordcloud import WordCloud\n\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n    # If text is empty or only whitespace after URL removal, use a dummy word to avoid ValueError\n    if not text or not text.strip():\n        text = 'empty'\n    wordcloud = WordCloud().generate(text)\n    return wordcloud\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/34_3",
        "turn": "3",
        "instruct_prompt": "If there are no words left in the text after removing URLs (i.e., the text is empty or contains only whitespace), raise a ValueError with the message: \"No words available to generate a word cloud after removing URLs.\"",
        "test": "import unittest\nfrom wordcloud import WordCloud\n\nclass TestCases(unittest.TestCase):\n    def test_normal_text_with_urls(self):\n        text = \"This is a test https://example.com with some words.\"\n        wc = task_func(text)\n        self.assertIsInstance(wc, WordCloud)\n\n    def test_text_without_urls(self):\n        text = \"Just some plain text without urls.\"\n        wc = task_func(text)\n        self.assertIsInstance(wc, WordCloud)\n\n    def test_text_with_only_url(self):\n        text = \"http://onlyurl.com\"\n        with self.assertRaises(ValueError) as cm:\n            task_func(text)\n        self.assertEqual(str(cm.exception), \"No words available to generate a word cloud after removing URLs.\")\n\n    def test_text_with_url_and_spaces_only(self):\n        text = \"   http://example.com    \"\n        with self.assertRaises(ValueError) as cm:\n            task_func(text)\n        self.assertEqual(str(cm.exception), \"No words available to generate a word cloud after removing URLs.\")\n\n    def test_empty_string(self):\n        text = \"\"\n        with self.assertRaises(ValueError) as cm:\n            task_func(text)\n        self.assertEqual(str(cm.exception), \"No words available to generate a word cloud after removing URLs.\")\n\n    def test_whitespace_string(self):\n        text = \"    \\t  \\n\"\n        with self.assertRaises(ValueError) as cm:\n            task_func(text)\n        self.assertEqual(str(cm.exception), \"No words available to generate a word cloud after removing URLs.\")\n",
        "code": "import re\nfrom wordcloud import WordCloud\n\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n    # If text is empty or only whitespace after URL removal, raise ValueError\n    if not text or not text.strip():\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n    wordcloud = WordCloud().generate(text)\n    return wordcloud\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/34_4",
        "turn": "4",
        "instruct_prompt": "Plot the generated word cloud using matplotlib without showing the axis.",
        "test": "import unittest\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    def test_wordcloud_generation_and_plot(self):\n        text = \"Hello world! Visit https://example.com for more info.\"\n        with patch('matplotlib.pyplot.show') as mock_show:\n            wc = task_func(text)\n            self.assertIsInstance(wc, WordCloud)\n            mock_show.assert_called_once()\n\n    def test_wordcloud_raises_value_error_for_empty_text_after_url_removal(self):\n        text = \"https://example.com\"\n        with self.assertRaises(ValueError):\n            task_func(text)\n\n    def test_wordcloud_calls_axis_off(self):\n        text = \"Sample text for word cloud\"\n        with patch('matplotlib.pyplot.axis') as mock_axis, patch('matplotlib.pyplot.show') as mock_show:\n            wc = task_func(text)\n            mock_axis.assert_called_once_with('off')\n            mock_show.assert_called_once()\n",
        "code": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Remove URLs from the text\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n    # If text is empty or only whitespace after URL removal, raise ValueError\n    if not text or not text.strip():\n        raise ValueError(\"No words available to generate a word cloud after removing URLs.\")\n    wordcloud = WordCloud().generate(text)\n    \n    # Plot the word cloud without axis\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n    \n    return wordcloud\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 6,
    "task_id": "BigCodeBench/37",
    "mt_data": [
      {
        "task_id": "BigCodeBench/37_1",
        "turn": "1",
        "instruct_prompt": "Train a random forest classifier on a dataframe to predict the target column. You should write self-contained code starting with:\n```\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\n\ndef task_func(df, target_column):\n```",
        "test": "import unittest\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\n\nclass TestCases(unittest.TestCase):\n    def test_basic_fit(self):\n        data = {\n            'feature1': [1, 2, 3, 4, 5],\n            'feature2': [5, 4, 3, 2, 1],\n            'target': [0, 1, 0, 1, 0]\n        }\n        df = pd.DataFrame(data)\n        clf = task_func(df, 'target')\n        self.assertIsInstance(clf, RandomForestClassifier)\n        # Check that the classifier has been fitted by checking if feature_importances_ attribute exists\n        self.assertTrue(hasattr(clf, 'feature_importances_'))\n\n    def test_predict(self):\n        data = {\n            'f1': [0, 1, 0, 1],\n            'f2': [1, 0, 1, 0],\n            'target': [0, 1, 0, 1]\n        }\n        df = pd.DataFrame(data)\n        clf = task_func(df, 'target')\n        X_test = df.drop(columns=['target'])\n        preds = clf.predict(X_test)\n        self.assertEqual(len(preds), len(df))\n        self.assertTrue(all(p in [0, 1] for p in preds))",
        "code": "from sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\n\ndef task_func(df, target_column):\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n    clf = RandomForestClassifier()\n    clf.fit(X, y)\n    return clf",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/37_2",
        "turn": "2",
        "instruct_prompt": "Plot a bar plot of the feature importances of the trained random forest classifier using seaborn and matplotlib.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_feature_importance_plot(self):\n        data = {\n            'feat1': [1, 2, 3, 4, 5],\n            'feat2': [5, 4, 3, 2, 1],\n            'feat3': [2, 3, 2, 3, 2],\n            'target': [0, 1, 0, 1, 0]\n        }\n        df = pd.DataFrame(data)\n\n        # Override plt.show to avoid GUI during test\n        original_show = plt.show\n        plt.show = lambda: None\n\n        # Count figures before\n        figs_before = len(plt.get_fignums())\n\n        # Call the function\n        clf = task_func(df, 'target')\n\n        # Count figures after\n        figs_after = len(plt.get_fignums())\n\n        # Restore plt.show\n        plt.show = original_show\n\n        # Check classifier is fitted\n        self.assertTrue(hasattr(clf, 'feature_importances_'))\n        self.assertEqual(len(clf.feature_importances_), 3)\n\n        # Check that a new figure was created (plot generated)\n        self.assertGreater(figs_after, figs_before)\n\n    def test_previous_round_code_fails_to_plot(self):\n        # Redefine previous round code locally\n        from sklearn.ensemble import RandomForestClassifier\n        import pandas as pd\n\n        def prev_task_func(df, target_column):\n            X = df.drop(columns=[target_column])\n            y = df[target_column]\n            clf = RandomForestClassifier()\n            clf.fit(X, y)\n            return clf\n\n        data = {\n            'feat1': [1, 2, 3, 4, 5],\n            'feat2': [5, 4, 3, 2, 1],\n            'target': [0, 1, 0, 1, 0]\n        }\n        df = pd.DataFrame(data)\n\n        figs_before = len(plt.get_fignums())\n        clf = prev_task_func(df, 'target')\n        figs_after = len(plt.get_fignums())\n\n        self.assertTrue(hasattr(clf, 'feature_importances_'))\n        # The previous round code should NOT create a new figure (no plot)\n        self.assertEqual(figs_before, figs_after)\n",
        "code": "from sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_column):\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n    clf = RandomForestClassifier()\n    clf.fit(X, y)\n    \n    importances = clf.feature_importances_\n    feature_names = X.columns\n    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n    \n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=importance_df.sort_values(by='Importance', ascending=False))\n    plt.title('Feature Importances')\n    plt.tight_layout()\n    plt.show()\n    \n    return clf",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/37_3",
        "turn": "3",
        "instruct_prompt": "The bar plot's x-axis should represent the feature importance scores, the y-axis should represent the feature names, and the title should be 'Visualizing Important Features'.",
        "test": "import unittest\nimport pandas as pd\nfrom io import StringIO\nimport matplotlib.pyplot as plt\nfrom matplotlib.testing.decorators import check_figures_equal\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_plot_labels_and_title(self):\n        # Prepare sample data\n        data = '''\n        A,B,C,Target\n        1,2,3,0\n        4,5,6,1\n        7,8,9,0\n        2,3,4,1\n        '''\n        df = pd.read_csv(StringIO(data))\n\n        # Patch plt.show to prevent actual rendering during test\n        import matplotlib.pyplot as plt\n        original_show = plt.show\n        plt.show = lambda: None\n\n        clf = None\n        try:\n            clf = task_func(df, 'Target')\n        finally:\n            plt.show = original_show\n\n        # Check clf is fitted\n        self.assertIsNotNone(clf)\n        self.assertTrue(hasattr(clf, 'feature_importances_'))\n\n        # Check the plot elements\n        fig = plt.gcf()\n        ax = plt.gca()\n\n        # Title check\n        self.assertEqual(ax.get_title(), 'Visualizing Important Features')\n\n        # Axis labels check\n        self.assertEqual(ax.get_xlabel(), 'Importance')\n        self.assertEqual(ax.get_ylabel(), 'Feature')",
        "code": "from sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_column):\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n    clf = RandomForestClassifier()\n    clf.fit(X, y)\n    \n    importances = clf.feature_importances_\n    feature_names = X.columns\n    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n    \n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=importance_df.sort_values(by='Importance', ascending=False))\n    plt.title('Visualizing Important Features')\n    plt.tight_layout()\n    plt.show()\n    \n    return clf",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/37_4",
        "turn": "4",
        "instruct_prompt": "Sort the features by their importance scores in descending order before plotting.",
        "test": "import unittest\nimport pandas as pd\nfrom sklearn.datasets import load_iris\n\nclass TestCases(unittest.TestCase):\n    def test_features_sorted_by_importance(self):\n        # Load iris dataset for testing\n        iris = load_iris()\n        df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n        df['target'] = iris.target\n        \n        clf, importance_df = task_func(df, 'target')\n        # Check that importance_df is sorted descendingly by 'Importance'\n        imp_values = importance_df['Importance'].values\n        self.assertTrue(all(imp_values[i] >= imp_values[i+1] for i in range(len(imp_values)-1)),\n                        \"Features are not sorted by importance descendingly\")\n        \n        # Check clf has feature_importances_\n        self.assertTrue(hasattr(clf, 'feature_importances_'))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.pyplot as plt\n\ndef task_func(df, target_column):\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n    clf = RandomForestClassifier()\n    clf.fit(X, y)\n    \n    importances = clf.feature_importances_\n    feature_names = X.columns\n    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n    # Sort features by importance descendingly before plotting\n    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n    \n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=importance_df)\n    plt.title('Visualizing Important Features')\n    plt.tight_layout()\n    plt.show()\n    \n    # Return both classifier and sorted importance_df for testing\n    return clf, importance_df",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 7,
    "task_id": "BigCodeBench/82",
    "mt_data": [
      {
        "task_id": "BigCodeBench/82_1",
        "turn": "1",
        "instruct_prompt": "Create a basic Flask application instance with dynamic configuration for secret key and template folder. You should write self-contained code starting with:```python\nfrom flask import Flask\n\ndef task_func(secret_key, template_folder):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_flask_app_creation(self):\n        secret_key = 'mysecret'\n        template_folder = 'mytemplates'\n        app = task_func(secret_key, template_folder)\n        self.assertEqual(app.config['SECRET_KEY'], secret_key)\n        self.assertEqual(app.template_folder, template_folder)\n        from flask import Flask\n        self.assertIsInstance(app, Flask)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "from flask import Flask\n\ndef task_func(secret_key, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    app.config['SECRET_KEY'] = secret_key\n    return app\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/82_2",
        "turn": "2",
        "instruct_prompt": "Add user authentication setup using Flask-Login to the Flask app, including initializing the LoginManager with the app.",
        "test": "import unittest\nfrom flask_login import LoginManager\n\nclass TestCases(unittest.TestCase):\n    def test_login_manager_initialized(self):\n        secret_key = 'testsecret'\n        template_folder = 'templates'\n        app = task_func(secret_key, template_folder)\n        self.assertIn('SECRET_KEY', app.config)\n        self.assertEqual(app.config['SECRET_KEY'], secret_key)\n        self.assertTrue(hasattr(app, 'login_manager'))\n        self.assertIsInstance(app.login_manager, LoginManager)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from flask import Flask\nfrom flask_login import LoginManager\n\ndef task_func(secret_key, template_folder):\n    app = Flask(__name__, template_folder=template_folder)\n    app.config['SECRET_KEY'] = secret_key\n    login_manager = LoginManager()\n    login_manager.init_app(app)\n    app.login_manager = login_manager  # Attach for testing\n    return app",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/82_3",
        "turn": "3",
        "instruct_prompt": "Define a simple User class inheriting from UserMixin that stores username as id and hashed password, and includes a method to verify passwords.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_user_creation_and_verify_password(self):\n        User = task_func()\n\n        user = User('testuser', 'mypassword')\n        self.assertEqual(user.id, 'testuser')\n        self.assertTrue(user.verify_password('mypassword'))\n        self.assertFalse(user.verify_password('wrongpassword'))\n\n    def test_password_hash_is_hashed(self):\n        User = task_func()\n\n        user = User('user2', 'pass2')\n        self.assertNotEqual(user.password_hash, 'pass2')\n        self.assertIsInstance(user.password_hash, str)\n",
        "code": "from flask_login import UserMixin\nfrom werkzeug.security import generate_password_hash, check_password_hash\n\ndef task_func():\n    class User(UserMixin):\n        def __init__(self, username, password):\n            self.id = username\n            self.password_hash = generate_password_hash(password)\n\n        def verify_password(self, password):\n            return check_password_hash(self.password_hash, password)\n\n    return User\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/82_4",
        "turn": "4",
        "instruct_prompt": "Implement routes for '/login', '/logout', and a protected '/protected' page with login required. Use Flask-WTF LoginForm for login validation, and handle user login and logout appropriately.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Directly call task_func since it's defined in the same file\n        self.app = task_func()\n        self.app.config['WTF_CSRF_ENABLED'] = False  # Disable CSRF for testing\n        self.client = self.app.test_client()\n        self.app.testing = True\n\n    def login(self, username, password):\n        return self.client.post('/login', data=dict(\n            username=username,\n            password=password\n        ), follow_redirects=True)\n\n    def logout(self):\n        return self.client.get('/logout', follow_redirects=True)\n\n    def test_login_page_get(self):\n        response = self.client.get('/login')\n        self.assertEqual(response.status_code, 200)\n        self.assertIn(b'Username', response.data)\n        self.assertIn(b'Password', response.data)\n\n    def test_login_invalid(self):\n        response = self.login('wronguser', 'wrongpass')\n        self.assertIn(b'Invalid username or password', response.data)\n\n    def test_login_valid_and_access_protected(self):\n        response = self.login('testuser', 'testpass')\n        self.assertIn(b'Hello, testuser! This is a protected page.', response.data)\n\n    def test_protected_requires_login(self):\n        response = self.client.get('/protected', follow_redirects=True)\n        self.assertIn(b'Username', response.data)  # redirected to login\n\n    def test_logout(self):\n        self.login('testuser', 'testpass')\n        response = self.logout()\n        self.assertIn(b'Username', response.data)  # redirected to login\n        # After logout, protected page redirects to login\n        response = self.client.get('/protected', follow_redirects=True)\n        self.assertIn(b'Username', response.data)\n",
        "code": "def task_func():\n    from flask import Flask, render_template_string, redirect, url_for, flash\n    from flask_login import LoginManager, login_user, logout_user, login_required, current_user, UserMixin\n    from flask_wtf import FlaskForm\n    from wtforms import StringField, PasswordField, SubmitField\n    from wtforms.validators import DataRequired\n    from werkzeug.security import generate_password_hash, check_password_hash\n\n    app = Flask(__name__)\n    app.config['SECRET_KEY'] = 'secret-key-for-testing'\n\n    login_manager = LoginManager(app)\n    login_manager.login_view = 'login'\n\n    class User(UserMixin):\n        def __init__(self, username, password):\n            self.id = username\n            self.password_hash = generate_password_hash(password)\n\n        def verify_password(self, password):\n            return check_password_hash(self.password_hash, password)\n\n    users = {\n        'testuser': User('testuser', 'testpass')\n    }\n\n    @login_manager.user_loader\n    def load_user(user_id):\n        return users.get(user_id)\n\n    class LoginForm(FlaskForm):\n        username = StringField('Username', validators=[DataRequired()])\n        password = PasswordField('Password', validators=[DataRequired()])\n        submit = SubmitField('Log In')\n\n    @app.route('/login', methods=['GET', 'POST'])\n    def login():\n        form = LoginForm()\n        if form.validate_on_submit():\n            user = users.get(form.username.data)\n            if user and user.verify_password(form.password.data):\n                login_user(user)\n                return redirect(url_for('protected'))\n            else:\n                flash('Invalid username or password')\n        return render_template_string('''\n            <form method=\"post\">\n                {{ form.hidden_tag() }}\n                {{ form.username.label }} {{ form.username() }}<br>\n                {{ form.password.label }} {{ form.password() }}<br>\n                {{ form.submit() }}\n            </form>\n            {% with messages = get_flashed_messages() %}\n              {% if messages %}\n                <ul>{% for message in messages %}<li>{{ message }}</li>{% endfor %}</ul>\n              {% endif %}\n            {% endwith %}\n        ''', form=form)\n\n    @app.route('/logout')\n    @login_required\n    def logout():\n        logout_user()\n        return redirect(url_for('login'))\n\n    @app.route('/protected')\n    @login_required\n    def protected():\n        return f'Hello, {current_user.id}! This is a protected page.'\n\n    return app\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/82_5",
        "turn": "5",
        "instruct_prompt": "Add a user loader function for Flask-Login that loads a User object based on user_id for session management.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.app = task_func()\n        self.app.testing = True\n        self.client = self.app.test_client()\n\n    def test_user_loader_function(self):\n        # Directly call the load_user function exposed on app\n        user = self.app.load_user('testuser')\n        self.assertIsNotNone(user)\n        self.assertEqual(user.id, 'testuser')\n\n        no_user = self.app.load_user('nonexistent')\n        self.assertIsNone(no_user)\n\n    def test_login_and_load_user_session(self):\n        # Login with valid credentials\n        response = self.client.post('/login', data={'username': 'testuser', 'password': 'testpass'}, follow_redirects=True)\n        self.assertIn(b'Hello, testuser! This is a protected page.', response.data)\n\n        # Access protected page to verify current_user is loaded\n        response = self.client.get('/protected')\n        self.assertIn(b'Hello, testuser! This is a protected page.', response.data)\n\n        # Logout\n        response = self.client.get('/logout', follow_redirects=True)\n        self.assertIn(b'Log In', response.data)\n\n        # Access protected page after logout should redirect to login\n        response = self.client.get('/protected', follow_redirects=True)\n        self.assertIn(b'Log In', response.data)\n",
        "code": "def task_func():\n    from flask import Flask, render_template_string, redirect, url_for, flash\n    from flask_login import LoginManager, login_user, logout_user, login_required, current_user, UserMixin\n    from flask_wtf import FlaskForm\n    from wtforms import StringField, PasswordField, SubmitField\n    from wtforms.validators import DataRequired\n    from werkzeug.security import generate_password_hash, check_password_hash\n\n    app = Flask(__name__)\n    app.config['SECRET_KEY'] = 'secret-key-for-testing'\n    # Disable CSRF in testing environment\n    app.config['WTF_CSRF_ENABLED'] = False\n\n    login_manager = LoginManager(app)\n    login_manager.login_view = 'login'\n\n    class User(UserMixin):\n        def __init__(self, username, password):\n            self.id = username\n            self.password_hash = generate_password_hash(password)\n\n        def verify_password(self, password):\n            return check_password_hash(self.password_hash, password)\n\n    users = {\n        'testuser': User('testuser', 'testpass')\n    }\n\n    @login_manager.user_loader\n    def load_user(user_id):\n        return users.get(user_id)\n\n    class LoginForm(FlaskForm):\n        username = StringField('Username', validators=[DataRequired()])\n        password = PasswordField('Password', validators=[DataRequired()])\n        submit = SubmitField('Log In')\n\n    @app.route('/login', methods=['GET', 'POST'])\n    def login():\n        form = LoginForm()\n        if form.validate_on_submit():\n            user = users.get(form.username.data)\n            if user and user.verify_password(form.password.data):\n                login_user(user)\n                return redirect(url_for('protected'))\n            else:\n                flash('Invalid username or password')\n        return render_template_string('''\n            <form method=\"post\">\n                {{ form.hidden_tag() }}\n                {{ form.username.label }} {{ form.username() }}<br>\n                {{ form.password.label }} {{ form.password() }}<br>\n                {{ form.submit() }}\n            </form>\n            {% with messages = get_flashed_messages() %}\n              {% if messages %}\n                <ul>{% for message in messages %}<li>{{ message }}</li>{% endfor %}</ul>\n              {% endif %}\n            {% endwith %}\n        ''', form=form)\n\n    @app.route('/logout')\n    @login_required\n    def logout():\n        logout_user()\n        return redirect(url_for('login'))\n\n    @app.route('/protected')\n    @login_required\n    def protected():\n        return f'Hello, {current_user.id}! This is a protected page.'\n\n    # Expose users and load_user for testing\n    app.users = users\n    app.load_user = load_user\n\n    return app\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 8,
    "task_id": "BigCodeBench/89",
    "mt_data": [
      {
        "task_id": "BigCodeBench/89_1",
        "turn": "1",
        "instruct_prompt": "Remove outliers from a specified column of a dataset based on Z-score. You should write self-contained code starting with:\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data, column, outlier_z_score):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_remove_outliers(self):\n        # Lower threshold to ensure outlier is removed\n        data = [\n            {'a': 10, 'b': 2},\n            {'a': 12, 'b': 3},\n            {'a': 11, 'b': 4},\n            {'a': 13, 'b': 5},\n            {'a': 1000, 'b': 6}, # Outlier for column 'a'\n        ]\n        # Using threshold 1, 1000 should be removed\n        filtered = task_func(data, 'a', 1)\n        self.assertEqual(len(filtered), 4)\n        a_values = [row['a'] for row in filtered]\n        self.assertNotIn(1000, a_values)\n    \n    def test_no_outliers(self):\n        data = [\n            {'a': 1},\n            {'a': 2},\n            {'a': 3},\n            {'a': 4}\n        ]\n        filtered = task_func(data, 'a', 3)\n        self.assertEqual(len(filtered), 4)\n\n    def test_all_outliers(self):\n        data = [\n            {'a': 100},\n            {'a': -100},\n            {'a': 0},\n        ]\n        filtered = task_func(data, 'a', 0.5)\n        # Only the value closest to the mean (0) should remain\n        self.assertEqual(len(filtered), 1)\n        self.assertEqual(filtered[0]['a'], 0)\n    \n    def test_single_row(self):\n        data = [{'a': 5}]\n        filtered = task_func(data, 'a', 2)\n        self.assertEqual(filtered, data)\n",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\ndef task_func(data, column, outlier_z_score):\n    '''\n    Remove outliers from a specified column in the dataset based on Z-score.\n    Args:\n        data (list of dict): The dataset, each element is a dict representing a row.\n        column (str): The column name to check for outliers.\n        outlier_z_score (float): The Z-score threshold for outlier removal.\n    Returns:\n        list of dict: Dataset with outliers removed from the specified column.\n    '''\n    values = np.array([row[column] for row in data])\n    if len(values) < 2:\n        return data\n    mean = np.mean(values)\n    std = np.std(values)\n    if std == 0:\n        z_scores = np.zeros_like(values)\n    else:\n        z_scores = np.abs((values - mean) / std)\n    filtered_data = [row for row, z in zip(data, z_scores) if z <= outlier_z_score]\n    return filtered_data\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/89_2",
        "turn": "2",
        "instruct_prompt": "Standardize the specified column before calculating Z-scores.",
        "test": "import unittest\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\nclass TestCases(unittest.TestCase):\n    def test_standardization_called(self):\n        # This test will fail for previous round's code because it does not use StandardScaler\n        called = {'count': 0}\n        real_StandardScaler = StandardScaler\n        \n        class CountingScaler(real_StandardScaler):\n            def fit_transform(self, X, y=None):\n                called['count'] += 1\n                return super().fit_transform(X, y)\n        \n        # Monkeypatch\n        import sklearn.preprocessing\n        old_scaler = sklearn.preprocessing.StandardScaler\n        sklearn.preprocessing.StandardScaler = CountingScaler\n        try:\n            data = [\n                {'id': 1, 'value': 1},\n                {'id': 2, 'value': 2},\n                {'id': 3, 'value': 100}\n            ]\n            # This should call fit_transform\n            task_func(data, 'value', 2)\n            self.assertGreaterEqual(called['count'], 1, \"StandardScaler.fit_transform was not called!\")\n        finally:\n            sklearn.preprocessing.StandardScaler = old_scaler\n\n    def test_output_matches_standardized_zscore(self):\n        data = [\n            {'id': 1, 'value': 2},\n            {'id': 2, 'value': 4},\n            {'id': 3, 'value': 6},\n            {'id': 4, 'value': 8},\n            {'id': 5, 'value': 100},\n        ]\n        outlier_z_score = 1.9\n        values = np.array([row['value'] for row in data]).reshape(-1, 1)\n        scaler = StandardScaler()\n        std_values = scaler.fit_transform(values).flatten()\n        expected = [row for row, z in zip(data, np.abs(std_values)) if z <= outlier_z_score]\n        result = task_func(data, 'value', outlier_z_score)\n        self.assertEqual(result, expected)\n\n    def test_single_row(self):\n        data = [{'id': 1, 'value': 10}]\n        result = task_func(data, 'value', 2)\n        self.assertEqual(result, data)\n\n    def test_all_same_value(self):\n        data = [\n            {'id': 1, 'value': 5},\n            {'id': 2, 'value': 5},\n            {'id': 3, 'value': 5},\n        ]\n        result = task_func(data, 'value', 2)\n        self.assertEqual(result, data)\n",
        "code": "import numpy as np\n\ndef task_func(data, column, outlier_z_score):\n    '''\n    Standardize the specified column before calculating Z-scores and remove outliers.\n    Args:\n        data (list of dict): The dataset, each element is a dict representing a row.\n        column (str): The column name to check for outliers.\n        outlier_z_score (float): The Z-score threshold for outlier removal.\n    Returns:\n        list of dict: Dataset with outliers removed from the specified column.\n    '''\n    from sklearn.preprocessing import StandardScaler\n    values = np.array([row[column] for row in data]).reshape(-1, 1)\n    if len(values) < 2:\n        return data\n    scaler = StandardScaler()\n    standardized_values = scaler.fit_transform(values).flatten()\n    z_scores = np.abs(standardized_values)\n    filtered_data = [row for row, z in zip(data, z_scores) if z <= outlier_z_score]\n    return filtered_data\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/89_3",
        "turn": "3",
        "instruct_prompt": "Return a tuple containing the original data, the data without outliers, and the indices of the outliers.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.data = [\n            {'id': 1, 'value': 10},\n            {'id': 2, 'value': 12},\n            {'id': 3, 'value': 11},\n            {'id': 4, 'value': 13},\n            {'id': 5, 'value': 100}  # outlier\n        ]\n\n    def test_returns_tuple(self):\n        result = task_func(self.data, 'value', 1.5)\n        self.assertIsInstance(result, tuple)\n        self.assertEqual(len(result), 3)\n\n    def test_original_data_preserved(self):\n        result = task_func(self.data, 'value', 1.5)\n        self.assertEqual(result[0], self.data)\n\n    def test_filtered_data_has_outlier_removed(self):\n        result = task_func(self.data, 'value', 1.5)\n        filtered = result[1]\n        self.assertNotIn({'id': 5, 'value': 100}, filtered)\n        self.assertEqual(len(filtered), 4)\n\n    def test_outlier_indices(self):\n        result = task_func(self.data, 'value', 1.5)\n        indices = result[2]\n        # The outlier (id=5) should be at index 4\n        self.assertEqual(indices, [4])\n\n    def test_no_outliers(self):\n        data = [\n            {'id': 1, 'value': 10},\n            {'id': 2, 'value': 12},\n            {'id': 3, 'value': 11},\n            {'id': 4, 'value': 13},\n        ]\n        result = task_func(data, 'value', 1.5)\n        self.assertEqual(result[1], data)\n        self.assertEqual(result[2], [])\n\n    def test_single_element(self):\n        data = [{'id': 1, 'value': 5}]\n        result = task_func(data, 'value', 1.5)\n        self.assertEqual(result, (data, data, []))\n",
        "code": "import numpy as np\n\ndef task_func(data, column, outlier_z_score):\n    '''\n    Standardize the specified column before calculating Z-scores and remove outliers.\n    Args:\n        data (list of dict): The dataset, each element is a dict representing a row.\n        column (str): The column name to check for outliers.\n        outlier_z_score (float): The Z-score threshold for outlier removal.\n    Returns:\n        tuple: (original data, data without outliers, indices of outliers)\n    '''\n    from sklearn.preprocessing import StandardScaler\n    if not data:\n        return ([], [], [])\n    values = np.array([row[column] for row in data]).reshape(-1, 1)\n    if len(values) < 2:\n        return (data, data, [])\n    scaler = StandardScaler()\n    standardized_values = scaler.fit_transform(values).flatten()\n    z_scores = np.abs(standardized_values)\n    filtered_data = [row for row, z in zip(data, z_scores) if z <= outlier_z_score]\n    outlier_indices = [i for i, z in enumerate(z_scores) if z > outlier_z_score]\n    return (data, filtered_data, outlier_indices)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/89_4",
        "turn": "4",
        "instruct_prompt": "Visualize the data using two scatter plots: one for the original data including outliers and one for the data after outlier removal.",
        "test": "import unittest\nfrom unittest.mock import patch\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    @patch('matplotlib.pyplot.show')\n    def test_visualization_scatter_plots(self, mock_show):\n        # Simple data with outliers\n        data = [\n            {'value': 10}, {'value': 12}, {'value': 11}, {'value': 13},\n            {'value': 12}, {'value': 100}  # Outlier\n        ]\n        column = 'value'\n        outlier_z_score = 2\n        # Should produce two scatter plots and call plt.show once\n        _ = task_func(data, column, outlier_z_score, visualize=True)\n        self.assertTrue(mock_show.called)\n        self.assertEqual(mock_show.call_count, 1)\n\n    @patch('matplotlib.pyplot.show')\n    def test_visualization_no_outliers(self, mock_show):\n        data = [{'value': x} for x in [10, 11, 12, 11, 10]]\n        column = 'value'\n        outlier_z_score = 3\n        _ = task_func(data, column, outlier_z_score, visualize=True)\n        self.assertTrue(mock_show.called)\n        self.assertEqual(mock_show.call_count, 1)\n\n    @patch('matplotlib.pyplot.show')\n    def test_no_visualization_flag(self, mock_show):\n        data = [{'value': 1}, {'value': 2}]\n        column = 'value'\n        outlier_z_score = 1\n        _ = task_func(data, column, outlier_z_score, visualize=False)\n        self.assertFalse(mock_show.called)\n",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data, column, outlier_z_score, visualize=False):\n    '''\n    Standardize the specified column before calculating Z-scores and remove outliers.\n    Optionally visualize the data using scatter plots.\n    Args:\n        data (list of dict): The dataset, each element is a dict representing a row.\n        column (str): The column name to check for outliers.\n        outlier_z_score (float): The Z-score threshold for outlier removal.\n        visualize (bool): If True, show scatter plots before and after outlier removal.\n    Returns:\n        tuple: (original data, data without outliers, indices of outliers)\n    '''\n    from sklearn.preprocessing import StandardScaler\n    if not data:\n        return ([], [], [])\n    values = np.array([row[column] for row in data]).reshape(-1, 1)\n    if len(values) < 2:\n        return (data, data, [])\n    scaler = StandardScaler()\n    standardized_values = scaler.fit_transform(values).flatten()\n    z_scores = np.abs(standardized_values)\n    filtered_data = [row for row, z in zip(data, z_scores) if z <= outlier_z_score]\n    outlier_indices = [i for i, z in enumerate(z_scores) if z > outlier_z_score]\n\n    if visualize:\n        x = np.arange(len(data))\n        y = values.flatten()\n        plt.figure(figsize=(10,4))\n        plt.subplot(1,2,1)\n        plt.scatter(x, y, color='blue', label='Original Data')\n        if outlier_indices:\n            plt.scatter([x[i] for i in outlier_indices], [y[i] for i in outlier_indices], color='red', label='Outliers')\n        plt.title('Original Data (with Outliers)')\n        plt.xlabel('Index')\n        plt.ylabel(column)\n        plt.legend()\n\n        # Data after outlier removal\n        filtered_x = [i for i in range(len(data)) if i not in outlier_indices]\n        filtered_y = [y[i] for i in filtered_x]\n        plt.subplot(1,2,2)\n        plt.scatter(filtered_x, filtered_y, color='green', label='Filtered Data')\n        plt.title('Data after Outlier Removal')\n        plt.xlabel('Index')\n        plt.ylabel(column)\n        plt.legend()\n        plt.tight_layout()\n        plt.show()\n\n    return (data, filtered_data, outlier_indices)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 9,
    "task_id": "BigCodeBench/92",
    "mt_data": [
      {
        "task_id": "BigCodeBench/92_1",
        "turn": "1",
        "instruct_prompt": "Perform K-means clustering on a dataset and return the cluster labels.\nYou should write self-contained code starting with:\n```python\nimport pandas as pd\nfrom sklearn.cluster import KMeans\n\ndef task_func(data, n_clusters=3):\n```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic(self):\n        data = pd.DataFrame({\n            'x': [1, 1, 4, 5, 6],\n            'y': [2, 1, 4, 5, 7]\n        })\n        labels = task_func(data, n_clusters=2)\n        self.assertEqual(len(labels), len(data))\n        self.assertTrue(set(labels.unique()).issubset({0,1}))\n\n    def test_task_func_three_clusters(self):\n        data = pd.DataFrame({\n            'x': [1, 1, 4, 5, 6, 9, 10, 10],\n            'y': [2, 1, 4, 5, 7, 10, 10, 11]\n        })\n        labels = task_func(data, n_clusters=3)\n        self.assertEqual(len(labels), len(data))\n        self.assertEqual(len(set(labels)), 3)\n\n    def test_task_func_single_cluster(self):\n        data = pd.DataFrame({\n            'x': [1, 1, 1],\n            'y': [2, 2, 2]\n        })\n        labels = task_func(data, n_clusters=1)\n        self.assertTrue((labels == 0).all())\n",
        "code": "import pandas as pd\nfrom sklearn.cluster import KMeans\n\ndef task_func(data, n_clusters=3):\n    \"\"\"\n    Perform K-means clustering on the input dataset and return the cluster labels.\n\n    Parameters:\n    data (pd.DataFrame): Input data for clustering.\n    n_clusters (int): Number of clusters to form.\n\n    Returns:\n    labels (pd.Series): Cluster labels for each data point.\n    \"\"\"\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    kmeans.fit(data)\n    return pd.Series(kmeans.labels_, index=data.index)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/92_2",
        "turn": "2",
        "instruct_prompt": "Raise a ValueError if 'data' is not a pandas DataFrame or if 'n_clusters' is not an integer greater than 1.",
        "test": "import unittest\nimport pandas as pd\nfrom sklearn.datasets import make_blobs\n\nclass TestCases(unittest.TestCase):\n    def test_valid_input(self):\n        data, _ = make_blobs(n_samples=10, centers=3, n_features=2, random_state=42)\n        df = pd.DataFrame(data, columns=['feat1', 'feat2'])\n        labels = task_func(df, n_clusters=3)\n        self.assertEqual(len(labels), 10)\n        self.assertTrue(isinstance(labels, pd.Series))\n\n    def test_data_not_dataframe(self):\n        data = [[1, 2], [3, 4]]\n        with self.assertRaises(ValueError) as cm:\n            task_func(data, n_clusters=3)\n        self.assertIn(\"'data' must be a pandas DataFrame\", str(cm.exception))\n\n    def test_n_clusters_not_int(self):\n        df = pd.DataFrame([[1, 2], [3, 4]])\n        with self.assertRaises(ValueError) as cm:\n            task_func(df, n_clusters='3')\n        self.assertIn(\"'n_clusters' must be an integer greater than 1\", str(cm.exception))\n\n    def test_n_clusters_less_than_2(self):\n        df = pd.DataFrame([[1, 2], [3, 4]])\n        with self.assertRaises(ValueError) as cm:\n            task_func(df, n_clusters=1)\n        self.assertIn(\"'n_clusters' must be an integer greater than 1\", str(cm.exception))\n",
        "code": "import pandas as pd\nfrom sklearn.cluster import KMeans\n\ndef task_func(data, n_clusters=3):\n    \"\"\"\n    Perform K-means clustering on the input dataset and return the cluster labels.\n\n    Parameters:\n    data (pd.DataFrame): Input data for clustering.\n    n_clusters (int): Number of clusters to form.\n\n    Returns:\n    labels (pd.Series): Cluster labels for each data point.\n    \"\"\"\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' must be a pandas DataFrame.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"'n_clusters' must be an integer greater than 1.\")\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    kmeans.fit(data)\n    return pd.Series(kmeans.labels_, index=data.index)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/92_3",
        "turn": "3",
        "instruct_prompt": "Generate a scatter plot showing the data points colored by their cluster labels and the cluster centroids. The function should return a tuple of the cluster labels and the matplotlib Axes object containing the plot.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')  # Use a non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    def test_scatter_plot_and_labels(self):\n        from matplotlib.axes import Axes\n        # Create sample data\n        data = pd.DataFrame({\n            'x': [1, 2, 1, 5, 6, 5],\n            'y': [1, 1, 2, 5, 5, 6]\n        })\n\n        labels, ax = task_func(data, n_clusters=2)\n\n        # Test labels type and length\n        self.assertIsInstance(labels, pd.Series)\n        self.assertEqual(len(labels), len(data))\n\n        # Test labels contains expected cluster labels\n        self.assertTrue(set(labels.unique()).issubset({0, 1}))\n\n        # Test ax is a matplotlib Axes instance\n        self.assertIsInstance(ax, Axes)\n\n        # Test that the scatter plot contains the correct number of points\n        scatter_paths = [child for child in ax.get_children() if isinstance(child, matplotlib.collections.PathCollection)]\n        # There should be two PathCollection objects: one for points, one for centroids\n        self.assertEqual(len(scatter_paths), 2)\n\n        # The first scatter corresponds to data points\n        data_points = scatter_paths[0]\n        self.assertEqual(len(data_points.get_offsets()), len(data))\n\n        # The second scatter corresponds to centroids\n        centroids = scatter_paths[1]\n        self.assertEqual(len(centroids.get_offsets()), 2)  # n_clusters=2\n\n    def test_invalid_inputs(self):\n        # data not DataFrame\n        with self.assertRaises(ValueError):\n            task_func([[1, 2], [3, 4]], n_clusters=2)\n\n        # n_clusters invalid\n        data = pd.DataFrame({'x': [1, 2], 'y': [3, 4]})\n        with self.assertRaises(ValueError):\n            task_func(data, n_clusters=1)\n\n        with self.assertRaises(ValueError):\n            task_func(data, n_clusters='a')\n",
        "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\ndef task_func(data, n_clusters=3):\n    \"\"\"\n    Perform K-means clustering on the input dataset, generate a scatter plot showing the data points colored by their cluster labels\n    and the cluster centroids.\n\n    Parameters:\n    data (pd.DataFrame): Input data for clustering.\n    n_clusters (int): Number of clusters to form.\n\n    Returns:\n    tuple: (labels (pd.Series), ax (matplotlib.axes.Axes))\n    \"\"\"\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"'data' must be a pandas DataFrame.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 1:\n        raise ValueError(\"'n_clusters' must be an integer greater than 1.\")\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    kmeans.fit(data)\n    labels = pd.Series(kmeans.labels_, index=data.index)\n\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(data.iloc[:, 0], data.iloc[:, 1], c=labels, cmap='viridis', alpha=0.6, edgecolor='k')\n    centroids = kmeans.cluster_centers_\n    ax.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=100, label='Centroids')\n    ax.legend()\n    ax.set_xlabel(data.columns[0])\n    ax.set_ylabel(data.columns[1])\n    ax.set_title('K-means Clustering')\n\n    return labels, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 10,
    "task_id": "BigCodeBench/93",
    "mt_data": [
      {
        "task_id": "BigCodeBench/93_1",
        "turn": "1",
        "instruct_prompt": "Perform Principal Component Analysis (PCA) on a dataset and return the transformed data as a DataFrame with principal components. You should write self-contained code starting with:\n```\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n```",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_pca_output_shape_and_columns(self):\n        data = pd.DataFrame({\n            'A': [1, 2, 3, 4],\n            'B': [4, 3, 2, 1],\n            'C': [2, 3, 4, 5]\n        })\n        result = task_func(data, n_components=2)\n        self.assertIsInstance(result, pd.DataFrame)\n        self.assertEqual(result.shape, (4, 2))\n        self.assertListEqual(list(result.columns), ['PC1', 'PC2'])\n\n    def test_pca_with_single_component(self):\n        data = pd.DataFrame(np.eye(3))\n        result = task_func(data, n_components=1)\n        self.assertEqual(result.shape, (3, 1))\n        self.assertListEqual(list(result.columns), ['PC1'])\n\n    def test_pca_values_change(self):\n        data = pd.DataFrame({\n            'X': [1, 2, 3, 4, 5],\n            'Y': [5, 4, 3, 2, 1]\n        })\n        result = task_func(data, n_components=2)\n        # The PCA transformed data should not be identical to the original\n        self.assertFalse(np.allclose(result.values, data.values))\n\n    def test_pca_default_components(self):\n        data = pd.DataFrame(np.random.rand(10, 5))\n        result = task_func(data)\n        self.assertEqual(result.shape[1], 2)  # default n_components=2\n",
        "code": "import numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    pca = PCA(n_components=n_components)\n    transformed = pca.fit_transform(data)\n    columns = [f'PC{i+1}' for i in range(n_components)]\n    return pd.DataFrame(transformed, columns=columns)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/93_2",
        "turn": "2",
        "instruct_prompt": "The function should raise a ValueError if n_components is not a positive integer.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.data = pd.DataFrame(np.random.rand(10, 5))\n\n    def test_valid_n_components(self):\n        df = task_func(self.data, n_components=3)\n        self.assertEqual(df.shape[1], 3)\n\n    def test_zero_n_components(self):\n        with self.assertRaises(ValueError):\n            task_func(self.data, n_components=0)\n\n    def test_negative_n_components(self):\n        with self.assertRaises(ValueError):\n            task_func(self.data, n_components=-1)\n\n    def test_non_integer_n_components(self):\n        with self.assertRaises(ValueError):\n            task_func(self.data, n_components=2.5)\n\n    def test_string_n_components(self):\n        with self.assertRaises(ValueError):\n            task_func(self.data, n_components='3')\n",
        "code": "import numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError('n_components must be a positive integer')\n    pca = PCA(n_components=n_components)\n    transformed = pca.fit_transform(data)\n    columns = [f'PC{i+1}' for i in range(n_components)]\n    return pd.DataFrame(transformed, columns=columns)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/93_3",
        "turn": "3",
        "instruct_prompt": "Generate a scatter plot of the first two principal components of the transformed data and return the matplotlib Axes object along with the DataFrame.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\n\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_scatter_plot_and_dataframe(self):\n        # Create sample data\n        np.random.seed(0)\n        data = pd.DataFrame(np.random.rand(10, 5), columns=[f'feature{i}' for i in range(5)])\n        \n        ax, df = task_func(data, n_components=2)\n        \n        # Check types\n        self.assertIsInstance(ax, Axes)\n        self.assertIsInstance(df, pd.DataFrame)\n        \n        # Check DataFrame shape and columns\n        self.assertEqual(df.shape, (10, 2))\n        self.assertListEqual(list(df.columns), ['PC1', 'PC2'])\n        \n        # Check scatter plot data matches DataFrame columns\n        scatter_offsets = ax.collections[0].get_offsets()\n        np.testing.assert_array_almost_equal(scatter_offsets[:,0], df['PC1'].values)\n        np.testing.assert_array_almost_equal(scatter_offsets[:,1], df['PC2'].values)\n\n    def test_invalid_n_components(self):\n        data = pd.DataFrame(np.random.rand(5, 3))\n        with self.assertRaises(ValueError):\n            task_func(data, n_components=0)\n        with self.assertRaises(ValueError):\n            task_func(data, n_components=-1)\n        with self.assertRaises(ValueError):\n            task_func(data, n_components='two')\n",
        "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError('n_components must be a positive integer')\n    pca = PCA(n_components=n_components)\n    transformed = pca.fit_transform(data)\n    columns = [f'PC{i+1}' for i in range(n_components)]\n    df = pd.DataFrame(transformed, columns=columns)\n    \n    fig, ax = plt.subplots()\n    ax.scatter(df['PC1'], df['PC2'])\n    ax.set_xlabel('PC1')\n    ax.set_ylabel('PC2')\n    ax.set_title('Scatter plot of first two principal components')\n    \n    return ax, df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/93_4",
        "turn": "4",
        "instruct_prompt": "Include all necessary imports for plotting and ensure the code is fully self-contained with the original function signature.",
        "test": "import unittest\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\n\nclass TestCases(unittest.TestCase):\n    def test_return_types_and_shape(self):\n        data = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n        result = task_func(data, n_components=2)\n        # Check the returned tuple length\n        self.assertEqual(len(result), 3)\n        fig, ax, df = result\n        self.assertIsInstance(fig, Figure)  # Expect matplotlib Figure instance\n        self.assertIsInstance(ax, Axes)    # Expect matplotlib Axes instance\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertEqual(df.shape, (4, 2))\n        self.assertListEqual(list(df.columns), ['PC1', 'PC2'])\n\n    def test_invalid_n_components(self):\n        data = np.array([[1, 2], [3, 4]])\n        with self.assertRaises(ValueError):\n            task_func(data, n_components=0)\n        with self.assertRaises(ValueError):\n            task_func(data, n_components=-1)\n        with self.assertRaises(ValueError):\n            task_func(data, n_components='two')\n\n    def test_plot_labels_and_title(self):\n        data = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n        fig, ax, _ = task_func(data, n_components=2)\n        self.assertEqual(ax.get_xlabel(), 'PC1')\n        self.assertEqual(ax.get_ylabel(), 'PC2')\n        self.assertEqual(ax.get_title(), 'Scatter plot of first two principal components')\n\n    def test_plot_draw(self):\n        data = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n        fig, ax, _ = task_func(data, n_components=2)\n        try:\n            fig.canvas.draw()\n        except Exception as e:\n            self.fail(f\"Plot drawing failed with exception: {e}\")\n",
        "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    if not isinstance(n_components, int) or n_components <= 0:\n        raise ValueError('n_components must be a positive integer')\n    pca = PCA(n_components=n_components)\n    transformed = pca.fit_transform(data)\n    columns = [f'PC{i+1}' for i in range(n_components)]\n    df = pd.DataFrame(transformed, columns=columns)\n    \n    fig, ax = plt.subplots()\n    ax.scatter(df['PC1'], df['PC2'])\n    ax.set_xlabel('PC1')\n    ax.set_ylabel('PC2')\n    ax.set_title('Scatter plot of first two principal components')\n    \n    return fig, ax, df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 11,
    "task_id": "BigCodeBench/99",
    "mt_data": [
      {
        "task_id": "BigCodeBench/99_1",
        "turn": "1",
        "instruct_prompt": "Draw a pair plot of the iris dataset using seaborn. You should write self-contained code starting with:\n```python\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\ndef task_func():\n```",
        "test": "import unittest\nimport io\nimport sys\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_runs_without_error(self):\n        # Redirect stdout and stderr to capture possible outputs\n        captured_output = io.StringIO()\n        sys.stdout = captured_output\n        sys.stderr = captured_output\n        try:\n            task_func()  # Directly call the function since it's in the same file\n        except Exception as e:\n            self.fail(f\"task_func() raised an exception: {e}\")\n        finally:\n            sys.stdout = sys.__stdout__\n            sys.stderr = sys.__stderr__\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\n\ndef task_func():\n    iris = load_iris()\n    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n    sns.pairplot(df, hue='species')\n    plt.show()",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/99_2",
        "turn": "2",
        "instruct_prompt": "Set the global font to Arial before plotting to improve readability.",
        "test": "import unittest\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_global_font_set_to_arial(self):\n        self.assertIn('Arial', plt.rcParams['font.family'])\n\n    def test_task_func_runs_without_error(self):\n        # Suppress plt.show() to avoid blocking during tests\n        original_show = plt.show\n        plt.show = lambda: None\n        try:\n            task_func()\n        finally:\n            plt.show = original_show\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\n\nplt.rcParams['font.family'] = 'Arial'\n\ndef task_func():\n    iris = load_iris()\n    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n    sns.pairplot(df, hue='species')\n    plt.show()",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/99_3",
        "turn": "3",
        "instruct_prompt": "Generate the pair plot so that each subplot shows the relationship between two features, colored by species.",
        "test": "import unittest\nimport seaborn as sns\n\nclass TestCases(unittest.TestCase):\n    def test_pairplot_contains_correct_hue(self):\n        pair_plot = task_func()\n        \n        # Check the returned object is a seaborn PairGrid\n        self.assertIsInstance(pair_plot, sns.axisgrid.PairGrid)\n\n        # Iris dataset has 4 features, so expect 4x4=16 subplots\n        axes = pair_plot.axes\n        self.assertEqual(axes.shape, (4,4))\n\n        # Check each subplot is a matplotlib Axes\n        for row_axes in axes:\n            for ax in row_axes:\n                self.assertTrue(hasattr(ax, 'plot'))\n\n        # Check legend labels to verify hue\n        legend = pair_plot._legend\n        self.assertIsNotNone(legend, \"Legend should not be None\")\n        legend_texts = [text.get_text() for text in legend.get_texts()]\n        expected_species = ['setosa', 'versicolor', 'virginica']\n        for species in expected_species:\n            self.assertIn(species, legend_texts)\n\n        # Close the plot to free memory\n        plt.close(pair_plot.fig)\n",
        "code": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\n\nplt.rcParams['font.family'] = 'Arial'\n\ndef task_func():\n    iris = load_iris()\n    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n    pair_plot = sns.pairplot(df, hue='species')\n    # Do not call plt.show() here to allow testing without GUI blocking\n    return pair_plot\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/99_4",
        "turn": "4",
        "instruct_prompt": "Add the title 'Iris Dataset Pair Plot' to the figure and ensure that each subplot's axes are labeled with the corresponding feature names like 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', and 'petal width (cm)'. Return the matplotlib Figure object containing the plot.",
        "test": "import unittest\nimport matplotlib.pyplot as plt\nfrom matplotlib.figure import Figure\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_returns_figure_and_labels(self):\n        fig = task_func()\n        self.assertIsInstance(fig, Figure)\n        # The figure should have title 'Iris Dataset Pair Plot'\n        self.assertIsNotNone(fig._suptitle)\n        self.assertEqual(fig._suptitle.get_text(), 'Iris Dataset Pair Plot')\n\n        # Check subplot axes labels\n        iris_feature_names = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n        n = len(iris_feature_names)\n        # axes are in an n*n grid\n        for i in range(n):\n            for j in range(n):\n                ax = fig.axes[i*n + j]\n                # y-label only on first column\n                if j == 0:\n                    self.assertEqual(ax.get_ylabel(), iris_feature_names[i])\n                else:\n                    self.assertEqual(ax.get_ylabel(), '')\n                # x-label only on last row\n                if i == n - 1:\n                    self.assertEqual(ax.get_xlabel(), iris_feature_names[j])\n                else:\n                    self.assertEqual(ax.get_xlabel(), '')\n",
        "code": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\n\nplt.rcParams['font.family'] = 'Arial'\n\ndef task_func():\n    iris = load_iris()\n    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n    pair_plot = sns.pairplot(df, hue='species')\n    pair_plot.fig.suptitle('Iris Dataset Pair Plot', y=1.02)\n    # Set axes labels explicitly for each subplot\n    for i, feature_i in enumerate(iris.feature_names):\n        for j, feature_j in enumerate(iris.feature_names):\n            ax = pair_plot.axes[i, j]\n            if j == 0:\n                ax.set_ylabel(feature_i)\n            else:\n                ax.set_ylabel('')\n            if i == (len(iris.feature_names) - 1):\n                ax.set_xlabel(feature_j)\n            else:\n                ax.set_xlabel('')\n    return pair_plot.fig\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 12,
    "task_id": "BigCodeBench/100",
    "mt_data": [
      {
        "task_id": "BigCodeBench/100_1",
        "turn": "1",
        "instruct_prompt": "Generate a line plot of random numeric values for 30 consecutive days ending today. You should write self-contained code starting with:\n```python\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime\ndef task_func(seed=42):\n```",
        "test": "import unittest\nimport matplotlib\nmatplotlib.use('Agg')  # Use a non-interactive backend for testing\nimport io\nimport sys\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_runs_without_error(self):\n        # Just test that function runs without raising exceptions\n        try:\n            task_func(seed=123)\n        except Exception as e:\n            self.fail(f'task_func raised Exception unexpectedly: {e}')\n\n    def test_task_func_generates_30_dates(self):\n        # Capture the dates generated inside the function by mocking plt.show\n        import matplotlib.pyplot as plt\n        original_show = plt.show\n        dates_captured = []\n        values_captured = []\n\n        def fake_show():\n            pass\n\n        plt.show = fake_show\n\n        # Modify task_func locally to return df for testing\n        def task_func_return_df(seed=42):\n            random.seed(seed)\n            end_date = datetime.today()\n            dates = [end_date - timedelta(days=i) for i in range(29, -1, -1)]\n            values = [random.random() for _ in range(30)]\n            df = pd.DataFrame({'Date': dates, 'Value': values})\n            df.set_index('Date', inplace=True)\n            plt.figure(figsize=(10, 5))\n            plt.plot(df.index, df['Value'], marker='o')\n            plt.title('Random Numeric Values for 30 Consecutive Days Ending Today')\n            plt.xlabel('Date')\n            plt.ylabel('Value')\n            plt.grid(True)\n            plt.tight_layout()\n            plt.show()\n            return df\n\n        df = task_func_return_df(seed=42)\n\n        self.assertEqual(len(df), 30, 'DataFrame should have 30 entries')\n\n        # Check dates are consecutive days ending today\n        expected_dates = [datetime.today() - timedelta(days=i) for i in range(29, -1, -1)]\n        # Compare dates ignoring time part\n        df_dates = [d.date() for d in df.index]\n        expected_dates_dates = [d.date() for d in expected_dates]\n        self.assertEqual(df_dates, expected_dates_dates, 'Dates should be 30 consecutive days ending today')\n\n        plt.show = original_show\n",
        "code": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\n\ndef task_func(seed=42):\n    random.seed(seed)\n    # Generate dates for 30 consecutive days ending today\n    end_date = datetime.today()\n    dates = [end_date - timedelta(days=i) for i in range(29, -1, -1)]\n    \n    # Generate 30 random numeric values\n    values = [random.random() for _ in range(30)]\n    \n    # Create a DataFrame\n    df = pd.DataFrame({'Date': dates, 'Value': values})\n    df.set_index('Date', inplace=True)\n    \n    # Plot line plot\n    plt.figure(figsize=(10, 5))\n    plt.plot(df.index, df['Value'], marker='o')\n    plt.title('Random Numeric Values for 30 Consecutive Days Ending Today')\n    plt.xlabel('Date')\n    plt.ylabel('Value')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/100_2",
        "turn": "2",
        "instruct_prompt": "Ensure the plot uses Arial font for all text elements for better readability.",
        "test": "import unittest\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom datetime import datetime, timedelta\nimport pandas as pd\nimport random\n\nclass TestCases(unittest.TestCase):\n    def test_font_arial(self):\n        # Call task_func directly (no import needed)\n        task_func()\n\n        # Check global rcParams font family is Arial\n        self.assertEqual(matplotlib.rcParams['font.family'][0].lower(), 'arial')\n\n        # To check font family of text elements, create a plot with Arial font set\n        random.seed(42)\n        end_date = datetime.today()\n        dates = [end_date - timedelta(days=i) for i in range(29, -1, -1)]\n        values = [random.random() for _ in range(30)]\n        df = pd.DataFrame({'Date': dates, 'Value': values})\n        df.set_index('Date', inplace=True)\n\n        fig, ax = plt.subplots(figsize=(10, 5))\n        ax.plot(df.index, df['Value'], marker='o')\n        ax.set_title('Random Numeric Values for 30 Consecutive Days Ending Today')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Value')\n        ax.grid(True)\n        plt.tight_layout()\n\n        # Helper to normalize font family to list of lowercase strings\n        def normalize_font_family(f):\n            if isinstance(f, str):\n                return [f.lower()]\n            elif isinstance(f, (list, tuple)):\n                return [x.lower() for x in f]\n            else:\n                return []\n\n        title_fonts = normalize_font_family(ax.title.get_fontfamily())\n        xlabel_fonts = normalize_font_family(ax.xaxis.label.get_fontfamily())\n        ylabel_fonts = normalize_font_family(ax.yaxis.label.get_fontfamily())\n\n        self.assertIn('arial', title_fonts)\n        self.assertIn('arial', xlabel_fonts)\n        self.assertIn('arial', ylabel_fonts)\n\n        plt.close(fig)\n",
        "code": "import matplotlib.pyplot as plt\nimport matplotlib\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\n\ndef task_func(seed=42):\n    # Set global font family to Arial\n    matplotlib.rcParams['font.family'] = 'Arial'\n\n    random.seed(seed)\n    # Generate dates for 30 consecutive days ending today\n    end_date = datetime.today()\n    dates = [end_date - timedelta(days=i) for i in range(29, -1, -1)]\n    \n    # Generate 30 random numeric values\n    values = [random.random() for _ in range(30)]\n    \n    # Create a DataFrame\n    df = pd.DataFrame({'Date': dates, 'Value': values})\n    df.set_index('Date', inplace=True)\n    \n    # Plot line plot\n    plt.figure(figsize=(10, 5))\n    plt.plot(df.index, df['Value'], marker='o')\n    plt.title('Random Numeric Values for 30 Consecutive Days Ending Today')\n    plt.xlabel('Date')\n    plt.ylabel('Value')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/100_3",
        "turn": "3",
        "instruct_prompt": "Label the x-axis as 'Date', the y-axis as 'Value', and set the plot title to 'Random Time Series Data'.",
        "test": "import unittest\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_plot_labels_and_title(self):\n        # Patch plt.show to prevent actual plot display\n        original_show = plt.show\n        plt.show = lambda: None\n\n        try:\n            # Call the function directly\n            task_func()\n\n            # Get current figure and axis\n            fig = plt.gcf()\n            ax = plt.gca()\n\n            # Check if title is correct\n            self.assertEqual(ax.get_title(), 'Random Time Series Data')\n\n            # Check x-axis label\n            self.assertEqual(ax.get_xlabel(), 'Date')\n\n            # Check y-axis label\n            self.assertEqual(ax.get_ylabel(), 'Value')\n\n        finally:\n            # Restore plt.show\n            plt.show = original_show\n",
        "code": "import matplotlib.pyplot as plt\nimport matplotlib\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\n\ndef task_func(seed=42):\n    # Set global font family to Arial\n    matplotlib.rcParams['font.family'] = 'Arial'\n\n    random.seed(seed)\n    # Generate dates for 30 consecutive days ending today\n    end_date = datetime.today()\n    dates = [end_date - timedelta(days=i) for i in range(29, -1, -1)]\n    \n    # Generate 30 random numeric values\n    values = [random.random() for _ in range(30)]\n    \n    # Create a DataFrame\n    df = pd.DataFrame({'Date': dates, 'Value': values})\n    df.set_index('Date', inplace=True)\n    \n    # Plot line plot\n    plt.figure(figsize=(10, 5))\n    plt.plot(df.index, df['Value'], marker='o')\n    plt.title('Random Time Series Data')\n    plt.xlabel('Date')\n    plt.ylabel('Value')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/100_4",
        "turn": "4",
        "instruct_prompt": "Control reproducibility of the random data generation using the optional seed parameter passed to the function.",
        "test": "import unittest\nimport random\nimport matplotlib\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def test_reproducibility_with_seed(self):\n        df1 = task_func(seed=123)\n        df2 = task_func(seed=123)\n        # Compare only the 'Value' column as list to avoid index differences\n        self.assertEqual(list(df1['Value']), list(df2['Value']))\n\n    def test_different_seed_produces_different_values(self):\n        df1 = task_func(seed=123)\n        df2 = task_func(seed=456)\n        self.assertNotEqual(list(df1['Value']), list(df2['Value']))\n\n    def test_no_seed_produces_different_values(self):\n        df1 = task_func(seed=None)\n        df2 = task_func(seed=None)\n        # It is possible but highly unlikely that two runs without seed produce same values\n        self.assertNotEqual(list(df1['Value']), list(df2['Value']))\n\n    def test_font_family_set_to_arial(self):\n        task_func(seed=0)\n        # rcParams['font.family'] is a list, check if 'Arial' is in it\n        self.assertIn('Arial', matplotlib.rcParams['font.family'])\n",
        "code": "import matplotlib.pyplot as plt\nimport matplotlib\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\n\ndef task_func(seed=None):\n    # Set global font family to Arial\n    matplotlib.rcParams['font.family'] = ['Arial']\n\n    if seed is not None:\n        random.seed(seed)\n\n    # Generate dates for 30 consecutive days ending today\n    end_date = datetime.today()\n    dates = [end_date - timedelta(days=i) for i in range(29, -1, -1)]\n\n    # Generate 30 random numeric values\n    values = [random.random() for _ in range(30)]\n\n    # Create a DataFrame\n    df = pd.DataFrame({'Date': dates, 'Value': values})\n    df.set_index('Date', inplace=True)\n\n    # Plot line plot\n    plt.figure(figsize=(10, 5))\n    plt.plot(df.index, df['Value'], marker='o')\n    plt.title('Random Time Series Data')\n    plt.xlabel('Date')\n    plt.ylabel('Value')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n    return df",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/100_5",
        "turn": "5",
        "instruct_prompt": "Wrap the entire data generation and plotting code in a try-except block that raises a ValueError with an informative message if any error occurs during the process. Return the matplotlib.axes.Axes object of the created plot.",
        "test": "import unittest\nimport matplotlib\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_returns_axes(self):\n        ax = task_func(seed=42)\n        # Check the returned object is an instance of matplotlib.axes.Axes\n        self.assertIsInstance(ax, matplotlib.axes.Axes)\n\n    def test_task_func_raises_value_error_on_error(self):\n        # To simulate an error, monkeypatch random.random to raise an exception\n        import random\n        original_random = random.random\n\n        def faulty_random():\n            raise RuntimeError(\"random failure\")\n\n        random.random = faulty_random\n\n        with self.assertRaises(ValueError) as context:\n            task_func()\n\n        self.assertIn(\"An error occurred during data generation and plotting\", str(context.exception))\n\n        # Restore original function\n        random.random = original_random\n",
        "code": "import matplotlib.pyplot as plt\nimport matplotlib\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\n\ndef task_func(seed=None):\n    try:\n        # Set global font family to Arial\n        matplotlib.rcParams['font.family'] = ['Arial']\n\n        if seed is not None:\n            random.seed(seed)\n\n        # Generate dates for 30 consecutive days ending today\n        end_date = datetime.today()\n        dates = [end_date - timedelta(days=i) for i in range(29, -1, -1)]\n\n        # Generate 30 random numeric values\n        values = [random.random() for _ in range(30)]\n\n        # Create a DataFrame\n        df = pd.DataFrame({'Date': dates, 'Value': values})\n        df.set_index('Date', inplace=True)\n\n        # Plot line plot\n        fig, ax = plt.subplots(figsize=(10, 5))\n        ax.plot(df.index, df['Value'], marker='o')\n        ax.set_title('Random Time Series Data')\n        ax.set_xlabel('Date')\n        ax.set_ylabel('Value')\n        ax.grid(True)\n        fig.tight_layout()\n        plt.show()\n\n        return ax\n    except Exception as e:\n        raise ValueError(f\"An error occurred during data generation and plotting: {e}\")\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 13,
    "task_id": "BigCodeBench/101",
    "mt_data": [
      {
        "task_id": "BigCodeBench/101_1",
        "turn": "1",
        "instruct_prompt": "Draw the correlation heatmap of the Boston Housing dataset using Seaborn.\nYou should write self-contained code starting with:\n```\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n```",
        "test": "import unittest\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-GUI backend for testing\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_runs_and_plots(self):\n        fig = task_func()\n\n        self.assertIsNotNone(fig, \"task_func should return a matplotlib Figure object.\")\n        self.assertTrue(hasattr(fig, 'axes'), \"Returned object should have axes attribute.\")\n        self.assertGreater(len(fig.axes), 0, \"Figure should have at least one Axes.\")\n\n        heatmap_found = False\n        for ax in fig.axes:\n            # seaborn heatmap uses QuadMesh in ax.collections\n            for coll in ax.collections:\n                # Check if collection is QuadMesh and has 2D array\n                if hasattr(coll, 'get_array'):\n                    arr = coll.get_array()\n                    # The correlation matrix is square and 2D,\n                    # get_array returns a 1D array of all cell values, so check size\n                    if arr is not None and arr.ndim == 1 and len(arr) > 1:\n                        heatmap_found = True\n                        break\n            if heatmap_found:\n                break\n\n        self.assertTrue(heatmap_found, \"No heatmap QuadMesh found in the figure axes.\")\n",
        "code": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n    import urllib.request\n\n    response = urllib.request.urlopen(data_url)\n    raw_data = response.read().decode('utf-8').splitlines()\n\n    # Remove empty lines\n    raw_data = [line for line in raw_data if line.strip() != '']\n\n    # Skip header (first 22 lines)\n    data_lines = raw_data[22:]\n\n    data = []\n    for i in range(0, len(data_lines), 2):\n        first_line_nums = list(map(float, data_lines[i].strip().split()))\n        second_line_nums = list(map(float, data_lines[i+1].strip().split()))\n        sample = first_line_nums + second_line_nums\n        data.append(sample)\n\n    data = np.array(data)  # shape (506, 14)\n\n    column_names = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n\n    df = pd.DataFrame(data, columns=column_names)\n\n    corr = df.corr()\n\n    fig, ax = plt.subplots(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8}, ax=ax)\n    ax.set_title('Correlation Heatmap of Boston Housing Dataset')\n    fig.tight_layout()\n\n    return fig\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/101_2",
        "turn": "2",
        "instruct_prompt": "Load the Boston Housing dataset from the given URL, process it into a DataFrame with appropriate column names, and compute the correlation matrix.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_boston_dataset_loading_and_correlation(self):\n        df, corr = task_func()\n\n        # Check that df is a DataFrame\n        self.assertIsInstance(df, pd.DataFrame)\n\n        # Check shape of DataFrame (number of rows should be 505)\n        self.assertEqual(df.shape, (505, 14))\n\n        # Check column names\n        expected_columns = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n        self.assertListEqual(list(df.columns), expected_columns)\n\n        # Check that correlation matrix is a DataFrame\n        self.assertIsInstance(corr, pd.DataFrame)\n\n        # Check correlation matrix shape\n        self.assertEqual(corr.shape, (14, 14))\n\n        # Correlation matrix should be symmetric\n        self.assertTrue((corr.values == corr.values.T).all())\n\n        # Diagonal values should be 1\n        self.assertTrue(np.allclose(np.diag(corr), 1))\n",
        "code": "import pandas as pd\nimport numpy as np\n\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\"):\n    import urllib.request\n\n    response = urllib.request.urlopen(data_url)\n    raw_data = response.read().decode('utf-8').splitlines()\n\n    # Remove empty lines\n    raw_data = [line for line in raw_data if line.strip() != '']\n\n    # Skip header (first 22 lines)\n    data_lines = raw_data[22:]\n\n    data = []\n    # Process data lines in pairs\n    for i in range(0, len(data_lines) - 1, 2):\n        first_line_nums = list(map(float, data_lines[i].strip().split()))\n        second_line_nums = list(map(float, data_lines[i + 1].strip().split()))\n        sample = first_line_nums + second_line_nums\n        if len(sample) != 14:\n            # If a sample does not have 14 features, skip it (defensive)\n            continue\n        data.append(sample)\n\n    data = np.array(data)\n\n    column_names = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n\n    df = pd.DataFrame(data, columns=column_names)\n\n    corr = df.corr()\n\n    return df, corr\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/101_3",
        "turn": "3",
        "instruct_prompt": "Plot the heatmap of the correlation matrix with annotations showing correlation values, using Seaborn, and return the matplotlib.axes.Axes object containing the heatmap.",
        "test": "import unittest\nimport matplotlib.axes\n\nclass TestCases(unittest.TestCase):\n    def test_heatmap_axes_returned(self):\n        from matplotlib.axes import Axes\n        ax = task_func()\n        self.assertIsInstance(ax, Axes, \"The returned object should be a matplotlib.axes.Axes instance.\")\n\n    def test_heatmap_annotations(self):\n        import matplotlib.text\n        ax = task_func()\n        # Check if there are text annotations on the heatmap\n        texts = [child for child in ax.get_children() if isinstance(child, matplotlib.text.Text)]\n        # There should be many annotation texts (one for each cell in the correlation matrix)\n        self.assertTrue(len(texts) >= 14*14, \"There should be annotation texts for each cell in the heatmap.\")\n",
        "code": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\"):\n    import urllib.request\n\n    response = urllib.request.urlopen(data_url)\n    raw_data = response.read().decode('utf-8').splitlines()\n\n    # Remove empty lines\n    raw_data = [line for line in raw_data if line.strip() != '']\n\n    # Skip header (first 22 lines)\n    data_lines = raw_data[22:]\n\n    data = []\n    # Process data lines in pairs\n    for i in range(0, len(data_lines) - 1, 2):\n        first_line_nums = list(map(float, data_lines[i].strip().split()))\n        second_line_nums = list(map(float, data_lines[i + 1].strip().split()))\n        sample = first_line_nums + second_line_nums\n        if len(sample) != 14:\n            # If a sample does not have 14 features, skip it (defensive)\n            continue\n        data.append(sample)\n\n    data = np.array(data)\n\n    column_names = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n\n    df = pd.DataFrame(data, columns=column_names)\n\n    corr = df.corr()\n\n    plt.figure(figsize=(10, 8))\n    ax = sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', cbar=True)\n\n    return ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/101_4",
        "turn": "4",
        "instruct_prompt": "Add exception handling to the function: if any error occurs during data loading, correlation calculation, plotting, or saving, raise a ValueError with a descriptive message.",
        "test": "import unittest\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for tests\nfrom matplotlib.axes import Axes\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    def test_valid_url(self):\n        # Test that the function returns a matplotlib Axes object for the valid data URL\n        try:\n            ax = task_func()\n        except Exception as e:\n            self.fail(f\"task_func raised an exception unexpectedly: {e}\")\n        self.assertIsInstance(ax, Axes)\n\n    def test_invalid_url(self):\n        # Test that an invalid URL raises a ValueError with descriptive message\n        with self.assertRaises(ValueError) as cm:\n            task_func(data_url=\"http://invalid-url\")\n        self.assertIn(\"Error occurred during task_func execution\", str(cm.exception))\n\n    def test_malformed_data(self):\n        # Patch urllib.request.urlopen to return malformed data (non-numeric strings)\n        class FakeResponse:\n            def read(self):\n                return b\"This is not a valid dataset\\nJust some random text\\n\"\n\n        with patch('urllib.request.urlopen', return_value=FakeResponse()):\n            with self.assertRaises(ValueError) as cm:\n                task_func(\"http://fake-url\")\n            self.assertIn(\"Error occurred during task_func execution\", str(cm.exception))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\"):\n    import urllib.request\n    try:\n        response = urllib.request.urlopen(data_url)\n        raw_data = response.read().decode('utf-8').splitlines()\n\n        # Remove empty lines\n        raw_data = [line for line in raw_data if line.strip() != '']\n\n        # Skip header (first 22 lines)\n        data_lines = raw_data[22:]\n\n        data = []\n        # Process data lines in pairs\n        for i in range(0, len(data_lines) - 1, 2):\n            first_line_nums = list(map(float, data_lines[i].strip().split()))\n            second_line_nums = list(map(float, data_lines[i + 1].strip().split()))\n            sample = first_line_nums + second_line_nums\n            if len(sample) != 14:\n                # If a sample does not have 14 features, skip it (defensive)\n                continue\n            data.append(sample)\n\n        data = np.array(data)\n\n        column_names = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n\n        df = pd.DataFrame(data, columns=column_names)\n\n        corr = df.corr()\n\n        plt.figure(figsize=(10, 8))\n        ax = sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', cbar=True)\n\n        return ax\n    except Exception as e:\n        raise ValueError(f\"Error occurred during task_func execution: {e}\")\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/101_5",
        "turn": "5",
        "instruct_prompt": "Add an optional parameter to save the generated heatmap plot to a specified file path if provided.",
        "test": "import unittest\nimport os\nimport tempfile\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    def test_heatmap_return_type(self):\n        # Test that the returned object is a matplotlib Axes\n        ax = task_func()\n        import matplotlib.axes\n        self.assertIsInstance(ax, matplotlib.axes.Axes)\n\n    def test_save_heatmap_file_created(self):\n        # Test that the heatmap is saved when save_path is given\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            file_path = os.path.join(tmpdirname, 'heatmap.png')\n            ax = task_func(save_path=file_path)\n            self.assertTrue(os.path.isfile(file_path))\n\n    def test_save_heatmap_file_content_not_empty(self):\n        # Test that the saved file is not empty\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            file_path = os.path.join(tmpdirname, 'heatmap.png')\n            task_func(save_path=file_path)\n            self.assertGreater(os.path.getsize(file_path), 0)\n",
        "code": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", save_path=None):\n    import urllib.request\n    try:\n        response = urllib.request.urlopen(data_url)\n        raw_data = response.read().decode('utf-8').splitlines()\n\n        # Remove empty lines\n        raw_data = [line for line in raw_data if line.strip() != '']\n\n        # Skip header (first 22 lines)\n        data_lines = raw_data[22:]\n\n        data = []\n        # Process data lines in pairs\n        for i in range(0, len(data_lines) - 1, 2):\n            first_line_nums = list(map(float, data_lines[i].strip().split()))\n            second_line_nums = list(map(float, data_lines[i + 1].strip().split()))\n            sample = first_line_nums + second_line_nums\n            if len(sample) != 14:\n                # If a sample does not have 14 features, skip it (defensive)\n                continue\n            data.append(sample)\n\n        data = np.array(data)\n\n        column_names = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n\n        df = pd.DataFrame(data, columns=column_names)\n\n        corr = df.corr()\n\n        plt.figure(figsize=(10, 8))\n        ax = sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', cbar=True)\n\n        if save_path is not None:\n            plt.savefig(save_path)\n\n        return ax\n    except Exception as e:\n        raise ValueError(f\"Error occurred during task_func execution: {e}\")\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 14,
    "task_id": "BigCodeBench/108",
    "mt_data": [
      {
        "task_id": "BigCodeBench/108_1",
        "turn": "1",
        "instruct_prompt": "Decompose the 'value' column of a DataFrame time series into trend, seasonality, and residuals using statsmodels' seasonal_decompose. You should write self-contained code starting with:\n```\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n```",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic_additive(self):\n        # Create a daily time series with at least 2 full weekly cycles (period=7)\n        rng = pd.date_range('2020-01-01', periods=21, freq='D')  # 3 weeks\n        np.random.seed(0)\n        trend = np.linspace(10, 20, 21)\n        seasonal = 2 * np.sin(2 * np.pi * ((rng.dayofyear - 1) % 7) / 7)  # weekly seasonality\n        noise = np.random.normal(0, 0.5, 21)\n        values = trend + seasonal + noise\n        df = pd.DataFrame({'value': values}, index=rng)\n\n        result = task_func(df, freq='D', decomposition_model='additive')\n\n        # Check keys\n        self.assertIn('trend', result)\n        self.assertIn('seasonal', result)\n        self.assertIn('resid', result)\n\n        # Check that returned components are pandas Series with the same index\n        self.assertIsInstance(result['trend'], pd.Series)\n        self.assertIsInstance(result['seasonal'], pd.Series)\n        self.assertIsInstance(result['resid'], pd.Series)\n\n        self.assertTrue(result['trend'].index.equals(df.index))\n        self.assertTrue(result['seasonal'].index.equals(df.index))\n        self.assertTrue(result['resid'].index.equals(df.index))\n\n        # Test reconstruction for additive model ignoring NaNs\n        trend = result['trend']\n        seasonal = result['seasonal']\n        resid = result['resid']\n\n        # Drop NaNs to avoid edge effects\n        valid_idx = trend.dropna().index.intersection(seasonal.dropna().index).intersection(resid.dropna().index)\n        reconstructed = trend.loc[valid_idx] + seasonal.loc[valid_idx] + resid.loc[valid_idx]\n        original = df['value'].loc[valid_idx]\n\n        max_diff = (original - reconstructed).abs().max()\n        self.assertLess(max_diff, 2)\n\n    def test_task_func_index_conversion(self):\n        # Provide enough data points (at least 2 * period) for period=7\n        data_len = 14\n        data = {'value': np.arange(1, data_len + 1)}\n        df = pd.DataFrame(data, index=pd.Index(range(data_len)))\n\n        result = task_func(df, freq='D', decomposition_model='additive')\n\n        # The returned components should have datetime index\n        self.assertTrue(isinstance(result['trend'].index, pd.DatetimeIndex))\n        self.assertTrue(isinstance(result['seasonal'].index, pd.DatetimeIndex))\n        self.assertTrue(isinstance(result['resid'].index, pd.DatetimeIndex))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    # Ensure the index is a datetime index\n    if not isinstance(df.index, pd.DatetimeIndex):\n        df = df.copy()\n        df.index = pd.to_datetime(df.index)\n\n    # Determine the period based on freq input if possible\n    period = None\n    if freq == 'D':\n        period = 7\n    elif freq == 'M':\n        period = 12\n    elif freq == 'Q':\n        period = 4\n    elif freq == 'Y':\n        period = 1\n\n    # Only set period if data length >= 2 * period as required by seasonal_decompose\n    if period is not None and len(df) >= 2 * period:\n        decomposition = seasonal_decompose(df['value'], model=decomposition_model, period=period)\n    else:\n        decomposition = seasonal_decompose(df['value'], model=decomposition_model)\n\n    result = {\n        'trend': decomposition.trend,\n        'seasonal': decomposition.seasonal,\n        'resid': decomposition.resid\n    }\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/108_2",
        "turn": "2",
        "instruct_prompt": "Raise a ValueError if 'df' is not a pandas DataFrame or does not contain the columns 'group', 'date', and 'value'.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_invalid_type(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func([1, 2, 3])\n        self.assertIn('pandas DataFrame', str(cm.exception))\n\n    def test_missing_columns(self):\n        df = pd.DataFrame({'group': [1,2], 'date': [pd.Timestamp('2020-01-01'), pd.Timestamp('2020-01-02')]})\n        with self.assertRaises(ValueError) as cm:\n            task_func(df)\n        self.assertIn('must contain the columns', str(cm.exception))\n\n    def test_multiplicative_with_nonpositive_values(self):\n        data = {\n            'group': ['A'] * 14,\n            'date': pd.date_range('2020-01-01', periods=14),\n            'value': [0] + list(range(1,14))  # contains zero\n        }\n        df = pd.DataFrame(data)\n        df.index = df['date']\n        with self.assertRaises(ValueError) as cm:\n            task_func(df, decomposition_model='multiplicative')\n        self.assertIn(\"'value' must be strictly positive\", str(cm.exception))\n\n    def test_valid_input(self):\n        data = {\n            'group': ['A'] * 14,\n            'date': pd.date_range('2020-01-01', periods=14),\n            'value': list(range(1, 15))  # strictly positive\n        }\n        df = pd.DataFrame(data)\n        df.index = df['date']\n        result = task_func(df, freq='D', decomposition_model='multiplicative')\n        self.assertIn('trend', result)\n        self.assertIn('seasonal', result)\n        self.assertIn('resid', result)\n\n    def test_valid_input_additional_column(self):\n        data = {\n            'group': ['A'] * 14,\n            'date': pd.date_range('2020-01-01', periods=14),\n            'value': list(range(1, 15)),\n            'extra': [0]*14\n        }\n        df = pd.DataFrame(data)\n        df.index = df['date']\n        result = task_func(df)\n        self.assertIn('trend', result)\n\n    def test_index_conversion(self):\n        # DataFrame with non-datetime index but date column present\n        data = {\n            'group': ['A'] * 14,\n            'date': pd.date_range('2020-01-01', periods=14),\n            'value': list(range(1, 15))  # strictly positive\n        }\n        df = pd.DataFrame(data)\n        # Default integer index\n        result = task_func(df, freq='D')\n        self.assertIn('trend', result)\n",
        "code": "import pandas as pd\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    # Validate input type and required columns\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df must be a pandas DataFrame.\")\n    required_columns = {'group', 'date', 'value'}\n    if not required_columns.issubset(df.columns):\n        raise ValueError(f\"DataFrame must contain the columns: {required_columns}\")\n\n    # Validate 'value' column for multiplicative model\n    if decomposition_model == 'multiplicative' and (df['value'] <= 0).any():\n        raise ValueError(\"For multiplicative model, 'value' must be strictly positive.\")\n\n    # Ensure the index is a datetime index\n    if not isinstance(df.index, pd.DatetimeIndex):\n        df = df.copy()\n        df.index = pd.to_datetime(df.index)\n\n    # Determine the period based on freq input if possible\n    period = None\n    if freq == 'D':\n        period = 7\n    elif freq == 'M':\n        period = 12\n    elif freq == 'Q':\n        period = 4\n    elif freq == 'Y':\n        period = 1\n\n    # Only set period if data length >= 2 * period as required by seasonal_decompose\n    if period is not None and len(df) >= 2 * period:\n        decomposition = seasonal_decompose(df['value'], model=decomposition_model, period=period)\n    else:\n        decomposition = seasonal_decompose(df['value'], model=decomposition_model)\n\n    result = {\n        'trend': decomposition.trend,\n        'seasonal': decomposition.seasonal,\n        'resid': decomposition.resid\n    }\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/108_3",
        "turn": "3",
        "instruct_prompt": "Raise a ValueError if 'freq' is not a string representing a valid pandas frequency.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a simple DataFrame for testing\n        dates = pd.date_range('2023-01-01', periods=20, freq='D')\n        data = {\n            'group': ['A'] * 20,\n            'date': dates,\n            'value': np.linspace(1, 20, 20)  # strictly positive for multiplicative\n        }\n        self.df = pd.DataFrame(data)\n        self.df.index = self.df['date']\n\n    def test_valid_freq(self):\n        # Should not raise error for valid freq\n        try:\n            result = task_func(self.df, freq='D')\n        except ValueError:\n            self.fail(\"task_func raised ValueError unexpectedly for valid freq 'D'!\")\n\n    def test_invalid_freq_type(self):\n        # freq not string\n        with self.assertRaises(ValueError):\n            task_func(self.df, freq=5)\n\n    def test_invalid_freq_value(self):\n        # freq string but invalid\n        with self.assertRaises(ValueError):\n            task_func(self.df, freq='invalid_freq')\n\n    def test_previous_code_fail_invalid_freq(self):\n        # The previous code does not check freq validity, so it would not raise\n        # We simulate that by calling previous code here (not possible directly)\n        # Instead, we check that current code raises for invalid freq\n        with self.assertRaises(ValueError):\n            task_func(self.df, freq='X')\n\n    def test_valid_non_default_freq(self):\n        # Other valid freq aliases\n        for valid_freq in ['B', 'W', 'M', 'Q', 'A']:\n            try:\n                task_func(self.df, freq=valid_freq)\n            except ValueError:\n                self.fail(f\"task_func raised ValueError unexpectedly for valid freq '{valid_freq}'!\")\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\n# List of valid pandas frequency aliases (common subset)\nVALID_FREQS = {\n    'B', 'C', 'D', 'W', 'M', 'Q', 'A', 'Y', 'H', 'T', 'S', 'L', 'U', 'N'\n}\n\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    # Validate input type and required columns\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df must be a pandas DataFrame.\")\n    required_columns = {'group', 'date', 'value'}\n    if not required_columns.issubset(df.columns):\n        raise ValueError(f\"DataFrame must contain the columns: {required_columns}\")\n\n    # Validate 'freq' parameter: must be string and valid pandas freq alias\n    if not isinstance(freq, str):\n        raise ValueError(\"freq must be a string representing a pandas frequency.\")\n    # Check freq validity by trying to convert to pd.Timedelta or pd.offsets\n    # Some freq strings like 'D', 'M', 'Q' are valid offsets\n    # We'll check if pandas can parse freq as offset alias\n    try:\n        pd.tseries.frequencies.to_offset(freq)\n    except Exception:\n        raise ValueError(f\"freq '{freq}' is not a valid pandas frequency string.\")\n\n    # Validate 'value' column for multiplicative model\n    if decomposition_model == 'multiplicative' and (df['value'] <= 0).any():\n        raise ValueError(\"For multiplicative model, 'value' must be strictly positive.\")\n\n    # Ensure the index is a datetime index\n    if not isinstance(df.index, pd.DatetimeIndex):\n        df = df.copy()\n        df.index = pd.to_datetime(df.index)\n\n    # Determine the period based on freq input if possible\n    period = None\n    if freq == 'D':\n        period = 7\n    elif freq == 'M':\n        period = 12\n    elif freq == 'Q':\n        period = 4\n    elif freq == 'Y':\n        period = 1\n\n    # Only set period if data length >= 2 * period as required by seasonal_decompose\n    if period is not None and len(df) >= 2 * period:\n        decomposition = seasonal_decompose(df['value'], model=decomposition_model, period=period)\n    else:\n        decomposition = seasonal_decompose(df['value'], model=decomposition_model)\n\n    result = {\n        'trend': decomposition.trend,\n        'seasonal': decomposition.seasonal,\n        'resid': decomposition.resid\n    }\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/108_4",
        "turn": "4",
        "instruct_prompt": "Raise a ValueError if 'decomposition_model' is not either 'additive' or 'multiplicative'.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a simple DataFrame with daily freq and positive values\n        dates = pd.date_range('2023-01-01', periods=14, freq='D')\n        self.df_valid = pd.DataFrame({\n            'group': ['A']*14,\n            'date': dates,\n            'value': np.arange(1, 15)\n        }, index=dates)\n\n    def test_invalid_decomposition_model(self):\n        # decomposition_model not in ('additive', 'multiplicative') should raise ValueError\n        with self.assertRaises(ValueError) as cm:\n            task_func(self.df_valid, decomposition_model='invalid_model')\n        self.assertIn(\"decomposition_model must be either 'additive' or 'multiplicative'\", str(cm.exception))\n\n    def test_valid_decomposition_models(self):\n        # Should not raise for valid models\n        for model in ('additive', 'multiplicative'):\n            result = task_func(self.df_valid, decomposition_model=model)\n            self.assertIn('trend', result)\n            self.assertIn('seasonal', result)\n            self.assertIn('resid', result)\n",
        "code": "import pandas as pd\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\n# List of valid pandas frequency aliases (common subset)\nVALID_FREQS = {\n    'B', 'C', 'D', 'W', 'M', 'Q', 'A', 'Y', 'H', 'T', 'S', 'L', 'U', 'N'\n}\n\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    # Validate input type and required columns\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df must be a pandas DataFrame.\")\n    required_columns = {'group', 'date', 'value'}\n    if not required_columns.issubset(df.columns):\n        raise ValueError(f\"DataFrame must contain the columns: {required_columns}\")\n\n    # Validate 'freq' parameter: must be string and valid pandas freq alias\n    if not isinstance(freq, str):\n        raise ValueError(\"freq must be a string representing a pandas frequency.\")\n    try:\n        pd.tseries.frequencies.to_offset(freq)\n    except Exception:\n        raise ValueError(f\"freq '{freq}' is not a valid pandas frequency string.\")\n\n    # Validate decomposition_model parameter\n    if decomposition_model not in ('additive', 'multiplicative'):\n        raise ValueError(\"decomposition_model must be either 'additive' or 'multiplicative'.\")\n\n    # Validate 'value' column for multiplicative model\n    if decomposition_model == 'multiplicative' and (df['value'] <= 0).any():\n        raise ValueError(\"For multiplicative model, 'value' must be strictly positive.\")\n\n    # Ensure the index is a datetime index\n    if not isinstance(df.index, pd.DatetimeIndex):\n        df = df.copy()\n        df.index = pd.to_datetime(df.index)\n\n    # Determine the period based on freq input if possible\n    period = None\n    if freq == 'D':\n        period = 7\n    elif freq == 'M':\n        period = 12\n    elif freq == 'Q':\n        period = 4\n    elif freq == 'Y':\n        period = 1\n\n    # Only set period if data length >= 2 * period as required by seasonal_decompose\n    if period is not None and len(df) >= 2 * period:\n        decomposition = seasonal_decompose(df['value'], model=decomposition_model, period=period)\n    else:\n        decomposition = seasonal_decompose(df['value'], model=decomposition_model)\n\n    result = {\n        'trend': decomposition.trend,\n        'seasonal': decomposition.seasonal,\n        'resid': decomposition.resid\n    }\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/108_5",
        "turn": "5",
        "instruct_prompt": "Ensure 'value' column is numeric and has no missing values after setting 'date' as index and reindexing with the given frequency; raise a ValueError otherwise. Return a tuple containing the decomposition result object and a matplotlib Axes object showing the original 'value' time series plot.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Base DataFrame\n        dates = pd.date_range('2023-01-01', periods=14, freq='D')\n        self.df = pd.DataFrame({\n            'group': ['A']*14,\n            'date': dates,\n            'value': np.arange(1, 15, dtype=float)\n        })\n\n    def test_valid_numeric_no_missing(self):\n        # Normal case, no missing values, numeric\n        decomposition, ax = task_func(self.df, freq='D', decomposition_model='additive')\n        self.assertTrue(hasattr(decomposition, 'trend'))\n        self.assertIsInstance(ax, Axes)\n\n    def test_value_not_numeric_after_reindex(self):\n        df = self.df.copy()\n        df.loc[5, 'value'] = 'non-numeric'\n        with self.assertRaises(ValueError) as cm:\n            task_func(df, freq='D')\n        self.assertIn(\"'value' column must be numeric\", str(cm.exception))\n\n    def test_value_has_missing_after_reindex(self):\n        df = self.df.copy()\n        # Remove one date to cause missing after reindex\n        df = df.drop(df.index[5])\n        with self.assertRaises(ValueError) as cm:\n            task_func(df, freq='D')\n        self.assertIn(\"'value' column has missing values\", str(cm.exception))\n\n    def test_multiplicative_with_nonpositive_value(self):\n        df = self.df.copy()\n        df.loc[0, 'value'] = 0\n        with self.assertRaises(ValueError) as cm:\n            task_func(df, freq='D', decomposition_model='multiplicative')\n        self.assertIn(\"For multiplicative model, 'value' must be strictly positive\", str(cm.exception))\n\n    def test_return_types(self):\n        decomposition, ax = task_func(self.df, freq='D', decomposition_model='multiplicative')\n        # decomposition is seasonal_decompose result\n        self.assertTrue(hasattr(decomposition, 'trend'))\n        self.assertIsInstance(ax, Axes)\n\n    def test_index_is_date_after_reindex(self):\n        decomposition, ax = task_func(self.df, freq='D')\n        # The index used should be DatetimeIndex\n        self.assertIsInstance(decomposition.trend.index, pd.DatetimeIndex)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    # Validate input type and required columns\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input df must be a pandas DataFrame.\")\n    required_columns = {'group', 'date', 'value'}\n    if not required_columns.issubset(df.columns):\n        raise ValueError(f\"DataFrame must contain the columns: {required_columns}\")\n\n    # Validate 'freq' parameter: must be string and valid pandas freq alias\n    if not isinstance(freq, str):\n        raise ValueError(\"freq must be a string representing a pandas frequency.\")\n    try:\n        pd.tseries.frequencies.to_offset(freq)\n    except Exception:\n        raise ValueError(f\"freq '{freq}' is not a valid pandas frequency string.\")\n\n    # Validate decomposition_model parameter\n    if decomposition_model not in ('additive', 'multiplicative'):\n        raise ValueError(\"decomposition_model must be either 'additive' or 'multiplicative'.\")\n\n    # Set 'date' as index\n    df = df.copy()\n    df['date'] = pd.to_datetime(df['date'])\n    df.set_index('date', inplace=True)\n\n    # Reindex with given frequency\n    idx = pd.date_range(start=df.index.min(), end=df.index.max(), freq=freq)\n    df = df.reindex(idx)\n\n    # Check 'value' column is numeric and has no missing values\n    if not pd.api.types.is_numeric_dtype(df['value']):\n        raise ValueError(\"'value' column must be numeric after reindexing.\")\n    if df['value'].isnull().any():\n        raise ValueError(\"'value' column has missing values after reindexing.\")\n\n    # Validate 'value' column for multiplicative model\n    if decomposition_model == 'multiplicative' and (df['value'] <= 0).any():\n        raise ValueError(\"For multiplicative model, 'value' must be strictly positive.\")\n\n    # Determine the period based on freq input if possible\n    period = None\n    if freq == 'D':\n        period = 7\n    elif freq == 'M':\n        period = 12\n    elif freq == 'Q':\n        period = 4\n    elif freq == 'Y':\n        period = 1\n\n    # Only set period if data length >= 2 * period as required by seasonal_decompose\n    if period is not None and len(df) >= 2 * period:\n        decomposition = seasonal_decompose(df['value'], model=decomposition_model, period=period)\n    else:\n        decomposition = seasonal_decompose(df['value'], model=decomposition_model)\n\n    # Plot original 'value' time series\n    fig, ax = plt.subplots()\n    ax.plot(df.index, df['value'], label='value')\n    ax.set_xlabel('date')\n    ax.set_ylabel('value')\n    ax.set_title('Original value time series')\n    ax.legend()\n\n    return decomposition, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 15,
    "task_id": "BigCodeBench/120",
    "mt_data": [
      {
        "task_id": "BigCodeBench/120_1",
        "turn": "1",
        "instruct_prompt": "Generate a pandas Series of random dates within a specified date range, including both start_date and end_date. You should write self-contained code starting with:\n```\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n```",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_dates_within_range(self):\n        start_date = datetime(2020, 1, 1)\n        end_date = datetime(2020, 12, 31)\n        series = task_func(start_date, end_date, seed=123)\n        self.assertIsInstance(series, pd.Series)\n        self.assertTrue(all(isinstance(d, datetime) for d in series))\n        self.assertTrue(all(start_date <= d <= end_date for d in series))\n\n    def test_inclusive_dates(self):\n        start_date = datetime(2020, 1, 1)\n        end_date = datetime(2020, 1, 3)\n        series = task_func(start_date, end_date, seed=7)\n        # Convert series values to python datetime for safe comparison\n        dates_list = [pd.Timestamp(d).to_pydatetime() if not isinstance(d, datetime) else d for d in series]\n        self.assertIn(start_date, dates_list, \"start_date not found in generated dates\")\n        self.assertIn(end_date, dates_list, \"end_date not found in generated dates\")\n\n    def test_different_seed(self):\n        s1 = task_func(seed=1)\n        s2 = task_func(seed=2)\n        self.assertFalse(s1.equals(s2))\n",
        "code": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    random_seed(seed)\n    delta = (end_date - start_date).days\n    num_dates = 10\n    dates = [start_date, end_date]\n    for _ in range(num_dates - 2):\n        random_day = randint(0, delta)\n        dates.append(start_date + timedelta(days=random_day))\n    return pd.Series(dates)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/120_2",
        "turn": "2",
        "instruct_prompt": "Ensure that the start_date and end_date are datetime.datetime instances and that start_date is not later than end_date. If not, raise a ValueError with an appropriate message.",
        "test": "import unittest\nfrom datetime import datetime\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_valid_dates(self):\n        start = datetime(2020, 1, 1)\n        end = datetime(2020, 1, 10)\n        result = task_func(start, end)\n        self.assertIsInstance(result, pd.Series)\n        self.assertEqual(len(result), 10)\n        # Convert Series values to python datetime.datetime for testing\n        result_dates = result.dt.to_pydatetime() if hasattr(result.dt, 'to_pydatetime') else [pd.to_datetime(d).to_pydatetime() for d in result]\n        self.assertTrue(all(isinstance(d, datetime) for d in result_dates))\n        self.assertIn(start, result_dates)\n        self.assertIn(end, result_dates)\n\n    def test_start_date_not_datetime(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(start_date='2020-01-01', end_date=datetime(2020, 1, 10))\n        self.assertEqual(str(cm.exception), 'start_date must be a datetime.datetime instance')\n\n    def test_end_date_not_datetime(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(start_date=datetime(2020, 1, 1), end_date='2020-01-10')\n        self.assertEqual(str(cm.exception), 'end_date must be a datetime.datetime instance')\n\n    def test_start_date_later_than_end_date(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(start_date=datetime(2020, 1, 11), end_date=datetime(2020, 1, 10))\n        self.assertEqual(str(cm.exception), 'start_date must not be later than end_date')\n",
        "code": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    if not isinstance(start_date, datetime):\n        raise ValueError('start_date must be a datetime.datetime instance')\n    if not isinstance(end_date, datetime):\n        raise ValueError('end_date must be a datetime.datetime instance')\n    if start_date > end_date:\n        raise ValueError('start_date must not be later than end_date')\n\n    random_seed(seed)\n    delta = (end_date - start_date).days\n    num_dates = 10\n    dates = [start_date, end_date]\n    for _ in range(num_dates - 2):\n        random_day = randint(0, delta)\n        dates.append(start_date + timedelta(days=random_day))\n    # Ensure all are datetime.datetime instances (should already be, but for safety)\n    dates = [d if isinstance(d, datetime) else d.to_pydatetime() for d in dates]\n    return pd.Series(dates)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/120_3",
        "turn": "3",
        "instruct_prompt": "Use the seed parameter to initialize the random number generator for reproducible results. The default seed is 42.",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime\nimport random\n\nclass TestCases(unittest.TestCase):\n    def test_reproducible_results_with_seed(self):\n        result1 = task_func(seed=123)\n        result2 = task_func(seed=123)\n        self.assertTrue(result1.equals(result2))\n\n    def test_different_results_with_different_seed(self):\n        result1 = task_func(seed=123)\n        result2 = task_func(seed=456)\n        self.assertFalse(result1.equals(result2))\n\n    def test_default_seed_reproducibility(self):\n        result1 = task_func()\n        result2 = task_func()\n        self.assertTrue(result1.equals(result2))\n\n    def test_dates_within_range(self):\n        start = datetime(2021, 1, 1)\n        end = datetime(2021, 1, 31)\n        series = task_func(start_date=start, end_date=end, seed=1)\n        self.assertTrue(all(start <= d <= end for d in series))\n\n    def test_value_error_on_invalid_start_date(self):\n        with self.assertRaises(ValueError):\n            task_func(start_date='2020-01-01')\n\n    def test_value_error_on_invalid_end_date(self):\n        with self.assertRaises(ValueError):\n            task_func(end_date='2020-12-31')\n\n    def test_value_error_on_start_date_after_end_date(self):\n        with self.assertRaises(ValueError):\n            task_func(start_date=datetime(2021,1,2), end_date=datetime(2021,1,1))\n\n    def test_global_random_state_not_modified(self):\n        # Save state of global random before\n        state_before = random.getstate()\n        task_func(seed=123)\n        state_after = random.getstate()\n        # The global random state should be unchanged by task_func\n        self.assertEqual(state_before, state_after)\n",
        "code": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import Random, randint, seed as random_seed\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    if not isinstance(start_date, datetime):\n        raise ValueError('start_date must be a datetime.datetime instance')\n    if not isinstance(end_date, datetime):\n        raise ValueError('end_date must be a datetime.datetime instance')\n    if start_date > end_date:\n        raise ValueError('start_date must not be later than end_date')\n\n    rng = Random(seed)  # Use local random generator for reproducibility\n    delta = (end_date - start_date).days\n    num_dates = 10\n    dates = [start_date, end_date]\n    for _ in range(num_dates - 2):\n        random_day = rng.randint(0, delta)\n        dates.append(start_date + timedelta(days=random_day))\n    dates = [d if isinstance(d, datetime) else d.to_pydatetime() for d in dates]\n    return pd.Series(dates)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/120_4",
        "turn": "4",
        "instruct_prompt": "Generate the pandas Series so that the length of the series matches the number of days in the date range (inclusive), and each element is a randomly chosen datetime.datetime object within the range [start_date, end_date].",
        "test": "import unittest\nfrom datetime import datetime, timedelta\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_length_and_range(self):\n        start = datetime(2021, 1, 1)\n        end = datetime(2021, 1, 10)\n        result = task_func(start, end, seed=123)\n        expected_length = (end - start).days + 1\n        self.assertEqual(len(result), expected_length)\n        for dt in result:\n            self.assertIsInstance(dt, datetime)\n            self.assertTrue(start <= dt <= end)\n\n    def test_single_day_range(self):\n        start = datetime(2022, 5, 5)\n        end = datetime(2022, 5, 5)\n        result = task_func(start, end, seed=99)\n        self.assertEqual(len(result), 1)\n        self.assertTrue(all(dt == start for dt in result))\n\n    def test_invalid_input(self):\n        with self.assertRaises(ValueError):\n            task_func('2020-01-01', datetime(2020,1,2))\n        with self.assertRaises(ValueError):\n            task_func(datetime(2020,1,2), '2020-01-01')\n        with self.assertRaises(ValueError):\n            task_func(datetime(2020,1,3), datetime(2020,1,2))\n",
        "code": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import Random\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    if not isinstance(start_date, datetime):\n        raise ValueError('start_date must be a datetime.datetime instance')\n    if not isinstance(end_date, datetime):\n        raise ValueError('end_date must be a datetime.datetime instance')\n    if start_date > end_date:\n        raise ValueError('start_date must not be later than end_date')\n\n    rng = Random(seed)  # Use local random generator for reproducibility\n    delta = (end_date - start_date).days\n    length = delta + 1  # number of days inclusive\n    dates = []\n    for _ in range(length):\n        random_day = rng.randint(0, delta)\n        dates.append(start_date + timedelta(days=random_day))\n    return pd.Series(dates)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 16,
    "task_id": "BigCodeBench/123",
    "mt_data": [
      {
        "task_id": "BigCodeBench/123_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a list and appends the element 12 to it. You should write self-contained code starting with:\n```\nimport pandas as pd\nimport os\nimport glob\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_append_12(self):\n        test_list = [1, 2, 3]\n        task_func(test_list)\n        self.assertEqual(test_list[-1], 12)\n        self.assertEqual(len(test_list), 4)\n\n    def test_append_12_empty_list(self):\n        test_list = []\n        task_func(test_list)\n        self.assertEqual(test_list, [12])\n\n    def test_append_12_multiple_calls(self):\n        test_list = [5]\n        task_func(test_list)\n        task_func(test_list)\n        self.assertEqual(test_list[-1], 12)\n        self.assertEqual(test_list[-2], 12)\n        self.assertEqual(len(test_list), 3)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport os\nimport glob\n\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    my_list.append(12)",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/123_2",
        "turn": "2",
        "instruct_prompt": "Calculate the sum of the elements in the modified list and use this sum to determine how many CSV files to read from the specified directory.",
        "test": "import unittest\nimport tempfile\nimport os\nimport pandas as pd\n\ndef create_csv_file(dir_path, filename, data):\n    file_path = os.path.join(dir_path, filename)\n    df = pd.DataFrame(data)\n    df.to_csv(file_path, index=False)\n    return file_path\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_reads_correct_number_of_files(self):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            # Create 5 CSV files\n            for i in range(5):\n                create_csv_file(tmpdirname, f'file{i}.csv', {'a': [i], 'b': [i*2]})\n\n            # Provide a list whose sum after appending 12 is 15 (3 + 0 + 0 + 0 + 0 + 12)\n            # So it should read 15 files but only 5 exist, so it reads 5\n            my_list = [3]\n            dfs = task_func(my_list, file_dir=tmpdirname)\n            self.assertEqual(len(dfs), 5)\n\n            # Provide a list whose sum after appending 12 is 10 (e.g., [ -2, 0, 0, 0 ] + 12 = 10)\n            my_list = [-2, 0, 0, 0]\n            dfs = task_func(my_list, file_dir=tmpdirname)\n            self.assertEqual(len(dfs), 10 if 10 <= 5 else 5)  # Actually 5 since only 5 files exist\n\n            # Provide a list whose sum after appending 12 is 3, should read 3 files\n            my_list = [-9]\n            dfs = task_func(my_list, file_dir=tmpdirname)\n            self.assertEqual(len(dfs), 3)\n\n    def test_task_func_returns_empty_list_when_no_files(self):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            my_list = [1, 1]\n            dfs = task_func(my_list, file_dir=tmpdirname)\n            self.assertEqual(dfs, [])\n",
        "code": "import pandas as pd\nimport os\nimport glob\n\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    my_list.append(12)\n    total = sum(my_list)\n    # Find all files with the given extension in the directory\n    files = sorted(glob.glob(os.path.join(file_dir, '*' + file_ext)))\n    # Determine how many files to read based on total\n    num_files_to_read = min(total, len(files))\n    dfs = []\n    for i in range(num_files_to_read):\n        df = pd.read_csv(files[i])\n        dfs.append(df)\n    return dfs\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/123_3",
        "turn": "3",
        "instruct_prompt": "Concatenate the determined number of CSV files from the directory into a single pandas DataFrame and return it.",
        "test": "import unittest\nimport os\nimport shutil\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = './test_data_files/'\n        os.makedirs(self.test_dir, exist_ok=True)\n        # Create some csv files\n        df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n        df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n        df3 = pd.DataFrame({'A': [9, 10], 'B': [11, 12]})\n        df1.to_csv(os.path.join(self.test_dir, 'file1.csv'), index=False)\n        df2.to_csv(os.path.join(self.test_dir, 'file2.csv'), index=False)\n        df3.to_csv(os.path.join(self.test_dir, 'file3.csv'), index=False)\n\n    def tearDown(self):\n        # Remove the temporary directory and files\n        shutil.rmtree(self.test_dir)\n\n    def test_concatenate_csv_files(self):\n        my_list = [1, 2]\n        # sum(my_list) + 12 = 15, but only 3 files exist, so all 3 should be read and concatenated\n        result_df = task_func(my_list, file_dir=self.test_dir, file_ext='.csv')\n        # The resulting dataframe should have 6 rows (2 rows per file * 3 files)\n        self.assertEqual(len(result_df), 6)\n        # Check that the columns are as expected\n        self.assertListEqual(list(result_df.columns), ['A', 'B'])\n        # Check values from first file\n        self.assertTrue((result_df.iloc[0] == pd.Series({'A': 1, 'B': 3})).all())\n        # Check values from last file\n        self.assertTrue((result_df.iloc[5] == pd.Series({'A': 10, 'B': 12})).all())\n\n    def test_no_files(self):\n        # Use empty directory\n        empty_dir = './empty_test_dir/'\n        os.makedirs(empty_dir, exist_ok=True)\n        my_list = [1]\n        result_df = task_func(my_list, file_dir=empty_dir, file_ext='.csv')\n        self.assertTrue(result_df.empty)\n        shutil.rmtree(empty_dir)\n\n    def test_partial_files(self):\n        my_list = [0]  # sum=0+12=12, but only 3 files exist\n        result_df = task_func(my_list, file_dir=self.test_dir, file_ext='.csv')\n        # All 3 files concatenated\n        self.assertEqual(len(result_df), 6)\n\n    def test_limit_files(self):\n        my_list = [-10]  # sum = 2, so only 2 files should be concatenated\n        result_df = task_func(my_list, file_dir=self.test_dir, file_ext='.csv')\n        self.assertEqual(len(result_df), 4)  # 2 files * 2 rows each\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import pandas as pd\nimport os\nimport glob\n\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    my_list.append(12)\n    total = sum(my_list)\n    # Find all files with the given extension in the directory\n    files = sorted(glob.glob(os.path.join(file_dir, '*' + file_ext)))\n    # Determine how many files to read based on total\n    num_files_to_read = min(total, len(files))\n    dfs = []\n    for i in range(num_files_to_read):\n        df = pd.read_csv(files[i])\n        dfs.append(df)\n    # Concatenate all dataframes into one\n    if dfs:\n        result_df = pd.concat(dfs, ignore_index=True)\n    else:\n        result_df = pd.DataFrame()\n    return result_df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/123_4",
        "turn": "4",
        "instruct_prompt": "Raise a TypeError if 'my_list' is not a list and raise a FileNotFoundError if no CSV files are found in the specified directory.",
        "test": "import unittest\nimport os\nimport tempfile\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        # Cleanup the temporary directory\n        self.test_dir.cleanup()\n\n    def create_csv_file(self, filename, content):\n        path = os.path.join(self.test_dir.name, filename)\n        with open(path, 'w') as f:\n            f.write(content)\n        return path\n\n    def test_type_error_when_my_list_not_list(self):\n        with self.assertRaises(TypeError):\n            task_func('not a list', file_dir=self.test_dir.name)\n\n    def test_filenotfounderror_when_no_csv_files(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func([], file_dir=self.test_dir.name)\n\n    def test_normal_behavior_with_csv_files(self):\n        # Create two CSV files\n        self.create_csv_file('file1.csv', 'a,b\\n1,2\\n3,4')\n        self.create_csv_file('file2.csv', 'a,b\\n5,6\\n7,8')\n\n        # my_list sum + 12 controls how many files read\n        df = task_func([0], file_dir=self.test_dir.name)  # sum=0+12=12, read all files\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertEqual(len(df), 4)  # 2 rows each file, total 4 rows\n\n    def test_filenotfounderror_with_wrong_extension(self):\n        # Create a CSV file but call with different extension\n        self.create_csv_file('file1.csv', 'a,b\\n1,2')\n        with self.assertRaises(FileNotFoundError):\n            task_func([], file_dir=self.test_dir.name, file_ext='.xyz')\n",
        "code": "import pandas as pd\nimport os\nimport glob\n\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    if not isinstance(my_list, list):\n        raise TypeError(\"my_list must be a list\")\n\n    # Find all files with the given extension in the directory\n    files = sorted(glob.glob(os.path.join(file_dir, '*' + file_ext)))\n    if not files:\n        raise FileNotFoundError(f\"No {file_ext} files found in directory: {file_dir}\")\n\n    my_list.append(12)\n    total = sum(my_list)\n\n    # Determine how many files to read based on total\n    num_files_to_read = min(total, len(files))\n    dfs = []\n    for i in range(num_files_to_read):\n        df = pd.read_csv(files[i])\n        dfs.append(df)\n\n    # Concatenate all dataframes into one\n    if dfs:\n        result_df = pd.concat(dfs, ignore_index=True)\n    else:\n        result_df = pd.DataFrame()\n\n    return result_df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 17,
    "task_id": "BigCodeBench/124",
    "mt_data": [
      {
        "task_id": "BigCodeBench/124_1",
        "turn": "1",
        "instruct_prompt": "Write a function task_func that takes a list my_list and an integer size (default 100). The function should append the number 12 to my_list and then generate a list of random integers between 1 and 100. The length of this list should be the sum of the elements in my_list, but not exceeding size. The function should return the generated list. You should write self-contained code starting with:```from random import randint, seed as random_seed\ndef task_func(my_list, size=100, seed=100):```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic_functionality(self):\n        my_list = [1, 2, 3]\n        result = task_func(my_list, size=100, seed=1)\n        self.assertIn(12, my_list)  # my_list should be modified by appending 12\n        self.assertEqual(len(result), 18)  # sum([1,2,3,12]) = 18\n        self.assertTrue(all(1 <= num <= 100 for num in result))\n\n    def test_length_capped_by_size(self):\n        my_list = [50, 60]\n        result = task_func(my_list, size=100, seed=2)\n        self.assertIn(12, my_list)\n        self.assertEqual(len(result), 100)  # capped by size\n        self.assertTrue(all(1 <= num <= 100 for num in result))\n\n    def test_default_size(self):\n        my_list = [10]\n        result = task_func(my_list)\n        self.assertIn(12, my_list)\n        expected_length = min(sum(my_list), 100)\n        self.assertEqual(len(result), expected_length)\n\n    def test_seed_reproducibility(self):\n        my_list1 = [5]\n        my_list2 = [5]\n        res1 = task_func(my_list1, seed=42)\n        res2 = task_func(my_list2, seed=42)\n        self.assertEqual(res1, res2)\n\n    def test_append_12(self):\n        my_list = [7, 8]\n        task_func(my_list, seed=5)\n        self.assertEqual(my_list, [7, 8, 12])\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from random import randint, seed as random_seed\n\ndef task_func(my_list, size=100, seed=100):\n    random_seed(seed)\n    my_list.append(12)\n    length = min(sum(my_list), size)\n    return [randint(1, 100) for _ in range(length)]",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/124_2",
        "turn": "2",
        "instruct_prompt": "Add error handling to the function: raise a TypeError if my_list is not a list, and raise a ValueError if any element in my_list is not an int or float.",
        "test": "import unittest\nfrom random import seed as random_seed\n\nclass TestCases(unittest.TestCase):\n    def test_valid_input(self):\n        result = task_func([1, 2.5, 3], size=10, seed=1)\n        self.assertIsInstance(result, list)\n        self.assertLessEqual(len(result), 10)\n\n    def test_type_error(self):\n        with self.assertRaises(TypeError):\n            task_func(\"not a list\")\n\n    def test_value_error(self):\n        with self.assertRaises(ValueError):\n            task_func([1, 2, '3'])\n        with self.assertRaises(ValueError):\n            task_func([None, 2])",
        "code": "from random import randint, seed as random_seed\n\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError(\"my_list must be a list\")\n    for element in my_list:\n        if not isinstance(element, (int, float)):\n            raise ValueError(\"all elements in my_list must be int or float\")\n    random_seed(seed)\n    my_list.append(12)\n    length = min(sum(my_list), size)\n    return [randint(1, 100) for _ in range(length)]",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/124_3",
        "turn": "3",
        "instruct_prompt": "Measure and return the time taken to generate the random integers list as a float (in seconds) along with the list itself.",
        "test": "import unittest\nfrom random import seed as random_seed\nimport time\n\nclass TestCases(unittest.TestCase):\n    def test_valid_output_and_time(self):\n        my_list = [1, 2, 3]\n        size = 10\n        seed = 42\n        random_seed(seed)  # ensure reproducibility outside\n        result, elapsed = task_func(my_list.copy(), size, seed)\n        # Check result is list\n        self.assertIsInstance(result, list)\n        # Check elapsed is float and positive\n        self.assertIsInstance(elapsed, float)\n        self.assertGreaterEqual(elapsed, 0)\n        # Check length of result\n        expected_length = min(sum(my_list) + 12, size)  # 12 appended to my_list\n        self.assertEqual(len(result), expected_length)\n        # Check all elements are int in range 1 to 100\n        for val in result:\n            self.assertIsInstance(val, int)\n            self.assertGreaterEqual(val, 1)\n            self.assertLessEqual(val, 100)\n\n    def test_type_error_for_non_list(self):\n        with self.assertRaises(TypeError):\n            task_func(\"not a list\")\n\n    def test_value_error_for_invalid_elements(self):\n        with self.assertRaises(ValueError):\n            task_func([1, 2, 'a'])\n\n    def test_time_measurement_nonzero(self):\n        my_list = [5, 5]\n        _, elapsed = task_func(my_list, size=1000, seed=1)\n        self.assertIsInstance(elapsed, float)\n        self.assertGreaterEqual(elapsed, 0)\n\n    def test_elapsed_time_changes_with_size(self):\n        my_list = [1, 1]\n        _, elapsed_small = task_func(my_list, size=5, seed=1)\n        _, elapsed_large = task_func(my_list, size=1000, seed=1)\n        self.assertLessEqual(elapsed_small, elapsed_large)\n",
        "code": "from random import randint, seed as random_seed\nimport time\n\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError(\"my_list must be a list\")\n    for element in my_list:\n        if not isinstance(element, (int, float)):\n            raise ValueError(\"all elements in my_list must be int or float\")\n    random_seed(seed)\n    my_list.append(12)\n    length = min(sum(my_list), size)\n    start_time = time.perf_counter()\n    result = [randint(1, 100) for _ in range(length)]\n    end_time = time.perf_counter()\n    elapsed = end_time - start_time\n    return result, elapsed\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/124_4",
        "turn": "4",
        "instruct_prompt": "Plot a histogram of the generated random integers using matplotlib. The histogram should have x-axis labeled 'Number' representing the range 1 to 100, and y-axis labeled 'Frequency' representing the count of each integer. Return a tuple of the time taken and the matplotlib Axes object.",
        "test": "import unittest\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_histogram_and_time(self):\n        original_list = [1, 2, 3]\n        my_list = original_list.copy()  # copy to avoid side effects\n        elapsed, ax = task_func(my_list, size=50, seed=42)\n\n        self.assertIsInstance(elapsed, float)\n        self.assertGreater(elapsed, 0)\n\n        self.assertIsInstance(ax, Axes)\n\n        patches = ax.patches\n        self.assertTrue(len(patches) > 0)\n\n        # Calculate expected length after append\n        expected_length = min(sum(my_list), 50)  # my_list already has 12 appended inside task_func\n\n        total_counts = sum(p.get_height() for p in patches)\n        self.assertEqual(total_counts, expected_length)\n\n    def test_invalid_my_list_type(self):\n        with self.assertRaises(TypeError):\n            task_func('not a list')\n\n    def test_invalid_my_list_elements(self):\n        with self.assertRaises(ValueError):\n            task_func([1, 'two', 3])\n",
        "code": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError(\"my_list must be a list\")\n    for element in my_list:\n        if not isinstance(element, (int, float)):\n            raise ValueError(\"all elements in my_list must be int or float\")\n    random_seed(seed)\n    my_list.append(12)\n    length = min(sum(my_list), size)\n    start_time = time.perf_counter()\n    result = [randint(1, 100) for _ in range(length)]\n    end_time = time.perf_counter()\n    elapsed = end_time - start_time\n\n    fig, ax = plt.subplots()\n    ax.hist(result, bins=range(1, 102), edgecolor='black', align='left')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n\n    return elapsed, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/124_5",
        "turn": "5",
        "instruct_prompt": "Use the seed parameter to set the seed for the random number generator for reproducibility.",
        "test": "import unittest\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    def test_seed_reproducibility_exact_sequence(self):\n        my_list = [1, 2, 3]\n        seed_value = 42\n\n        elapsed1, ax1, result1 = task_func(my_list.copy(), size=50, seed=seed_value)\n        elapsed2, ax2, result2 = task_func(my_list.copy(), size=50, seed=seed_value)\n\n        self.assertEqual(result1, result2, \"Random sequences should be identical for the same seed\")\n\n    def test_seed_reproducibility_different_seed(self):\n        my_list = [1, 2, 3]\n\n        elapsed1, ax1, result1 = task_func(my_list.copy(), size=50, seed=42)\n        elapsed2, ax2, result2 = task_func(my_list.copy(), size=50, seed=24)\n\n        self.assertNotEqual(result1, result2, \"Random sequences should differ for different seeds\")\n\n    def test_invalid_my_list_type(self):\n        with self.assertRaises(TypeError):\n            task_func(\"not a list\")\n\n    def test_invalid_my_list_element(self):\n        with self.assertRaises(ValueError):\n            task_func([1, 'a', 3])\n",
        "code": "from random import randint, seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, size=100, seed=100):\n    if not isinstance(my_list, list):\n        raise TypeError(\"my_list must be a list\")\n    for element in my_list:\n        if not isinstance(element, (int, float)):\n            raise ValueError(\"all elements in my_list must be int or float\")\n    random_seed(seed)\n    my_list.append(12)\n    length = min(int(sum(my_list)), size)\n    start_time = time.perf_counter()\n    result = [randint(1, 100) for _ in range(length)]\n    end_time = time.perf_counter()\n    elapsed = end_time - start_time\n\n    fig, ax = plt.subplots()\n    ax.hist(result, bins=range(1, 102), edgecolor='black', align='left')\n    ax.set_xlabel('Number')\n    ax.set_ylabel('Frequency')\n\n    return elapsed, ax, result\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 18,
    "task_id": "BigCodeBench/129",
    "mt_data": [
      {
        "task_id": "BigCodeBench/129_1",
        "turn": "1",
        "instruct_prompt": "Write a function that fetches the HTML content from a given URL and returns it as text. You should write self-contained code starting with:```import requests\ndef task_func(url='http://example.com'):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        return response.text\n    except requests.ConnectionError as e:\n        raise ConnectionError(f\"Could not connect to URL: {e}\")\n    except requests.HTTPError as e:\n        raise requests.HTTPError(f\"HTTP error occurred: {e}\")\n```",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\nimport requests\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_successful_fetch(self, mock_get):\n        mock_response = Mock()\n        mock_response.raise_for_status = Mock()\n        mock_response.text = '<html>Example</html>'\n        mock_get.return_value = mock_response\n\n        result = task_func('http://test.com')\n        self.assertEqual(result, '<html>Example</html>')\n        mock_get.assert_called_once_with('http://test.com')\n\n    @patch('requests.get')\n    def test_connection_error(self, mock_get):\n        mock_get.side_effect = requests.ConnectionError('Failed to connect')\n\n        with self.assertRaises(ConnectionError) as context:\n            task_func('http://fail.com')\n        self.assertIn('Could not connect to URL', str(context.exception))\n\n    @patch('requests.get')\n    def test_http_error(self, mock_get):\n        mock_response = Mock()\n        mock_response.raise_for_status.side_effect = requests.HTTPError('404 Not Found')\n        mock_get.return_value = mock_response\n\n        with self.assertRaises(requests.HTTPError) as context:\n            task_func('http://error.com')\n        self.assertIn('HTTP error occurred', str(context.exception))\n",
        "code": "import requests\n\ndef task_func(url='http://example.com'):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        return response.text\n    except requests.ConnectionError as e:\n        raise ConnectionError(f\"Could not connect to URL: {e}\")\n    except requests.HTTPError as e:\n        raise requests.HTTPError(f\"HTTP error occurred: {e}\")\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/129_2",
        "turn": "2",
        "instruct_prompt": "Parse the HTML content to find the first <table> element and extract all rows (<tr>) that contain data cells (<td>). Raise a ValueError if no table or no data rows are found.",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_table_with_data_rows(self, mock_get):\n        html_content = '''\n        <html>\n            <body>\n                <table>\n                    <tr><th>Header1</th><th>Header2</th></tr>\n                    <tr><td>Data1</td><td>Data2</td></tr>\n                    <tr><td>Data3</td><td>Data4</td></tr>\n                </table>\n            </body>\n        </html>\n        '''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        data_rows = task_func('http://fakeurl.com')\n        self.assertEqual(len(data_rows), 2)\n        self.assertTrue(all(row.find('td') for row in data_rows))\n\n    @patch('requests.get')\n    def test_no_table(self, mock_get):\n        html_content = '''<html><body><p>No table here</p></body></html>'''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        with self.assertRaises(ValueError) as cm:\n            task_func('http://fakeurl.com')\n        self.assertIn('No table found', str(cm.exception))\n\n    @patch('requests.get')\n    def test_table_without_data_rows(self, mock_get):\n        html_content = '''\n        <html>\n            <body>\n                <table>\n                    <tr><th>Header1</th><th>Header2</th></tr>\n                    <tr><th>Header3</th><th>Header4</th></tr>\n                </table>\n            </body>\n        </html>\n        '''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        with self.assertRaises(ValueError) as cm:\n            task_func('http://fakeurl.com')\n        self.assertIn('No data rows with <td>', str(cm.exception))\n",
        "code": "import requests\nfrom bs4 import BeautifulSoup\n\ndef task_func(url='http://example.com'):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        html = response.text\n    except requests.ConnectionError as e:\n        raise ConnectionError(f\"Could not connect to URL: {e}\")\n    except requests.HTTPError as e:\n        raise requests.HTTPError(f\"HTTP error occurred: {e}\")\n\n    soup = BeautifulSoup(html, 'html.parser')\n    table = soup.find('table')\n    if not table:\n        raise ValueError(\"No table found in the HTML content.\")\n\n    data_rows = []\n    for tr in table.find_all('tr'):\n        if tr.find('td'):\n            data_rows.append(tr)\n\n    if not data_rows:\n        raise ValueError(\"No data rows with <td> found in the table.\")\n\n    return data_rows\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/129_3",
        "turn": "3",
        "instruct_prompt": "Extract the table headers from the <th> elements of the first table, if present, and extract the text from each <td> cell in the data rows into a list of lists representing the table data.",
        "test": "import unittest\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_table_with_headers_and_data(self, mock_get):\n        html = '''\n        <html><body>\n        <table>\n          <tr><th>Name</th><th>Age</th><th>City</th></tr>\n          <tr><td>Alice</td><td>30</td><td>New York</td></tr>\n          <tr><td>Bob</td><td>25</td><td>Los Angeles</td></tr>\n        </table>\n        </body></html>\n        '''\n        mock_get.return_value.status_code = 200\n        mock_get.return_value.text = html\n\n        headers, data = task_func('http://fakeurl.com')\n        self.assertEqual(headers, ['Name', 'Age', 'City'])\n        self.assertEqual(data, [['Alice', '30', 'New York'], ['Bob', '25', 'Los Angeles']])\n\n    @patch('requests.get')\n    def test_table_no_headers(self, mock_get):\n        html = '''\n        <html><body>\n        <table>\n          <tr><td>Alice</td><td>30</td><td>New York</td></tr>\n          <tr><td>Bob</td><td>25</td><td>Los Angeles</td></tr>\n        </table>\n        </body></html>\n        '''\n        mock_get.return_value.status_code = 200\n        mock_get.return_value.text = html\n\n        headers, data = task_func('http://fakeurl.com')\n        self.assertEqual(headers, [])\n        self.assertEqual(data, [['Alice', '30', 'New York'], ['Bob', '25', 'Los Angeles']])\n\n    @patch('requests.get')\n    def test_no_table(self, mock_get):\n        html = '<html><body><p>No table here</p></body></html>'\n        mock_get.return_value.status_code = 200\n        mock_get.return_value.text = html\n\n        with self.assertRaises(ValueError):\n            task_func('http://fakeurl.com')\n\n    @patch('requests.get')\n    def test_table_with_headers_but_no_data_rows(self, mock_get):\n        html = '''\n        <html><body>\n        <table>\n          <tr><th>Name</th><th>Age</th></tr>\n          <tr><th>Header Only</th></tr>\n        </table>\n        </body></html>\n        '''\n        mock_get.return_value.status_code = 200\n        mock_get.return_value.text = html\n\n        headers, data = task_func('http://fakeurl.com')\n        self.assertEqual(headers, ['Name', 'Age'])\n        self.assertEqual(data, [])\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import requests\nfrom bs4 import BeautifulSoup\n\ndef task_func(url='http://example.com'):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        html = response.text\n    except requests.ConnectionError as e:\n        raise ConnectionError(f\"Could not connect to URL: {e}\")\n    except requests.HTTPError as e:\n        raise requests.HTTPError(f\"HTTP error occurred: {e}\")\n\n    soup = BeautifulSoup(html, 'html.parser')\n    table = soup.find('table')\n    if not table:\n        raise ValueError(\"No table found in the HTML content.\")\n\n    # Extract headers from the first <tr> that contains <th>\n    header_row = None\n    for tr in table.find_all('tr'):\n        if tr.find('th'):\n            header_row = tr\n            break\n\n    headers = []\n    if header_row:\n        headers = [th.get_text(strip=True) for th in header_row.find_all('th')]\n\n    # Extract data rows: rows that contain <td> elements\n    data = []\n    for tr in table.find_all('tr'):\n        tds = tr.find_all('td')\n        if tds:\n            row_data = [td.get_text(strip=True) for td in tds]\n            data.append(row_data)\n\n    return headers, data\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/129_4",
        "turn": "4",
        "instruct_prompt": "Convert the extracted table data into a Pandas DataFrame, using the headers as column names if headers exist; otherwise, create an unnamed column DataFrame. Raise a ValueError if the data is empty or if parsing fails.",
        "test": "import unittest\nimport pandas as pd\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.html_with_headers = '''\n        <html><body><table>\n        <tr><th>Name</th><th>Age</th></tr>\n        <tr><td>Alice</td><td>30</td></tr>\n        <tr><td>Bob</td><td>25</td></tr>\n        </table></body></html>\n        '''\n\n        self.html_no_headers = '''\n        <html><body><table>\n        <tr><td>Apple</td><td>Red</td></tr>\n        <tr><td>Banana</td><td>Yellow</td></tr>\n        </table></body></html>\n        '''\n\n        self.html_empty_table = '''\n        <html><body><table></table></body></html>\n        '''\n\n        self.html_no_table = '''\n        <html><body><p>No table here</p></body></html>\n        '''\n\n    @patch('requests.get')\n    def test_with_headers(self, mock_get):\n        mock_get.return_value.status_code = 200\n        mock_get.return_value.text = self.html_with_headers\n\n        df = task_func('http://fakeurl.com')\n\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertListEqual(list(df.columns), ['Name', 'Age'])\n        self.assertEqual(len(df), 2)\n        self.assertEqual(df.iloc[0]['Name'], 'Alice')\n        self.assertEqual(df.iloc[1]['Age'], '25')\n\n    @patch('requests.get')\n    def test_without_headers(self, mock_get):\n        mock_get.return_value.status_code = 200\n        mock_get.return_value.text = self.html_no_headers\n\n        df = task_func('http://fakeurl.com')\n\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertListEqual(list(df.columns), [0, 1])\n        self.assertEqual(len(df), 2)\n        self.assertEqual(df.iloc[0, 0], 'Apple')\n        self.assertEqual(df.iloc[1, 1], 'Yellow')\n\n    @patch('requests.get')\n    def test_empty_table_raises(self, mock_get):\n        mock_get.return_value.status_code = 200\n        mock_get.return_value.text = self.html_empty_table\n\n        with self.assertRaises(ValueError) as cm:\n            task_func('http://fakeurl.com')\n        self.assertIn('No data found', str(cm.exception))\n\n    @patch('requests.get')\n    def test_no_table_raises(self, mock_get):\n        mock_get.return_value.status_code = 200\n        mock_get.return_value.text = self.html_no_table\n\n        with self.assertRaises(ValueError) as cm:\n            task_func('http://fakeurl.com')\n        self.assertIn('No table found', str(cm.exception))\n",
        "code": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef task_func(url='http://example.com'):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        html = response.text\n    except requests.ConnectionError as e:\n        raise ConnectionError(f\"Could not connect to URL: {e}\")\n    except requests.HTTPError as e:\n        raise requests.HTTPError(f\"HTTP error occurred: {e}\")\n\n    soup = BeautifulSoup(html, 'html.parser')\n    table = soup.find('table')\n    if not table:\n        raise ValueError(\"No table found in the HTML content.\")\n\n    # Extract headers from the first <tr> that contains <th>\n    header_row = None\n    for tr in table.find_all('tr'):\n        if tr.find('th'):\n            header_row = tr\n            break\n\n    headers = []\n    if header_row:\n        headers = [th.get_text(strip=True) for th in header_row.find_all('th')]\n\n    # Extract data rows: rows that contain <td> elements\n    data = []\n    for tr in table.find_all('tr'):\n        tds = tr.find_all('td')\n        if tds:\n            row_data = [td.get_text(strip=True) for td in tds]\n            data.append(row_data)\n\n    if not data:\n        raise ValueError(\"No data found in the table.\")\n\n    try:\n        if headers:\n            df = pd.DataFrame(data, columns=headers)\n        else:\n            df = pd.DataFrame(data)\n    except Exception as e:\n        raise ValueError(f\"Failed to parse table data into DataFrame: {e}\")\n\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 19,
    "task_id": "BigCodeBench/139",
    "mt_data": [
      {
        "task_id": "BigCodeBench/139_1",
        "turn": "1",
        "instruct_prompt": "Write a function task_func that takes a DataFrame and draws a histogram for each numeric column, returning a list of Matplotlib Axes objects. You should write self-contained code starting with:\n```\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(df):\n```",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic(self):\n        data = {\n            'A': [1, 2, 3, 4, 5],\n            'B': [5, 4, 3, 2, 1],\n            'C': ['a', 'b', 'c', 'd', 'e']\n        }\n        df = pd.DataFrame(data)\n        axes = task_func(df)\n        # There should be histograms only for numeric columns A and B\n        self.assertEqual(len(axes), 2)\n        for ax in axes:\n            self.assertIsInstance(ax, plt.Axes)\n            self.assertGreater(len(ax.patches), 0)\n\n    def test_task_func_with_nan(self):\n        data = {\n            'X': [1, 2, np.nan, 4, 5],\n            'Y': [np.nan, np.nan, np.nan, np.nan, np.nan],\n            'Z': ['foo', 'bar', 'baz', 'qux', 'quux']\n        }\n        df = pd.DataFrame(data)\n        axes = task_func(df)\n        # Only 'X' is numeric and has some valid values\n        self.assertEqual(len(axes), 1)\n        ax = axes[0]\n        self.assertIsInstance(ax, plt.Axes)\n        self.assertGreater(len(ax.patches), 0)\n\n    def test_task_func_no_numeric(self):\n        data = {\n            'A': ['one', 'two', 'three'],\n            'B': ['x', 'y', 'z']\n        }\n        df = pd.DataFrame(data)\n        axes = task_func(df)\n        # No numeric columns, so return empty list\n        self.assertEqual(axes, [])\n",
        "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    axes = []\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    for col in numeric_cols:\n        if df[col].dropna().empty:\n            continue  # skip columns with no valid numeric data\n        fig, ax = plt.subplots()\n        ax.hist(df[col].dropna())\n        ax.set_title(f'Histogram of {col}')\n        axes.append(ax)\n    return axes\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/139_2",
        "turn": "2",
        "instruct_prompt": "The function should raise a ValueError if the input is not a non-empty pandas DataFrame.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_valid_dataframe(self):\n        df = pd.DataFrame({\n            'A': [1, 2, 3, 4],\n            'B': [4, 5, 6, 7],\n            'C': ['a', 'b', 'c', 'd']\n        })\n        axes = task_func(df)\n        self.assertTrue(all(isinstance(ax, Axes) for ax in axes))\n        self.assertEqual(len(axes), 2)  # Only numeric columns A and B\n\n    def test_empty_dataframe(self):\n        df = pd.DataFrame()\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_non_dataframe_input(self):\n        with self.assertRaises(ValueError):\n            task_func([1, 2, 3])\n        with self.assertRaises(ValueError):\n            task_func(None)\n        with self.assertRaises(ValueError):\n            task_func('not a dataframe')\n\n    def test_dataframe_with_no_numeric(self):\n        df = pd.DataFrame({'A': ['a', 'b'], 'B': ['c', 'd']})\n        axes = task_func(df)\n        self.assertEqual(axes, [])\n",
        "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError('Input must be a non-empty pandas DataFrame')\n    axes = []\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    for col in numeric_cols:\n        if df[col].dropna().empty:\n            continue  # skip columns with no valid numeric data\n        fig, ax = plt.subplots()\n        ax.hist(df[col].dropna())\n        ax.set_title(f'Histogram of {col}')\n        axes.append(ax)\n    return axes\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/139_3",
        "turn": "3",
        "instruct_prompt": "The function should raise a ValueError if the DataFrame contains no numeric columns.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_no_numeric_columns_raises(self):\n        df = pd.DataFrame({'A': ['a', 'b', 'c'], 'B': ['x', 'y', 'z']})\n        with self.assertRaises(ValueError) as cm:\n            task_func(df)\n        self.assertEqual(str(cm.exception), 'DataFrame contains no numeric columns')\n\n    def test_numeric_columns_returns_axes(self):\n        df = pd.DataFrame({'num1': [1, 2, 3, 4], 'num2': [10, 20, 30, 40]})\n        axes = task_func(df)\n        self.assertEqual(len(axes), 2)\n        for ax in axes:\n            self.assertIsInstance(ax, plt.Axes)\n\n    def test_mixed_columns(self):\n        df = pd.DataFrame({'num': [1, 2, 3], 'cat': ['a', 'b', 'c']})\n        axes = task_func(df)\n        self.assertEqual(len(axes), 1)\n        self.assertIsInstance(axes[0], plt.Axes)\n\n    def test_empty_dataframe_raises(self):\n        df = pd.DataFrame()\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_non_dataframe_input_raises(self):\n        with self.assertRaises(ValueError):\n            task_func([1, 2, 3])\n",
        "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError('Input must be a non-empty pandas DataFrame')\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if len(numeric_cols) == 0:\n        raise ValueError('DataFrame contains no numeric columns')\n    axes = []\n    for col in numeric_cols:\n        if df[col].dropna().empty:\n            continue  # skip columns with no valid numeric data\n        fig, ax = plt.subplots()\n        ax.hist(df[col].dropna())\n        ax.set_title(f'Histogram of {col}')\n        axes.append(ax)\n    return axes\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/139_4",
        "turn": "4",
        "instruct_prompt": "Each histogram should have the column name as the plot title, 'Value' as the x-axis label, and 'Frequency' as the y-axis label.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_histogram_labels(self):\n        data = {\n            'A': [1, 2, 2, 3, 4, 5],\n            'B': [10, 10, 20, 30, 30, 30],\n            'C': ['x', 'y', 'z', 'x', 'y', 'z']\n        }\n        df = pd.DataFrame(data)\n        axes = task_func(df)\n        # Only columns A and B are numeric\n        self.assertEqual(len(axes), 2)\n        for ax, col in zip(axes, ['A', 'B']):\n            self.assertEqual(ax.get_title(), col)\n            self.assertEqual(ax.get_xlabel(), 'Value')\n            self.assertEqual(ax.get_ylabel(), 'Frequency')\n\n    def test_empty_dataframe(self):\n        df = pd.DataFrame()\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_no_numeric_columns(self):\n        df = pd.DataFrame({'X': ['a', 'b', 'c']})\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_column_with_all_nan(self):\n        df = pd.DataFrame({'A': [np.nan, np.nan], 'B': [1, 2]})\n        axes = task_func(df)\n        # Should only plot column B\n        self.assertEqual(len(axes), 1)\n        self.assertEqual(axes[0].get_title(), 'B')\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        raise ValueError('Input must be a non-empty pandas DataFrame')\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    if len(numeric_cols) == 0:\n        raise ValueError('DataFrame contains no numeric columns')\n    axes = []\n    for col in numeric_cols:\n        if df[col].dropna().empty:\n            continue  # skip columns with no valid numeric data\n        fig, ax = plt.subplots()\n        ax.hist(df[col].dropna())\n        ax.set_title(col)  # column name as plot title\n        ax.set_xlabel('Value')  # x-axis label\n        ax.set_ylabel('Frequency')  # y-axis label\n        axes.append(ax)\n    return axes\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 20,
    "task_id": "BigCodeBench/147",
    "mt_data": [
      {
        "task_id": "BigCodeBench/147_1",
        "turn": "1",
        "instruct_prompt": "Check if a given port is open on a list of IP addresses. You should write self-contained code starting with:\n```\nimport socket\ndef task_func(ip_list, port):\n```",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport socket\n\ndef fake_connect_success(addr):\n    return None\n\ndef fake_connect_fail(addr):\n    raise socket.error\n\nclass TestCases(unittest.TestCase):\n    @patch('socket.socket')\n    def test_all_ports_open(self, mock_socket):\n        mock_sock_instance = MagicMock()\n        mock_sock_instance.connect.side_effect = fake_connect_success\n        mock_socket.return_value = mock_sock_instance\n        ips = ['192.168.1.1', '10.0.0.1']\n        port = 80\n        result = task_func(ips, port)\n        self.assertEqual(result, {ip: True for ip in ips})\n\n    @patch('socket.socket')\n    def test_all_ports_closed(self, mock_socket):\n        mock_sock_instance = MagicMock()\n        mock_sock_instance.connect.side_effect = fake_connect_fail\n        mock_socket.return_value = mock_sock_instance\n        ips = ['127.0.0.1', '8.8.8.8']\n        port = 1234\n        result = task_func(ips, port)\n        self.assertEqual(result, {ip: False for ip in ips})\n\n    @patch('socket.socket')\n    def test_mixed_ports(self, mock_socket):\n        mock_sock_instance = MagicMock()\n        # First IP succeeds, second fails\n        mock_sock_instance.connect.side_effect = [None, socket.error]\n        mock_socket.return_value = mock_sock_instance\n        ips = ['1.2.3.4', '5.6.7.8']\n        port = 8080\n        result = task_func(ips, port)\n        self.assertEqual(result, {\n            '1.2.3.4': True,\n            '5.6.7.8': False\n        })\n",
        "code": "import socket\n\ndef task_func(ip_list, port):\n    result = {}\n    for ip in ip_list:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(1)\n        try:\n            s.connect((ip, port))\n            result[ip] = True\n        except (socket.timeout, socket.error):\n            result[ip] = False\n        finally:\n            s.close()\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/147_2",
        "turn": "2",
        "instruct_prompt": "Instead of a list of IP addresses, accept an IP range in CIDR notation and scan all IPs in that range.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport socket\n\nclass TestCases(unittest.TestCase):\n    @patch('socket.socket')\n    def test_scan_cidr_success_and_fail(self, mock_socket):\n        # Arrange\n        # For IP 192.168.1.1: connect succeeds\n        # For IP 192.168.1.2: connect fails\n        instance = MagicMock()\n        def connect_side_effect(addr):\n            if addr[0] == '192.168.1.1':\n                return None\n            elif addr[0] == '192.168.1.2':\n                raise socket.error()\n            else:\n                raise AssertionError('Unexpected IP in test')\n        instance.connect.side_effect = connect_side_effect\n        mock_socket.return_value = instance\n\n        cidr = '192.168.1.0/30'  # hosts: 192.168.1.1 and 192.168.1.2\n        port = 80\n        result = task_func(cidr, port)\n        self.assertIn('192.168.1.1', result)\n        self.assertIn('192.168.1.2', result)\n        self.assertEqual(result['192.168.1.1'], True)\n        self.assertEqual(result['192.168.1.2'], False)\n\n    def test_invalid_cidr(self):\n        with self.assertRaises(ValueError):\n            task_func('invalid_cidr', 80)\n",
        "code": "import socket\nimport ipaddress\n\ndef task_func(cidr, port):\n    result = {}\n    try:\n        network = ipaddress.ip_network(cidr, strict=False)\n    except ValueError:\n        raise ValueError('Invalid CIDR notation')\n    for ip in network.hosts():\n        ip_str = str(ip)\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(1)\n        try:\n            s.connect((ip_str, port))\n            result[ip_str] = True\n        except (socket.timeout, socket.error):\n            result[ip_str] = False\n        finally:\n            s.close()\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/147_3",
        "turn": "3",
        "instruct_prompt": "Return the results as a dictionary mapping each IP address to a boolean indicating if the port is open (True if open, False otherwise).",
        "test": "import unittest\nimport socket\nimport threading\nfrom time import sleep\n\ndef find_free_port():\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.bind(('127.0.0.1', 0))\n    addr, port = s.getsockname()\n    s.close()\n    return port\n\ndef start_test_server(port, ready_event):\n    def server():\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n            s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            s.bind(('127.0.0.1', port))\n            s.listen(1)\n            ready_event.set()\n            conn, _ = s.accept()\n            conn.close()\n            sleep(0.2)\n    t = threading.Thread(target=server, daemon=True)\n    t.start()\n    return t\n\nclass TestCases(unittest.TestCase):\n    def test_open_and_closed_ports(self):\n        open_port = find_free_port()\n        closed_port = find_free_port()\n        ready_event = threading.Event()\n        server_thread = start_test_server(open_port, ready_event)\n        ready_event.wait(timeout=1)\n        sleep(0.05)\n        cidr = '127.0.0.0/30'\n        result = task_func(cidr, open_port)\n        self.assertIn('127.0.0.1', result)\n        self.assertIn('127.0.0.2', result)\n        self.assertEqual(result['127.0.0.1'], 'open')\n        self.assertEqual(result['127.0.0.2'], 'closed')\n        result_closed = task_func(cidr, closed_port)\n        self.assertEqual(result_closed['127.0.0.1'], 'closed')\n        self.assertEqual(result_closed['127.0.0.2'], 'closed')\n    def test_invalid_cidr(self):\n        with self.assertRaises(ValueError):\n            task_func('invalid-cidr', 80)\n",
        "code": "import socket\nimport ipaddress\n\ndef task_func(cidr, port):\n    results = {}\n    try:\n        network = ipaddress.ip_network(cidr, strict=False)\n    except ValueError:\n        raise ValueError('Invalid CIDR notation')\n    for ip in network.hosts():\n        ip_str = str(ip)\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(1)\n        try:\n            s.connect((ip_str, port))\n            results[ip_str] = 'open'\n        except (socket.timeout, socket.error):\n            results[ip_str] = 'closed'\n        finally:\n            s.close()\n    return results\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/147_4",
        "turn": "4",
        "instruct_prompt": "Use multi-threading to speed up the scanning process.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport socket\n\nclass TestCases(unittest.TestCase):\n    @patch('socket.socket')\n    def test_multithreading_scans_all_ips(self, mock_socket):\n        # Simulate connect: Open for 192.168.1.1, closed for 192.168.1.2\n        def connect_side_effect(addr):\n            if addr[0] == '192.168.1.1':\n                return None\n            raise socket.error\n        mock_sock_instance = MagicMock()\n        mock_sock_instance.connect.side_effect = connect_side_effect\n        mock_socket.return_value = mock_sock_instance\n\n        cidr = '192.168.1.0/30' # hosts: 192.168.1.1, 192.168.1.2\n        port = 80\n        result = task_func(cidr, port)\n        self.assertEqual(result['192.168.1.1'], 'open')\n        self.assertEqual(result['192.168.1.2'], 'closed')\n        self.assertEqual(set(result.keys()), {'192.168.1.1', '192.168.1.2'})\n\n    def test_invalid_cidr_raises(self):\n        with self.assertRaises(ValueError):\n            task_func('not_a_cidr', 80)\n\n    @patch('socket.socket')\n    def test_threading_used(self, mock_socket):\n        import concurrent.futures\n        called = {}\n        orig_executor = concurrent.futures.ThreadPoolExecutor\n        class MyExecutor(orig_executor):\n            def __init__(self, *a, **kw):\n                called['used'] = True\n                super().__init__(*a, **kw)\n        with patch('concurrent.futures.ThreadPoolExecutor', MyExecutor):\n            cidr = '10.0.0.0/30'\n            port = 80\n            mock_sock_instance = MagicMock()\n            mock_sock_instance.connect.side_effect = socket.error\n            mock_socket.return_value = mock_sock_instance\n            task_func(cidr, port)\n        self.assertTrue(called.get('used', False))\n",
        "code": "import socket\nimport ipaddress\nimport concurrent.futures\n\ndef scan_ip(ip, port, timeout=1):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.settimeout(timeout)\n    ip_str = str(ip)\n    try:\n        s.connect((ip_str, port))\n        return ip_str, 'open'\n    except (socket.timeout, socket.error):\n        return ip_str, 'closed'\n    finally:\n        s.close()\n\ndef task_func(cidr, port):\n    results = {}\n    try:\n        network = ipaddress.ip_network(cidr, strict=False)\n    except ValueError:\n        raise ValueError('Invalid CIDR notation')\n    hosts = list(network.hosts())\n    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n        future_to_ip = {executor.submit(scan_ip, ip, port): ip for ip in hosts}\n        for future in concurrent.futures.as_completed(future_to_ip):\n            ip_str, status = future.result()\n            results[ip_str] = status\n    return results\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 21,
    "task_id": "BigCodeBench/161",
    "mt_data": [
      {
        "task_id": "BigCodeBench/161_1",
        "turn": "1",
        "instruct_prompt": "Write a function that reads a log file and extracts the log entries consisting of a message type, a timestamp, and a message. You should write self-contained code starting with:\n```\nimport re\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(log_file):\n```",
        "test": "import unittest\nimport tempfile\nimport os\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_valid_log_entries(self):\n        log_content = '''\nINFO [2023-04-01 12:00:00] System started\nERROR [2023-04-01 12:05:00] Failed to load module\nWARNING [2023-04-01 12:10:00] Low disk space\n'''\n        with tempfile.NamedTemporaryFile('w+', delete=False) as tmpfile:\n            tmpfile.write(log_content)\n            tmpfile.flush()\n            df = task_func(tmpfile.name)\n        os.unlink(tmpfile.name)\n\n        self.assertEqual(len(df), 3)\n        self.assertEqual(list(df['type']), ['INFO', 'ERROR', 'WARNING'])\n        self.assertEqual(list(df['message']), ['System started', 'Failed to load module', 'Low disk space'])\n        self.assertTrue(all(isinstance(ts, datetime) for ts in df['timestamp']))\n        self.assertEqual(df['timestamp'].iloc[0], datetime(2023, 4, 1, 12, 0, 0))\n\n    def test_invalid_lines_skipped(self):\n        log_content = '''\nINFO [2023-04-01 12:00:00] System started\nINVALID LINE WITHOUT FORMAT\nERROR [not-a-timestamp] Something went wrong\n'''\n        with tempfile.NamedTemporaryFile('w+', delete=False) as tmpfile:\n            tmpfile.write(log_content)\n            tmpfile.flush()\n            df = task_func(tmpfile.name)\n        os.unlink(tmpfile.name)\n\n        self.assertEqual(len(df), 1)\n        self.assertEqual(df.iloc[0]['type'], 'INFO')\n        self.assertEqual(df.iloc[0]['message'], 'System started')\n\n    def test_empty_file(self):\n        with tempfile.NamedTemporaryFile('w+', delete=False) as tmpfile:\n            df = task_func(tmpfile.name)\n        os.unlink(tmpfile.name)\n        self.assertTrue(df.empty)\n",
        "code": "import re\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(log_file):\n    pattern = re.compile(r\"^(?P<type>\\w+)\\s+\\[(?P<timestamp>[^\\]]+)\\]\\s+(?P<message>.+)$\")\n    entries = []\n    with open(log_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            match = pattern.match(line)\n            if match:\n                msg_type = match.group('type')\n                timestamp_str = match.group('timestamp')\n                message = match.group('message')\n                try:\n                    timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')\n                except ValueError:\n                    # Skip lines with invalid timestamp format\n                    continue\n                entries.append({'type': msg_type, 'timestamp': timestamp, 'message': message})\n    df = pd.DataFrame(entries)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/161_2",
        "turn": "2",
        "instruct_prompt": "The log entries in the file have the format: 'TYPE: [TIMESTAMP (YYYY-MM-DD HH:MM:SS)] - MESSAGE' where TYPE can be 'ERROR' or 'INFO'. Extract these fields using a regular expression.",
        "test": "import unittest\nimport tempfile\nimport os\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_log_parsing(self):\n        log_content = (\n            \"ERROR: [2023-01-01 12:00:00] - Something went wrong\\n\"\n            \"INFO: [2023-01-01 12:05:00] - Process started\\n\"\n            \"ERROR: [2023-01-01 12:10:00] - Another error occurred\\n\"\n            \"INVALID: [2023-01-01 12:15:00] - This should not match\\n\"\n            \"INFO: [2023-01-01 12:20:00] - Process ended\\n\"\n            \"ERROR: [2023-01-01 99:99:99] - Invalid timestamp\\n\"\n        )\n        with tempfile.NamedTemporaryFile('w+', delete=False) as tmp:\n            tmp.write(log_content)\n            tmp_name = tmp.name\n\n        try:\n            df = task_func(tmp_name)\n\n            self.assertEqual(len(df), 4)  # Only 4 valid entries\n            self.assertListEqual(df['type'].tolist(), ['ERROR', 'INFO', 'ERROR', 'INFO'])\n            self.assertTrue(all(isinstance(ts, datetime) for ts in df['timestamp']))\n            self.assertIn('Something went wrong', df['message'].values)\n            self.assertIn('Process ended', df['message'].values)\n\n        finally:\n            os.remove(tmp_name)\n",
        "code": "import re\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(log_file):\n    pattern = re.compile(r\"^(ERROR|INFO): \\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\] - (.+)$\")\n    entries = []\n    with open(log_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            match = pattern.match(line)\n            if match:\n                msg_type = match.group(1)\n                timestamp_str = match.group(2)\n                message = match.group(3)\n                try:\n                    timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')\n                except ValueError:\n                    # Skip lines with invalid timestamp format\n                    continue\n                entries.append({'type': msg_type, 'timestamp': timestamp, 'message': message})\n    df = pd.DataFrame(entries)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/161_3",
        "turn": "3",
        "instruct_prompt": "Validate that each extracted timestamp matches the format '%Y-%m-%d %H:%M:%S'. If any timestamp is invalid, raise a ValueError with an appropriate message.",
        "test": "import unittest\nimport tempfile\nimport os\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.maxDiff = None\n\n    def write_log_file(self, content):\n        tmp = tempfile.NamedTemporaryFile(delete=False, mode='w', encoding='utf-8')\n        tmp.write(content)\n        tmp.close()\n        return tmp.name\n\n    def test_valid_log_entries(self):\n        log_content = (\n            \"ERROR: [2023-05-01 12:30:45] - Something went wrong\\n\"\n            \"INFO: [2023-05-01 12:31:00] - Process started\\n\"\n        )\n        log_file = self.write_log_file(log_content)\n        try:\n            df = task_func(log_file)\n            self.assertEqual(len(df), 2)\n            self.assertEqual(df.iloc[0]['type'], 'ERROR')\n            self.assertEqual(df.iloc[0]['timestamp'], datetime(2023,5,1,12,30,45))\n            self.assertEqual(df.iloc[0]['message'], 'Something went wrong')\n            self.assertEqual(df.iloc[1]['type'], 'INFO')\n            self.assertEqual(df.iloc[1]['timestamp'], datetime(2023,5,1,12,31,0))\n            self.assertEqual(df.iloc[1]['message'], 'Process started')\n        finally:\n            os.unlink(log_file)\n\n    def test_invalid_timestamp_raises_value_error(self):\n        log_content = (\n            \"ERROR: [2023-05-01 12:30:45] - Valid entry\\n\"\n            \"INFO: [2023-05-01 25:61:00] - Invalid timestamp\\n\"\n        )\n        log_file = self.write_log_file(log_content)\n        try:\n            with self.assertRaises(ValueError) as context:\n                task_func(log_file)\n            self.assertIn('Invalid timestamp format', str(context.exception))\n        finally:\n            os.unlink(log_file)\n\n    def test_non_matching_lines_ignored(self):\n        log_content = (\n            \"ERROR: [2023-05-01 12:30:45] - Valid entry\\n\"\n            \"Some random text not matching pattern\\n\"\n            \"INFO: [2023-05-01 12:31:00] - Another valid entry\\n\"\n        )\n        log_file = self.write_log_file(log_content)\n        try:\n            df = task_func(log_file)\n            self.assertEqual(len(df), 2)\n            self.assertEqual(df.iloc[0]['type'], 'ERROR')\n            self.assertEqual(df.iloc[1]['type'], 'INFO')\n        finally:\n            os.unlink(log_file)\n",
        "code": "import re\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(log_file):\n    pattern = re.compile(r\"^(ERROR|INFO): \\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\] - (.+)$\")\n    entries = []\n    with open(log_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            match = pattern.match(line)\n            if match:\n                msg_type = match.group(1)\n                timestamp_str = match.group(2)\n                message = match.group(3)\n                # Validate timestamp format strictly\n                try:\n                    timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')\n                except ValueError:\n                    raise ValueError(f\"Invalid timestamp format: {timestamp_str}\")\n                entries.append({'type': msg_type, 'timestamp': timestamp, 'message': message})\n    df = pd.DataFrame(entries)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/161_4",
        "turn": "4",
        "instruct_prompt": "If no valid log entries are found in the file, raise a ValueError indicating that no valid log entries were found.",
        "test": "import unittest\nimport tempfile\nimport os\nimport pandas as pd\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_no_valid_entries_raises(self):\n        content = \"\"\"This is a line without valid format\\nAnother invalid line\"\"\"\n        with tempfile.NamedTemporaryFile('w+', delete=False) as tmp:\n            tmp.write(content)\n            tmp_path = tmp.name\n        try:\n            with self.assertRaises(ValueError) as cm:\n                task_func(tmp_path)\n            self.assertEqual(str(cm.exception), \"No valid log entries were found.\")\n        finally:\n            os.remove(tmp_path)\n\n    def test_valid_and_invalid_entries(self):\n        content = \"\"\"INFO: [2024-06-01 12:00:00] - System started\\nInvalid line\\nERROR: [2024-06-01 12:01:00] - Failure occurred\"\"\"\n        with tempfile.NamedTemporaryFile('w+', delete=False) as tmp:\n            tmp.write(content)\n            tmp_path = tmp.name\n        try:\n            df = task_func(tmp_path)\n            self.assertEqual(len(df), 2)\n            self.assertTrue(all(df['type'].isin(['INFO', 'ERROR'])))\n            self.assertTrue(all(isinstance(ts, datetime) for ts in df['timestamp']))\n        finally:\n            os.remove(tmp_path)\n",
        "code": "import re\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(log_file):\n    pattern = re.compile(r\"^(ERROR|INFO): \\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\] - (.+)$\")\n    entries = []\n    with open(log_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            match = pattern.match(line)\n            if match:\n                msg_type = match.group(1)\n                timestamp_str = match.group(2)\n                message = match.group(3)\n                # Validate timestamp format strictly\n                try:\n                    timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')\n                except ValueError:\n                    raise ValueError(f\"Invalid timestamp format: {timestamp_str}\")\n                entries.append({'type': msg_type, 'timestamp': timestamp, 'message': message})\n    if not entries:\n        raise ValueError(\"No valid log entries were found.\")\n    df = pd.DataFrame(entries)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/161_5",
        "turn": "5",
        "instruct_prompt": "Store the extracted and validated log data into a CSV file named 'log_data.csv' with columns 'Type', 'Timestamp', and 'Message'. Return the file path to this CSV file as a string.",
        "test": "import unittest\nimport os\nimport tempfile\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary log file for testing\n        self.temp_log = tempfile.NamedTemporaryFile(delete=False, mode='w', encoding='utf-8')\n        self.temp_log.write(\n            \"ERROR: [2023-03-15 14:22:01] - Failed to connect to database\\n\"\n            \"INFO: [2023-03-15 14:23:05] - Connection established\\n\"\n            \"ERROR: [2023-03-15 14:24:10] - Timeout occurred\\n\"\n        )\n        self.temp_log.close()\n\n    def tearDown(self):\n        # Remove temporary files created during tests\n        if os.path.exists(self.temp_log.name):\n            os.remove(self.temp_log.name)\n        if os.path.exists('log_data.csv'):\n            os.remove('log_data.csv')\n\n    def test_task_func_creates_csv_and_returns_path(self):\n        csv_path = task_func(self.temp_log.name)\n        # Check returned path is correct and file exists\n        self.assertTrue(os.path.isabs(csv_path))\n        self.assertTrue(os.path.isfile(csv_path))\n        # Check content of CSV file\n        df = pd.read_csv(csv_path)\n        self.assertListEqual(list(df.columns), ['Type', 'Timestamp', 'Message'])\n        self.assertEqual(len(df), 3)\n        self.assertEqual(df.iloc[0]['Type'], 'ERROR')\n        self.assertEqual(df.iloc[0]['Timestamp'], '2023-03-15 14:22:01')\n        self.assertEqual(df.iloc[0]['Message'], 'Failed to connect to database')\n        self.assertEqual(df.iloc[1]['Type'], 'INFO')\n        self.assertEqual(df.iloc[1]['Timestamp'], '2023-03-15 14:23:05')\n        self.assertEqual(df.iloc[1]['Message'], 'Connection established')\n\n    def test_task_func_raises_valueerror_for_invalid_timestamp(self):\n        # Write invalid timestamp line\n        with open(self.temp_log.name, 'a', encoding='utf-8') as f:\n            f.write('ERROR: [2023-15-03 99:99:99] - Invalid timestamp\\n')\n        with self.assertRaises(ValueError):\n            task_func(self.temp_log.name)\n\n    def test_task_func_raises_valueerror_for_no_valid_entries(self):\n        # Create a temp log file with no valid entries\n        with open(self.temp_log.name, 'w', encoding='utf-8') as f:\n            f.write('This is an invalid log line\\nAnother bad line\\n')\n        with self.assertRaises(ValueError):\n            task_func(self.temp_log.name)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import re\nimport pandas as pd\nfrom datetime import datetime\nimport os\n\ndef task_func(log_file):\n    pattern = re.compile(r\"^(ERROR|INFO): \\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\] - (.+)$\")\n    entries = []\n    with open(log_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            match = pattern.match(line)\n            if match:\n                msg_type = match.group(1)\n                timestamp_str = match.group(2)\n                message = match.group(3)\n                # Validate timestamp format strictly\n                try:\n                    datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')\n                except ValueError:\n                    raise ValueError(f\"Invalid timestamp format: {timestamp_str}\")\n                entries.append({'Type': msg_type, 'Timestamp': timestamp_str, 'Message': message})\n    if not entries:\n        raise ValueError(\"No valid log entries were found.\")\n    df = pd.DataFrame(entries, columns=['Type', 'Timestamp', 'Message'])\n    csv_path = 'log_data.csv'\n    df.to_csv(csv_path, index=False)\n    return os.path.abspath(csv_path)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 22,
    "task_id": "BigCodeBench/162",
    "mt_data": [
      {
        "task_id": "BigCodeBench/162_1",
        "turn": "1",
        "instruct_prompt": "Analyze the lengths of words in a given text and plot a histogram showing the distribution of these word lengths. You should write self-contained code starting with:\n```\nimport re\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(text, rwidth=0.8):\n```",
        "test": "import unittest\nfrom unittest.mock import patch\nimport io\nimport matplotlib\nmatplotlib.use('Agg')  # Use a non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    def test_basic_text(self):\n        text = \"Hello world! This is a test.\"\n        # Just ensure no exceptions raised and output is generated\n        try:\n            task_func(text)\n        except Exception as e:\n            self.fail(f\"task_func raised an exception {e}\")\n\n    def test_empty_text(self):\n        text = \"\"\n        with patch('sys.stdout', new=io.StringIO()) as fake_out:\n            task_func(text)\n            self.assertIn(\"No words found\", fake_out.getvalue())\n\n    def test_single_word(self):\n        text = \"Python\"\n        try:\n            task_func(text)\n        except Exception as e:\n            self.fail(f\"task_func raised an exception {e}\")\n\n    def test_words_with_varied_lengths(self):\n        text = \"a aa aaa aaaa aaaaa\"\n        try:\n            task_func(text)\n        except Exception as e:\n            self.fail(f\"task_func raised an exception {e}\")\n\n    def test_words_with_punctuation(self):\n        text = \"Well, this: is; tricky!\"\n        try:\n            task_func(text)\n        except Exception as e:\n            self.fail(f\"task_func raised an exception {e}\")\n",
        "code": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(text, rwidth=0.8):\n    # Extract words using regex\n    words = re.findall(r\"\\b\\w+\\b\", text)\n    # Get lengths of the words\n    lengths = [len(word) for word in words]\n    if not lengths:\n        print(\"No words found in the input text.\")\n        return\n    # Get the range of word lengths\n    min_len = min(lengths)\n    max_len = max(lengths)\n    bins = np.arange(min_len - 0.5, max_len + 1.5, 1)\n    # Plot histogram\n    plt.hist(lengths, bins=bins, rwidth=rwidth, edgecolor='black')\n    plt.xticks(range(min_len, max_len + 1))\n    plt.xlabel('Word Length')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Word Lengths')\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/162_2",
        "turn": "2",
        "instruct_prompt": "Split the input text into words using non-word characters as delimiters, and exclude any empty strings from the list of words.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_split_words_basic(self):\n        text = \"Hello, world! This is a test.\"\n        expected = ['Hello', 'world', 'This', 'is', 'a', 'test']\n        result = task_func(text, return_words_only=True)\n        self.assertEqual(result, expected)\n\n    def test_split_words_empty_strings_excluded(self):\n        text = \"!!!Hello!!!  \\n\\t world??\"\n        result = task_func(text, return_words_only=True)\n        self.assertNotIn('', result)\n\n    def test_split_words_only_non_word(self):\n        text = \"!!! ??? ...\"\n        result = task_func(text, return_words_only=True)\n        self.assertEqual(result, [])\n\n    def test_split_words_consecutive_delimiters(self):\n        text = \"word1,,,word2;;word3\"\n        expected = ['word1', 'word2', 'word3']\n        result = task_func(text, return_words_only=True)\n        self.assertEqual(result, expected)\n",
        "code": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(text, rwidth=0.8, return_words_only=False):\n    # Split text into words using non-word characters as delimiters\n    words = re.split(r'\\W+', text)\n    # Exclude empty strings\n    words = [word for word in words if word != '']\n    if return_words_only:\n        return words\n    lengths = [len(word) for word in words]\n    if not lengths:\n        print(\"No words found in the input text.\")\n        return\n    min_len = min(lengths)\n    max_len = max(lengths)\n    bins = np.arange(min_len - 0.5, max_len + 1.5, 1)\n    plt.hist(lengths, bins=bins, rwidth=rwidth, edgecolor='black')\n    plt.xticks(range(min_len, max_len + 1))\n    plt.xlabel('Word Length')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Word Lengths')\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/162_3",
        "turn": "3",
        "instruct_prompt": "Create a histogram subplot using matplotlib that displays the frequency of each word length. Use numpy to define bins that cover all word lengths plus one extra bin to properly align the histogram bars.",
        "test": "import unittest\nimport matplotlib\nmatplotlib.use('Agg')  # Use a non-interactive backend for testing\nimport io\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_histogram_bins_and_subplot(self):\n        text = 'a aa aaa aaaa aaaaa'\n        # Expected word lengths: [1,2,3,4,5]\n\n        # Override plt.show to prevent blocking during test\n        original_show = plt.show\n        plt.show = lambda: None\n\n        try:\n            rwidth_test = 0.8\n            # Call with explicit rwidth\n            task_func(text, rwidth=rwidth_test)\n            fig = plt.gcf()\n            ax = plt.gca()\n\n            # Check there is exactly one subplot\n            self.assertEqual(len(fig.axes), 1)\n\n            # Check histogram patches (bars)\n            patches = ax.patches\n            self.assertTrue(len(patches) > 0)\n\n            # Number of bars should be number of bins - 1\n            # Bins are from 0.5 to 6.5 step 1 -> 7 edges, 6 bars\n            expected_num_bins = 6\n            self.assertEqual(len(patches), expected_num_bins)\n\n            # Check that bars are approximately aligned with expected bins\n            expected_bins = np.arange(0.5, 7.0, 1)  # 0.5 to 6.5 inclusive\n\n            for i, patch in enumerate(patches):\n                bar_x = patch.get_x()\n                expected_x = expected_bins[i]\n                # Allow small tolerance due to matplotlib bar positioning\n                self.assertAlmostEqual(bar_x, expected_x, delta=0.15)\n                # Bar width should be close to rwidth_test\n                self.assertAlmostEqual(patch.get_width(), rwidth_test, delta=0.01)\n\n            # Check x-ticks are integers from 1 to max_len (5)\n            xticks = [tick.get_text() for tick in ax.get_xticklabels() if tick.get_text() != '']\n            expected_xticks = [str(i) for i in range(1, 6)]\n            self.assertEqual(xticks, expected_xticks)\n\n        finally:\n            plt.show = original_show\n\n    def test_return_words_only(self):\n        text = \"Hello, world!\"\n        words = task_func(text, return_words_only=True)\n        self.assertEqual(words, ['Hello', 'world'])\n\n    def test_no_words(self):\n        captured_output = io.StringIO()\n        sys.stdout = captured_output\n        task_func(\"!!!\", return_words_only=False)\n        sys.stdout = sys.__stdout__\n        self.assertIn(\"No words found\", captured_output.getvalue())\n",
        "code": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(text, rwidth=0.8, return_words_only=False):\n    # Split text into words using non-word characters as delimiters\n    words = re.split(r'\\W+', text)\n    # Exclude empty strings\n    words = [word for word in words if word != '']\n    if return_words_only:\n        return words\n    lengths = [len(word) for word in words]\n    if not lengths:\n        print(\"No words found in the input text.\")\n        return\n    max_len = max(lengths)\n    # Define bins from 0.5 to max_len + 1.5 to cover all lengths plus one extra bin\n    bins = np.arange(0.5, max_len + 2, 1)\n    plt.subplot(1,1,1)\n    plt.hist(lengths, bins=bins, rwidth=rwidth, edgecolor='black')\n    plt.xticks(range(1, max_len + 1))\n    plt.xlabel('Word Length')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Word Lengths')\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/162_4",
        "turn": "4",
        "instruct_prompt": "If there are no words or all words are filtered out (resulting in an empty word length list), produce an empty histogram without bins to prevent errors.",
        "test": "import unittest\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    @patch('matplotlib.pyplot.hist')\n    def test_empty_string_produces_empty_histogram(self, mock_hist):\n        # Call with empty string\n        task_func('')\n        # Assert plt.hist called once\n        self.assertTrue(mock_hist.called)\n        args, kwargs = mock_hist.call_args\n        # First arg is data list, should be empty\n        self.assertEqual(args[0], [])\n        # bins kwarg should be empty list\n        self.assertIn('bins', kwargs)\n        self.assertEqual(kwargs['bins'], [])\n\n    @patch('matplotlib.pyplot.hist')\n    def test_only_non_words_produces_empty_histogram(self, mock_hist):\n        text = '!!! ??? ,,, ---'\n        task_func(text)\n        self.assertTrue(mock_hist.called)\n        args, kwargs = mock_hist.call_args\n        self.assertEqual(args[0], [])\n        self.assertIn('bins', kwargs)\n        self.assertEqual(kwargs['bins'], [])\n\n    @patch('matplotlib.pyplot.hist')\n    def test_normal_text_produces_nonempty_histogram(self, mock_hist):\n        text = 'Hello world! This is a test.'\n        task_func(text)\n        self.assertTrue(mock_hist.called)\n        args, kwargs = mock_hist.call_args\n        # Data list should not be empty\n        self.assertTrue(len(args[0]) > 0)\n        # bins should not be empty\n        self.assertIn('bins', kwargs)\n        self.assertTrue(len(kwargs['bins']) > 0)\n\n    def test_return_words_only(self):\n        text = 'Hello world!'\n        words = task_func(text, return_words_only=True)\n        self.assertEqual(words, ['Hello', 'world'])",
        "code": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(text, rwidth=0.8, return_words_only=False):\n    # Split text into words using non-word characters as delimiters\n    words = re.split(r'\\W+', text)\n    # Exclude empty strings\n    words = [word for word in words if word != '']\n    if return_words_only:\n        return words\n    lengths = [len(word) for word in words]\n    if not lengths:\n        # Produce an empty histogram without bins\n        plt.subplot(1,1,1)\n        plt.hist([], bins=[], rwidth=rwidth, edgecolor='black')\n        plt.xlabel('Word Length')\n        plt.ylabel('Frequency')\n        plt.title('Histogram of Word Lengths')\n        plt.show()\n        return\n    max_len = max(lengths)\n    # Define bins from 0.5 to max_len + 1.5 to cover all lengths plus one extra bin\n    bins = np.arange(0.5, max_len + 2, 1)\n    plt.subplot(1,1,1)\n    plt.hist(lengths, bins=bins, rwidth=rwidth, edgecolor='black')\n    plt.xticks(range(1, max_len + 1))\n    plt.xlabel('Word Length')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Word Lengths')\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/162_5",
        "turn": "5",
        "instruct_prompt": "Set the histogram title to 'Distribution of Word Lengths', label the x-axis as 'Word Length' and the y-axis as 'Frequency', and return the matplotlib Axes object containing the histogram.",
        "test": "import unittest\nimport matplotlib.pyplot as plt\nfrom matplotlib.text import Text\nfrom matplotlib.axis import Axis\n\nclass TestCases(unittest.TestCase):\n    def test_histogram_labels_and_title(self):\n        text = 'hello world test case'\n        ax = task_func(text)\n        # Check the title\n        self.assertIsInstance(ax.title, Text)\n        self.assertEqual(ax.get_title(), 'Distribution of Word Lengths')\n        # Check x-axis label\n        self.assertIsInstance(ax.xaxis, Axis)\n        self.assertEqual(ax.get_xlabel(), 'Word Length')\n        # Check y-axis label\n        self.assertIsInstance(ax.yaxis, Axis)\n        self.assertEqual(ax.get_ylabel(), 'Frequency')\n\n    def test_return_type(self):\n        text = 'some random words'\n        ax = task_func(text)\n        self.assertTrue(hasattr(ax, 'hist'))  # Axes object has hist method\n\n    def test_empty_text(self):\n        ax = task_func('')\n        self.assertEqual(ax.get_title(), 'Distribution of Word Lengths')\n        self.assertEqual(ax.get_xlabel(), 'Word Length')\n        self.assertEqual(ax.get_ylabel(), 'Frequency')\n\n    def test_return_words_only(self):\n        words = task_func('hello world', return_words_only=True)\n        self.assertEqual(words, ['hello', 'world'])\n",
        "code": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(text, rwidth=0.8, return_words_only=False):\n    # Split text into words using non-word characters as delimiters\n    words = re.split(r'\\W+', text)\n    # Exclude empty strings\n    words = [word for word in words if word != '']\n    if return_words_only:\n        return words\n    lengths = [len(word) for word in words]\n    if not lengths:\n        # Produce an empty histogram without bins\n        fig, ax = plt.subplots()\n        ax.hist([], bins=[], rwidth=rwidth, edgecolor='black')\n        ax.set_xlabel('Word Length')\n        ax.set_ylabel('Frequency')\n        ax.set_title('Distribution of Word Lengths')\n        plt.show()\n        return ax\n    max_len = max(lengths)\n    # Define bins from 0.5 to max_len + 1.5 to cover all lengths plus one extra bin\n    bins = np.arange(0.5, max_len + 2, 1)\n    fig, ax = plt.subplots()\n    ax.hist(lengths, bins=bins, rwidth=rwidth, edgecolor='black')\n    ax.set_xticks(range(1, max_len + 1))\n    ax.set_xlabel('Word Length')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution of Word Lengths')\n    plt.show()\n    return ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 23,
    "task_id": "BigCodeBench/177",
    "mt_data": [
      {
        "task_id": "BigCodeBench/177_1",
        "turn": "1",
        "instruct_prompt": "Extract articles from a DataFrame whose 'Title' column contains the keywords \"like\" or \"what\" (case-insensitive). You should write self-contained code starting with:```python\nimport re\n\ndef task_func(df):\n```",
        "test": "import unittest\nimport pandas as pd\nfrom io import StringIO\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        data = StringIO(\"\"\"\nTitle,Content\nI like apples,Apples are great\nWhat is this?,This is a test\nNothing here,No keywords\nLIKELY event,Something\n\"\"\")\n        df = pd.read_csv(data)\n        result = task_func(df)\n        expected_titles = ['I like apples', 'What is this?']\n        self.assertEqual(list(result['Title']), expected_titles)\n\n    def test_case_insensitive(self):\n        df = pd.DataFrame({\n            'Title': ['LIKE it', 'whAt now', 'no match'],\n            'Content': ['a', 'b', 'c']\n        })\n        result = task_func(df)\n        expected_titles = ['LIKE it', 'whAt now']\n        self.assertEqual(list(result['Title']), expected_titles)\n\n    def test_no_matches(self):\n        df = pd.DataFrame({\n            'Title': ['hello', 'world', 'python'],\n            'Content': ['a', 'b', 'c']\n        })\n        result = task_func(df)\n        self.assertTrue(result.empty)\n",
        "code": "import re\n\ndef task_func(df):\n    pattern = re.compile(r'\\b(like|what)\\b', re.IGNORECASE)\n    mask = df['Title'].apply(lambda x: bool(pattern.search(x)))\n    return df[mask]\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/177_2",
        "turn": "2",
        "instruct_prompt": "If the DataFrame is empty or does not contain the columns 'Title' and 'Content', raise a ValueError with an appropriate message.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_valid_df(self):\n        data = {\n            'Title': ['I like apples', 'What is this?', 'No match here'],\n            'Content': ['Fruit', 'Question', 'Statement']\n        }\n        df = pd.DataFrame(data)\n        result = task_func(df)\n        self.assertEqual(len(result), 2)\n        self.assertTrue(all(result['Title'].str.contains('like|what', case=False)))\n\n    def test_empty_df(self):\n        df = pd.DataFrame(columns=['Title', 'Content'])\n        with self.assertRaises(ValueError) as context:\n            task_func(df)\n        self.assertEqual(str(context.exception), 'DataFrame is empty')\n\n    def test_missing_title_column(self):\n        data = {\n            'Content': ['Some content']\n        }\n        df = pd.DataFrame(data)\n        with self.assertRaises(ValueError) as context:\n            task_func(df)\n        self.assertEqual(str(context.exception), 'DataFrame must contain Title and Content columns')\n\n    def test_missing_content_column(self):\n        data = {\n            'Title': ['I like apples']\n        }\n        df = pd.DataFrame(data)\n        with self.assertRaises(ValueError) as context:\n            task_func(df)\n        self.assertEqual(str(context.exception), 'DataFrame must contain Title and Content columns')\n",
        "code": "import re\n\ndef task_func(df):\n    if df.empty:\n        raise ValueError('DataFrame is empty')\n    if 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError('DataFrame must contain Title and Content columns')\n    pattern = re.compile(r'\\b(like|what)\\b', re.IGNORECASE)\n    mask = df['Title'].apply(lambda x: bool(pattern.search(x)))\n    return df[mask]\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/177_3",
        "turn": "3",
        "instruct_prompt": "Analyze the frequency of each word in the 'Content' column of the filtered articles, excluding any punctuation characters.",
        "test": "import unittest\nimport pandas as pd\nfrom collections import Counter\n\nclass TestCases(unittest.TestCase):\n    def test_word_frequency(self):\n        data = {\n            'Title': ['I like apples', 'What is this?', 'No match here'],\n            'Content': ['Apples are good. Apples, apples!', 'What do you like?', 'This should not be counted.']\n        }\n        df = pd.DataFrame(data)\n        result = task_func(df)\n        expected = Counter({'apples': 3, 'are': 1, 'good': 1, 'what': 1, 'do': 1, 'you': 1, 'like': 1})\n        self.assertEqual(result, expected)\n\n    def test_empty_dataframe(self):\n        df = pd.DataFrame(columns=['Title', 'Content'])\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_missing_columns(self):\n        df = pd.DataFrame({'Title': ['like this']})\n        with self.assertRaises(ValueError):\n            task_func(df)\n",
        "code": "import re\nfrom collections import Counter\n\ndef task_func(df):\n    if df.empty:\n        raise ValueError('DataFrame is empty')\n    if 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError('DataFrame must contain Title and Content columns')\n    pattern = re.compile(r'\\b(like|what)\\b', re.IGNORECASE)\n    mask = df['Title'].apply(lambda x: bool(pattern.search(x)))\n    filtered_df = df[mask]\n\n    # Combine all content from filtered articles\n    all_content = ' '.join(filtered_df['Content'].dropna())\n\n    # Remove punctuation\n    all_content_clean = re.sub(r'[\\W_]+', ' ', all_content)\n\n    # Split into words and count frequency\n    words = all_content_clean.lower().split()\n    freq = Counter(words)\n    return freq\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/177_4",
        "turn": "4",
        "instruct_prompt": "Return a dictionary where keys are words and values are their corresponding frequency counts.",
        "test": "import unittest\nimport pandas as pd\nfrom collections import Counter\n\nclass TestCases(unittest.TestCase):\n    def test_return_type_and_content(self):\n        data = {\n            'Title': ['What is AI?', 'I like Python', 'Hello World'],\n            'Content': ['Artificial intelligence is amazing.', 'Python is great and I like it.', 'Just saying hello.']\n        }\n        df = pd.DataFrame(data)\n        result = task_func(df)\n        # Check that the return type is exactly dict, not Counter or other\n        self.assertIsInstance(result, dict)\n        self.assertNotIsInstance(result, Counter)\n\n        expected_freq = {\n            'artificial': 1,\n            'intelligence': 1,\n            'is': 2,\n            'amazing': 1,\n            'python': 1,\n            'great': 1,\n            'and': 1,\n            'i': 1,\n            'like': 1,\n            'it': 1\n        }\n        self.assertEqual(result, expected_freq)\n\n    def test_empty_dataframe(self):\n        df = pd.DataFrame(columns=['Title', 'Content'])\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_missing_columns(self):\n        df = pd.DataFrame({'Title': ['What is this?']})\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_no_matching_titles(self):\n        data = {'Title': ['Hello there', 'Good morning'], 'Content': ['No keywords here.', 'Still no keywords.']}\n        df = pd.DataFrame(data)\n        result = task_func(df)\n        self.assertIsInstance(result, dict)\n        self.assertEqual(result, {})\n",
        "code": "import re\nfrom collections import Counter\n\ndef task_func(df):\n    if df.empty:\n        raise ValueError('DataFrame is empty')\n    if 'Title' not in df.columns or 'Content' not in df.columns:\n        raise ValueError('DataFrame must contain Title and Content columns')\n    pattern = re.compile(r'\\b(like|what)\\b', re.IGNORECASE)\n    mask = df['Title'].apply(lambda x: bool(pattern.search(x)))\n    filtered_df = df[mask]\n\n    all_content = ' '.join(filtered_df['Content'].dropna())\n\n    all_content_clean = re.sub(r'[\\W_]+', ' ', all_content)\n\n    words = all_content_clean.lower().split()\n    freq = Counter(words)\n    return dict(freq)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 24,
    "task_id": "BigCodeBench/184",
    "mt_data": [
      {
        "task_id": "BigCodeBench/184_1",
        "turn": "1",
        "instruct_prompt": "Prepares text data from a specified column in a DataFrame by applying a vectorization process to convert text into a numeric format suitable for analysis. You should write self-contained code starting with:```import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\ndef task_func(dataframe, text_column):\n    pass\n```",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nclass TestCases(unittest.TestCase):\n    def test_basic_vectorization(self):\n        df = pd.DataFrame({\"text\": [\"hello world\", \"hello\", \"test case\"]})\n        result = task_func(df, \"text\")\n        vectorizer = CountVectorizer()\n        expected = vectorizer.fit_transform(df[\"text\"]).toarray()\n        self.assertTrue((result == expected).all())\n\n    def test_empty_strings(self):\n        df = pd.DataFrame({\"text\": [\"\", \"\", \"\"]})\n        result = task_func(df, \"text\")\n        self.assertEqual(result.shape[0], 3)\n        self.assertEqual(result.shape[1], 0)  # no features\n\n    def test_non_string_values(self):\n        df = pd.DataFrame({\"text\": [123, None, \"text\"]})\n        result = task_func(df, \"text\")\n        vectorizer = CountVectorizer()\n        expected = vectorizer.fit_transform(df[\"text\"].astype(str)).toarray()\n        self.assertTrue((result == expected).all())",
        "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef task_func(dataframe, text_column):\n    vectorizer = CountVectorizer()\n    text_data = dataframe[text_column].astype(str).tolist()\n    try:\n        matrix = vectorizer.fit_transform(text_data)\n        return matrix.toarray()\n    except ValueError as e:\n        # Handle empty vocabulary (e.g., all empty strings) by returning empty feature matrix\n        if 'empty vocabulary' in str(e):\n            return np.zeros((len(text_data), 0), dtype=int)\n        else:\n            raise",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/184_2",
        "turn": "2",
        "instruct_prompt": "Before vectorization, preprocess the text by converting all text to lowercase and removing all numbers.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_lowercase_and_number_removal(self):\n        df = pd.DataFrame({\n            'text': ['Hello World 123', 'Test 456 test', 'NoNumbersHere', '123456']\n        })\n        result = task_func(df, 'text')\n        # After preprocessing, texts become:\n        # 'hello world ', 'test  test', 'nonumbershere', ''\n        # Vectorizer should build vocab from these\n        expected_vocab = sorted(['hello', 'world', 'test', 'nonumbershere'])\n        # Check that the feature names correspond to expected_vocab\n        from sklearn.feature_extraction.text import CountVectorizer\n        vectorizer = CountVectorizer()\n        processed_texts = [\n            'hello world ',\n            'test  test',\n            'nonumbershere',\n            ''\n        ]\n        vectorizer.fit(processed_texts)\n        self.assertEqual(sorted(vectorizer.get_feature_names_out()), expected_vocab)\n        # Check result shape\n        self.assertEqual(result.shape[0], 4)\n        self.assertEqual(result.shape[1], len(expected_vocab))\n        # Check that the row corresponding to '123456' (which becomes '') is all zeros\n        self.assertTrue(np.all(result[3] == 0))\n\n    def test_empty_strings_after_removal(self):\n        df = pd.DataFrame({\n            'text': ['1234', '5678', '90']\n        })\n        result = task_func(df, 'text')\n        # All texts become empty strings after removal\n        self.assertEqual(result.shape, (3, 0))\n\n    def test_mixed_case_and_numbers(self):\n        df = pd.DataFrame({\n            'text': ['AbC123', 'abc', 'ABC456']\n        })\n        result = task_func(df, 'text')\n        # After preprocessing all 'abc'\n        from sklearn.feature_extraction.text import CountVectorizer\n        processed_texts = ['abc', 'abc', 'abc']\n        vectorizer = CountVectorizer()\n        vectorizer.fit(processed_texts)\n        expected_vocab = vectorizer.get_feature_names_out()\n        self.assertEqual(len(expected_vocab), 1)\n        self.assertEqual(expected_vocab[0], 'abc')\n        self.assertTrue(np.all(result == 1))\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport re\n\ndef task_func(dataframe, text_column):\n    vectorizer = CountVectorizer()\n    # Preprocess: lowercase and remove numbers\n    def preprocess(text):\n        text = text.lower()\n        text = re.sub(r'\\d+', '', text)\n        return text\n    \n    text_data = dataframe[text_column].astype(str).apply(preprocess).tolist()\n    try:\n        matrix = vectorizer.fit_transform(text_data)\n        return matrix.toarray()\n    except ValueError as e:\n        # Handle empty vocabulary (e.g., all empty strings) by returning empty feature matrix\n        if 'empty vocabulary' in str(e):\n            return np.zeros((len(text_data), 0), dtype=int)\n        else:\n            raise\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/184_3",
        "turn": "3",
        "instruct_prompt": "Further preprocess the text by removing all punctuation characters.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport string\n\nclass TestCases(unittest.TestCase):\n    def test_punctuation_removed_from_features(self):\n        df = pd.DataFrame({\n            'text': [\n                'Hello, world!',\n                'Test: remove; punctuation.',\n                'No punctuation here',\n                '1234 numbers and symbols #$%!',\n                '',\n                '!!!'\n            ]\n        })\n        matrix, vectorizer = task_func(df, 'text')\n        feature_names = vectorizer.get_feature_names_out()\n\n        # Assert no punctuation characters in any feature name\n        for feature in feature_names:\n            self.assertFalse(any(ch in string.punctuation for ch in feature),\n                             msg=f\"Punctuation found in feature: {feature}\")\n\n        # Check that matrix shape matches number of rows\n        self.assertEqual(matrix.shape[0], len(df))\n\n        # Check that rows with only punctuation or empty string have zero vector\n        # Rows 4 and 5 correspond to '' and '!!!'\n        self.assertTrue(np.all(matrix[4] == 0))\n        self.assertTrue(np.all(matrix[5] == 0))\n\n        # Check that other rows have at least one non-zero count\n        self.assertTrue(np.any(matrix[0] > 0))\n        self.assertTrue(np.any(matrix[1] > 0))\n\n    def test_all_punctuation_leads_to_empty_vocabulary(self):\n        df = pd.DataFrame({'text': ['!!!', '...', '???']})\n        matrix, vectorizer = task_func(df, 'text')\n        # Expect empty vocabulary and zero-column matrix\n        self.assertEqual(matrix.shape, (3, 0))\n\n    def test_mixed_content(self):\n        df = pd.DataFrame({'text': ['abc123, def! ghi?', '4567', 'No numbers, no punctuation']})\n        matrix, vectorizer = task_func(df, 'text')\n\n        # Check shape\n        self.assertEqual(matrix.shape[0], 3)\n\n        # First row should have non-zero counts (words after removing digits and punctuation)\n        self.assertTrue(np.any(matrix[0] > 0))\n\n        # Second row is only digits, so after removing digits and punctuation should be empty -> zero vector\n        self.assertTrue(np.all(matrix[1] == 0))\n\n        # Third row has words and no punctuation after preprocessing\n        self.assertTrue(np.any(matrix[2] > 0))\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport re\nimport string\n\ndef task_func(dataframe, text_column):\n    vectorizer = CountVectorizer()\n    # Preprocess: lowercase, remove numbers, remove punctuation\n    def preprocess(text):\n        text = text.lower()\n        text = re.sub(r'\\d+', '', text)\n        text = text.translate(str.maketrans('', '', string.punctuation))\n        return text\n    \n    text_data = dataframe[text_column].astype(str).apply(preprocess).tolist()\n    try:\n        matrix = vectorizer.fit_transform(text_data)\n        return matrix.toarray(), vectorizer\n    except ValueError as e:\n        # Handle empty vocabulary (e.g., all empty strings) by returning empty feature matrix\n        if 'empty vocabulary' in str(e):\n            return np.zeros((len(text_data), 0), dtype=int), vectorizer\n        else:\n            raise\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/184_4",
        "turn": "4",
        "instruct_prompt": "Remove stopwords from the text during preprocessing. Use the provided STOPWORDS list:\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_stopwords_removal(self):\n        data = pd.DataFrame({'text': ['This is a test', 'I have a pen', 'She and he went to the market', 'No stopwords here']})\n        matrix, vectorizer = task_func(data, 'text')\n        feature_names = vectorizer.get_feature_names_out()\n        # None of the stopwords should appear in feature names\n        for stopword in [\n            'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n            'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n            'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n            'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n            'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n            'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n            'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n            'further', 'then', 'once'\n        ]:\n            self.assertNotIn(stopword, feature_names)\n\n    def test_empty_after_stopwords(self):\n        # All words are stopwords, should return empty matrix with zero features\n        data = pd.DataFrame({'text': ['I am the', 'You are a', 'He is an']})\n        matrix, vectorizer = task_func(data, 'text')\n        self.assertEqual(matrix.shape[1], 0)\n        self.assertEqual(matrix.shape[0], 3)\n\n    def test_normal_text(self):\n        data = pd.DataFrame({'text': ['hello world', 'test case', 'hello test']})\n        matrix, vectorizer = task_func(data, 'text')\n        feature_names = vectorizer.get_feature_names_out()\n        expected_features = set(['hello', 'world', 'test', 'case'])\n        self.assertEqual(set(feature_names), expected_features)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport re\nimport string\n\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\n\ndef task_func(dataframe, text_column):\n    vectorizer = CountVectorizer()\n    # Preprocess: lowercase, remove numbers, remove punctuation, remove stopwords\n    def preprocess(text):\n        text = text.lower()\n        text = re.sub(r'\\d+', '', text)\n        text = text.translate(str.maketrans('', '', string.punctuation))\n        words = text.split()\n        words = [word for word in words if word not in STOPWORDS]\n        return ' '.join(words)\n    \n    text_data = dataframe[text_column].astype(str).apply(preprocess).tolist()\n    try:\n        matrix = vectorizer.fit_transform(text_data)\n        return matrix.toarray(), vectorizer\n    except ValueError as e:\n        # Handle empty vocabulary (e.g., all empty strings) by returning empty feature matrix\n        if 'empty vocabulary' in str(e):\n            return np.zeros((len(text_data), 0), dtype=int), vectorizer\n        else:\n            raise\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 25,
    "task_id": "BigCodeBench/187",
    "mt_data": [
      {
        "task_id": "BigCodeBench/187_1",
        "turn": "1",
        "instruct_prompt": "Create a GeoPandas GeoDataFrame with columns 'City' and 'Coordinates', where 'Coordinates' are Point objects with longitude and latitude values randomly generated within given ranges. You should write self-contained code starting with:```import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):```",
        "test": "import unittest\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\nclass TestCases(unittest.TestCase):\n    def test_task_func(self):\n        dic = {'Lon': (-180, 180), 'Lat': (-90, 90)}\n        cities = ['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']\n        gdf = task_func(dic, cities)\n        # Check type\n        self.assertIsInstance(gdf, gpd.GeoDataFrame)\n        # Check columns\n        self.assertIn('City', gdf.columns)\n        self.assertIn('Coordinates', gdf.columns)\n        # Check length\n        self.assertEqual(len(gdf), len(cities))\n        # Check City values\n        self.assertListEqual(list(gdf['City']), cities)\n        # Check Coordinates are Points and within ranges\n        for pt in gdf['Coordinates']:\n            self.assertIsInstance(pt, Point)\n            self.assertGreaterEqual(pt.x, dic['Lon'][0])\n            self.assertLessEqual(pt.x, dic['Lon'][1])\n            self.assertGreaterEqual(pt.y, dic['Lat'][0])\n            self.assertLessEqual(pt.y, dic['Lat'][1])\n",
        "code": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    lons = np.random.uniform(dic['Lon'][0], dic['Lon'][1], len(cities))\n    lats = np.random.uniform(dic['Lat'][0], dic['Lat'][1], len(cities))\n    points = [Point(lon, lat) for lon, lat in zip(lons, lats)]\n    gdf = gpd.GeoDataFrame({'City': cities, 'Coordinates': points})\n    return gdf\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/187_2",
        "turn": "2",
        "instruct_prompt": "Raise a ValueError exception if the input dictionary does not contain the keys 'Lon' and 'Lat', or if the values for these keys are not tuples.",
        "test": "import unittest\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\nclass TestCases(unittest.TestCase):\n    def test_valid_input(self):\n        dic = {'Lon': (-180, 180), 'Lat': (-90, 90)}\n        cities = ['A', 'B']\n        gdf = task_func(dic, cities)\n        self.assertIsInstance(gdf, gpd.GeoDataFrame)\n        self.assertEqual(len(gdf), 2)\n        self.assertTrue(all(isinstance(pt, Point) for pt in gdf['Coordinates']))\n\n    def test_missing_lon_key(self):\n        dic = {'Lat': (-90, 90)}\n        with self.assertRaises(ValueError) as cm:\n            task_func(dic)\n        self.assertIn(\"must contain 'Lon' and 'Lat'\", str(cm.exception))\n\n    def test_missing_lat_key(self):\n        dic = {'Lon': (-180, 180)}\n        with self.assertRaises(ValueError) as cm:\n            task_func(dic)\n        self.assertIn(\"must contain 'Lon' and 'Lat'\", str(cm.exception))\n\n    def test_lon_not_tuple(self):\n        dic = {'Lon': [-180, 180], 'Lat': (-90, 90)}\n        with self.assertRaises(ValueError) as cm:\n            task_func(dic)\n        self.assertIn(\"must be tuples\", str(cm.exception))\n\n    def test_lat_not_tuple(self):\n        dic = {'Lon': (-180, 180), 'Lat': [-90, 90]}\n        with self.assertRaises(ValueError) as cm:\n            task_func(dic)\n        self.assertIn(\"must be tuples\", str(cm.exception))\n",
        "code": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"Input dictionary must contain 'Lon' and 'Lat' keys.\")\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"Values for 'Lon' and 'Lat' must be tuples.\")\n    lons = np.random.uniform(dic['Lon'][0], dic['Lon'][1], len(cities))\n    lats = np.random.uniform(dic['Lat'][0], dic['Lat'][1], len(cities))\n    points = [Point(lon, lat) for lon, lat in zip(lons, lats)]\n    gdf = gpd.GeoDataFrame({'City': cities, 'Coordinates': points})\n    return gdf\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/187_3",
        "turn": "3",
        "instruct_prompt": "Ensure that the function returns a GeoPandas GeoDataFrame with 'City' and 'Coordinates' columns, where 'Coordinates' are shapely Point objects created using randomly generated longitude and latitude values within the specified ranges.",
        "test": "import unittest\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\nclass TestCases(unittest.TestCase):\n    def test_output_type_and_columns(self):\n        gdf = task_func()\n        self.assertIsInstance(gdf, gpd.GeoDataFrame)\n        self.assertIn('City', gdf.columns)\n        self.assertIn('Coordinates', gdf.columns)\n\n    def test_geometry_column_is_coordinates(self):\n        gdf = task_func()\n        self.assertEqual(gdf.geometry.name, 'Coordinates')\n\n    def test_coordinates_are_points(self):\n        gdf = task_func()\n        for geom in gdf['Coordinates']:\n            self.assertIsInstance(geom, Point)\n\n    def test_coordinates_within_bounds(self):\n        dic = {'Lon': (-50, 50), 'Lat': (-20, 20)}\n        cities = ['A', 'B', 'C']\n        gdf = task_func(dic=dic, cities=cities)\n        for point in gdf['Coordinates']:\n            self.assertGreaterEqual(point.x, dic['Lon'][0])\n            self.assertLessEqual(point.x, dic['Lon'][1])\n            self.assertGreaterEqual(point.y, dic['Lat'][0])\n            self.assertLessEqual(point.y, dic['Lat'][1])\n\n    def test_length_matches_cities(self):\n        cities = ['City1', 'City2', 'City3', 'City4']\n        gdf = task_func(cities=cities)\n        self.assertEqual(len(gdf), len(cities))\n\n    def test_error_on_missing_keys(self):\n        with self.assertRaises(ValueError):\n            task_func(dic={'Lon': (-10, 10)})\n        with self.assertRaises(ValueError):\n            task_func(dic={'Lat': (-10, 10)})\n\n    def test_error_on_non_tuple_values(self):\n        with self.assertRaises(ValueError):\n            task_func(dic={'Lon': [-10, 10], 'Lat': (-10, 10)})\n        with self.assertRaises(ValueError):\n            task_func(dic={'Lon': (-10, 10), 'Lat': [-10, 10]})\n",
        "code": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    if 'Lon' not in dic or 'Lat' not in dic:\n        raise ValueError(\"Input dictionary must contain 'Lon' and 'Lat' keys.\")\n    if not isinstance(dic['Lon'], tuple) or not isinstance(dic['Lat'], tuple):\n        raise ValueError(\"Values for 'Lon' and 'Lat' must be tuples.\")\n    lons = np.random.uniform(dic['Lon'][0], dic['Lon'][1], len(cities))\n    lats = np.random.uniform(dic['Lat'][0], dic['Lat'][1], len(cities))\n    points = [Point(lon, lat) for lon, lat in zip(lons, lats)]\n    gdf = gpd.GeoDataFrame({'City': cities, 'Coordinates': points}, geometry='Coordinates')\n    return gdf\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 26,
    "task_id": "BigCodeBench/199",
    "mt_data": [
      {
        "task_id": "BigCodeBench/199_1",
        "turn": "1",
        "instruct_prompt": "Generate a weather report for specified cities at a given UTC datetime. You should write self-contained code starting with:```python\nimport pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):",
        "test": "import unittest\nfrom datetime import datetime\nimport pandas as pd\nimport pytz\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic(self):\n        utc_dt = datetime(2023, 1, 1, 12, 0, 0, tzinfo=pytz.UTC)\n        df = task_func(utc_dt)\n        # Check type\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check columns\n        self.assertListEqual(list(df.columns), ['City', 'Local Time', 'Weather'])\n        # Check number of rows\n        self.assertEqual(len(df), 5)\n        # Check cities\n        expected_cities = ['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']\n        self.assertTrue(all(city in expected_cities for city in df['City']))\n        # Check local times have correct format\n        for lt in df['Local Time']:\n            datetime.strptime(lt, '%Y-%m-%d %H:%M:%S')  # should not raise\n        # Check weather is from given list\n        valid_weathers = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\n        self.assertTrue(all(w in valid_weathers for w in df['Weather']))\n\n    def test_task_func_timezone_conversion(self):\n        # UTC datetime corresponds to 12:00 UTC\n        utc_dt = datetime(2023, 6, 1, 12, 0, 0, tzinfo=pytz.UTC)\n        df = task_func(utc_dt)\n        # Check that local times correspond to correct timezone offsets\n        timezones = {\n            'New York': 'America/New_York',\n            'London': 'Europe/London',\n            'Beijing': 'Asia/Shanghai',\n            'Tokyo': 'Asia/Tokyo',\n            'Sydney': 'Australia/Sydney'\n        }\n        for _, row in df.iterrows():\n            city = row['City']\n            local_time_str = row['Local Time']\n            local_time = datetime.strptime(local_time_str, '%Y-%m-%d %H:%M:%S')\n            tz = pytz.timezone(timezones[city])\n            local_dt = tz.localize(local_time, is_dst=None)\n            # Convert back to UTC\n            back_utc = local_dt.astimezone(pytz.UTC)\n            # The back_utc should be equal to the original utc_dt (hour and minute)\n            self.assertEqual(back_utc.hour, utc_dt.hour)\n            self.assertEqual(back_utc.minute, utc_dt.minute)\n            self.assertEqual(back_utc.date(), utc_dt.date())\n\n    def test_task_func_seed_consistency(self):\n        utc_dt = datetime(2023, 1, 1, 12, 0, 0, tzinfo=pytz.UTC)\n        df1 = task_func(utc_dt, seed=123)\n        df2 = task_func(utc_dt, seed=123)\n        # The weather columns should be identical when using the same seed\n        self.assertListEqual(df1['Weather'].tolist(), df2['Weather'].tolist())\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\n\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    # Set random seed for reproducibility\n    set_seed(seed)\n    \n    # Ensure utc_datetime is timezone-aware in UTC\n    if utc_datetime.tzinfo is None:\n        utc_datetime = utc_datetime.replace(tzinfo=pytz.UTC)\n    else:\n        utc_datetime = utc_datetime.astimezone(pytz.UTC)\n\n    report_data = []\n    for city in cities:\n        # Convert UTC datetime to local city time\n        tz = pytz.timezone(timezones.get(city, 'UTC'))\n        local_time = utc_datetime.astimezone(tz)\n        # Randomly select a weather condition\n        weather = weather_conditions[randint(0, len(weather_conditions) - 1)]\n        # Collect data\n        report_data.append({\n            'City': city,\n            'Local Time': local_time.strftime('%Y-%m-%d %H:%M:%S'),\n            'Weather': weather\n        })\n    # Create a DataFrame and return\n    df = pd.DataFrame(report_data)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/199_2",
        "turn": "2",
        "instruct_prompt": "The function should raise a ValueError if utc_datetime is not a datetime object.",
        "test": "import unittest\nfrom datetime import datetime\nimport pandas as pd\nimport pytz\n\nclass TestCases(unittest.TestCase):\n    def test_valid_datetime(self):\n        dt = datetime(2024, 4, 27, 12, 0, 0)\n        df = task_func(dt)\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertIn('City', df.columns)\n        self.assertIn('Local Time', df.columns)\n        self.assertIn('Weather', df.columns)\n\n    def test_invalid_type(self):\n        with self.assertRaises(ValueError):\n            task_func('2024-04-27T12:00:00Z')\n\n    def test_timezone_aware_datetime(self):\n        dt_aware = datetime(2024, 4, 27, 12, 0, 0, tzinfo=pytz.UTC)\n        df = task_func(dt_aware)\n        self.assertIsInstance(df, pd.DataFrame)\n\n    def test_none_input(self):\n        with self.assertRaises(ValueError):\n            task_func(None)\n",
        "code": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\n\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    # Check if utc_datetime is a datetime object\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError('utc_datetime must be a datetime object')\n\n    # Set random seed for reproducibility\n    set_seed(seed)\n    \n    # Ensure utc_datetime is timezone-aware in UTC\n    if utc_datetime.tzinfo is None:\n        utc_datetime = utc_datetime.replace(tzinfo=pytz.UTC)\n    else:\n        utc_datetime = utc_datetime.astimezone(pytz.UTC)\n\n    report_data = []\n    for city in cities:\n        # Convert UTC datetime to local city time\n        tz = pytz.timezone(timezones.get(city, 'UTC'))\n        local_time = utc_datetime.astimezone(tz)\n        # Randomly select a weather condition\n        weather = weather_conditions[randint(0, len(weather_conditions) - 1)]\n        # Collect data\n        report_data.append({\n            'City': city,\n            'Local Time': local_time.strftime('%Y-%m-%d %H:%M:%S'),\n            'Weather': weather\n        })\n    # Create a DataFrame and return\n    df = pd.DataFrame(report_data)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/199_3",
        "turn": "3",
        "instruct_prompt": "The function should raise a ValueError if any city in the cities list does not have a corresponding timezone in the timezones dictionary.",
        "test": "import unittest\nfrom datetime import datetime\nimport pytz\n\nclass TestCases(unittest.TestCase):\n    def test_valid_cities(self):\n        # Should not raise error\n        utc_dt = datetime(2023, 1, 1, 12, 0, 0, tzinfo=pytz.UTC)\n        result = task_func(utc_dt)\n        self.assertEqual(len(result), 5)\n        self.assertIn('City', result.columns)\n        self.assertIn('Local Time', result.columns)\n        self.assertIn('Weather', result.columns)\n\n    def test_missing_timezone(self):\n        utc_dt = datetime(2023, 1, 1, 12, 0, 0, tzinfo=pytz.UTC)\n        cities = ['New York', 'Atlantis']  # 'Atlantis' not in timezones\n        with self.assertRaises(ValueError) as context:\n            task_func(utc_dt, cities=cities)\n        self.assertIn(\"Timezone for city 'Atlantis' not found\", str(context.exception))\n\n    def test_non_datetime_input(self):\n        with self.assertRaises(ValueError):\n            task_func('2023-01-01T12:00:00Z')\n",
        "code": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\n\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    # Check if utc_datetime is a datetime object\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError('utc_datetime must be a datetime object')\n\n    # Check all cities have corresponding timezones\n    for city in cities:\n        if city not in timezones:\n            raise ValueError(f\"Timezone for city '{city}' not found in timezones dictionary\")\n\n    # Set random seed for reproducibility\n    set_seed(seed)\n    \n    # Ensure utc_datetime is timezone-aware in UTC\n    if utc_datetime.tzinfo is None:\n        utc_datetime = utc_datetime.replace(tzinfo=pytz.UTC)\n    else:\n        utc_datetime = utc_datetime.astimezone(pytz.UTC)\n\n    report_data = []\n    for city in cities:\n        # Convert UTC datetime to local city time\n        tz = pytz.timezone(timezones[city])\n        local_time = utc_datetime.astimezone(tz)\n        # Randomly select a weather condition\n        weather = weather_conditions[randint(0, len(weather_conditions) - 1)]\n        # Collect data\n        report_data.append({\n            'City': city,\n            'Local Time': local_time.strftime('%Y-%m-%d %H:%M:%S'),\n            'Weather': weather\n        })\n    # Create a DataFrame and return\n    df = pd.DataFrame(report_data)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/199_4",
        "turn": "4",
        "instruct_prompt": "The function should output a pandas DataFrame with columns ['City', 'Local Time', 'Weather Condition']. 'Local Time' should be the city's local time converted from utc_datetime, formatted as 'YYYY-MM-DD HH:MM:SS ZZZ' where ZZZ is the timezone abbreviation, and 'Weather Condition' should be randomly selected from the weather_conditions list using the provided seed.",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime\nimport pytz\n\nclass TestCases(unittest.TestCase):\n    def test_output_dataframe_columns_and_types(self):\n        utc_dt = datetime(2024, 6, 1, 12, 0, 0, tzinfo=pytz.UTC)\n        df = task_func(utc_dt, seed=123)\n        # Check type\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check columns\n        self.assertListEqual(list(df.columns), ['City', 'Local Time', 'Weather Condition'])\n        # Check all cities present\n        expected_cities = ['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']\n        self.assertCountEqual(df['City'].tolist(), expected_cities)\n\n    def test_local_time_format_and_timezone_abbr(self):\n        utc_dt = datetime(2024, 6, 1, 12, 0, 0, tzinfo=pytz.UTC)\n        df = task_func(utc_dt, seed=123)\n        for _, row in df.iterrows():\n            local_time_str = row['Local Time']\n            # Format should be 'YYYY-MM-DD HH:MM:SS ZZZ'\n            parts = local_time_str.rsplit(' ', 1)\n            self.assertEqual(len(parts), 2)\n            datetime_part, tz_abbr = parts\n            # Check datetime_part format\n            try:\n                dt_obj = datetime.strptime(datetime_part, '%Y-%m-%d %H:%M:%S')\n            except ValueError:\n                self.fail(f\"Local Time datetime part format incorrect: {datetime_part}\")\n            # Check tz_abbr is non-empty string\n            self.assertTrue(isinstance(tz_abbr, str) and len(tz_abbr) > 0)\n\n    def test_weather_condition_randomness_with_seed(self):\n        utc_dt = datetime(2024, 6, 1, 12, 0, 0, tzinfo=pytz.UTC)\n        df1 = task_func(utc_dt, seed=999)\n        df2 = task_func(utc_dt, seed=999)\n        # With same seed, weather conditions should be the same\n        self.assertListEqual(df1['Weather Condition'].tolist(), df2['Weather Condition'].tolist())\n\n        df3 = task_func(utc_dt, seed=1000)\n        # With different seed, weather conditions likely differ\n        self.assertNotEqual(df1['Weather Condition'].tolist(), df3['Weather Condition'].tolist())\n\n    def test_raises_value_error_for_invalid_utc_datetime(self):\n        with self.assertRaises(ValueError):\n            task_func('not a datetime')\n\n    def test_raises_value_error_for_missing_city_timezone(self):\n        with self.assertRaises(ValueError):\n            task_func(datetime.utcnow(), cities=['UnknownCity'])\n",
        "code": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\n\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    # Check if utc_datetime is a datetime object\n    if not isinstance(utc_datetime, datetime):\n        raise ValueError('utc_datetime must be a datetime object')\n\n    # Check all cities have corresponding timezones\n    for city in cities:\n        if city not in timezones:\n            raise ValueError(f\"Timezone for city '{city}' not found in timezones dictionary\")\n\n    # Set random seed for reproducibility\n    set_seed(seed)\n    \n    # Ensure utc_datetime is timezone-aware in UTC\n    if utc_datetime.tzinfo is None:\n        utc_datetime = utc_datetime.replace(tzinfo=pytz.UTC)\n    else:\n        utc_datetime = utc_datetime.astimezone(pytz.UTC)\n\n    report_data = []\n    for city in cities:\n        # Convert UTC datetime to local city time\n        tz = pytz.timezone(timezones[city])\n        local_time = utc_datetime.astimezone(tz)\n        # Get timezone abbreviation\n        tz_abbr = local_time.tzname()\n        # Randomly select a weather condition\n        weather = weather_conditions[randint(0, len(weather_conditions) - 1)]\n        # Collect data with required columns and formatted Local Time\n        report_data.append({\n            'City': city,\n            'Local Time': local_time.strftime(f'%Y-%m-%d %H:%M:%S {tz_abbr}'),\n            'Weather Condition': weather\n        })\n    # Create a DataFrame and return\n    df = pd.DataFrame(report_data, columns=['City', 'Local Time', 'Weather Condition'])\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 27,
    "task_id": "BigCodeBench/208",
    "mt_data": [
      {
        "task_id": "BigCodeBench/208_1",
        "turn": "1",
        "instruct_prompt": "Generate a random sequence of steps of length `elements`, where each step is either -1 or 1, and compute the cumulative sum to represent a random walk. You should write self-contained code starting with:```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(elements, seed=0):\n```",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_length_and_values(self):\n        elements = 10\n        walk = task_func(elements, seed=42)\n        # Check the length\n        self.assertEqual(len(walk), elements)\n        # Check all steps are cumulative sums of -1 or 1\n        diffs = np.diff(np.insert(walk, 0, 0))\n        for d in diffs:\n            self.assertIn(d, [-1, 1])\n\n    def test_reproducibility(self):\n        elements = 100\n        walk1 = task_func(elements, seed=123)\n        walk2 = task_func(elements, seed=123)\n        np.testing.assert_array_equal(walk1, walk2)\n\n    def test_randomness(self):\n        elements = 100\n        walk1 = task_func(elements, seed=1)\n        walk2 = task_func(elements, seed=2)\n        with self.assertRaises(AssertionError):\n            np.testing.assert_array_equal(walk1, walk2)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(elements, seed=0):\n    np.random.seed(seed)\n    steps = np.random.choice([-1, 1], size=elements)\n    walk = np.cumsum(steps)\n    return walk",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/208_2",
        "turn": "2",
        "instruct_prompt": "Add input validation to raise a ValueError if `elements` is not a positive integer.",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_valid_positive_integer(self):\n        result = task_func(5, seed=1)\n        self.assertEqual(len(result), 5)\n        self.assertTrue(all(step in [-1, 1] for step in np.diff(np.insert(result, 0, 0))))\n\n    def test_zero_elements(self):\n        with self.assertRaises(ValueError):\n            task_func(0)\n\n    def test_negative_elements(self):\n        with self.assertRaises(ValueError):\n            task_func(-10)\n\n    def test_non_integer_elements(self):\n        with self.assertRaises(ValueError):\n            task_func(3.5)\n        with self.assertRaises(ValueError):\n            task_func('10')\n\n    def test_seed_consistency(self):\n        result1 = task_func(10, seed=42)\n        result2 = task_func(10, seed=42)\n        np.testing.assert_array_equal(result1, result2)\n",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError('elements must be a positive integer')\n    np.random.seed(seed)\n    steps = np.random.choice([-1, 1], size=elements)\n    walk = np.cumsum(steps)\n    return walk\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/208_3",
        "turn": "3",
        "instruct_prompt": "Calculate descriptive statistics of the random walk including count, mean, standard deviation, minimum, 5th percentile, 25th percentile, median, 75th percentile, 95th percentile, and maximum, and return these as a dictionary.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_statistics_values(self):\n        stats = task_func(1000, seed=42)\n        # Check all expected keys present\n        expected_keys = ['count', 'mean', 'std', 'min', '5%', '25%', '50%', '75%', '95%', 'max']\n        self.assertTrue(all(key in stats for key in expected_keys))\n        self.assertEqual(stats['count'], 1000)\n        # Mean is a float\n        self.assertIsInstance(stats['mean'], float)\n        # Standard deviation should be positive\n        self.assertGreater(stats['std'], 0)\n        # Minimum should be less than or equal to maximum\n        self.assertLessEqual(stats['min'], stats['max'])\n        # Percentiles should be in ascending order\n        self.assertLessEqual(stats['5%'], stats['25%'])\n        self.assertLessEqual(stats['25%'], stats['50%'])\n        self.assertLessEqual(stats['50%'], stats['75%'])\n        self.assertLessEqual(stats['75%'], stats['95%'])\n\n    def test_invalid_elements(self):\n        with self.assertRaises(ValueError):\n            task_func(0)\n        with self.assertRaises(ValueError):\n            task_func(-5)\n        with self.assertRaises(ValueError):\n            task_func('a')\n",
        "code": "import numpy as np\n\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError('elements must be a positive integer')\n    np.random.seed(seed)\n    steps = np.random.choice([-1, 1], size=elements)\n    walk = np.cumsum(steps)\n    stats = {\n        'count': len(walk),\n        'mean': np.mean(walk),\n        'std': np.std(walk, ddof=1),\n        'min': np.min(walk),\n        '5%': np.percentile(walk, 5),\n        '25%': np.percentile(walk, 25),\n        '50%': np.median(walk),\n        '75%': np.percentile(walk, 75),\n        '95%': np.percentile(walk, 95),\n        'max': np.max(walk)\n    }\n    return stats\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/208_4",
        "turn": "4",
        "instruct_prompt": "Plot the random walk on a matplotlib figure and return the Axes object along with the descriptive statistics dictionary.",
        "test": "import unittest\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_random_walk_output(self):\n        ax, stats = task_func(100, seed=42)\n        # Check type of returned Axes\n        self.assertIsInstance(ax, Axes)\n        # Check stats keys\n        expected_keys = {'count', 'mean', 'std', 'min', '5%', '25%', '50%', '75%', '95%', 'max'}\n        self.assertEqual(set(stats.keys()), expected_keys)\n        # Check count value\n        self.assertEqual(stats['count'], 100)\n\n    def test_invalid_elements(self):\n        with self.assertRaises(ValueError):\n            task_func(-1)\n        with self.assertRaises(ValueError):\n            task_func(0)\n        with self.assertRaises(ValueError):\n            task_func('abc')\n\n    def test_stats_values(self):\n        _, stats = task_func(10, seed=1)\n        # Check that mean is float\n        self.assertIsInstance(stats['mean'], float)\n        # Check min <= max\n        self.assertLessEqual(stats['min'], stats['max'])\n\n    def test_plot_content(self):\n        ax, _ = task_func(50, seed=123)\n        # There should be one line in the axes\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 1)\n        ydata = lines[0].get_ydata()\n        self.assertEqual(len(ydata), 50)\n\n",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(elements, seed=0):\n    if not isinstance(elements, int) or elements <= 0:\n        raise ValueError('elements must be a positive integer')\n    np.random.seed(seed)\n    steps = np.random.choice([-1, 1], size=elements)\n    walk = np.cumsum(steps)\n    stats = {\n        'count': len(walk),\n        'mean': np.mean(walk),\n        'std': np.std(walk, ddof=1),\n        'min': np.min(walk),\n        '5%': np.percentile(walk, 5),\n        '25%': np.percentile(walk, 25),\n        '50%': np.median(walk),\n        '75%': np.percentile(walk, 75),\n        '95%': np.percentile(walk, 95),\n        'max': np.max(walk)\n    }\n    fig, ax = plt.subplots()\n    ax.plot(walk)\n    ax.set_title('Random Walk')\n    ax.set_xlabel('Step')\n    ax.set_ylabel('Position')\n    return ax, stats\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 28,
    "task_id": "BigCodeBench/211",
    "mt_data": [
      {
        "task_id": "BigCodeBench/211_1",
        "turn": "1",
        "instruct_prompt": "Download a file from a given URL and save it to a specified directory. You should write self-contained code starting with:\n```python\nimport requests\nimport os\ndef task_func(url, destination_directory, headers=None):\n```",
        "test": "import unittest\nimport os\nimport tempfile\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    def test_download_file_success(self):\n        test_url = 'http://example.com/testfile.txt'\n        with tempfile.TemporaryDirectory() as tmpdir:\n            # Mock requests.get to avoid actual HTTP requests\n            with patch('requests.get') as mock_get:\n                mock_response = MagicMock()\n                mock_response.iter_content = lambda chunk_size: [b'hello world']\n                mock_response.raise_for_status = lambda: None\n                mock_response.__enter__.return_value = mock_response\n                mock_get.return_value = mock_response\n\n                downloaded_path = task_func(test_url, tmpdir)\n\n                self.assertTrue(os.path.isfile(downloaded_path))\n                with open(downloaded_path, 'rb') as f:\n                    content = f.read()\n                self.assertEqual(content, b'hello world')\n\n    def test_create_directory_if_not_exists(self):\n        test_url = 'http://example.com/file.txt'\n        with tempfile.TemporaryDirectory() as tmpdir:\n            new_dir = os.path.join(tmpdir, 'new_folder')\n            self.assertFalse(os.path.exists(new_dir))\n            with patch('requests.get') as mock_get:\n                mock_response = MagicMock()\n                mock_response.iter_content = lambda chunk_size: [b'data']\n                mock_response.raise_for_status = lambda: None\n                mock_response.__enter__.return_value = mock_response\n                mock_get.return_value = mock_response\n\n                downloaded_path = task_func(test_url, new_dir)\n\n                self.assertTrue(os.path.exists(new_dir))\n                self.assertTrue(os.path.isfile(downloaded_path))\n\n    def test_filename_fallback(self):\n        test_url = 'http://example.com/'  # URL ends with slash, no filename\n        with tempfile.TemporaryDirectory() as tmpdir:\n            with patch('requests.get') as mock_get:\n                mock_response = MagicMock()\n                mock_response.iter_content = lambda chunk_size: [b'data']\n                mock_response.raise_for_status = lambda: None\n                mock_response.__enter__.return_value = mock_response\n                mock_get.return_value = mock_response\n\n                downloaded_path = task_func(test_url, tmpdir)\n\n                self.assertTrue(downloaded_path.endswith('downloaded_file'))\n                self.assertTrue(os.path.isfile(downloaded_path))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import requests\nimport os\n\ndef task_func(url, destination_directory, headers=None):\n    if not os.path.exists(destination_directory):\n        os.makedirs(destination_directory)\n\n    local_filename = url.split('/')[-1]\n    if not local_filename:\n        local_filename = 'downloaded_file'\n    full_path = os.path.join(destination_directory, local_filename)\n\n    with requests.get(url, headers=headers, stream=True) as r:\n        r.raise_for_status()\n        with open(full_path, 'wb') as f:\n            for chunk in r.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n\n    return full_path\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/211_2",
        "turn": "2",
        "instruct_prompt": "The downloaded file is a zip archive. Extract its contents into the specified destination directory.",
        "test": "import unittest\nimport tempfile\nimport os\nimport zipfile\nfrom io import BytesIO\nfrom unittest import mock\nimport requests\n\nclass TestCases(unittest.TestCase):\n    @mock.patch('requests.get')\n    def test_download_and_extract_zip(self, mock_get):\n        # Create a simple zip archive in memory\n        mem_zip = BytesIO()\n        with zipfile.ZipFile(mem_zip, mode='w') as zf:\n            zf.writestr('testfile.txt', 'This is a test file')\n        mem_zip.seek(0)\n\n        # Mock response object\n        class MockResponse:\n            def __init__(self, content):\n                self.content = content\n                self.status_code = 200\n\n            def raise_for_status(self):\n                pass\n\n            def iter_content(self, chunk_size=8192):\n                # Yield content in chunks\n                for i in range(0, len(self.content), chunk_size):\n                    yield self.content[i:i+chunk_size]\n\n            def __enter__(self):\n                return self\n\n            def __exit__(self, exc_type, exc_val, exc_tb):\n                pass\n\n        mock_get.return_value = MockResponse(mem_zip.getvalue())\n\n        with tempfile.TemporaryDirectory() as tmpdir:\n            url = 'http://example.com/test.zip'\n            # Directly call task_func without import\n            downloaded_path = task_func(url, tmpdir)\n\n            # Check that the downloaded file exists\n            self.assertTrue(os.path.isfile(downloaded_path))\n\n            # Check that the extracted file exists in the destination directory\n            extracted_file_path = os.path.join(tmpdir, 'testfile.txt')\n            self.assertTrue(os.path.isfile(extracted_file_path))\n\n            # Check content of extracted file\n            with open(extracted_file_path, 'r') as f:\n                content = f.read()\n            self.assertEqual(content, 'This is a test file')\n",
        "code": "import requests\nimport os\nimport zipfile\n\ndef task_func(url, destination_directory, headers=None):\n    if not os.path.exists(destination_directory):\n        os.makedirs(destination_directory)\n\n    local_filename = url.split('/')[-1]\n    if not local_filename:\n        local_filename = 'downloaded_file'\n    full_path = os.path.join(destination_directory, local_filename)\n\n    with requests.get(url, headers=headers, stream=True) as r:\n        r.raise_for_status()\n        with open(full_path, 'wb') as f:\n            for chunk in r.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n\n    # Extract the zip file contents\n    with zipfile.ZipFile(full_path, 'r') as zip_ref:\n        zip_ref.extractall(destination_directory)\n\n    return full_path\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/211_3",
        "turn": "3",
        "instruct_prompt": "Return a list of filenames of the extracted files in the destination directory.",
        "test": "import unittest\nimport tempfile\nimport os\nimport zipfile\nfrom io import BytesIO\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory for extraction\n        self.temp_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        self.temp_dir.cleanup()\n\n    def create_test_zip_bytes(self, file_dict):\n        # file_dict: {filename: content}\n        mem_zip = BytesIO()\n        with zipfile.ZipFile(mem_zip, mode='w') as zf:\n            for filename, content in file_dict.items():\n                zf.writestr(filename, content)\n        mem_zip.seek(0)\n        return mem_zip.read()\n\n    @patch('requests.get')\n    def test_task_func_returns_extracted_filenames(self, mock_get):\n        # Prepare a zip file in bytes\n        files_in_zip = {'file1.txt': 'hello', 'file2.txt': 'world'}\n        zip_bytes = self.create_test_zip_bytes(files_in_zip)\n\n        # Mock the requests.get context manager and iter_content\n        mock_response = MagicMock()\n        # iter_content yields chunks, so yield multiple or single elements\n        # Here yield chunks of size up to 8192, but since zip_bytes is small, yield all at once\n        mock_response.iter_content = MagicMock(return_value=[zip_bytes])\n        mock_response.__enter__.return_value = mock_response\n        mock_response.raise_for_status = MagicMock()\n        mock_get.return_value = mock_response\n\n        # Directly call task_func without import\n        extracted_files = task_func('http://example.com/test.zip', self.temp_dir.name)\n\n        # Check that the extracted files list matches the zip content\n        self.assertCountEqual(extracted_files, list(files_in_zip.keys()))\n\n        # Check that extracted files actually exist in the destination directory\n        for filename in files_in_zip:\n            self.assertTrue(os.path.isfile(os.path.join(self.temp_dir.name, filename)))\n\n    @patch('requests.get')\n    def test_empty_zip_returns_empty_list(self, mock_get):\n        # Prepare an empty zip file\n        zip_bytes = self.create_test_zip_bytes({})\n\n        mock_response = MagicMock()\n        mock_response.iter_content = MagicMock(return_value=[zip_bytes])\n        mock_response.__enter__.return_value = mock_response\n        mock_response.raise_for_status = MagicMock()\n        mock_get.return_value = mock_response\n\n        extracted_files = task_func('http://example.com/empty.zip', self.temp_dir.name)\n\n        self.assertEqual(extracted_files, [])\n",
        "code": "import requests\nimport os\nimport zipfile\n\ndef task_func(url, destination_directory, headers=None):\n    if not os.path.exists(destination_directory):\n        os.makedirs(destination_directory)\n\n    local_filename = url.split('/')[-1]\n    if not local_filename:\n        local_filename = 'downloaded_file'\n    full_path = os.path.join(destination_directory, local_filename)\n\n    with requests.get(url, headers=headers, stream=True) as r:\n        r.raise_for_status()\n        with open(full_path, 'wb') as f:\n            for chunk in r.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n\n    # Extract the zip file contents\n    with zipfile.ZipFile(full_path, 'r') as zip_ref:\n        zip_ref.extractall(destination_directory)\n        extracted_files = zip_ref.namelist()\n\n    return extracted_files\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 29,
    "task_id": "BigCodeBench/214",
    "mt_data": [
      {
        "task_id": "BigCodeBench/214_1",
        "turn": "1",
        "instruct_prompt": "Generate a random RGB image as a numpy array with a given seed and image size. You should write self-contained code starting with:\n```\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n```",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_image_shape_and_dtype(self):\n        img = task_func(seed=123, image_size=(50, 60, 3), range_low=0, range_high=255)\n        self.assertEqual(img.shape, (50, 60, 3))\n        self.assertEqual(img.dtype, np.uint8)\n\n    def test_reproducibility(self):\n        img1 = task_func(seed=99, image_size=(20, 20, 3), range_low=0, range_high=255)\n        img2 = task_func(seed=99, image_size=(20, 20, 3), range_low=0, range_high=255)\n        self.assertTrue(np.array_equal(img1, img2))\n\n    def test_range(self):\n        img = task_func(seed=0, image_size=(10, 10, 3), range_low=50, range_high=100)\n        self.assertTrue(np.all(img >= 50))\n        self.assertTrue(np.all(img <= 100))\n",
        "code": "import random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    random.seed(seed)\n    np.random.seed(seed)\n    # Generate random integers in the given range for the image size\n    img = np.random.randint(range_low, range_high + 1, size=image_size, dtype=np.uint8)\n    return img\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/214_2",
        "turn": "2",
        "instruct_prompt": "The function should raise a ValueError if range_low is not less than range_high.",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_valid_range(self):\n        img = task_func(seed=1, image_size=(10, 10, 3), range_low=10, range_high=20)\n        self.assertEqual(img.shape, (10, 10, 3))\n        self.assertTrue(np.all(img >= 10))\n        self.assertTrue(np.all(img <= 20))\n\n    def test_invalid_range_equal(self):\n        with self.assertRaises(ValueError):\n            task_func(range_low=10, range_high=10)\n\n    def test_invalid_range_low_greater(self):\n        with self.assertRaises(ValueError):\n            task_func(range_low=20, range_high=10)\n",
        "code": "import random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low >= range_high:\n        raise ValueError(\"range_low must be less than range_high\")\n    random.seed(seed)\n    np.random.seed(seed)\n    # Generate random integers in the given range for the image size\n    img = np.random.randint(range_low, range_high + 1, size=image_size, dtype=np.uint8)\n    return img\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/214_3",
        "turn": "3",
        "instruct_prompt": "The function should generate the image pixel values by randomly selecting integers between range_low and range_high (inclusive) for each channel.",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_pixel_value_range(self):\n        # Test that all pixel values are within the inclusive range [range_low, range_high]\n        range_low = 10\n        range_high = 20\n        img = task_func(seed=123, image_size=(50, 50, 3), range_low=range_low, range_high=range_high)\n        self.assertTrue(np.all(img >= range_low), \"Some pixel values are less than range_low\")\n        self.assertTrue(np.all(img <= range_high), \"Some pixel values are greater than range_high\")\n\n    def test_edge_case_equal_range(self):\n        # When range_low == range_high, all pixel values should be that value\n        val = 128\n        img = task_func(seed=0, image_size=(10, 10, 3), range_low=val, range_high=val)\n        self.assertTrue(np.all(img == val), \"All pixel values should be equal to the single allowed value\")\n\n    def test_invalid_range(self):\n        # If range_low > range_high, should raise ValueError\n        with self.assertRaises(ValueError):\n            task_func(range_low=10, range_high=5)\n",
        "code": "import random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low > range_high:\n        raise ValueError(\"range_low must be less than or equal to range_high\")\n    random.seed(seed)\n    np.random.seed(seed)\n    # Generate random integers in the given range (inclusive) for each channel\n    img = np.random.randint(range_low, range_high + 1, size=image_size, dtype=np.uint8)\n    return img\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/214_4",
        "turn": "4",
        "instruct_prompt": "The function should display the generated image using matplotlib by converting it from BGR to RGB color space, and return the matplotlib axes object and the generated image numpy array.",
        "test": "import unittest\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\nclass TestCases(unittest.TestCase):\n    def test_display_and_return(self):\n        ax, img = task_func(seed=1, image_size=(10, 10, 3), range_low=0, range_high=10)\n        # Check types\n        self.assertTrue(hasattr(ax, 'imshow'))\n        self.assertIsInstance(img, np.ndarray)\n        # Check image shape\n        self.assertEqual(img.shape, (10, 10, 3))\n        # Check image dtype\n        self.assertEqual(img.dtype, np.uint8)\n        # Check pixel value range\n        self.assertTrue(np.all(img >= 0) and np.all(img <= 10))\n\n    def test_invalid_range(self):\n        with self.assertRaises(ValueError):\n            task_func(range_low=10, range_high=5)\n\n    def test_image_content_consistency(self):\n        # Check that the returned image is the same as generated (without conversion)\n        _, img1 = task_func(seed=5, image_size=(5, 5, 3), range_low=50, range_high=60)\n        _, img2 = task_func(seed=5, image_size=(5, 5, 3), range_low=50, range_high=60)\n        self.assertTrue(np.array_equal(img1, img2))\n",
        "code": "import random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    if range_low > range_high:\n        raise ValueError(\"range_low must be less than or equal to range_high\")\n    random.seed(seed)\n    np.random.seed(seed)\n    # Generate random integers in the given range (inclusive) for each channel\n    img = np.random.randint(range_low, range_high + 1, size=image_size, dtype=np.uint8)\n    # Convert BGR to RGB for matplotlib display\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    fig, ax = plt.subplots()\n    ax.imshow(img_rgb)\n    ax.axis('off')\n    plt.show()\n    return ax, img\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 30,
    "task_id": "BigCodeBench/227",
    "mt_data": [
      {
        "task_id": "BigCodeBench/227_1",
        "turn": "1",
        "instruct_prompt": "Create an MxN matrix from a list L. You should write self-contained code starting with:\n```\nimport numpy as np\n\ndef task_func(L, M, N, audio_file):\n```",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_create_matrix(self):\n        L = [1, 2, 3, 4, 5, 6]\n        M, N = 2, 3\n        expected = np.array([[1, 2, 3], [4, 5, 6]])\n        result = task_func(L, M, N, None)\n        self.assertTrue(np.array_equal(result, expected))\n\n    def test_empty_list(self):\n        L = []\n        M, N = 0, 0\n        expected = np.array([]).reshape(0, 0)\n        result = task_func(L, M, N, None)\n        self.assertTrue(np.array_equal(result, expected))\n\n    def test_single_element(self):\n        L = [7]\n        M, N = 1, 1\n        expected = np.array([[7]])\n        result = task_func(L, M, N, None)\n        self.assertTrue(np.array_equal(result, expected))\n\n    def test_invalid_reshape(self):\n        L = [1, 2, 3]\n        M, N = 2, 2\n        with self.assertRaises(ValueError):\n            task_func(L, M, N, None)\n",
        "code": "import numpy as np\n\ndef task_func(L, M, N, audio_file):\n    return np.array(L).reshape(M, N)",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/227_2",
        "turn": "2",
        "instruct_prompt": "Read the audio data from the specified audio_file and calculate the sound pressure level (SPL) using the formula SPL = 20 * log10(sqrt(mean(data^2))). If the audio file does not exist, raise a FileNotFoundError.",
        "test": "import unittest\nimport os\nimport wave\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary wave file for testing\n        self.test_filename = 'test_audio.wav'\n        with wave.open(self.test_filename, 'wb') as wf:\n            wf.setnchannels(1)  # mono\n            wf.setsampwidth(2)  # 16-bit\n            wf.setframerate(44100)\n            # Generate 1 second of 440Hz sine wave\n            t = np.linspace(0, 1, 44100, False)\n            amplitude = 10000\n            data = (amplitude * np.sin(2 * np.pi * 440 * t)).astype(np.int16)\n            wf.writeframes(data.tobytes())\n\n    def tearDown(self):\n        if os.path.exists(self.test_filename):\n            os.remove(self.test_filename)\n\n    def test_spl_calculation(self):\n        # Calculate expected SPL manually\n        amplitude = 10000\n        rms = amplitude / np.sqrt(2)  # RMS of sine wave\n        expected_spl = 20 * np.log10(rms)\n        result = task_func(None, None, None, self.test_filename)\n        self.assertAlmostEqual(result, expected_spl, places=1)\n\n    def test_file_not_found(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func(None, None, None, 'non_existent_file.wav')\n",
        "code": "import numpy as np\nimport os\n\nimport wave\n\ndef task_func(L, M, N, audio_file):\n    if not os.path.isfile(audio_file):\n        raise FileNotFoundError(f\"The file {audio_file} does not exist.\")\n\n    with wave.open(audio_file, 'rb') as wf:\n        n_frames = wf.getnframes()\n        frames = wf.readframes(n_frames)\n        # Assuming 16-bit PCM audio\n        data = np.frombuffer(frames, dtype=np.int16)\n\n    rms = np.sqrt(np.mean(data.astype(np.float64)**2))\n    spl = 20 * np.log10(rms) if rms > 0 else -np.inf\n    return spl\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/227_3",
        "turn": "3",
        "instruct_prompt": "Normalize the MxN matrix created from list L by scaling its values so that its maximum value matches the calculated SPL.",
        "test": "import unittest\nimport numpy as np\nimport tempfile\nimport wave\nimport os\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary wave file with known data\n        self.tmpfile = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')\n        with wave.open(self.tmpfile.name, 'wb') as wf:\n            wf.setnchannels(1)  # mono\n            wf.setsampwidth(2)  # 16-bit\n            wf.setframerate(44100)\n            # create a simple wave: 1000 samples of amplitude 1000\n            frames = (np.ones(1000, dtype=np.int16) * 1000).tobytes()\n            wf.writeframes(frames)\n\n    def tearDown(self):\n        os.unlink(self.tmpfile.name)\n\n    def test_normalize_matrix(self):\n        L = [1, 2, 3, 4]\n        M, N = 2, 2\n        spl, matrix = task_func(L, M, N, self.tmpfile.name)\n\n        # Check spl is a finite value\n        self.assertTrue(np.isfinite(spl))\n\n        # Check matrix shape\n        self.assertEqual(matrix.shape, (M, N))\n\n        # Check matrix max equals 10^(spl/20)\n        expected_max = 10 ** (spl / 20)\n        self.assertAlmostEqual(matrix.max(), expected_max, places=5)\n\n    def test_zero_max_value_matrix(self):\n        L = [0, 0, 0, 0]\n        M, N = 2, 2\n        spl, matrix = task_func(L, M, N, self.tmpfile.name)\n\n        # matrix should remain zeros\n        self.assertTrue(np.all(matrix == 0))\n\n    def test_file_not_found(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func([1,2,3,4], 2, 2, 'non_existent_file.wav')\n",
        "code": "import numpy as np\nimport os\nimport wave\n\ndef task_func(L, M, N, audio_file):\n    if not os.path.isfile(audio_file):\n        raise FileNotFoundError(f\"The file {audio_file} does not exist.\")\n\n    with wave.open(audio_file, 'rb') as wf:\n        n_frames = wf.getnframes()\n        frames = wf.readframes(n_frames)\n        # Assuming 16-bit PCM audio\n        data = np.frombuffer(frames, dtype=np.int16)\n\n    rms = np.sqrt(np.mean(data.astype(np.float64)**2))\n    spl = 20 * np.log10(rms) if rms > 0 else -np.inf\n\n    matrix = np.array(L).reshape(M, N)\n    max_val = matrix.max()\n    if max_val != 0:\n        matrix = matrix * (10 ** (spl / 20)) / max_val\n    else:\n        matrix = matrix.copy()  # no scaling if max_val is 0\n\n    return spl, matrix\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/227_4",
        "turn": "4",
        "instruct_prompt": "Generate and display a spectrogram from the normalized matrix using a logarithmic scale for frequency and a linear scale for time. The SPL should be used to adjust the amplitude displayed in the spectrogram. Return both the normalized matrix and the matplotlib figure object of the spectrogram.",
        "test": "import unittest\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport os\nimport wave\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary wave file for testing\n        self.test_wave_path = 'test_audio.wav'\n        framerate = 8000\n        duration = 0.1  # seconds\n        frequency = 440  # A4\n        t = np.linspace(0, duration, int(framerate * duration), endpoint=False)\n        amplitude = 32767\n        data = (amplitude * np.sin(2 * np.pi * frequency * t)).astype(np.int16)\n\n        with wave.open(self.test_wave_path, 'wb') as wf:\n            wf.setnchannels(1)\n            wf.setsampwidth(2)  # 16 bits\n            wf.setframerate(framerate)\n            wf.writeframes(data.tobytes())\n\n    def tearDown(self):\n        if os.path.isfile(self.test_wave_path):\n            os.remove(self.test_wave_path)\n\n    def test_spectrogram_output_and_return(self):\n        # Prepare matrix L with known values\n        M, N = 10, 20\n        L = list(range(1, M * N + 1))\n\n        normalized_matrix, fig = task_func(L, M, N, self.test_wave_path)\n\n        # Check normalized_matrix shape\n        self.assertEqual(normalized_matrix.shape, (M, N))\n\n        # Check that normalized_matrix is scaled properly (max should be <= original max scaled by SPL factor)\n        orig_matrix = np.array(L).reshape(M, N)\n        max_orig = orig_matrix.max()\n\n        with wave.open(self.test_wave_path, 'rb') as wf:\n            frames = wf.readframes(wf.getnframes())\n            data = np.frombuffer(frames, dtype=np.int16)\n            rms = np.sqrt(np.mean(data.astype(np.float64)**2))\n            spl = 20 * np.log10(rms) if rms > 0 else -np.inf\n        expected_max = 10 ** (spl / 20) if spl != -np.inf else 0\n\n        # Because of floating point, allow small tolerance\n        self.assertAlmostEqual(normalized_matrix.max(), expected_max, places=5)\n\n        # Check that returned fig is a matplotlib figure instance\n        import matplotlib.figure\n        self.assertIsInstance(fig, matplotlib.figure.Figure)\n\n        # Check axes scales\n        ax = fig.axes[0]\n        self.assertEqual(ax.get_yscale(), 'log')\n        self.assertEqual(ax.get_xscale(), 'linear')\n\n        # Check that colorbar label contains 'Amplitude'\n        colorbar = fig.axes[1]\n        self.assertIn('Amplitude', colorbar.get_ylabel())\n\n    def test_file_not_found_error(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func([1,2,3,4], 2, 2, 'non_existent_file.wav')\n",
        "code": "import numpy as np\nimport os\nimport wave\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LogNorm\n\ndef task_func(L, M, N, audio_file):\n    if not os.path.isfile(audio_file):\n        raise FileNotFoundError(f\"The file {audio_file} does not exist.\")\n\n    with wave.open(audio_file, 'rb') as wf:\n        n_frames = wf.getnframes()\n        frames = wf.readframes(n_frames)\n        # Assuming 16-bit PCM audio\n        data = np.frombuffer(frames, dtype=np.int16)\n\n    rms = np.sqrt(np.mean(data.astype(np.float64)**2))\n    spl = 20 * np.log10(rms) if rms > 0 else -np.inf\n\n    matrix = np.array(L).reshape(M, N)\n    max_val = matrix.max()\n    if max_val != 0:\n        normalized_matrix = matrix * (10 ** (spl / 20)) / max_val\n    else:\n        normalized_matrix = matrix.copy()  # no scaling if max_val is 0\n\n    fig, ax = plt.subplots()\n    # Display spectrogram with logarithmic frequency scale (y-axis) and linear time scale (x-axis)\n    # Use SPL adjusted normalized_matrix as amplitude\n    # Set extent to have frequency from 1 to M (to allow log scale, start from 1 to avoid log(0))\n    extent = [0, N, 1, M]\n    cax = ax.imshow(normalized_matrix, aspect='auto', origin='lower', extent=extent, norm=LogNorm(vmin=normalized_matrix[normalized_matrix > 0].min() if np.any(normalized_matrix > 0) else 1e-10, vmax=normalized_matrix.max()), cmap='viridis')\n    ax.set_yscale('log')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Frequency (log scale)')\n    ax.set_title('Spectrogram (log freq scale, linear time scale)')\n    fig.colorbar(cax, ax=ax, label='Amplitude (SPL adjusted)')\n\n    return normalized_matrix, fig\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 31,
    "task_id": "BigCodeBench/239",
    "mt_data": [
      {
        "task_id": "BigCodeBench/239_1",
        "turn": "1",
        "instruct_prompt": "Given a list of tuples, extract the second element from each tuple and return it as a numpy array.\nYou should write self-contained code starting with:\n```python\nimport numpy as np\ndef task_func(original):\n```",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        data = [(1, 2), (3, 4), (5, 6)]\n        result = task_func(data)\n        expected = np.array([2, 4, 6])\n        np.testing.assert_array_equal(result, expected)\n\n    def test_empty(self):\n        data = []\n        result = task_func(data)\n        expected = np.array([])\n        np.testing.assert_array_equal(result, expected)\n\n    def test_single_tuple(self):\n        data = [(10, 20)]\n        result = task_func(data)\n        expected = np.array([20])\n        np.testing.assert_array_equal(result, expected)\n\n    def test_varied_types(self):\n        data = [(\"a\", 1), (\"b\", 2), (\"c\", 3)]\n        result = task_func(data)\n        expected = np.array([1, 2, 3])\n        np.testing.assert_array_equal(result, expected)\n",
        "code": "import numpy as np\n\ndef task_func(original):\n    return np.array([t[1] for t in original])",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/239_2",
        "turn": "2",
        "instruct_prompt": "Compute basic statistics (mean, standard deviation, minimum, and maximum) for the extracted numpy array and return them as a dictionary.",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_statistics(self):\n        data = [(1, 10), (2, 20), (3, 30), (4, 40)]\n        result = task_func(data)\n        expected = {\n            'mean': np.mean([10, 20, 30, 40]),\n            'std': np.std([10, 20, 30, 40]),\n            'min': np.min([10, 20, 30, 40]),\n            'max': np.max([10, 20, 30, 40])\n        }\n        self.assertAlmostEqual(result['mean'], expected['mean'])\n        self.assertAlmostEqual(result['std'], expected['std'])\n        self.assertEqual(result['min'], expected['min'])\n        self.assertEqual(result['max'], expected['max'])\n\n    def test_single_element(self):\n        data = [(1, 5)]\n        result = task_func(data)\n        expected = {\n            'mean': 5.0,\n            'std': 0.0,\n            'min': 5,\n            'max': 5\n        }\n        self.assertEqual(result, expected)\n\n    def test_negative_values(self):\n        data = [(1, -10), (2, -20), (3, -30)]\n        result = task_func(data)\n        expected = {\n            'mean': np.mean([-10, -20, -30]),\n            'std': np.std([-10, -20, -30]),\n            'min': -30,\n            'max': -10\n        }\n        self.assertAlmostEqual(result['mean'], expected['mean'])\n        self.assertAlmostEqual(result['std'], expected['std'])\n        self.assertEqual(result['min'], expected['min'])\n        self.assertEqual(result['max'], expected['max'])",
        "code": "import numpy as np\n\ndef task_func(original):\n    arr = np.array([t[1] for t in original])\n    stats = {\n        'mean': np.mean(arr),\n        'std': np.std(arr),\n        'min': np.min(arr),\n        'max': np.max(arr)\n    }\n    return stats",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/239_3",
        "turn": "3",
        "instruct_prompt": "Plot a histogram of the numpy array with density=True, alpha=0.6, and bins='auto', then overlay a normal distribution PDF curve based on the computed mean and standard deviation. Return the matplotlib Axes object showing this plot.",
        "test": "import unittest\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nclass TestCases(unittest.TestCase):\n    def test_histogram_and_pdf_overlay(self):\n        # Prepare input data (list of tuples with second element as value)\n        np.random.seed(0)\n        data = [(i, v) for i, v in enumerate(np.random.normal(loc=5, scale=2, size=1000))]\n\n        ax = task_func(data)\n\n        # Check that returned object is a matplotlib Axes\n        self.assertIsInstance(ax, plt.Axes)\n\n        # Extract histogram patches and line data\n        patches = ax.patches\n        lines = ax.lines\n\n        # There should be histogram bars (patches)\n        self.assertTrue(len(patches) > 0)\n\n        # There should be one line for the PDF\n        self.assertEqual(len(lines), 1)\n\n        # Check histogram properties: density=True means area ~1\n        heights = [p.get_height() for p in patches]\n        # Sum of bar heights * bin width should be close to 1\n        bin_widths = [p.get_width() for p in patches]\n        area = sum(h * w for h, w in zip(heights, bin_widths))\n        self.assertAlmostEqual(area, 1, places=2)\n\n        # Check line data corresponds roughly to normal PDF with mean and std of data\n        arr = np.array([t[1] for t in data])\n        mean = np.mean(arr)\n        std = np.std(arr)\n\n        x_line = lines[0].get_xdata()\n        y_line = lines[0].get_ydata()\n\n        # Check y_line values match norm.pdf values at x_line\n        expected_pdf = norm.pdf(x_line, mean, std)\n        np.testing.assert_allclose(y_line, expected_pdf, rtol=1e-5)\n",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(original):\n    arr = np.array([t[1] for t in original])\n    mean = np.mean(arr)\n    std = np.std(arr)\n\n    fig, ax = plt.subplots()\n    # Plot histogram with specified parameters\n    count, bins, patches = ax.hist(arr, bins='auto', density=True, alpha=0.6, color='b')\n\n    # Plot normal distribution PDF curve\n    xmin, xmax = bins[0], bins[-1]\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mean, std)\n    ax.plot(x, p, 'r', linewidth=2)\n\n    return ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 32,
    "task_id": "BigCodeBench/241",
    "mt_data": [
      {
        "task_id": "BigCodeBench/241_1",
        "turn": "1",
        "instruct_prompt": "Create a numpy array from the input list named \"original\" inside the function task_func. You should write self-contained code starting with:\n```\nimport numpy as np\nfrom sklearn import preprocessing\ndef task_func(original):\n```",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_create_numpy_array(self):\n        original = [1, 2, 3, 4]\n        result = task_func(original)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue((result == np.array([1, 2, 3, 4])).all())\n\n    def test_create_numpy_array_empty(self):\n        original = []\n        result = task_func(original)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.size, 0)\n\n    def test_create_numpy_array_with_strings(self):\n        original = ['a', 'b', 'c']\n        result = task_func(original)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertTrue((result == np.array(['a', 'b', 'c'])).all())",
        "code": "import numpy as np\nfrom sklearn import preprocessing\ndef task_func(original):\n    return np.array(original)",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/241_2",
        "turn": "2",
        "instruct_prompt": "Normalize the created numpy array using sklearn.preprocessing.normalize.",
        "test": "import unittest\nimport numpy as np\nfrom sklearn.preprocessing import normalize\n\nclass TestCases(unittest.TestCase):\n    def test_normalize_simple(self):\n        original = [[1, 0], [0, 1]]\n        result = task_func(original)\n        expected = normalize(np.array(original))\n        np.testing.assert_almost_equal(result, expected)\n\n    def test_normalize_non_normalized(self):\n        original = [[3, 4], [1, 2]]\n        result = task_func(original)\n        expected = normalize(np.array(original))\n        np.testing.assert_almost_equal(result, expected)\n\n    def test_normalize_with_zeros(self):\n        original = [[0, 0], [1, 0]]\n        result = task_func(original)\n        expected = normalize(np.array(original))\n        np.testing.assert_almost_equal(result, expected)\n\nif __name__ == \"__main__\":\n    unittest.main()",
        "code": "import numpy as np\nfrom sklearn import preprocessing\n\ndef task_func(original):\n    arr = np.array(original)\n    normalized_arr = preprocessing.normalize(arr)\n    return normalized_arr",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/241_3",
        "turn": "3",
        "instruct_prompt": "Plot the original and normalized arrays on the same matplotlib Axes object with the title 'Original vs. Normalized Data' and include a legend distinguishing the two lines.",
        "test": "import unittest\nimport numpy as np\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_normalization_and_plot(self):\n        original = [[1, 2, 3], [4, 5, 6]]\n        arr = np.array(original)\n        expected = preprocessing.normalize(arr)\n\n        fig, ax = plt.subplots()\n        normalized_arr = task_func(original, ax=ax)\n\n        # Check normalization correctness\n        np.testing.assert_almost_equal(normalized_arr, expected)\n\n        # Check that the title is exactly as required\n        self.assertEqual(ax.get_title(), 'Original vs. Normalized Data')\n\n        # Check legend labels\n        legend = ax.get_legend()\n        self.assertIsNotNone(legend)\n        labels = [text.get_text() for text in legend.get_texts()]\n        self.assertIn('Original', labels)\n        self.assertIn('Normalized', labels)\n        self.assertEqual(len(labels), 2)\n\n        # Check that two lines are plotted on the same Axes\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 2)\n\n    def test_previous_round_code_fails(self):\n        # This test ensures that the previous round's code (which only returns normalized array and does not plot)\n        # would fail the current test requirements.\n        # We simulate the previous round by calling a dummy function without plotting.\n        def previous_round_task_func(original):\n            arr = np.array(original)\n            return preprocessing.normalize(arr)\n\n        original = [[1, 2, 3], [4, 5, 6]]\n        fig, ax = plt.subplots()\n        normalized_arr = previous_round_task_func(original)\n\n        # The previous round code does not plot, so no lines should be present\n        lines = ax.get_lines()\n        self.assertNotEqual(len(lines), 2)  # This should fail as no lines are plotted\n\n        # Also title should not be set\n        self.assertNotEqual(ax.get_title(), 'Original vs. Normalized Data')\n\n        # Legend should be None or empty\n        legend = ax.get_legend()\n        self.assertTrue(legend is None or len(legend.get_texts()) == 0)\n",
        "code": "import numpy as np\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\n\ndef task_func(original, ax=None):\n    arr = np.array(original)\n    normalized_arr = preprocessing.normalize(arr)\n    if ax is None:\n        fig, ax = plt.subplots()\n    ax.plot(arr.flatten(), label='Original')\n    ax.plot(normalized_arr.flatten(), label='Normalized')\n    ax.set_title('Original vs. Normalized Data')\n    ax.legend()\n    return normalized_arr",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/241_4",
        "turn": "4",
        "instruct_prompt": "Return a tuple containing the original numpy array, the normalized numpy array, and the matplotlib.axes.Axes object containing the plot.",
        "test": "import unittest\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_return_types_and_values(self):\n        original = [[1, 2, 3], [4, 5, 6]]\n        arr, normalized_arr, ax = task_func(original)\n        # Check types\n        self.assertIsInstance(arr, np.ndarray)\n        self.assertIsInstance(normalized_arr, np.ndarray)\n        self.assertIsInstance(ax, Axes)\n        # Check original array is unchanged\n        np.testing.assert_array_equal(arr, np.array(original))\n        # Check normalized array shape matches original\n        self.assertEqual(normalized_arr.shape, arr.shape)\n        # Check normalized array is normalized (rows norm to 1)\n        norms = np.linalg.norm(normalized_arr, axis=1)\n        np.testing.assert_allclose(norms, np.ones_like(norms))\n\n    def test_task_func_with_provided_ax(self):\n        original = [[3, 4]]\n        fig, ax = plt.subplots()\n        arr, normalized_arr, returned_ax = task_func(original, ax=ax)\n        self.assertIs(returned_ax, ax)\n        plt.close(fig)\n\n    def test_task_func_plot_labels(self):\n        original = [[1, 0], [0, 1]]\n        fig, ax = plt.subplots()\n        _, _, ax = task_func(original, ax=ax)\n        labels = [line.get_label() for line in ax.get_lines()]\n        self.assertIn('Original', labels)\n        self.assertIn('Normalized', labels)\n        plt.close(fig)\n",
        "code": "import numpy as np\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\n\ndef task_func(original, ax=None):\n    arr = np.array(original)\n    normalized_arr = preprocessing.normalize(arr)\n    if ax is None:\n        fig, ax = plt.subplots()\n    ax.plot(arr.flatten(), label='Original')\n    ax.plot(normalized_arr.flatten(), label='Normalized')\n    ax.set_title('Original vs. Normalized Data')\n    ax.legend()\n    return arr, normalized_arr, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 33,
    "task_id": "BigCodeBench/267",
    "mt_data": [
      {
        "task_id": "BigCodeBench/267_1",
        "turn": "1",
        "instruct_prompt": "Write a function that adds a new key 'a' with the value 1 to the input dictionary `data`. You should write self-contained code starting with:\n```\nimport numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\ndef task_func(data, sample_rate=8000):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_add_key_a(self):\n        input_dict = {'x': 10}\n        expected = {'x': 10, 'a': 1}\n        result = task_func(input_dict.copy())\n        self.assertEqual(result, expected)\n\n    def test_empty_dict(self):\n        input_dict = {}\n        expected = {'a': 1}\n        result = task_func(input_dict.copy())\n        self.assertEqual(result, expected)\n\n    def test_overwrite_existing_a(self):\n        input_dict = {'a': 5}\n        expected = {'a': 1}\n        result = task_func(input_dict.copy())\n        self.assertEqual(result, expected)\n",
        "code": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\ndef task_func(data, sample_rate=8000):\n    data['a'] = 1\n    return data\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/267_2",
        "turn": "2",
        "instruct_prompt": "Generate a signal as a numpy array from the values of the updated dictionary `data`. The signal should be created by taking the sine of the outer product of a time vector and the array of dictionary values multiplied by pi. The time vector should be linearly spaced from 0 to 2 seconds with length equal to 2 * sample_rate.",
        "test": "import unittest\nimport numpy as np\nfrom math import isclose\n\nclass TestCases(unittest.TestCase):\n    def test_signal_shape_and_values(self):\n        data = {'x': 2, 'y': 3}\n        sample_rate = 8000\n        signal = task_func(data, sample_rate)\n        # Check that 'a' was added\n        self.assertIn('a', data)\n        self.assertEqual(data['a'], 1)\n        # Check shape\n        expected_shape = (2 * sample_rate, len(data))\n        self.assertEqual(signal.shape, expected_shape)\n        # Check some known values\n        # At t=0, sin(0) = 0 for all\n        self.assertTrue(np.allclose(signal[0, :], 0))\n        # At t=2, sin(2 * pi * values) = sin(2*pi*values) = 0\n        self.assertTrue(np.allclose(signal[-1, :], 0, atol=1e-10))\n        # Check that values are between -1 and 1\n        self.assertTrue(np.all(signal <= 1))\n        self.assertTrue(np.all(signal >= -1))\n",
        "code": "import numpy as np\n\ndef task_func(data, sample_rate=8000):\n    data['a'] = 1\n    values = np.array(list(data.values()))\n    t = np.linspace(0, 2, 2 * sample_rate)\n    signal = np.sin(np.outer(t, values) * np.pi)\n    return signal\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/267_3",
        "turn": "3",
        "instruct_prompt": "Perform a Fast Fourier Transform (FFT) on the generated signal using `scipy.fftpack.fft`.",
        "test": "import unittest\nimport numpy as np\nfrom scipy.fftpack import fft\n\nclass TestCases(unittest.TestCase):\n    def test_fft_output_shape(self):\n        data = {'x': 2, 'y': 3}\n        sample_rate = 8000\n        result = task_func(data, sample_rate)\n        # In task_func, 'a' is added, so total keys = len(data) + 1\n        expected_num_columns = len(data) + 1\n        self.assertEqual(result.shape, (2 * sample_rate, expected_num_columns))\n\n    def test_fft_values(self):\n        data = {'x': 1}\n        sample_rate = 4  # smaller sample rate for easier manual verification\n        # replicate task_func logic for expected fft\n        data_copy = data.copy()\n        data_copy['a'] = 1\n        values = np.array(list(data_copy.values()))\n        t = np.linspace(0, 2, 2 * sample_rate)\n        signal = np.sin(np.outer(t, values) * np.pi)\n        expected_fft = fft(signal, axis=0)\n\n        result = task_func(data, sample_rate)\n        np.testing.assert_allclose(result, expected_fft, rtol=1e-7, atol=1e-7)\n",
        "code": "import numpy as np\nfrom scipy.fftpack import fft\n\ndef task_func(data, sample_rate=8000):\n    data = data.copy()  # avoid modifying the original dict\n    data['a'] = 1\n    values = np.array(list(data.values()))\n    t = np.linspace(0, 2, 2 * sample_rate)\n    signal = np.sin(np.outer(t, values) * np.pi)\n    signal_fft = fft(signal, axis=0)\n    return signal_fft\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/267_4",
        "turn": "4",
        "instruct_prompt": "Plot the magnitude of the FFT using matplotlib. The plot should have the title 'FFT of the Signal', with x-axis labeled 'Frequency [Hz]' and y-axis labeled 'Frequency Spectrum Magnitude'. Finally, return a tuple containing the FFT result and the matplotlib Axes object.",
        "test": "import unittest\nimport numpy as np\nfrom scipy.fftpack import fft\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_fft_and_plot(self):\n        data = {'x': 1, 'y': 2}\n        fft_result, ax = task_func(data, sample_rate=8000)\n\n        # Check fft_result shape\n        self.assertEqual(fft_result.shape[0], 16000)\n        self.assertEqual(fft_result.shape[1], len(data) + 1)  # because 'a' was added\n\n        # Check that ax is a matplotlib Axes object\n        self.assertTrue(hasattr(ax, 'plot'))\n\n        # Check plot labels and title\n        self.assertEqual(ax.get_title(), 'FFT of the Signal')\n        self.assertEqual(ax.get_xlabel(), 'Frequency [Hz]')\n        self.assertEqual(ax.get_ylabel(), 'Frequency Spectrum Magnitude')\n\n    def test_previous_code_should_fail(self):\n        # Previous code did not return a plot, so using old version should fail these tests\n        from types import SimpleNamespace\n\n        def old_task_func(data, sample_rate=8000):\n            data = data.copy()\n            data['a'] = 1\n            values = np.array(list(data.values()))\n            t = np.linspace(0, 2, 2 * sample_rate)\n            signal = np.sin(np.outer(t, values) * np.pi)\n            signal_fft = fft(signal, axis=0)\n            return signal_fft\n\n        data = {'x': 1, 'y': 2}\n        result = old_task_func(data, sample_rate=8000)\n\n        # This will fail because old_task_func returns only fft_result, no ax\n        with self.assertRaises(ValueError):\n            fft_result, ax = result  # unpacking should fail\n\n        # Even if we try to forcibly treat result as ax, it won't have plotting attributes\n        self.assertFalse(hasattr(result, 'plot'))\n",
        "code": "import numpy as np\nfrom scipy.fftpack import fft\nimport matplotlib.pyplot as plt\n\ndef task_func(data, sample_rate=8000):\n    data = data.copy()  # avoid modifying the original dict\n    data['a'] = 1\n    values = np.array(list(data.values()))\n    t = np.linspace(0, 2, 2 * sample_rate)\n    signal = np.sin(np.outer(t, values) * np.pi)\n    signal_fft = fft(signal, axis=0)\n\n    # Frequency axis\n    freqs = np.fft.fftfreq(signal.shape[0], d=1/sample_rate)\n\n    # Plotting\n    fig, ax = plt.subplots()\n    ax.plot(freqs[:signal.shape[0] // 2], np.abs(signal_fft[:signal.shape[0] // 2]))\n    ax.set_title('FFT of the Signal')\n    ax.set_xlabel('Frequency [Hz]')\n    ax.set_ylabel('Frequency Spectrum Magnitude')\n\n    return signal_fft, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 34,
    "task_id": "BigCodeBench/273",
    "mt_data": [
      {
        "task_id": "BigCodeBench/273_1",
        "turn": "1",
        "instruct_prompt": "Create a basic HTTP POST request handler class that can accept requests and send a fixed 200 success response. You should write self-contained code starting with:\n```\nimport cgi\nimport http.server\nimport json\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\ndef task_func():\n```",
        "test": "import unittest\nimport threading\nimport http.client\nimport time\nimport json\nfrom http.server import HTTPServer\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        handler_class = task_func()\n        self.server = HTTPServer(('localhost', 0), handler_class)  # Bind to free port\n        self.port = self.server.server_port\n        self.thread = threading.Thread(target=self.server.serve_forever)\n        self.thread.daemon = True\n        self.thread.start()\n\n    def tearDown(self):\n        self.server.shutdown()\n        self.thread.join()\n\n    def test_post_success_response(self):\n        conn = http.client.HTTPConnection('localhost', self.port)\n        headers = {'Content-Type': 'application/json'}\n        body = json.dumps({'key': 'value'})\n        conn.request('POST', '/', body=body, headers=headers)\n        response = conn.getresponse()\n        self.assertEqual(response.status, 200)\n        data = response.read()\n        response_json = json.loads(data.decode('utf-8'))\n        self.assertEqual(response_json, {\n            'status': 'success',\n            'message': 'Data received successfully.'\n        })\n        conn.close()\n",
        "code": "import cgi\nimport http.server\nimport json\n\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\n\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\n\ndef task_func():\n    class SimplePostHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            # Read and ignore the incoming data\n            content_length = int(self.headers.get('Content-Length', 0))\n            _ = self.rfile.read(content_length)\n            \n            # Send 200 success response\n            self.send_response(200)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            response = json.dumps(SUCCESS_RESPONSE).encode('utf-8')\n            self.wfile.write(response)\n\n    return SimplePostHandler\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/273_2",
        "turn": "2",
        "instruct_prompt": "Add validation to the handler so that it checks if the 'content-type' header of the incoming POST request is 'application/json'. If it is not, respond with a 400 Bad Request and the message 'Content-Type header is not application/json'.",
        "test": "import unittest\nfrom io import BytesIO\nfrom http.client import HTTPMessage\nfrom http.server import BaseHTTPRequestHandler\n\nclass DummyRequest:\n    def __init__(self, headers, body=b''):\n        self.headers = headers\n        self.rfile = BytesIO(body)\n        self.wfile = BytesIO()\n\nclass DummyHeaders(HTTPMessage):\n    def __init__(self, headers):\n        super().__init__()\n        for key, value in headers.items():\n            self[key] = value\n\nclass TestCases(unittest.TestCase):\n    def test_post_with_application_json_content_type(self):\n        handler_class = task_func()\n\n        headers = DummyHeaders({'Content-Type': 'application/json', 'Content-Length': '2'})\n        req = DummyRequest(headers, b'{}')\n\n        class TestHandler(handler_class):\n            def __init__(self):\n                self.headers = req.headers\n                self.rfile = req.rfile\n                self.wfile = req.wfile\n                self.responses = []\n            def send_response(self, code, message=None):\n                self.responses.append(('code', code))\n            def send_header(self, key, value):\n                self.responses.append(('header', (key, value)))\n            def end_headers(self):\n                self.responses.append(('end_headers', None))\n\n        handler = TestHandler()\n        handler.do_POST()\n\n        # Check that response code is 200\n        self.assertIn(('code', 200), handler.responses)\n        # Check that Content-Type header is application/json\n        self.assertIn(('header', ('Content-Type', 'application/json')), handler.responses)\n        # Check response body contains success status\n        handler.wfile.seek(0)\n        response_body = handler.wfile.read().decode('utf-8')\n        self.assertIn('success', response_body)\n\n    def test_post_with_wrong_content_type(self):\n        handler_class = task_func()\n\n        headers = DummyHeaders({'Content-Type': 'text/plain', 'Content-Length': '2'})\n        req = DummyRequest(headers, b'{}')\n\n        class TestHandler(handler_class):\n            def __init__(self):\n                self.headers = req.headers\n                self.rfile = req.rfile\n                self.wfile = req.wfile\n                self.responses = []\n            def send_response(self, code, message=None):\n                self.responses.append(('code', code))\n            def send_header(self, key, value):\n                self.responses.append(('header', (key, value)))\n            def end_headers(self):\n                self.responses.append(('end_headers', None))\n\n        handler = TestHandler()\n        handler.do_POST()\n\n        # Check that response code is 400\n        self.assertIn(('code', 400), handler.responses)\n        # Check that Content-Type header is application/json\n        self.assertIn(('header', ('Content-Type', 'application/json')), handler.responses)\n        # Check response body contains error message\n        handler.wfile.seek(0)\n        response_body = handler.wfile.read().decode('utf-8')\n        self.assertIn('Content-Type header is not application/json', response_body)\n\n    def test_post_with_missing_content_type(self):\n        handler_class = task_func()\n\n        headers = DummyHeaders({'Content-Length': '2'})\n        req = DummyRequest(headers, b'{}')\n\n        class TestHandler(handler_class):\n            def __init__(self):\n                self.headers = req.headers\n                self.rfile = req.rfile\n                self.wfile = req.wfile\n                self.responses = []\n            def send_response(self, code, message=None):\n                self.responses.append(('code', code))\n            def send_header(self, key, value):\n                self.responses.append(('header', (key, value)))\n            def end_headers(self):\n                self.responses.append(('end_headers', None))\n\n        handler = TestHandler()\n        handler.do_POST()\n\n        # Missing Content-Type treated as error\n        self.assertIn(('code', 400), handler.responses)\n        self.assertIn(('header', ('Content-Type', 'application/json')), handler.responses)\n        handler.wfile.seek(0)\n        response_body = handler.wfile.read().decode('utf-8')\n        self.assertIn('Content-Type header is not application/json', response_body)\n",
        "code": "import cgi\nimport http.server\nimport json\n\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\n\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Content-Type header is not application/json'\n}\n\ndef task_func():\n    class SimplePostHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_type = self.headers.get('Content-Type')\n            if content_type != 'application/json':\n                self.send_response(400)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                response = json.dumps(ERROR_RESPONSE).encode('utf-8')\n                self.wfile.write(response)\n                return\n\n            content_length = int(self.headers.get('Content-Length', 0))\n            _ = self.rfile.read(content_length)\n\n            self.send_response(200)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            response = json.dumps(SUCCESS_RESPONSE).encode('utf-8')\n            self.wfile.write(response)\n\n    return SimplePostHandler\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/273_3",
        "turn": "3",
        "instruct_prompt": "Parse the request body as JSON. If parsing fails due to invalid JSON, respond with a 400 Bad Request and the message 'Invalid JSON'.",
        "test": "import unittest\nimport io\nimport json\nimport http.server\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.HandlerClass = task_func()\n\n    class TestHandler(http.server.BaseHTTPRequestHandler):\n        # Override methods to prevent actual socket operations and parsing\n        def __init__(self, request_bytes, headers_dict):\n            self.rfile = io.BytesIO(request_bytes)\n            self.wfile = io.BytesIO()\n            self.headers = http.client.HTTPMessage()\n            for k, v in headers_dict.items():\n                self.headers[k] = v\n            self.responses = []\n            self._headers_buffer = []\n\n        def send_response(self, code, message=None):\n            self.responses.append(code)\n\n        def send_header(self, keyword, value):\n            pass\n\n        def end_headers(self):\n            pass\n\n    def make_handler(self, headers, body_bytes):\n        # Create an instance of the subclassed handler with controlled headers and body\n        handler = self.TestHandler(body_bytes, headers)\n        # Bind do_POST method from the actual HandlerClass to this instance\n        handler.do_POST = self.HandlerClass.do_POST.__get__(handler, self.HandlerClass)\n        return handler\n\n    def test_valid_json(self):\n        body = json.dumps({'key': 'value'}).encode('utf-8')\n        headers = {'Content-Type': 'application/json', 'Content-Length': str(len(body))}\n        handler = self.make_handler(headers, body)\n\n        handler.do_POST()\n\n        self.assertIn(200, handler.responses)\n        handler.wfile.seek(0)\n        response_data = json.loads(handler.wfile.read())\n        self.assertEqual(response_data['status'], 'success')\n\n    def test_invalid_content_type(self):\n        body = b'{}'\n        headers = {'Content-Type': 'text/plain', 'Content-Length': str(len(body))}\n        handler = self.make_handler(headers, body)\n\n        handler.do_POST()\n\n        self.assertIn(400, handler.responses)\n        handler.wfile.seek(0)\n        response_data = json.loads(handler.wfile.read())\n        self.assertEqual(response_data['message'], 'Content-Type header is not application/json')\n\n    def test_invalid_json(self):\n        body = b'{invalid json}'\n        headers = {'Content-Type': 'application/json', 'Content-Length': str(len(body))}\n        handler = self.make_handler(headers, body)\n\n        handler.do_POST()\n\n        self.assertIn(400, handler.responses)\n        handler.wfile.seek(0)\n        response_data = json.loads(handler.wfile.read())\n        self.assertEqual(response_data['message'], 'Invalid JSON')\n",
        "code": "import http.server\nimport json\n\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\n\nERROR_CONTENT_TYPE_RESPONSE = {\n    'status': 'error',\n    'message': 'Content-Type header is not application/json'\n}\n\nERROR_INVALID_JSON_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid JSON'\n}\n\ndef task_func():\n    class SimplePostHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_type = self.headers.get('Content-Type')\n            if content_type != 'application/json':\n                self.send_response(400)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                response = json.dumps(ERROR_CONTENT_TYPE_RESPONSE).encode('utf-8')\n                self.wfile.write(response)\n                return\n\n            content_length = int(self.headers.get('Content-Length', 0))\n            body = self.rfile.read(content_length)\n\n            try:\n                _ = json.loads(body)\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                response = json.dumps(ERROR_INVALID_JSON_RESPONSE).encode('utf-8')\n                self.wfile.write(response)\n                return\n\n            self.send_response(200)\n            self.send_header('Content-Type', 'application/json')\n            self.end_headers()\n            response = json.dumps(SUCCESS_RESPONSE).encode('utf-8')\n            self.wfile.write(response)\n\n    return SimplePostHandler\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/273_4",
        "turn": "4",
        "instruct_prompt": "Check if the parsed JSON contains the key 'data'. If the 'data' key is missing, respond with a 400 Bad Request and the message 'No data key in request'. If all validations pass, respond with a 200 success message containing the SUCCESS_RESPONSE as JSON, and set the response headers 'content-type' and 'content-length' accordingly.",
        "test": "import unittest\nimport io\nimport json\nfrom http.server import BaseHTTPRequestHandler\n\nclass FakeSocket:\n    def __init__(self, response_bytes):\n        self._rfile = io.BytesIO(response_bytes)\n        self._wfile = io.BytesIO()\n\n    def makefile(self, mode, *args, **kwargs):\n        if 'r' in mode:\n            return self._rfile\n        elif 'w' in mode:\n            return self._wfile\n        else:\n            raise ValueError('Unsupported mode: ' + mode)\n\n    def sendall(self, data):\n        # For compatibility, write to wfile\n        self._wfile.write(data)\n\n    def close(self):\n        pass\n\nclass TestCases(unittest.TestCase):\n    def _run_handler(self, request_text_bytes):\n        # Create a fake socket with the full HTTP request bytes\n        fake_socket = FakeSocket(request_text_bytes)\n\n        # Instantiate handler with fake socket and dummy address/server\n        HandlerClass = task_func()\n        handler = HandlerClass(fake_socket, ('127.0.0.1', 12345), None)\n\n        # After handler finishes, get the response bytes from fake_socket._wfile\n        fake_socket._wfile.seek(0)\n        response = fake_socket._wfile.read()\n        return response\n\n    def _parse_http_response(self, response_bytes):\n        # Parse raw HTTP response bytes into status code, headers dict, and body bytes\n        response_text = response_bytes.decode('iso-8859-1')  # HTTP headers are iso-8859-1\n        header_end = response_text.find('\\r\\n\\r\\n')\n        self.assertNotEqual(header_end, -1, 'Invalid HTTP response format')\n\n        header_lines = response_text[:header_end].split('\\r\\n')\n        status_line = header_lines[0]\n\n        # Extract status code\n        parts = status_line.split(' ')\n        self.assertGreaterEqual(len(parts), 2)\n        status_code = int(parts[1])\n\n        headers = {}\n        for line in header_lines[1:]:\n            if ': ' in line:\n                k, v = line.split(': ', 1)\n                headers[k.lower()] = v\n\n        body = response_bytes[header_end + 4:]\n\n        return status_code, headers, body\n\n    def test_missing_data_key(self):\n        # Construct minimal valid HTTP POST request without 'data' key\n        body_dict = {\"hello\": \"world\"}\n        body_bytes = json.dumps(body_dict).encode('utf-8')\n\n        request_lines = [\n            b\"POST / HTTP/1.1\",\n            b\"Host: localhost\",\n            b\"Content-Type: application/json\",\n            f\"Content-Length: {len(body_bytes)}\".encode('ascii'),\n            b\"\",\n            body_bytes\n        ]\n\n        request_bytes = b\"\\r\\n\".join(request_lines)\n\n        response = self._run_handler(request_bytes)\n        status_code, headers, body = self._parse_http_response(response)\n\n        self.assertEqual(status_code, 400)\n        self.assertEqual(headers.get('content-type'), 'application/json')\n\n        response_json = json.loads(body.decode('utf-8'))\n        self.assertEqual(response_json.get('message'), 'No data key in request')\n\n    def test_success_response_with_data_key(self):\n        # Construct minimal valid HTTP POST request with 'data' key\n        body_dict = {\"data\": \"some value\"}\n        body_bytes = json.dumps(body_dict).encode('utf-8')\n\n        request_lines = [\n            b\"POST / HTTP/1.1\",\n            b\"Host: localhost\",\n            b\"Content-Type: application/json\",\n            f\"Content-Length: {len(body_bytes)}\".encode('ascii'),\n            b\"\",\n            body_bytes\n        ]\n\n        request_bytes = b\"\\r\\n\".join(request_lines)\n\n        response = self._run_handler(request_bytes)\n        status_code, headers, body = self._parse_http_response(response)\n\n        self.assertEqual(status_code, 200)\n        self.assertEqual(headers.get('content-type'), 'application/json')\n        self.assertEqual(int(headers.get('content-length')), len(body))\n\n        response_json = json.loads(body.decode('utf-8'))\n        self.assertEqual(response_json, {\n            'status': 'success',\n            'message': 'Data received successfully.'\n        })\n\n    def test_previous_round_code_should_fail(self):\n        # Previous round code does not check 'data' key and always returns 200 on valid JSON\n        import http.server\n        import json\n\n        SUCCESS_RESPONSE = {\n            'status': 'success',\n            'message': 'Data received successfully.'\n        }\n\n        ERROR_CONTENT_TYPE_RESPONSE = {\n            'status': 'error',\n            'message': 'Content-Type header is not application/json'\n        }\n\n        ERROR_INVALID_JSON_RESPONSE = {\n            'status': 'error',\n            'message': 'Invalid JSON'\n        }\n\n        class PreviousHandler(http.server.BaseHTTPRequestHandler):\n            def do_POST(self):\n                content_type = self.headers.get('Content-Type')\n                if content_type != 'application/json':\n                    self.send_response(400)\n                    self.send_header('Content-Type', 'application/json')\n                    self.end_headers()\n                    response = json.dumps(ERROR_CONTENT_TYPE_RESPONSE).encode('utf-8')\n                    self.wfile.write(response)\n                    return\n\n                content_length = int(self.headers.get('Content-Length', 0))\n                body = self.rfile.read(content_length)\n\n                try:\n                    _ = json.loads(body)\n                except json.JSONDecodeError:\n                    self.send_response(400)\n                    self.send_header('Content-Type', 'application/json')\n                    self.end_headers()\n                    response = json.dumps(ERROR_INVALID_JSON_RESPONSE).encode('utf-8')\n                    self.wfile.write(response)\n                    return\n\n                self.send_response(200)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                response = json.dumps(SUCCESS_RESPONSE).encode('utf-8')\n                self.wfile.write(response)\n\n            def log_message(self, format, *args):\n                pass\n\n        # Prepare request missing 'data' key\n        body_dict = {\"hello\": \"world\"}\n        body_bytes = json.dumps(body_dict).encode('utf-8')\n\n        request_lines = [\n            b\"POST / HTTP/1.1\",\n            b\"Host: localhost\",\n            b\"Content-Type: application/json\",\n            f\"Content-Length: {len(body_bytes)}\".encode('ascii'),\n            b\"\", \n            body_bytes\n        ]\n        request_bytes = b\"\\r\\n\".join(request_lines)\n\n        fake_socket = FakeSocket(request_bytes)\n        handler = PreviousHandler(fake_socket, ('127.0.0.1', 12345), None)\n\n        fake_socket._wfile.seek(0)\n        response = fake_socket._wfile.read()\n        status_code, headers, body = self._parse_http_response(response)\n\n        # The previous code returns 200 status for JSON missing 'data' key, which is incorrect per current requirements\n        self.assertEqual(status_code, 200)\n        response_json = json.loads(body.decode('utf-8'))\n        self.assertEqual(response_json.get('status'), 'success')\n        self.assertNotIn('No data key in request', response_json.get('message', ''))\n",
        "code": "import http.server\nimport json\n\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\n\nERROR_CONTENT_TYPE_RESPONSE = {\n    'status': 'error',\n    'message': 'Content-Type header is not application/json'\n}\n\nERROR_INVALID_JSON_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid JSON'\n}\n\nERROR_NO_DATA_KEY_RESPONSE = {\n    'status': 'error',\n    'message': 'No data key in request'\n}\n\ndef task_func():\n    class SimplePostHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_type = self.headers.get('Content-Type')\n            if content_type != 'application/json':\n                self.send_response(400)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                response = json.dumps(ERROR_CONTENT_TYPE_RESPONSE).encode('utf-8')\n                self.wfile.write(response)\n                return\n\n            content_length = int(self.headers.get('Content-Length', 0))\n            body = self.rfile.read(content_length)\n\n            try:\n                parsed_json = json.loads(body)\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                response = json.dumps(ERROR_INVALID_JSON_RESPONSE).encode('utf-8')\n                self.wfile.write(response)\n                return\n\n            if 'data' not in parsed_json:\n                self.send_response(400)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                response = json.dumps(ERROR_NO_DATA_KEY_RESPONSE).encode('utf-8')\n                self.wfile.write(response)\n                return\n\n            response_bytes = json.dumps(SUCCESS_RESPONSE).encode('utf-8')\n            self.send_response(200)\n            self.send_header('Content-Type', 'application/json')\n            self.send_header('Content-Length', str(len(response_bytes)))\n            self.end_headers()\n            self.wfile.write(response_bytes)\n\n        def log_message(self, format, *args):\n            # Override to suppress console output during tests\n            pass\n\n    return SimplePostHandler\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 35,
    "task_id": "BigCodeBench/274",
    "mt_data": [
      {
        "task_id": "BigCodeBench/274_1",
        "turn": "1",
        "instruct_prompt": "Create a class inside the function `task_func` that handles HTTP POST requests. The handler should read the POST request body as JSON and parse it into a Python dictionary. You should write self-contained code starting with:\n```\nimport cgi\nimport http.server\nimport json\n\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n```",
        "test": "import unittest\nfrom io import BytesIO\nimport json\n\nclass DummySocket:\n    def __init__(self, recv_bytes):\n        self._rfile = BytesIO(recv_bytes)\n        self._wfile = BytesIO()\n\n    def makefile(self, mode, buffering=None):\n        if 'r' in mode:\n            return self._rfile\n        elif 'w' in mode:\n            return self._wfile\n        else:\n            raise ValueError('Unsupported mode for makefile')\n\n    def sendall(self, data):\n        # Write data to the write buffer\n        self._wfile.write(data)\n\nclass TestCases(unittest.TestCase):\n    def test_post_handler_parses_json(self):\n        HandlerClass = task_func('smtp.example.com', 25, 'user', 'pass')\n\n        def run_handler_with_body(body_bytes):\n            # Prepare raw HTTP request bytes for POST\n            request_line = b'POST / HTTP/1.1\\r\\n'\n            headers = f'Content-Length: {len(body_bytes)}\\r\\nHost: localhost\\r\\n\\r\\n'.encode('utf-8')\n            raw_request = request_line + headers + body_bytes\n\n            dummy_socket = DummySocket(raw_request)\n\n            # Instantiate handler\n            handler = HandlerClass(dummy_socket, ('127.0.0.1', 12345), None)\n\n            # After handling, get response from dummy_socket._wfile\n            dummy_socket._wfile.seek(0)\n            response_data = dummy_socket._wfile.read()\n            return handler, response_data\n\n        # Test valid JSON\n        valid_json = json.dumps({'hello': 'world'}).encode('utf-8')\n        handler, response = run_handler_with_body(valid_json)\n        self.assertEqual(handler.command, 'POST')\n        self.assertEqual(handler.path, '/')\n        self.assertIn(b'200 OK', response)\n        self.assertIn(b'POST received', response)\n\n        # Test invalid JSON\n        invalid_json = b'{bad json}'\n        handler, response = run_handler_with_body(invalid_json)\n        self.assertEqual(handler.command, 'POST')\n        self.assertEqual(handler.path, '/')\n        self.assertIn(b'400 Bad Request', response)\n        self.assertIn(b'Invalid JSON', response)\n",
        "code": "import cgi\nimport http.server\nimport json\n\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class PostHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_length = int(self.headers.get('Content-Length', 0))\n            post_data = self.rfile.read(content_length)\n            try:\n                data = json.loads(post_data.decode('utf-8'))\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Invalid JSON')\n                return\n            # For demonstration, just respond with 200 OK\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'POST received')\n\n    return PostHandler\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/274_2",
        "turn": "2",
        "instruct_prompt": "Make the handler validate that the incoming request's Content-Type header is 'application/json' and that the JSON data contains the keys 'subject', 'message', and 'to'. If Content-Type is not 'application/json' or any key is missing, respond with HTTP status 400 Bad Request.",
        "test": "import unittest\nfrom io import BytesIO\nfrom http.client import HTTPMessage\nfrom http.server import BaseHTTPRequestHandler\n\nimport json\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create handler class from task_func\n        self.HandlerClass = task_func('smtp.example.com', 587, 'user', 'pass')\n\n    def create_handler(self, headers, body_bytes):\n        # A minimal subclass to test do_POST without real socket\n        class TestHandler(self.HandlerClass):\n            def __init__(self):\n                self.rfile = BytesIO(body_bytes)\n                self.wfile = BytesIO()\n                self.headers = headers\n                self.response_code = None\n                self.sent_headers = []\n\n            def send_response(self, code, message=None):\n                self.response_code = code\n\n            def send_header(self, keyword, value):\n                self.sent_headers.append((keyword, value))\n\n            def end_headers(self):\n                pass\n\n        return TestHandler()\n\n    def test_valid_json_and_content_type(self):\n        headers = HTTPMessage()\n        headers.add_header('Content-Type', 'application/json')\n        body = json.dumps({'subject': 'Hi', 'message': 'Hello', 'to': 'test@example.com'}).encode('utf-8')\n        headers.add_header('Content-Length', str(len(body)))\n\n        handler = self.create_handler(headers, body)\n        handler.do_POST()\n\n        self.assertEqual(handler.response_code, 200)\n        handler.wfile.seek(0)\n        self.assertEqual(handler.wfile.read(), b'POST received')\n\n    def test_missing_content_type(self):\n        headers = HTTPMessage()\n        body = json.dumps({'subject': 'Hi', 'message': 'Hello', 'to': 'test@example.com'}).encode('utf-8')\n        headers.add_header('Content-Length', str(len(body)))\n\n        handler = self.create_handler(headers, body)\n        handler.do_POST()\n\n        self.assertEqual(handler.response_code, 400)\n        handler.wfile.seek(0)\n        self.assertIn(b'Content-Type must be application/json', handler.wfile.read())\n\n    def test_wrong_content_type(self):\n        headers = HTTPMessage()\n        headers.add_header('Content-Type', 'text/plain')\n        body = json.dumps({'subject': 'Hi', 'message': 'Hello', 'to': 'test@example.com'}).encode('utf-8')\n        headers.add_header('Content-Length', str(len(body)))\n\n        handler = self.create_handler(headers, body)\n        handler.do_POST()\n\n        self.assertEqual(handler.response_code, 400)\n        handler.wfile.seek(0)\n        self.assertIn(b'Content-Type must be application/json', handler.wfile.read())\n\n    def test_missing_keys(self):\n        headers = HTTPMessage()\n        headers.add_header('Content-Type', 'application/json')\n        # Missing 'to'\n        body = json.dumps({'subject': 'Hi', 'message': 'Hello'}).encode('utf-8')\n        headers.add_header('Content-Length', str(len(body)))\n\n        handler = self.create_handler(headers, body)\n        handler.do_POST()\n\n        self.assertEqual(handler.response_code, 400)\n        handler.wfile.seek(0)\n        self.assertIn(b'Missing required keys', handler.wfile.read())\n\n    def test_invalid_json(self):\n        headers = HTTPMessage()\n        headers.add_header('Content-Type', 'application/json')\n        body = b'not a json'\n        headers.add_header('Content-Length', str(len(body)))\n\n        handler = self.create_handler(headers, body)\n        handler.do_POST()\n\n        self.assertEqual(handler.response_code, 400)\n        handler.wfile.seek(0)\n        self.assertIn(b'Invalid JSON', handler.wfile.read())\n",
        "code": "import http.server\nimport json\n\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class PostHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_type = self.headers.get('Content-Type')\n            if content_type != 'application/json':\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Content-Type must be application/json')\n                return\n\n            content_length = int(self.headers.get('Content-Length', 0))\n            post_data = self.rfile.read(content_length)\n            try:\n                data = json.loads(post_data.decode('utf-8'))\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Invalid JSON')\n                return\n\n            required_keys = ['subject', 'message', 'to']\n            if not all(key in data for key in required_keys):\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Missing required keys')\n                return\n\n            # For demonstration, just respond with 200 OK\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'POST received')\n\n    return PostHandler\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/274_3",
        "turn": "3",
        "instruct_prompt": "Implement sending an email using the SMTP server with the parsed 'subject', 'message', and 'to' fields. Use the SMTP server info and credentials passed into `task_func`. Construct the email using `email.mime.text.MIMEText`.",
        "test": "import unittest\nimport io\nimport json\nfrom unittest import mock\n\nclass DummySocket:\n    def makefile(self, *args, **kwargs):\n        return io.BytesIO()\n\nclass DummyHeaders(dict):\n    def get(self, key, default=None):\n        return self[key] if key in self else default\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.smtp_server = 'smtp.example.com'\n        self.smtp_port = 587\n        self.smtp_username = 'user@example.com'\n        self.smtp_password = 'password'\n        global task_func\n        self.HandlerClass = task_func(self.smtp_server, self.smtp_port, self.smtp_username, self.smtp_password)\n\n    def create_handler(self, headers_dict, body_bytes):\n        handler = self.HandlerClass(\n            request=DummySocket(),\n            client_address=('127.0.0.1', 12345),\n            server=None\n        )\n        handler.rfile = io.BytesIO(body_bytes)\n        handler.wfile = io.BytesIO()\n        handler.headers = DummyHeaders(headers_dict)\n        # Set required attributes to avoid AttributeError in BaseHTTPRequestHandler\n        handler.request_version = 'HTTP/1.1'\n        handler.command = 'POST'\n        handler.requestline = 'POST / HTTP/1.1'\n        return handler\n\n    @mock.patch('smtplib.SMTP')\n    def test_email_sending_success(self, mock_smtp_class):\n        subject = 'Test Subject'\n        message = 'This is a test message.'\n        to = 'recipient@example.com'\n        body_dict = {'subject': subject, 'message': message, 'to': to}\n        body_bytes = json.dumps(body_dict).encode('utf-8')\n        headers = {\n            'Content-Type': 'application/json',\n            'Content-Length': str(len(body_bytes))\n        }\n\n        handler = self.create_handler(headers, body_bytes)\n        handler.do_POST()\n\n        mock_smtp = mock_smtp_class.return_value.__enter__.return_value\n        mock_smtp.starttls.assert_called_once()\n        mock_smtp.login.assert_called_once_with(self.smtp_username, self.smtp_password)\n        mock_smtp.sendmail.assert_called_once()\n\n        handler.wfile.seek(0)\n        response_bytes = handler.wfile.read()\n        self.assertIn(b'Email sent successfully', response_bytes)\n\n    def test_invalid_content_type(self):\n        body_bytes = b'{}'\n        headers = {\n            'Content-Type': 'text/plain',\n            'Content-Length': str(len(body_bytes))\n        }\n\n        handler = self.create_handler(headers, body_bytes)\n        handler.do_POST()\n\n        handler.wfile.seek(0)\n        response_bytes = handler.wfile.read()\n        self.assertIn(b'Content-Type must be application/json', response_bytes)\n\n    def test_missing_keys(self):\n        body_dict = {'subject': 'Hi', 'message': 'Hello'}  # missing 'to'\n        body_bytes = json.dumps(body_dict).encode('utf-8')\n        headers = {\n            'Content-Type': 'application/json',\n            'Content-Length': str(len(body_bytes))\n        }\n\n        handler = self.create_handler(headers, body_bytes)\n        handler.do_POST()\n\n        handler.wfile.seek(0)\n        response_bytes = handler.wfile.read()\n        self.assertIn(b'Missing required keys', response_bytes)\n",
        "code": "import http.server\nimport json\nimport smtplib\nfrom email.mime.text import MIMEText\n\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class PostHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_type = self.headers.get('Content-Type')\n            if content_type != 'application/json':\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Content-Type must be application/json')\n                return\n\n            content_length = int(self.headers.get('Content-Length', 0))\n            post_data = self.rfile.read(content_length)\n            try:\n                data = json.loads(post_data.decode('utf-8'))\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Invalid JSON')\n                return\n\n            required_keys = ['subject', 'message', 'to']\n            if not all(key in data for key in required_keys):\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Missing required keys')\n                return\n\n            subject = data['subject']\n            message = data['message']\n            to_addr = data['to']\n\n            msg = MIMEText(message)\n            msg['Subject'] = subject\n            msg['From'] = smtp_username\n            msg['To'] = to_addr\n\n            try:\n                with smtplib.SMTP(smtp_server, smtp_port) as server:\n                    server.starttls()\n                    server.login(smtp_username, smtp_password)\n                    server.sendmail(smtp_username, [to_addr], msg.as_string())\n            except Exception:\n                self.send_response(500)\n                self.end_headers()\n                self.wfile.write(b'Failed to send email')\n                return\n\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'Email sent successfully')\n\n    return PostHandler\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/274_4",
        "turn": "4",
        "instruct_prompt": "Add error handling for: JSONDecodeError to respond with HTTP 400; missing keys (ValueError) to respond with HTTP 400; and smtplib.SMTPAuthenticationError to respond with HTTP 535 Authentication Failed. Ensure to send appropriate HTTP responses and end headers properly.",
        "test": "import unittest\nimport io\nimport json\nimport smtplib\nfrom email.mime.text import MIMEText\nfrom http import HTTPStatus\n\nclass DummySMTP:\n    def __init__(self, server, port):\n        self.server = server\n        self.port = port\n        self.started_tls = False\n        self.logged_in = False\n        self.sent_mail = False\n    def starttls(self):\n        self.started_tls = True\n    def login(self, username, password):\n        if username == 'baduser':\n            raise smtplib.SMTPAuthenticationError(535, b'Authentication Failed')\n        self.logged_in = True\n    def sendmail(self, from_addr, to_addrs, msg):\n        self.sent_mail = True\n    def __enter__(self):\n        return self\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        pass\n\nclass DummyRequest:\n    def __init__(self, headers, body_bytes):\n        self.headers = headers\n        self.rfile = io.BytesIO(body_bytes)\n        self.wfile = io.BytesIO()\n        self.response_code = None\n        self.response_message = None\n    def send_response(self, code, message=None):\n        self.response_code = code\n        self.response_message = message\n    def send_header(self, key, value):\n        pass\n    def end_headers(self):\n        pass\n    def get_response_body(self):\n        self.wfile.seek(0)\n        return self.wfile.read()\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # patch smtplib.SMTP\n        self.original_smtp = smtplib.SMTP\n        smtplib.SMTP = DummySMTP\n        self.smtp_server = 'smtp.example.com'\n        self.smtp_port = 587\n        self.smtp_username = 'user@example.com'\n        self.smtp_password = 'password'\n        self.HandlerClass = task_func(self.smtp_server, self.smtp_port, self.smtp_username, self.smtp_password)\n\n    def tearDown(self):\n        smtplib.SMTP = self.original_smtp\n\n    def test_json_decode_error(self):\n        # invalid JSON\n        headers = {'Content-Type': 'application/json', 'Content-Length': '10'}\n        body = b'{bad json}'\n        handler = self.HandlerClass\n        request = DummyRequest(headers, body)\n        handler.do_POST(request)\n        self.assertEqual(request.response_code, 400)\n        self.assertIn(b'Invalid JSON', request.get_response_body())\n\n    def test_missing_keys(self):\n        # JSON missing keys\n        data = {'subject': 'Hi', 'message': 'Hello'}  # missing 'to'\n        body = json.dumps(data).encode('utf-8')\n        headers = {'Content-Type': 'application/json', 'Content-Length': str(len(body))}\n        handler = self.HandlerClass\n        request = DummyRequest(headers, body)\n        handler.do_POST(request)\n        self.assertEqual(request.response_code, 400)\n        self.assertIn(b'Missing required keys', request.get_response_body())\n\n    def test_smtp_authentication_error(self):\n        # Use a handler with bad username to trigger SMTPAuthenticationError\n        bad_handler = task_func(self.smtp_server, self.smtp_port, 'baduser', self.smtp_password)\n        data = {'subject': 'Hi', 'message': 'Hello', 'to': 'to@example.com'}\n        body = json.dumps(data).encode('utf-8')\n        headers = {'Content-Type': 'application/json', 'Content-Length': str(len(body))}\n        request = DummyRequest(headers, body)\n        bad_handler.do_POST(request)\n        self.assertEqual(request.response_code, 535)\n        self.assertIn(b'SMTP Authentication Failed', request.get_response_body())\n\n    def test_successful_email_send(self):\n        data = {'subject': 'Hi', 'message': 'Hello', 'to': 'to@example.com'}\n        body = json.dumps(data).encode('utf-8')\n        headers = {'Content-Type': 'application/json', 'Content-Length': str(len(body))}\n        request = DummyRequest(headers, body)\n        handler = self.HandlerClass\n        handler.do_POST(request)\n        self.assertEqual(request.response_code, 200)\n        self.assertIn(b'Email sent successfully', request.get_response_body())\n\n    def test_invalid_content_type(self):\n        data = {'subject': 'Hi', 'message': 'Hello', 'to': 'to@example.com'}\n        body = json.dumps(data).encode('utf-8')\n        headers = {'Content-Type': 'text/plain', 'Content-Length': str(len(body))}\n        request = DummyRequest(headers, body)\n        handler = self.HandlerClass\n        handler.do_POST(request)\n        self.assertEqual(request.response_code, 400)\n        self.assertIn(b'Content-Type must be application/json', request.get_response_body())\n",
        "code": "import http.server\nimport json\nimport smtplib\nfrom email.mime.text import MIMEText\n\nclass BadRequestError(ValueError):\n    pass\n\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    class PostHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_type = self.headers.get('Content-Type')\n            if content_type != 'application/json':\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Content-Type must be application/json')\n                return\n\n            content_length = int(self.headers.get('Content-Length', 0))\n            post_data = self.rfile.read(content_length)\n\n            try:\n                data = json.loads(post_data.decode('utf-8'))\n                required_keys = ['subject', 'message', 'to']\n                if not all(key in data for key in required_keys):\n                    raise ValueError('Missing required keys')\n\n                subject = data['subject']\n                message = data['message']\n                to_addr = data['to']\n\n                msg = MIMEText(message)\n                msg['Subject'] = subject\n                msg['From'] = smtp_username\n                msg['To'] = to_addr\n\n                try:\n                    with smtplib.SMTP(smtp_server, smtp_port) as server:\n                        server.starttls()\n                        server.login(smtp_username, smtp_password)\n                        server.sendmail(smtp_username, [to_addr], msg.as_string())\n                except smtplib.SMTPAuthenticationError:\n                    self.send_response(535, 'Authentication Failed')\n                    self.end_headers()\n                    self.wfile.write(b'SMTP Authentication Failed')\n                    return\n                except Exception:\n                    self.send_response(500)\n                    self.end_headers()\n                    self.wfile.write(b'Failed to send email')\n                    return\n\n                self.send_response(200)\n                self.end_headers()\n                self.wfile.write(b'Email sent successfully')\n\n            except json.JSONDecodeError:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Invalid JSON')\n            except ValueError:\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(b'Missing required keys')\n\n    return PostHandler\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 36,
    "task_id": "BigCodeBench/287",
    "mt_data": [
      {
        "task_id": "BigCodeBench/287_1",
        "turn": "1",
        "instruct_prompt": "Count the number of words in all .txt files within a specified directory and return the total number of words. You should write self-contained code starting with:\n```\nfrom collections import Counter\nimport os\nimport json\ndef task_func(filename, directory):\n```",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def test_no_txt_files(self):\n        # Directory with no .txt files\n        with open(os.path.join(self.test_dir.name, 'file1.md'), 'w') as f:\n            f.write('This should not be counted')\n        self.assertEqual(task_func('dummy', self.test_dir.name), 0)\n\n    def test_single_txt_file(self):\n        content = 'Hello world\\nThis is a test file.'\n        with open(os.path.join(self.test_dir.name, 'test.txt'), 'w') as f:\n            f.write(content)\n        # Word count: Hello(1) world(2) This(3) is(4) a(5) test(6) file.(7)\n        self.assertEqual(task_func('dummy', self.test_dir.name), 7)\n\n    def test_multiple_txt_files(self):\n        content1 = 'one two three'\n        content2 = 'four five'\n        with open(os.path.join(self.test_dir.name, 'a.txt'), 'w') as f:\n            f.write(content1)\n        with open(os.path.join(self.test_dir.name, 'b.txt'), 'w') as f:\n            f.write(content2)\n        self.assertEqual(task_func('dummy', self.test_dir.name), 5)\n\n    def test_txt_file_with_empty_lines(self):\n        content = '\\nhello\\n\\nworld\\n'\n        with open(os.path.join(self.test_dir.name, 'empty_lines.txt'), 'w') as f:\n            f.write(content)\n        # Words: hello(1) world(2)\n        self.assertEqual(task_func('dummy', self.test_dir.name), 2)\n\n    def test_ignore_non_txt_files(self):\n        with open(os.path.join(self.test_dir.name, 'file.txt'), 'w') as f:\n            f.write('word1 word2')\n        with open(os.path.join(self.test_dir.name, 'file.doc'), 'w') as f:\n            f.write('word3 word4')\n        self.assertEqual(task_func('dummy', self.test_dir.name), 2)\n",
        "code": "from collections import Counter\nimport os\nimport json\n\ndef task_func(filename, directory):\n    total_words = 0\n    for entry in os.listdir(directory):\n        if entry.endswith('.txt'):\n            file_path = os.path.join(directory, entry)\n            if os.path.isfile(file_path):\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    for line in f:\n                        words = line.split()\n                        total_words += len(words)\n    return total_words\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/287_2",
        "turn": "2",
        "instruct_prompt": "After counting the words in all .txt files, export the counts of each unique word into a JSON file specified by the filename parameter.",
        "test": "import unittest\nimport tempfile\nimport os\nimport json\n\nclass TestCases(unittest.TestCase):\n    def test_word_count_export(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            # Create sample txt files\n            file1 = os.path.join(tmpdir, 'file1.txt')\n            with open(file1, 'w', encoding='utf-8') as f:\n                f.write('hello world\\nhello')\n            file2 = os.path.join(tmpdir, 'file2.txt')\n            with open(file2, 'w', encoding='utf-8') as f:\n                f.write('world test test')\n\n            output_file = os.path.join(tmpdir, 'output.json')\n            task_func(output_file, tmpdir)\n\n            with open(output_file, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n\n            expected = {'hello': 2, 'world': 2, 'test': 2}\n            self.assertEqual(data, expected)\n\n    def test_empty_directory(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            output_file = os.path.join(tmpdir, 'output.json')\n            task_func(output_file, tmpdir)\n            with open(output_file, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n            self.assertEqual(data, {})\n",
        "code": "from collections import Counter\nimport os\nimport json\n\ndef task_func(filename, directory):\n    word_counts = Counter()\n    for entry in os.listdir(directory):\n        if entry.endswith('.txt'):\n            file_path = os.path.join(directory, entry)\n            if os.path.isfile(file_path):\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    for line in f:\n                        words = line.split()\n                        word_counts.update(words)\n    with open(filename, 'w', encoding='utf-8') as json_file:\n        json.dump(dict(word_counts), json_file, ensure_ascii=False, indent=4)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 37,
    "task_id": "BigCodeBench/302",
    "mt_data": [
      {
        "task_id": "BigCodeBench/302_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a pandas DataFrame with columns 'Date' and 'Value', where 'Value' contains lists, and splits the lists in the 'Value' column into separate columns. You should write self-contained code starting with:\n```python\nimport pandas as pd\n# Constants\nCOLUMNS = ['Date', 'Value']\ndef task_func(df, plot=False):\n```",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_split_value_lists(self):\n        data = {\n            'Date': ['2023-01-01', '2023-01-02'],\n            'Value': [[1, 2, 3], [4, 5, 6]]\n        }\n        df = pd.DataFrame(data)\n        expected_data = {\n            'Date': ['2023-01-01', '2023-01-02'],\n            'Value_0': [1, 4],\n            'Value_1': [2, 5],\n            'Value_2': [3, 6]\n        }\n        expected_df = pd.DataFrame(expected_data)\n\n        result_df = task_func(df)\n\n        pd.testing.assert_frame_equal(result_df, expected_df)\n\n    def test_empty_lists(self):\n        data = {\n            'Date': ['2023-01-01', '2023-01-02'],\n            'Value': [[], []]\n        }\n        df = pd.DataFrame(data)\n        expected_df = pd.DataFrame({'Date': ['2023-01-01', '2023-01-02']})\n\n        result_df = task_func(df)\n\n        pd.testing.assert_frame_equal(result_df, expected_df, check_dtype=False)\n\n    def test_lists_of_different_lengths(self):\n        data = {\n            'Date': ['2023-01-01', '2023-01-02'],\n            'Value': [[1, 2], [3, 4, 5]]\n        }\n        df = pd.DataFrame(data)\n        expected_data = {\n            'Date': ['2023-01-01', '2023-01-02'],\n            'Value_0': [1, 3],\n            'Value_1': [2, 4],\n            'Value_2': [np.nan, 5]\n        }\n        expected_df = pd.DataFrame(expected_data)\n\n        result_df = task_func(df)\n\n        pd.testing.assert_frame_equal(result_df, expected_df, check_dtype=False)\n",
        "code": "import pandas as pd\n# Constants\nCOLUMNS = ['Date', 'Value']\ndef task_func(df, plot=False):\n    # Expand the 'Value' column lists into separate columns\n    value_expanded = pd.DataFrame(df['Value'].tolist())\n    if value_expanded.empty:\n        # If no values to expand, just return 'Date' column\n        return df[['Date']].copy()\n    # Rename columns to Value_0, Value_1, ...\n    value_expanded.columns = [f'Value_{i}' for i in range(value_expanded.shape[1])]\n    # Concatenate the 'Date' column with the expanded values\n    result_df = pd.concat([df['Date'], value_expanded], axis=1)\n    return result_df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/302_2",
        "turn": "2",
        "instruct_prompt": "Calculate the Pearson correlation coefficient matrix between the newly created columns from the split 'Value' lists and return this correlation DataFrame.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_correlation_matrix(self):\n        df = pd.DataFrame({\n            'Date': ['2023-01-01', '2023-01-02', '2023-01-03'],\n            'Value': [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n        })\n        expected_columns = ['Value_0', 'Value_1', 'Value_2']\n        result = task_func(df)\n        # Check the result is a DataFrame\n        self.assertIsInstance(result, pd.DataFrame)\n        # Check columns are the expected value columns\n        self.assertListEqual(list(result.columns), expected_columns)\n        self.assertListEqual(list(result.index), expected_columns)\n        # Check correlation values (since these are perfectly correlated sequences, correlation should be 1)\n        for col in expected_columns:\n            self.assertAlmostEqual(result.loc[col, col], 1.0)\n\n    def test_empty_value_lists(self):\n        df = pd.DataFrame({\n            'Date': ['2023-01-01'],\n            'Value': [[]]\n        })\n        result = task_func(df)\n        # When no values to expand, correlation matrix should be empty DataFrame\n        self.assertTrue(result.empty)\n\n    def test_single_value_column(self):\n        df = pd.DataFrame({\n            'Date': ['2023-01-01', '2023-01-02'],\n            'Value': [[10], [20]]\n        })\n        result = task_func(df)\n        # Correlation matrix should be 1x1 with value 1.0\n        self.assertEqual(result.shape, (1, 1))\n        self.assertAlmostEqual(result.iloc[0, 0], 1.0)\n",
        "code": "import pandas as pd\n# Constants\nCOLUMNS = ['Date', 'Value']\ndef task_func(df, plot=False):\n    # Expand the 'Value' column lists into separate columns\n    value_expanded = pd.DataFrame(df['Value'].tolist())\n    # If no values to expand (zero rows or zero columns), return empty DataFrame\n    if value_expanded.empty or value_expanded.shape[1] == 0:\n        return pd.DataFrame()\n    # Rename columns to Value_0, Value_1, ...\n    value_expanded.columns = [f'Value_{i}' for i in range(value_expanded.shape[1])]\n    # Calculate Pearson correlation matrix of the expanded value columns\n    corr_df = value_expanded.corr(method='pearson')\n    return corr_df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/302_3",
        "turn": "3",
        "instruct_prompt": "Raise a ValueError if the input DataFrame is empty or if it does not contain the required columns 'Date' and 'Value' or if the 'Value' column contains invalid data that cannot be split into separate columns.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_valid_input(self):\n        df = pd.DataFrame({\n            'Date': ['2023-01-01', '2023-01-02'],\n            'Value': [[1, 2], [3, 4]]\n        })\n        result = task_func(df)\n        self.assertEqual(result.shape, (2, 2))\n        # Pearson correlation of two columns [1,3] and [2,4] is 1\n        self.assertAlmostEqual(result.loc['Value_0', 'Value_1'], 1.0)\n\n    def test_empty_dataframe(self):\n        df = pd.DataFrame(columns=['Date', 'Value'])\n        with self.assertRaises(ValueError) as cm:\n            task_func(df)\n        self.assertIn('empty', str(cm.exception))\n\n    def test_missing_date_column(self):\n        df = pd.DataFrame({'Value': [[1, 2]]})\n        with self.assertRaises(ValueError) as cm:\n            task_func(df)\n        self.assertIn(\"'Date'\", str(cm.exception))\n\n    def test_missing_value_column(self):\n        df = pd.DataFrame({'Date': ['2023-01-01']})\n        with self.assertRaises(ValueError) as cm:\n            task_func(df)\n        self.assertIn(\"'Value'\", str(cm.exception))\n\n    def test_value_column_not_expandable(self):\n        df = pd.DataFrame({\n            'Date': ['2023-01-01'],\n            'Value': [123]  # int, not iterable\n        })\n        with self.assertRaises(ValueError) as cm:\n            task_func(df)\n        self.assertIn('not a list or tuple', str(cm.exception))\n\n    def test_value_column_empty_lists(self):\n        df = pd.DataFrame({\n            'Date': ['2023-01-01', '2023-01-02'],\n            'Value': [[], []]  # empty lists\n        })\n        with self.assertRaises(ValueError) as cm:\n            task_func(df)\n        self.assertIn('empty list or tuple', str(cm.exception))\n",
        "code": "import pandas as pd\n\n# Constants\nCOLUMNS = ['Date', 'Value']\n\ndef task_func(df, plot=False):\n    # Validate input DataFrame\n    if df.empty:\n        raise ValueError(\"Input DataFrame is empty.\")\n    for col in COLUMNS:\n        if col not in df.columns:\n            raise ValueError(f\"Input DataFrame must contain the required column: '{col}'.\")\n\n    # Validate 'Value' column entries are non-empty iterables (list or tuple)\n    for idx, val in enumerate(df['Value']):\n        if not isinstance(val, (list, tuple)):\n            raise ValueError(f\"Entry at index {idx} in 'Value' column is not a list or tuple.\")\n        if len(val) == 0:\n            raise ValueError(f\"Entry at index {idx} in 'Value' column is an empty list or tuple.\")\n\n    # Expand the 'Value' column lists into separate columns\n    value_expanded = pd.DataFrame(df['Value'].tolist())\n\n    # Rename columns to Value_0, Value_1, ...\n    value_expanded.columns = [f'Value_{i}' for i in range(value_expanded.shape[1])]\n\n    # Calculate Pearson correlation matrix of the expanded value columns\n    corr_df = value_expanded.corr(method='pearson')\n    return corr_df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/302_4",
        "turn": "4",
        "instruct_prompt": "If the argument 'plot' is True, generate a heatmap plot of the correlation matrix using seaborn with the title 'Correlation Heatmap' and return both the correlation DataFrame and the matplotlib Axes object containing the heatmap; otherwise, return only the correlation DataFrame.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Sample DataFrame for tests\n        self.df = pd.DataFrame({\n            'Date': ['2021-01-01', '2021-01-02', '2021-01-03'],\n            'Value': [(1, 2, 3), (4, 5, 6), (7, 8, 9)]\n        })\n\n    def test_return_type_without_plot(self):\n        corr = task_func(self.df, plot=False)\n        self.assertIsInstance(corr, pd.DataFrame)\n\n    def test_return_type_with_plot(self):\n        corr, ax = task_func(self.df, plot=True)\n        self.assertIsInstance(corr, pd.DataFrame)\n        import matplotlib.axes\n        self.assertIsInstance(ax, matplotlib.axes.Axes)\n\n    def test_heatmap_title(self):\n        _, ax = task_func(self.df, plot=True)\n        self.assertEqual(ax.get_title(), 'Correlation Heatmap')\n\n    def test_invalid_empty_dataframe(self):\n        empty_df = pd.DataFrame(columns=['Date', 'Value'])\n        with self.assertRaises(ValueError):\n            task_func(empty_df, plot=True)\n\n    def test_missing_columns(self):\n        df_missing = pd.DataFrame({'Date': ['2021-01-01'], 'Other': [123]})\n        with self.assertRaises(ValueError):\n            task_func(df_missing, plot=False)\n\n    def test_invalid_value_entry(self):\n        df_invalid = pd.DataFrame({\n            'Date': ['2021-01-01'],\n            'Value': [123]  # Not a list or tuple\n        })\n        with self.assertRaises(ValueError):\n            task_func(df_invalid, plot=False)\n\n    def test_empty_value_entry(self):\n        df_empty_val = pd.DataFrame({\n            'Date': ['2021-01-01'],\n            'Value': [()]  # Empty tuple\n        })\n        with self.assertRaises(ValueError):\n            task_func(df_empty_val, plot=False)\n",
        "code": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['Date', 'Value']\n\ndef task_func(df, plot=False):\n    # Validate input DataFrame\n    if df.empty:\n        raise ValueError(\"Input DataFrame is empty.\")\n    for col in COLUMNS:\n        if col not in df.columns:\n            raise ValueError(f\"Input DataFrame must contain the required column: '{col}'.\")\n\n    # Validate 'Value' column entries are non-empty iterables (list or tuple)\n    for idx, val in enumerate(df['Value']):\n        if not isinstance(val, (list, tuple)):\n            raise ValueError(f\"Entry at index {idx} in 'Value' column is not a list or tuple.\")\n        if len(val) == 0:\n            raise ValueError(f\"Entry at index {idx} in 'Value' column is an empty list or tuple.\")\n\n    # Expand the 'Value' column lists into separate columns\n    value_expanded = pd.DataFrame(df['Value'].tolist())\n\n    # Rename columns to Value_0, Value_1, ...\n    value_expanded.columns = [f'Value_{i}' for i in range(value_expanded.shape[1])]\n\n    # Calculate Pearson correlation matrix of the expanded value columns\n    corr_df = value_expanded.corr(method='pearson')\n\n    if plot:\n        plt.figure(figsize=(8, 6))\n        ax = sns.heatmap(corr_df, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n        ax.set_title('Correlation Heatmap')\n        plt.close()  # Prevent immediate display in some environments\n        return corr_df, ax\n    else:\n        return corr_df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 38,
    "task_id": "BigCodeBench/308",
    "mt_data": [
      {
        "task_id": "BigCodeBench/308_1",
        "turn": "1",
        "instruct_prompt": "Create a pandas DataFrame showing grades for 100 students (named 'Student_1' to 'Student_100') in predefined subjects ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']. You should write self-contained code starting with:```import pandas as pd\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\ndef task_func(additional_fields = []):\n```",
        "test": "import unittest\nimport pandas as pd\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic(self):\n        df = task_func()\n        # Check type\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check index\n        expected_index = ['Student_' + str(i) for i in range(1, 101)]\n        self.assertListEqual(list(df.index), expected_index)\n        # Check columns\n        expected_columns = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\n        self.assertListEqual(list(df.columns), expected_columns)\n        # Check values range\n        for col in expected_columns:\n            self.assertTrue(df[col].between(0, 100).all())\n    def test_task_func_with_additional_fields(self):\n        additional = ['Art', 'Music']\n        df = task_func(additional_fields=additional)\n        expected_columns = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History'] + additional\n        self.assertListEqual(list(df.columns), expected_columns)\n        self.assertEqual(len(df), 100)\n        for col in expected_columns:\n            self.assertTrue(df[col].between(0, 100).all())\n",
        "code": "import pandas as pd\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\ndef task_func(additional_fields = []):\n    subjects = FIELDS + additional_fields\n    data = {subject: [random.randint(0, 100) for _ in STUDENTS] for subject in subjects}\n    df = pd.DataFrame(data, index=STUDENTS)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/308_2",
        "turn": "2",
        "instruct_prompt": "Generate random integer grades between 0 and 100 (inclusive) for each student in each subject (including any additional subjects passed as 'additional_fields').",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_base_fields_sorted_columns(self):\n        df = task_func(additional_fields=[])\n        expected_columns = sorted(FIELDS)\n        self.assertEqual(list(df.columns), expected_columns)\n        self.assertEqual(len(df), 100)\n        for subject in df.columns:\n            for grade in df[subject]:\n                self.assertIsInstance(grade, int)\n                self.assertGreaterEqual(grade, 0)\n                self.assertLessEqual(grade, 100)\n\n    def test_additional_fields_sorted_columns(self):\n        additional = ['Art', 'Music']\n        df = task_func(additional_fields=additional)\n        expected_columns = sorted(FIELDS + additional)\n        self.assertEqual(list(df.columns), expected_columns)\n        self.assertEqual(len(df), 100)\n        for subject in df.columns:\n            for grade in df[subject]:\n                self.assertIsInstance(grade, int)\n                self.assertGreaterEqual(grade, 0)\n                self.assertLessEqual(grade, 100)\n\n    def test_grades_range_and_type(self):\n        additional = ['Geography']\n        df = task_func(additional_fields=additional)\n        self.assertIn('Geography', df.columns)\n        self.assertEqual(len(df), 100)\n        for subject in df.columns:\n            for grade in df[subject]:\n                self.assertIsInstance(grade, int)\n                self.assertGreaterEqual(grade, 0)\n                self.assertLessEqual(grade, 100)\n\n    def test_index_names(self):\n        df = task_func()\n        expected_index = ['Student_' + str(i) for i in range(1, 101)]\n        self.assertEqual(list(df.index), expected_index)\n",
        "code": "import pandas as pd\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\n\ndef task_func(additional_fields = []):\n    subjects = sorted(FIELDS + additional_fields)\n    data = {subject: [random.randint(0, 100) for _ in STUDENTS] for subject in subjects}\n    df = pd.DataFrame(data, index=STUDENTS)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/308_3",
        "turn": "3",
        "instruct_prompt": "Construct a DataFrame with students as row indices and subjects as columns containing the generated grades.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_dataframe_structure(self):\n        df = task_func()\n        expected_index = ['Student_' + str(i) for i in range(1, 101)]\n        expected_columns = sorted(['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History'])\n\n        # Check index is pandas Index with correct name and values\n        self.assertIsInstance(df.index, pd.Index)\n        self.assertEqual(df.index.name, 'Students')  # This will fail previous code\n        self.assertListEqual(list(df.index), expected_index)\n\n        # Check columns exactly match sorted subjects\n        self.assertIsInstance(df.columns, pd.Index)\n        self.assertListEqual(list(df.columns), expected_columns)\n\n        # Check shape matches\n        self.assertEqual(df.shape, (len(expected_index), len(expected_columns)))\n\n        # Check data type and value range\n        for col in df.columns:\n            col_data = df[col]\n            self.assertTrue(all(isinstance(x, int) for x in col_data))\n            self.assertTrue(all(0 <= x <= 100 for x in col_data))\n\n    def test_dataframe_with_additional_fields(self):\n        additional = ['Art', 'Music']\n        df = task_func(additional_fields=additional)\n        expected_index = ['Student_' + str(i) for i in range(1, 101)]\n        expected_columns = sorted(FIELDS + additional)\n\n        # Check index\n        self.assertIsInstance(df.index, pd.Index)\n        self.assertEqual(df.index.name, 'Students')  # This will fail previous code\n        self.assertListEqual(list(df.index), expected_index)\n\n        # Check columns\n        self.assertIsInstance(df.columns, pd.Index)\n        self.assertListEqual(list(df.columns), expected_columns)\n\n        # Check shape\n        self.assertEqual(df.shape, (len(expected_index), len(expected_columns)))\n\n        # Check data type and value range\n        for col in df.columns:\n            col_data = df[col]\n            self.assertTrue(all(isinstance(x, int) for x in col_data))\n            self.assertTrue(all(0 <= x <= 100 for x in col_data))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\n\ndef task_func(additional_fields=[]):\n    subjects = sorted(FIELDS + additional_fields)\n    data = {subject: [random.randint(0, 100) for _ in STUDENTS] for subject in subjects}\n    df = pd.DataFrame(data, index=STUDENTS)\n    df.index.name = 'Students'  # Set the index name to differentiate from previous rounds\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/308_4",
        "turn": "4",
        "instruct_prompt": "Calculate the average grade for each student across all subjects and add it as a new column named 'Average Grade'.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_average_grade_column(self):\n        df = task_func()\n        # Check if 'Average Grade' column exists\n        self.assertIn('Average Grade', df.columns)\n        # Check if the average grade is correctly calculated\n        for idx, row in df.iterrows():\n            subjects = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\n            expected_avg = sum(row[subj] for subj in subjects) / len(subjects)\n            self.assertAlmostEqual(row['Average Grade'], expected_avg)\n\n    def test_average_includes_additional_fields(self):\n        additional = ['Art', 'Music']\n        df = task_func(additional_fields=additional)\n        self.assertIn('Average Grade', df.columns)\n        subjects = sorted(FIELDS + additional)\n        for idx, row in df.iterrows():\n            expected_avg = sum(row[subj] for subj in subjects) / len(subjects)\n            self.assertAlmostEqual(row['Average Grade'], expected_avg)\n",
        "code": "import pandas as pd\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\n\ndef task_func(additional_fields=[]):\n    subjects = sorted(FIELDS + additional_fields)\n    data = {subject: [random.randint(0, 100) for _ in STUDENTS] for subject in subjects}\n    df = pd.DataFrame(data, index=STUDENTS)\n    df.index.name = 'Students'\n    df['Average Grade'] = df.mean(axis=1)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/308_5",
        "turn": "5",
        "instruct_prompt": "Calculate the average grade for each subject across all students and add it as a new row named 'Average'. The DataFrame should include all students, subjects, their average grades per student, and the average grades per subject.",
        "test": "import unittest\nimport pandas as pd\nfrom pandas.testing import assert_frame_equal\n\nclass TestCases(unittest.TestCase):\n    def test_average_row_added(self):\n        df = task_func()\n        # Check that 'Average' row exists\n        self.assertIn('Average', df.index)\n\n        # Check that 'Average Grade' column exists\n        self.assertIn('Average Grade', df.columns)\n\n        # Check that all original students are present\n        for i in range(1, 101):\n            self.assertIn('Student_' + str(i), df.index)\n\n        subjects = ['Biology', 'Chemistry', 'English', 'History', 'Math', 'Physics']\n\n        # Check average values in 'Average' row for each subject\n        for subject in subjects:\n            expected_avg = df.loc['Student_1': 'Student_100', subject].mean()\n            self.assertAlmostEqual(df.at['Average', subject], expected_avg, places=5)\n\n        # Check 'Average Grade' in 'Average' row is the mean of subject averages\n        expected_avg_grade = df.loc['Average', subjects].mean()\n        self.assertAlmostEqual(df.at['Average', 'Average Grade'], expected_avg_grade, places=5)\n\n    def test_with_additional_fields(self):\n        additional = ['Art', 'Music']\n        df = task_func(additional_fields=additional)\n        self.assertIn('Average', df.index)\n        for field in additional:\n            self.assertIn(field, df.columns)\n\n        # Check average calculations for additional fields\n        for field in additional:\n            expected_avg = df.loc['Student_1': 'Student_100', field].mean()\n            self.assertAlmostEqual(df.at['Average', field], expected_avg, places=5)\n\n        # Check 'Average Grade' in 'Average' row\n        subjects = sorted(['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History'] + additional)\n        expected_avg_grade = df.loc['Average', subjects].mean()\n        self.assertAlmostEqual(df.at['Average', 'Average Grade'], expected_avg_grade, places=5)\n",
        "code": "import pandas as pd\nimport random\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\n\ndef task_func(additional_fields=[]):\n    subjects = sorted(FIELDS + additional_fields)\n    data = {subject: [random.randint(0, 100) for _ in STUDENTS] for subject in subjects}\n    df = pd.DataFrame(data, index=STUDENTS)\n    df.index.name = 'Students'\n    df['Average Grade'] = df.mean(axis=1)\n    avg_row = df[subjects].mean(axis=0)\n    avg_row['Average Grade'] = avg_row.mean()\n    df.loc['Average'] = avg_row\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 39,
    "task_id": "BigCodeBench/310",
    "mt_data": [
      {
        "task_id": "BigCodeBench/310_1",
        "turn": "1",
        "instruct_prompt": "Generate a CSV file containing data for 100 people with columns: name, age, height, and weight. You should write self-contained code starting with:\n```\nimport os\nimport csv\n# Constants\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\ndef task_func(filename):\n```",
        "test": "import unittest\nimport os\nimport csv\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.filename = 'test_people.csv'\n\n    def tearDown(self):\n        if os.path.exists(self.filename):\n            os.remove(self.filename)\n\n    def test_csv_file_created_with_correct_columns_and_rows(self):\n        # Directly call task_func without import\n        task_func(self.filename)\n\n        # Check file exists\n        self.assertTrue(os.path.exists(self.filename))\n\n        # Read the file and check content\n        with open(self.filename, mode='r', newline='') as csvfile:\n            reader = csv.reader(csvfile)\n            rows = list(reader)\n\n        # Check header\n        self.assertEqual(rows[0], COLUMNS)\n\n        # Check number of data rows\n        self.assertEqual(len(rows) - 1, PEOPLE_COUNT)\n\n        # Check data rows format\n        for row in rows[1:]:\n            self.assertEqual(len(row), 4)\n            name, age, height, weight = row\n            self.assertTrue(name.startswith('Person'))\n            self.assertTrue(age.isdigit())\n            self.assertTrue(height.isdigit())\n            self.assertTrue(weight.isdigit())\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import os\nimport csv\n# Constants\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\n\ndef task_func(filename):\n    # Generate data for 100 people\n    data = []\n    for i in range(1, PEOPLE_COUNT + 1):\n        name = f'Person{i}'\n        age = 20 + (i % 50)  # Age between 20 and 69\n        height = 150 + (i % 51)  # Height between 150 and 200 cm\n        weight = 50 + (i % 51)  # Weight between 50 and 100 kg\n        data.append([name, age, height, weight])\n\n    with open(filename, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(COLUMNS)\n        writer.writerows(data)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/310_2",
        "turn": "2",
        "instruct_prompt": "Fill the CSV file with simulated data for each person. Names should be in the format 'Person_1', 'Person_2', ..., 'Person_100'. Age should be a random integer between 20 and 50, height between 150 and 200 cm, and weight between 50 and 100 kg.",
        "test": "import unittest\nimport os\nimport csv\nfrom io import StringIO\nimport tempfile\n\n# Import the task_func from the solution (assuming it is in the same file or adapted accordingly)\n\nclass TestCases(unittest.TestCase):\n    def test_csv_content_and_ranges(self):\n        with tempfile.NamedTemporaryFile(delete=False, mode='r+', newline='') as tmpfile:\n            filename = tmpfile.name\n        try:\n            # Run the task_func to generate the CSV\n            task_func(filename)\n\n            # Read and verify contents\n            with open(filename, mode='r', newline='') as f:\n                reader = csv.DictReader(f)\n                rows = list(reader)\n\n            # Check number of rows\n            self.assertEqual(len(rows), 100)\n\n            for i, row in enumerate(rows, start=1):\n                # Check name format\n                expected_name = f'Person_{i}'\n                self.assertEqual(row['Name'], expected_name)\n\n                # Check age is integer and in range\n                age = int(row['Age'])\n                self.assertGreaterEqual(age, 20)\n                self.assertLessEqual(age, 50)\n\n                # Check height is integer and in range\n                height = int(row['Height'])\n                self.assertGreaterEqual(height, 150)\n                self.assertLessEqual(height, 200)\n\n                # Check weight is integer and in range\n                weight = int(row['Weight'])\n                self.assertGreaterEqual(weight, 50)\n                self.assertLessEqual(weight, 100)\n\n        finally:\n            os.remove(filename)\n",
        "code": "import os\nimport csv\nimport random\n\n# Constants\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\n\n\ndef task_func(filename):\n    # Generate data for 100 people with random values as required\n    data = []\n    for i in range(1, PEOPLE_COUNT + 1):\n        name = f'Person_{i}'\n        age = random.randint(20, 50)  # Age between 20 and 50\n        height = random.randint(150, 200)  # Height between 150 and 200 cm\n        weight = random.randint(50, 100)  # Weight between 50 and 100 kg\n        data.append([name, age, height, weight])\n\n    with open(filename, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(COLUMNS)\n        writer.writerows(data)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/310_3",
        "turn": "3",
        "instruct_prompt": "Calculate the average age, height, and weight of all people and append a row labeled 'Average' with these values at the end of the CSV file.",
        "test": "import unittest\nimport os\nimport csv\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.filename = 'test_people.csv'\n\n    def tearDown(self):\n        if os.path.exists(self.filename):\n            os.remove(self.filename)\n\n    def test_average_row_exists_and_values(self):\n        # Directly call task_func without import\n        task_func(self.filename)\n\n        with open(self.filename, newline='') as csvfile:\n            reader = list(csv.reader(csvfile))\n\n        # Check header\n        self.assertEqual(reader[0], ['Name', 'Age', 'Height', 'Weight'])\n\n        # There should be 101 data rows + 1 header = 102 rows\n        self.assertEqual(len(reader), 102)\n\n        # Last row label should be 'Average'\n        self.assertEqual(reader[-1][0], 'Average')\n\n        # Extract all Age, Height, Weight values from data rows\n        ages = [int(row[1]) for row in reader[1:-1]]\n        heights = [int(row[2]) for row in reader[1:-1]]\n        weights = [int(row[3]) for row in reader[1:-1]]\n\n        avg_age = sum(ages) / len(ages)\n        avg_height = sum(heights) / len(heights)\n        avg_weight = sum(weights) / len(weights)\n\n        # Check that average values in the last row match calculated averages with 2 decimals\n        self.assertAlmostEqual(float(reader[-1][1]), avg_age, places=2)\n        self.assertAlmostEqual(float(reader[-1][2]), avg_height, places=2)\n        self.assertAlmostEqual(float(reader[-1][3]), avg_weight, places=2)\n",
        "code": "import os\nimport csv\nimport random\n\n# Constants\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\n\n\ndef task_func(filename):\n    # Generate data for 100 people with random values as required\n    data = []\n    for i in range(1, PEOPLE_COUNT + 1):\n        name = f'Person_{i}'\n        age = random.randint(20, 50)  # Age between 20 and 50\n        height = random.randint(150, 200)  # Height between 150 and 200 cm\n        weight = random.randint(50, 100)  # Weight between 50 and 100 kg\n        data.append([name, age, height, weight])\n\n    with open(filename, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(COLUMNS)\n        writer.writerows(data)\n\n        # Calculate averages\n        total_age = sum(row[1] for row in data)\n        total_height = sum(row[2] for row in data)\n        total_weight = sum(row[3] for row in data)\n\n        avg_age = total_age / PEOPLE_COUNT\n        avg_height = total_height / PEOPLE_COUNT\n        avg_weight = total_weight / PEOPLE_COUNT\n\n        # Append average row\n        avg_row = ['Average', f'{avg_age:.2f}', f'{avg_height:.2f}', f'{avg_weight:.2f}']\n        writer.writerow(avg_row)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/310_4",
        "turn": "4",
        "instruct_prompt": "Ensure the function returns the absolute path of the created CSV file as a string.",
        "test": "import unittest\nimport os\nimport csv\n\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_returns_absolute_path_and_file_content(self):\n        with NamedTemporaryFile(delete=False, suffix='.csv') as tmpfile:\n            tmpfile_name = tmpfile.name\n\n        try:\n            abs_path = task_func(tmpfile_name)\n\n            # Check returned path is absolute\n            self.assertTrue(os.path.isabs(abs_path))\n\n            # Check the returned path matches the input path absolute\n            self.assertEqual(abs_path, os.path.abspath(tmpfile_name))\n\n            # Check the file exists\n            self.assertTrue(os.path.exists(abs_path))\n\n            # Check file content: header, 100 data rows, 1 average row\n            with open(abs_path, newline='') as f:\n                reader = csv.reader(f)\n                rows = list(reader)\n\n            # Header row\n            self.assertEqual(rows[0], ['Name', 'Age', 'Height', 'Weight'])\n\n            # 100 data rows\n            self.assertEqual(len(rows), 102)  # header + 100 data + 1 average\n\n            # Check last row label 'Average'\n            self.assertEqual(rows[-1][0], 'Average')\n\n            # Check average values are floats formatted to 2 decimals\n            for val in rows[-1][1:]:\n                float_val = float(val)  # should not raise\n                self.assertEqual(len(val.split('.')[-1]), 2)  # two decimals\n\n        finally:\n            if os.path.exists(tmpfile_name):\n                os.remove(tmpfile_name)\n",
        "code": "import os\nimport csv\nimport random\n\n# Constants\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\n\n\ndef task_func(filename):\n    # Generate data for 100 people with random values as required\n    data = []\n    for i in range(1, PEOPLE_COUNT + 1):\n        name = f'Person_{i}'\n        age = random.randint(20, 50)  # Age between 20 and 50\n        height = random.randint(150, 200)  # Height between 150 and 200 cm\n        weight = random.randint(50, 100)  # Weight between 50 and 100 kg\n        data.append([name, age, height, weight])\n\n    with open(filename, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(COLUMNS)\n        writer.writerows(data)\n\n        # Calculate averages\n        total_age = sum(row[1] for row in data)\n        total_height = sum(row[2] for row in data)\n        total_weight = sum(row[3] for row in data)\n\n        avg_age = total_age / PEOPLE_COUNT\n        avg_height = total_height / PEOPLE_COUNT\n        avg_weight = total_weight / PEOPLE_COUNT\n\n        # Append average row\n        avg_row = ['Average', f'{avg_age:.2f}', f'{avg_height:.2f}', f'{avg_weight:.2f}']\n        writer.writerow(avg_row)\n\n    # Return absolute path of the created CSV file\n    return os.path.abspath(filename)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 40,
    "task_id": "BigCodeBench/313",
    "mt_data": [
      {
        "task_id": "BigCodeBench/313_1",
        "turn": "1",
        "instruct_prompt": "Organize files in a directory by reading each file's content. You should write self-contained code starting with:\n```\nimport os\n\ndef task_func(directory):\n```",
        "test": "import unittest\nimport os\nimport tempfile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def test_read_files_content(self):\n        # Create sample files\n        files_contents = {\n            'file1.txt': 'Hello World',\n            'file2.txt': 'Python Testing',\n            'file3.txt': ''\n        }\n        for fname, content in files_contents.items():\n            with open(os.path.join(self.test_dir.name, fname), 'w', encoding='utf-8') as f:\n                f.write(content)\n\n        result = task_func(self.test_dir.name)\n        self.assertEqual(result, files_contents)\n\n    def test_ignore_subdirectories(self):\n        # Create a subdirectory inside test_dir\n        sub_dir = os.path.join(self.test_dir.name, 'subdir')\n        os.mkdir(sub_dir)\n        # Create a file inside subdirectory\n        with open(os.path.join(sub_dir, 'subfile.txt'), 'w', encoding='utf-8') as f:\n            f.write('Should not be read')\n        # Create a file in main dir\n        with open(os.path.join(self.test_dir.name, 'mainfile.txt'), 'w', encoding='utf-8') as f:\n            f.write('Main file content')\n\n        result = task_func(self.test_dir.name)\n        self.assertEqual(result, {'mainfile.txt': 'Main file content'})\n\n    def test_invalid_directory(self):\n        with self.assertRaises(ValueError):\n            task_func('non_existing_directory')\n",
        "code": "import os\n\ndef task_func(directory):\n    \"\"\"Read each file's content in the given directory.\"\"\"\n    if not os.path.isdir(directory):\n        raise ValueError(\"The provided path is not a valid directory.\")\n\n    contents = {}\n    for filename in os.listdir(directory):\n        filepath = os.path.join(directory, filename)\n        if os.path.isfile(filepath):\n            with open(filepath, 'r', encoding='utf-8') as f:\n                contents[filename] = f.read()\n    return contents\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/313_2",
        "turn": "2",
        "instruct_prompt": "For each file, extract the first text segment that is not enclosed in square brackets from its content.",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def write_file(self, filename, content):\n        filepath = os.path.join(self.test_dir.name, filename)\n        with open(filepath, 'w', encoding='utf-8') as f:\n            f.write(content)\n\n    def test_extract_first_non_bracket_segment(self):\n        self.write_file('file1.txt', '[abc]def[ghi] jkl')\n        self.write_file('file2.txt', '[123][456]789')\n        self.write_file('file3.txt', 'no brackets here')\n        self.write_file('file4.txt', '[onlybrackets]')\n        self.write_file('file5.txt', '   [skip]   text after')\n        self.write_file('file6.txt', '')\n\n        expected = {\n            'file1.txt': 'def',\n            'file2.txt': '789',\n            'file3.txt': 'no brackets here',\n            'file4.txt': '',\n            'file5.txt': 'text after',\n            'file6.txt': ''\n        }\n\n        result = task_func(self.test_dir.name)\n        self.assertEqual(result, expected)\n\n    def test_invalid_directory(self):\n        with self.assertRaises(ValueError):\n            task_func('non_existing_directory')\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import os\nimport re\n\ndef task_func(directory):\n    \"\"\"For each file in directory, extract the first text segment not enclosed in square brackets.\"\"\"\n    if not os.path.isdir(directory):\n        raise ValueError(\"The provided path is not a valid directory.\")\n\n    result = {}\n    pattern = re.compile(r'\\[.*?\\]|([^\\[\\]]+)')\n\n    for filename in os.listdir(directory):\n        filepath = os.path.join(directory, filename)\n        if os.path.isfile(filepath):\n            with open(filepath, 'r', encoding='utf-8') as f:\n                content = f.read()\n\n            matches = pattern.findall(content)\n            first_non_bracket_text = None\n            for match in matches:\n                if match and match.strip():\n                    first_non_bracket_text = match.strip()\n                    break\n\n            result[filename] = first_non_bracket_text if first_non_bracket_text is not None else ''\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/313_3",
        "turn": "3",
        "instruct_prompt": "Move each file into a subdirectory named after the extracted text segment. If the subdirectory does not exist, create it. If no matching text is found, do not move the file.",
        "test": "import unittest\nimport tempfile\nimport os\nfrom shutil import rmtree\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        rmtree(self.test_dir)\n\n    def test_files_moved_to_subdirectories(self):\n        # Create files with contents that have text outside brackets\n        file1 = os.path.join(self.test_dir, 'file1.txt')\n        file2 = os.path.join(self.test_dir, 'file2.txt')\n        file3 = os.path.join(self.test_dir, 'file3.txt')\n\n        with open(file1, 'w', encoding='utf-8') as f:\n            f.write('[ignore]Hello World')  # first non-bracket text is 'Hello World'\n        with open(file2, 'w', encoding='utf-8') as f:\n            f.write('Sample text [ignore] more text')  # first non-bracket text is 'Sample text'\n        with open(file3, 'w', encoding='utf-8') as f:\n            f.write('[only brackets]')  # no non-bracket text\n\n        task_func(self.test_dir)\n\n        # Check that file1 moved to subdir 'Hello World'\n        self.assertTrue(os.path.isdir(os.path.join(self.test_dir, 'Hello World')))\n        self.assertTrue(os.path.isfile(os.path.join(self.test_dir, 'Hello World', 'file1.txt')))\n\n        # Check that file2 moved to subdir 'Sample text'\n        self.assertTrue(os.path.isdir(os.path.join(self.test_dir, 'Sample text')))\n        self.assertTrue(os.path.isfile(os.path.join(self.test_dir, 'Sample text', 'file2.txt')))\n\n        # file3 should remain in the original directory\n        self.assertTrue(os.path.isfile(os.path.join(self.test_dir, 'file3.txt')))\n\n    def test_no_matching_text_file_untouched(self):\n        file_path = os.path.join(self.test_dir, 'file.txt')\n        with open(file_path, 'w', encoding='utf-8') as f:\n            f.write('[brackets only]')\n\n        task_func(self.test_dir)\n\n        # File should still be in original location\n        self.assertTrue(os.path.isfile(file_path))\n\n    def test_subdirectory_created_if_not_exist(self):\n        file_path = os.path.join(self.test_dir, 'file.txt')\n        with open(file_path, 'w', encoding='utf-8') as f:\n            f.write('Category1 [brackets]')\n\n        task_func(self.test_dir)\n\n        # Subdirectory 'Category1' should be created\n        self.assertTrue(os.path.isdir(os.path.join(self.test_dir, 'Category1')))\n        # File moved inside that subdirectory\n        self.assertTrue(os.path.isfile(os.path.join(self.test_dir, 'Category1', 'file.txt')))\n\n    def test_raises_value_error_for_invalid_directory(self):\n        with self.assertRaises(ValueError):\n            task_func('non_existent_dir')\n",
        "code": "import os\nimport re\n\ndef task_func(directory):\n    \"\"\"For each file in directory, extract the first text segment not enclosed in square brackets.\n    Move each file into a subdirectory named after the extracted text segment.\n    If the subdirectory does not exist, create it.\n    If no matching text is found, do not move the file.\n    \"\"\"\n    if not os.path.isdir(directory):\n        raise ValueError(\"The provided path is not a valid directory.\")\n\n    pattern = re.compile(r'\\[.*?\\]|([^\\[\\]]+)')\n\n    for filename in os.listdir(directory):\n        filepath = os.path.join(directory, filename)\n        if os.path.isfile(filepath):\n            with open(filepath, 'r', encoding='utf-8') as f:\n                content = f.read()\n\n            matches = pattern.findall(content)\n            first_non_bracket_text = None\n            for match in matches:\n                if match and match.strip():\n                    first_non_bracket_text = match.strip()\n                    break\n\n            if first_non_bracket_text:\n                subdir_path = os.path.join(directory, first_non_bracket_text)\n                if not os.path.exists(subdir_path):\n                    os.mkdir(subdir_path)\n                new_path = os.path.join(subdir_path, filename)\n                os.rename(filepath, new_path)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/313_4",
        "turn": "4",
        "instruct_prompt": "Return a tuple where the first element is the directory path, and the second element is a dictionary mapping each created subdirectory to a list of files moved into it.",
        "test": "import unittest\nimport os\nimport tempfile\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.test_dir)\n\n    def create_file(self, filename, content):\n        path = os.path.join(self.test_dir, filename)\n        with open(path, 'w', encoding='utf-8') as f:\n            f.write(content)\n\n    def test_move_files_and_return_structure(self):\n        # Create files with different contents\n        self.create_file('file1.txt', '[abc] hello world')  # first non-bracket text: 'hello world'\n        self.create_file('file2.txt', '[ignore]foo[bar]baz')  # first non-bracket text: 'foo'\n        self.create_file('file3.txt', '[skip]')  # no non-bracket text\n        self.create_file('file4.txt', '  leading  ')  # first non-bracket text: 'leading'\n        self.create_file('file5.txt', '[]empty[brackets]text')  # first non-bracket text: 'empty'\n\n        dir_path, moved = task_func(self.test_dir)\n\n        # Check returned directory path\n        self.assertEqual(dir_path, self.test_dir)\n\n        # Check moved dictionary keys\n        expected_dirs = {'hello world', 'foo', 'leading', 'empty'}\n        self.assertEqual(set(moved.keys()), expected_dirs)\n\n        # Check files in moved dict\n        self.assertIn('file1.txt', moved['hello world'])\n        self.assertIn('file2.txt', moved['foo'])\n        self.assertIn('file4.txt', moved['leading'])\n        self.assertIn('file5.txt', moved['empty'])\n\n        # file3.txt should not be moved\n        self.assertFalse(any('file3.txt' in files for files in moved.values()))\n\n        # Check actual file locations\n        for subdir, files in moved.items():\n            subdir_path = os.path.join(self.test_dir, subdir)\n            self.assertTrue(os.path.isdir(subdir_path))\n            for f in files:\n                self.assertTrue(os.path.isfile(os.path.join(subdir_path, f)))\n\n        # Original directory should no longer contain moved files\n        remaining_files = [f for f in os.listdir(self.test_dir) if os.path.isfile(os.path.join(self.test_dir, f))]\n        self.assertIn('file3.txt', remaining_files)\n        for files in moved.values():\n            for f in files:\n                self.assertNotIn(f, remaining_files)\n",
        "code": "import os\nimport re\n\ndef task_func(directory):\n    \"\"\"For each file in directory, extract the first text segment not enclosed in square brackets.\n    Move each file into a subdirectory named after the extracted text segment.\n    If the subdirectory does not exist, create it.\n    If no matching text is found, do not move the file.\n    Return a tuple: (directory path, {subdirectory_name: [files moved into it]})\n    \"\"\"\n    if not os.path.isdir(directory):\n        raise ValueError(\"The provided path is not a valid directory.\")\n\n    pattern = re.compile(r'\\[.*?\\]|([^\\[\\]]+)')\n    moved_files = {}\n\n    for filename in os.listdir(directory):\n        filepath = os.path.join(directory, filename)\n        if os.path.isfile(filepath):\n            with open(filepath, 'r', encoding='utf-8') as f:\n                content = f.read()\n\n            matches = pattern.findall(content)\n            first_non_bracket_text = None\n            for match in matches:\n                if match and match.strip():\n                    first_non_bracket_text = match.strip()\n                    break\n\n            if first_non_bracket_text:\n                subdir_path = os.path.join(directory, first_non_bracket_text)\n                if not os.path.exists(subdir_path):\n                    os.mkdir(subdir_path)\n                new_path = os.path.join(subdir_path, filename)\n                os.rename(filepath, new_path)\n\n                if first_non_bracket_text not in moved_files:\n                    moved_files[first_non_bracket_text] = []\n                moved_files[first_non_bracket_text].append(filename)\n\n    return (directory, moved_files)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 41,
    "task_id": "BigCodeBench/324",
    "mt_data": [
      {
        "task_id": "BigCodeBench/324_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a list of file paths and runs each file as a subprocess. You should write self-contained code starting with:\n```python\nimport subprocess\ndef task_func(file_list):\n```",
        "test": "import unittest\nimport subprocess\nfrom unittest.mock import patch, call\n\nclass TestCases(unittest.TestCase):\n    @patch('subprocess.run')\n    def test_task_func_runs_all_files(self, mock_run):\n        files = ['/path/to/script1.sh', '/path/to/script2.sh']\n        task_func(files)\n        expected_calls = [call([files[0]]), call([files[1]])]\n        mock_run.assert_has_calls(expected_calls)\n        self.assertEqual(mock_run.call_count, 2)\n",
        "code": "import subprocess\n\ndef task_func(file_list):\n    for file_path in file_list:\n        subprocess.run([file_path])\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/324_2",
        "turn": "2",
        "instruct_prompt": "Run all subprocesses at the same time (concurrently), not one after another.",
        "test": "import unittest\nfrom unittest.mock import patch\nimport time\n\nclass TestCases(unittest.TestCase):\n    @patch('subprocess.run')\n    def test_task_func_runs_all_concurrently(self, mock_run):\n        # Mock subprocess.run to sleep for 0.1 seconds to simulate work\n        def fake_run(args):\n            time.sleep(0.1)\n        mock_run.side_effect = fake_run\n\n        file_list = ['file1', 'file2', 'file3', 'file4']\n\n        start_time = time.time()\n        task_func(file_list)\n        elapsed = time.time() - start_time\n\n        # Ensure subprocess.run called once per file\n        self.assertEqual(mock_run.call_count, len(file_list))\n\n        # If run sequentially, total time >= 0.1 * len(file_list)\n        # If run concurrently, total time should be just over 0.1 seconds\n        self.assertLess(elapsed, 0.1 * len(file_list) * 0.8, \n                        f\"Elapsed time {elapsed} indicates sequential run\")",
        "code": "import subprocess\nimport threading\n\ndef task_func(file_list):\n    threads = []\n    for file_path in file_list:\n        t = threading.Thread(target=subprocess.run, args=([file_path],))\n        t.start()\n        threads.append(t)\n    for t in threads:\n        t.join()",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/324_3",
        "turn": "3",
        "instruct_prompt": "Return a list containing the exit codes of all subprocesses after they have finished running.",
        "test": "import unittest\nimport sys\nimport os\nimport tempfile\nimport stat\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create temporary executable scripts that exit with specific codes\n        self.temp_files = []\n        self.exit_codes = [0, 1, 2]\n        for code in self.exit_codes:\n            fd, path = tempfile.mkstemp()\n            os.close(fd)\n            if sys.platform.startswith('win'):\n                # Create a batch file that exits with the code\n                bat_path = path + '.bat'\n                with open(bat_path, 'w') as f:\n                    f.write(f\"@echo off\\nexit /b {code}\\n\")\n                self.temp_files.append(bat_path)\n                os.remove(path)  # remove original empty file\n            else:\n                # Create a shell script that exits with the code\n                with open(path, 'w') as f:\n                    f.write(f\"#!/bin/sh\\nexit {code}\\n\")\n                st = os.stat(path)\n                os.chmod(path, st.st_mode | stat.S_IEXEC)\n                self.temp_files.append(path)\n\n    def tearDown(self):\n        for f in self.temp_files:\n            try:\n                os.remove(f)\n            except OSError:\n                pass\n\n    def test_exit_codes(self):\n        result_codes = task_func(self.temp_files)\n        self.assertEqual(result_codes, self.exit_codes)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import subprocess\nimport threading\n\nclass SubprocessThread(threading.Thread):\n    def __init__(self, file_path):\n        super().__init__()\n        self.file_path = file_path\n        self.exit_code = None\n\n    def run(self):\n        result = subprocess.run([self.file_path])\n        self.exit_code = result.returncode\n\n\ndef task_func(file_list):\n    threads = []\n    for file_path in file_list:\n        t = SubprocessThread(file_path)\n        t.start()\n        threads.append(t)\n    for t in threads:\n        t.join()\n    return [t.exit_code for t in threads]\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 42,
    "task_id": "BigCodeBench/326",
    "mt_data": [
      {
        "task_id": "BigCodeBench/326_1",
        "turn": "1",
        "instruct_prompt": "Write a function that lists all .bat files in a given directory and returns their file names as a list. You should write self-contained code starting with:\n```\nimport os\nimport glob\ndef task_func(directory_path):\n```",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_list_bat_files(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            # Create some .bat files\n            filenames = ['file1.bat', 'file2.bat', 'file3.txt', 'script.BAT']\n            for name in filenames:\n                with open(os.path.join(tempdir, name), 'w') as f:\n                    f.write('echo test')\n\n            result = task_func(tempdir)\n            # Only files with .bat extension in lowercase should be listed\n            expected = ['file1.bat', 'file2.bat']\n            self.assertCountEqual(result, expected)\n\n    def test_empty_directory(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            result = task_func(tempdir)\n            self.assertEqual(result, [])\n\n    def test_nonexistent_directory(self):\n        result = task_func('/path/to/nonexistent/directory')\n        self.assertEqual(result, [])",
        "code": "import os\nimport glob\n\ndef task_func(directory_path):\n    pattern = os.path.join(directory_path, '*.bat')\n    bat_files = glob.glob(pattern)\n    return [os.path.basename(f) for f in bat_files]",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/326_2",
        "turn": "2",
        "instruct_prompt": "Modify the function to execute each .bat file found and collect its exit code, returning a list of tuples where each tuple contains the file name and its exit code.",
        "test": "import unittest\nimport tempfile\nimport os\nimport stat\nimport sys\n\nclass TestCases(unittest.TestCase):\n    @unittest.skipUnless(sys.platform.startswith('win'), \"Requires Windows platform\")\n    def test_task_func_exit_codes(self):\n        with tempfile.TemporaryDirectory() as temp_dir:\n            bat1 = os.path.join(temp_dir, 'test1.bat')\n            bat2 = os.path.join(temp_dir, 'test2.bat')\n\n            with open(bat1, 'w') as f:\n                f.write(\"\"\"@echo off\nexit /b 0\n\"\"\")\n            with open(bat2, 'w') as f:\n                f.write(\"\"\"@echo off\nexit /b 1\n\"\"\")\n\n            os.chmod(bat1, stat.S_IREAD | stat.S_IWRITE)\n            os.chmod(bat2, stat.S_IREAD | stat.S_IWRITE)\n\n            results = task_func(temp_dir)\n\n            results.sort(key=lambda x: x[0])\n\n            self.assertEqual(len(results), 2)\n            self.assertEqual(results[0][0], 'test1.bat')\n            self.assertEqual(results[1][0], 'test2.bat')\n            self.assertEqual(results[0][1], 0)\n            self.assertEqual(results[1][1], 1)\n\n    def test_task_func_no_bat_files(self):\n        with tempfile.TemporaryDirectory() as temp_dir:\n            results = task_func(temp_dir)\n            self.assertEqual(results, [])\n\n    def test_task_func_non_windows(self):\n        if not sys.platform.startswith('win'):\n            with tempfile.TemporaryDirectory() as temp_dir:\n                bat_file = os.path.join(temp_dir, 'dummy.bat')\n                with open(bat_file, 'w') as f:\n                    f.write(\"exit /b 0\")\n                results = task_func(temp_dir)\n                self.assertEqual(results, [('dummy.bat', -1)])\n",
        "code": "import os\nimport glob\nimport subprocess\nimport sys\n\ndef task_func(directory_path):\n    pattern = os.path.join(directory_path, '*.bat')\n    bat_files = glob.glob(pattern)\n    results = []\n    if sys.platform.startswith('win'):\n        for bat_file in bat_files:\n            exit_code = subprocess.call(['cmd.exe', '/c', bat_file], shell=False)\n            results.append((os.path.basename(bat_file), exit_code))\n    else:\n        # Non-Windows platform: return exit code -1 for each bat file to indicate no execution\n        for bat_file in bat_files:\n            results.append((os.path.basename(bat_file), -1))\n    return results\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/326_3",
        "turn": "3",
        "instruct_prompt": "If a .bat file cannot be executed for any reason, catch the exception and set its exit code to None in the output list.",
        "test": "import unittest\nimport os\nimport tempfile\nfrom unittest import mock\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.TemporaryDirectory()\n        self.dir_path = self.test_dir.name\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    @mock.patch('sys.platform', 'win32')\n    @mock.patch('subprocess.call')\n    def test_bat_execution_success(self, mock_call):\n        mock_call.return_value = 0\n        bat_path = os.path.join(self.dir_path, 'success.bat')\n        with open(bat_path, 'w') as f:\n            f.write('@echo off\\nexit /b 0\\n')\n\n        results = task_func(self.dir_path)\n        self.assertEqual(len(results), 1)\n        self.assertEqual(results[0][0], 'success.bat')\n        self.assertEqual(results[0][1], 0)\n\n    @mock.patch('sys.platform', 'win32')\n    @mock.patch('subprocess.call')\n    def test_bat_execution_failure(self, mock_call):\n        mock_call.return_value = 1\n        bat_path = os.path.join(self.dir_path, 'fail.bat')\n        with open(bat_path, 'w') as f:\n            f.write('@echo off\\nexit /b 1\\n')\n\n        results = task_func(self.dir_path)\n        self.assertEqual(len(results), 1)\n        self.assertEqual(results[0][0], 'fail.bat')\n        self.assertEqual(results[0][1], 1)\n\n    @mock.patch('sys.platform', 'win32')\n    @mock.patch('subprocess.call', side_effect=Exception('Execution failed'))\n    def test_bat_execution_exception(self, mock_call):\n        bat_path = os.path.join(self.dir_path, 'exception.bat')\n        with open(bat_path, 'w') as f:\n            f.write('@echo off\\nexit /b 0\\n')\n\n        results = task_func(self.dir_path)\n        self.assertEqual(len(results), 1)\n        self.assertEqual(results[0][0], 'exception.bat')\n        self.assertIsNone(results[0][1])\n\n    def test_non_windows_platform(self):\n        bat1 = os.path.join(self.dir_path, 'one.bat')\n        bat2 = os.path.join(self.dir_path, 'two.bat')\n        with open(bat1, 'w') as f:\n            f.write('dummy')\n        with open(bat2, 'w') as f:\n            f.write('dummy')\n\n        with mock.patch('sys.platform', 'linux'):\n            results = task_func(self.dir_path)\n            self.assertEqual(len(results), 2)\n            names = [name for name, code in results]\n            self.assertIn('one.bat', names)\n            self.assertIn('two.bat', names)\n            for _, code in results:\n                self.assertEqual(code, -1)\n",
        "code": "import os\nimport glob\nimport subprocess\nimport sys\n\ndef task_func(directory_path):\n    pattern = os.path.join(directory_path, '*.bat')\n    bat_files = glob.glob(pattern)\n    results = []\n    if sys.platform.startswith('win'):\n        for bat_file in bat_files:\n            try:\n                exit_code = subprocess.call(['cmd.exe', '/c', bat_file], shell=False)\n            except Exception:\n                exit_code = None\n            results.append((os.path.basename(bat_file), exit_code))\n    else:\n        # Non-Windows platform: return exit code -1 for each bat file to indicate no execution\n        for bat_file in bat_files:\n            results.append((os.path.basename(bat_file), -1))\n    return results\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 43,
    "task_id": "BigCodeBench/341",
    "mt_data": [
      {
        "task_id": "BigCodeBench/341_1",
        "turn": "1",
        "instruct_prompt": "Write a function named task_func that takes a pandas DataFrame df and a column name col as input and returns a matplotlib figure containing two subplots stacked vertically. You should write self-contained code starting with:\n```\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df, col):\n```",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic(self):\n        data = {'A': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7]}\n        df = pd.DataFrame(data)\n        fig = task_func(df, 'A')\n        self.assertIsInstance(fig, plt.Figure)\n        self.assertEqual(len(fig.axes), 2)\n        # Check that the titles of the subplots are correct\n        self.assertEqual(fig.axes[0].get_title(), 'Histogram of A')\n        self.assertEqual(fig.axes[1].get_title(), 'Boxplot of A')\n\n    def test_task_func_with_empty_column(self):\n        df = pd.DataFrame({'A': []})\n        fig = task_func(df, 'A')\n        self.assertIsInstance(fig, plt.Figure)\n        self.assertEqual(len(fig.axes), 2)\n\n    def test_task_func_with_non_numeric(self):\n        df = pd.DataFrame({'A': ['a', 'b', 'a', 'c']})\n        fig = task_func(df, 'A')\n        self.assertIsInstance(fig, plt.Figure)\n        self.assertEqual(len(fig.axes), 2)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, col):\n    fig, axes = plt.subplots(2, 1, figsize=(8, 10))\n    sns.histplot(df[col], ax=axes[0], kde=False)\n    axes[0].set_title(f'Histogram of {col}')\n    sns.boxplot(x=df[col], ax=axes[1])\n    axes[1].set_title(f'Boxplot of {col}')\n    plt.tight_layout()\n    return fig\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/341_2",
        "turn": "2",
        "instruct_prompt": "Add input validation to the function so that it raises a ValueError if df is not a pandas DataFrame, or if df is empty, or if col is not a column in df.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_valid_input(self):\n        df = pd.DataFrame({'A': [1, 2, 3, 4, 5]})\n        fig = task_func(df, 'A')\n        self.assertIsInstance(fig, plt.Figure)\n\n    def test_df_not_dataframe(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func([1, 2, 3], 'A')\n        self.assertEqual(str(cm.exception), 'df must be a pandas DataFrame')\n\n    def test_df_empty(self):\n        df = pd.DataFrame({'A': []})\n        with self.assertRaises(ValueError) as cm:\n            task_func(df, 'A')\n        self.assertEqual(str(cm.exception), 'df must not be empty')\n\n    def test_col_not_in_df(self):\n        df = pd.DataFrame({'A': [1, 2, 3]})\n        with self.assertRaises(ValueError) as cm:\n            task_func(df, 'B')\n        self.assertEqual(str(cm.exception), 'B is not a column in df')\n",
        "code": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"df must be a pandas DataFrame\")\n    if df.empty:\n        raise ValueError(\"df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(f\"{col} is not a column in df\")\n\n    fig, axes = plt.subplots(2, 1, figsize=(8, 10))\n    sns.histplot(df[col], ax=axes[0], kde=False)\n    axes[0].set_title(f'Histogram of {col}')\n    sns.boxplot(x=df[col], ax=axes[1])\n    axes[1].set_title(f'Boxplot of {col}')\n    plt.tight_layout()\n    return fig\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/341_3",
        "turn": "3",
        "instruct_prompt": "For the first subplot, plot a histogram with a kernel density estimate if the specified column is numerical; if it is categorical, plot a count plot instead.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nfrom matplotlib.figure import Figure\n\nclass TestCases(unittest.TestCase):\n    def test_numeric_column(self):\n        df = pd.DataFrame({'num_col': [1, 2, 2, 3, 4, 5, 5, 5, 6]})\n        fig = task_func(df, 'num_col')\n        self.assertIsInstance(fig, Figure)\n        axes = fig.axes\n        self.assertEqual(len(axes), 2)\n        # First axes should contain a histogram with KDE\n        # Check that the title contains 'Histogram with KDE'\n        self.assertIn('Histogram with KDE', axes[0].get_title())\n\n    def test_categorical_column(self):\n        df = pd.DataFrame({'cat_col': ['a', 'b', 'a', 'c', 'b', 'b', 'a']})\n        fig = task_func(df, 'cat_col')\n        self.assertIsInstance(fig, Figure)\n        axes = fig.axes\n        self.assertEqual(len(axes), 2)\n        # First axes should contain a count plot\n        self.assertIn('Count plot', axes[0].get_title())\n\n    def test_invalid_df_type(self):\n        with self.assertRaises(ValueError):\n            task_func([1, 2, 3], 'col')\n\n    def test_empty_df(self):\n        df = pd.DataFrame()\n        with self.assertRaises(ValueError):\n            task_func(df, 'any_col')\n\n    def test_column_not_in_df(self):\n        df = pd.DataFrame({'a': [1, 2, 3]})\n        with self.assertRaises(ValueError):\n            task_func(df, 'b')\n",
        "code": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"df must be a pandas DataFrame\")\n    if df.empty:\n        raise ValueError(\"df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(f\"{col} is not a column in df\")\n\n    fig, axes = plt.subplots(2, 1, figsize=(8, 10))\n\n    if pd.api.types.is_numeric_dtype(df[col]):\n        sns.histplot(df[col], ax=axes[0], kde=True)\n        axes[0].set_title(f'Histogram with KDE of {col}')\n    else:\n        sns.countplot(x=df[col], ax=axes[0])\n        axes[0].set_title(f'Count plot of {col}')\n\n    sns.boxplot(x=df[col], ax=axes[1])\n    axes[1].set_title(f'Boxplot of {col}')\n\n    plt.tight_layout()\n    return fig\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/341_4",
        "turn": "4",
        "instruct_prompt": "For the second subplot, plot a box plot if the specified column is numerical; if it is categorical, plot a strip plot with jitter.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.collections as mcollections\nimport matplotlib.patches as mpatches\n\nclass TestCases(unittest.TestCase):\n    def test_numeric_column(self):\n        df = pd.DataFrame({'num_col': [1, 2, 2, 3, 4, 5, 5, 5]})\n        fig = task_func(df, 'num_col')\n        self.assertEqual(len(fig.axes), 2)\n\n        # First subplot title check\n        self.assertIn('Histogram', fig.axes[0].get_title())\n\n        # First subplot should contain Rectangle patches (bars)\n        patches = [p for p in fig.axes[0].patches if isinstance(p, mpatches.Rectangle)]\n        self.assertTrue(len(patches) > 0, \"Histogram bars not found\")\n\n        # Also check that there is a KDE line (Line2D with data)\n        lines = fig.axes[0].lines\n        kde_lines = [line for line in lines if len(line.get_xdata()) > 0 and len(line.get_ydata()) > 0]\n        self.assertTrue(len(kde_lines) > 0, \"KDE line not found\")\n\n        # Second subplot title check\n        self.assertIn('Boxplot', fig.axes[1].get_title())\n\n        # Second subplot should contain boxplot elements: check for PathPatch (boxes) or LineCollections\n        has_boxpatch = any(isinstance(p, mpatches.PathPatch) for p in fig.axes[1].patches)\n        has_lines = any(isinstance(c, mcollections.LineCollection) for c in fig.axes[1].collections)\n        self.assertTrue(has_boxpatch or has_lines, \"Boxplot elements not found\")\n\n    def test_categorical_column(self):\n        df = pd.DataFrame({'cat_col': ['a', 'b', 'a', 'c', 'b', 'a']})\n        fig = task_func(df, 'cat_col')\n        self.assertEqual(len(fig.axes), 2)\n\n        # First subplot title check\n        self.assertIn('Count plot', fig.axes[0].get_title())\n\n        # First subplot should have Rectangle patches (bars)\n        patches = [p for p in fig.axes[0].patches if isinstance(p, mpatches.Rectangle)]\n        self.assertTrue(len(patches) > 0, \"Countplot bars not found\")\n\n        # Second subplot title check\n        self.assertIn('Strip plot', fig.axes[1].get_title())\n\n        # Second subplot should contain PathCollection objects (stripplot points)\n        collections = [c for c in fig.axes[1].collections if isinstance(c, mcollections.PathCollection)]\n        self.assertTrue(len(collections) > 0, \"Stripplot points not found\")\n\n    def test_invalid_df_type(self):\n        with self.assertRaises(ValueError):\n            task_func([1, 2, 3], 'col')\n\n    def test_empty_df(self):\n        df = pd.DataFrame({'col': []})\n        with self.assertRaises(ValueError):\n            task_func(df, 'col')\n\n    def test_missing_column(self):\n        df = pd.DataFrame({'a': [1, 2, 3]})\n        with self.assertRaises(ValueError):\n            task_func(df, 'b')\n",
        "code": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, col):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"df must be a pandas DataFrame\")\n    if df.empty:\n        raise ValueError(\"df must not be empty\")\n    if col not in df.columns:\n        raise ValueError(f\"{col} is not a column in df\")\n\n    fig, axes = plt.subplots(2, 1, figsize=(8, 10))\n\n    if pd.api.types.is_numeric_dtype(df[col]):\n        sns.histplot(df[col], ax=axes[0], kde=True)\n        axes[0].set_title(f'Histogram with KDE of {col}')\n        sns.boxplot(x=df[col], ax=axes[1])\n        axes[1].set_title(f'Boxplot of {col}')\n    else:\n        sns.countplot(x=df[col], ax=axes[0])\n        axes[0].set_title(f'Count plot of {col}')\n        sns.stripplot(x=df[col], ax=axes[1], jitter=True)\n        axes[1].set_title(f'Strip plot with jitter of {col}')\n\n    plt.tight_layout()\n    return fig\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 44,
    "task_id": "BigCodeBench/346",
    "mt_data": [
      {
        "task_id": "BigCodeBench/346_1",
        "turn": "1",
        "instruct_prompt": "Write a Python function named `task_func` with the signature `def task_func(script_path, wait=True, *args):` that runs a Python script located at `script_path` as a subprocess with additional arguments `*args`. The function should check if the script exists before running it and raise a `ValueError` if it does not. You should write self-contained code starting with:\n```\nimport subprocess\nimport os\nimport sys\n\ndef task_func(script_path, wait=True, *args):\n```",
        "test": "import unittest\nimport tempfile\nimport os\nimport sys\nfrom io import StringIO\n\nclass TestCases(unittest.TestCase):\n    def test_script_not_exist_raises(self):\n        with self.assertRaises(ValueError):\n            task_func(\"non_existent_script.py\")\n\n    def test_script_runs_and_waits(self):\n        with tempfile.NamedTemporaryFile('w', suffix='.py', delete=False) as tmp:\n            tmp.write('import sys\\nprint(\\'args:\\', sys.argv[1:])\\n')\n            tmp_path = tmp.name\n        try:\n            proc = task_func(tmp_path, True, 'hello', 'world')\n            self.assertEqual(proc.returncode, 0)\n        finally:\n            os.unlink(tmp_path)\n\n    def test_script_runs_and_not_wait(self):\n        with tempfile.NamedTemporaryFile('w', suffix='.py', delete=False) as tmp:\n            tmp.write('import time\\ntime.sleep(1)\\n')\n            tmp_path = tmp.name\n        try:\n            proc = task_func(tmp_path, False)\n            self.assertIsNotNone(proc.pid)\n            # Wait for process to finish to avoid zombie\n            proc.wait()\n        finally:\n            os.unlink(tmp_path)\n",
        "code": "import subprocess\nimport os\nimport sys\n\ndef task_func(script_path, wait=True, *args):\n    if not os.path.isfile(script_path):\n        raise ValueError(f\"Script does not exist: {script_path}\")\n    cmd = [sys.executable, script_path] + list(args)\n    proc = subprocess.Popen(cmd)\n    if wait:\n        proc.wait()\n    return proc",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/346_2",
        "turn": "2",
        "instruct_prompt": "Run the Python script as a subprocess using the current Python interpreter (`sys.executable`), passing the script path and additional arguments. Capture both stdout and stderr of the subprocess.",
        "test": "import unittest\nimport sys\nimport os\nimport tempfile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary Python script to run\n        self.temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False)\n        self.temp_file.write('import sys\\nprint(f\"args: {sys.argv[1:]}\")\\nprint(\"error\", file=sys.stderr)')\n        self.temp_file.close()\n\n    def tearDown(self):\n        os.unlink(self.temp_file.name)\n\n    def test_task_func_captures_stdout_stderr(self):\n        proc, stdout, stderr = task_func(self.temp_file.name, True, 'arg1', 'arg2')\n        self.assertEqual(proc.returncode, 0)\n        self.assertIn('args: [\\'arg1\\', \\'arg2\\']', stdout)\n        self.assertIn('error', stderr)\n\n    def test_task_func_no_wait(self):\n        proc, stdout, stderr = task_func(self.temp_file.name, False, 'arg1')\n        self.assertIsNotNone(proc)\n        self.assertIsNone(stdout)\n        self.assertIsNone(stderr)\n\n    def test_task_func_invalid_script(self):\n        with self.assertRaises(ValueError):\n            task_func('non_existent_script.py')\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import subprocess\nimport os\nimport sys\n\ndef task_func(script_path, wait=True, *args):\n    if not os.path.isfile(script_path):\n        raise ValueError(f\"Script does not exist: {script_path}\")\n    cmd = [sys.executable, script_path] + list(args)\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n    if wait:\n        stdout, stderr = proc.communicate()\n        return proc, stdout, stderr\n    return proc, None, None\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/346_3",
        "turn": "3",
        "instruct_prompt": "If the `wait` parameter is True, wait for the subprocess to complete, then return the subprocess return code as an integer.",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary python script that exits with code 42\n        self.temp_script = tempfile.NamedTemporaryFile(delete=False, suffix='.py', mode='w')\n        self.temp_script.write('import sys\\nsys.exit(42)')\n        self.temp_script.close()\n\n    def tearDown(self):\n        os.unlink(self.temp_script.name)\n\n    def test_wait_true_returns_returncode(self):\n        # When wait=True, it should return the subprocess return code as an int\n        retcode = task_func(self.temp_script.name, wait=True)\n        self.assertIsInstance(retcode, int)\n        self.assertEqual(retcode, 42)\n\n    def test_wait_false_returns_proc_tuple(self):\n        # When wait=False, it should return a tuple with proc, None, None\n        result = task_func(self.temp_script.name, wait=False)\n        self.assertIsInstance(result, tuple)\n        self.assertEqual(len(result), 3)\n        proc, stdout, stderr = result\n        self.assertTrue(hasattr(proc, 'pid'))\n        self.assertIsNone(stdout)\n        self.assertIsNone(stderr)\n\n    def test_nonexistent_script_raises(self):\n        with self.assertRaises(ValueError):\n            task_func('nonexistent_script.py')\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import subprocess\nimport os\nimport sys\n\ndef task_func(script_path, wait=True, *args):\n    if not os.path.isfile(script_path):\n        raise ValueError(f\"Script does not exist: {script_path}\")\n    cmd = [sys.executable, script_path] + list(args)\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n    if wait:\n        proc.wait()\n        return proc.returncode\n    return proc, None, None\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/346_4",
        "turn": "4",
        "instruct_prompt": "If the `wait` parameter is False, do not wait for the subprocess to complete and immediately return None.",
        "test": "import unittest\nimport tempfile\nimport os\nimport time\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary python script that sleeps for a short time\n        self.temp_script = tempfile.NamedTemporaryFile(delete=False, suffix='.py')\n        self.script_path = self.temp_script.name\n        self.temp_script.write(b\"import time\\ntime.sleep(1)\\n\")\n        self.temp_script.close()\n\n    def tearDown(self):\n        if os.path.exists(self.script_path):\n            os.remove(self.script_path)\n\n    def test_wait_true_returns_returncode(self):\n        ret = task_func(self.script_path, wait=True)\n        self.assertIsInstance(ret, int)\n        self.assertEqual(ret, 0)\n\n    def test_wait_false_returns_none_and_process_runs(self):\n        ret = task_func(self.script_path, wait=False)\n        self.assertIsNone(ret)\n\n    def test_wait_false_does_not_wait(self):\n        start_time = time.time()\n        ret = task_func(self.script_path, wait=False)\n        duration = time.time() - start_time\n        self.assertLess(duration, 0.5)\n\n    def test_invalid_script_raises_value_error(self):\n        with self.assertRaises(ValueError):\n            task_func(\"/non/existent/script.py\")\n\nif __name__ == \"__main__\":\n    unittest.main()",
        "code": "import subprocess\nimport os\nimport sys\n\ndef task_func(script_path, wait=True, *args):\n    if not os.path.isfile(script_path):\n        raise ValueError(f\"Script does not exist: {script_path}\")\n    cmd = [sys.executable, script_path] + list(args)\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n    if wait:\n        proc.wait()\n        return proc.returncode\n    else:\n        return None",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/346_5",
        "turn": "5",
        "instruct_prompt": "If the subprocess's stderr output contains the word 'Exception', raise a `subprocess.CalledProcessError` with the subprocesss return code and arguments.",
        "test": "import unittest\nimport subprocess\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create temporary scripts for testing\n        self.tmpdir = tempfile.TemporaryDirectory()\n        self.script_ok = os.path.join(self.tmpdir.name, 'script_ok.py')\n        self.script_exception = os.path.join(self.tmpdir.name, 'script_exception.py')\n        with open(self.script_ok, 'w') as f:\n            f.write('print(\"Hello World\")\\n')\n        with open(self.script_exception, 'w') as f:\n            f.write('import sys\\nsys.stderr.write(\"Exception: error occurred\\\")\\n')\n\n    def tearDown(self):\n        self.tmpdir.cleanup()\n\n    def test_no_exception_stderr(self):\n        # Should return returncode normally\n        ret = task_func(self.script_ok)\n        self.assertEqual(ret, 0)\n\n    def test_exception_in_stderr(self):\n        # Should raise CalledProcessError if 'Exception' in stderr\n        with self.assertRaises(subprocess.CalledProcessError) as cm:\n            task_func(self.script_exception)\n        exc = cm.exception\n        self.assertIn('Exception', exc.stderr)\n        self.assertEqual(exc.returncode, 0)\n\n    def test_wait_false(self):\n        # If wait is False, should return None without raising\n        ret = task_func(self.script_exception, wait=False)\n        self.assertIsNone(ret)\n",
        "code": "import subprocess\nimport os\nimport sys\n\ndef task_func(script_path, wait=True, *args):\n    if not os.path.isfile(script_path):\n        raise ValueError(f\"Script does not exist: {script_path}\")\n    cmd = [sys.executable, script_path] + list(args)\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n    if wait:\n        stdout, stderr = proc.communicate()\n        if 'Exception' in stderr:\n            raise subprocess.CalledProcessError(proc.returncode, cmd, output=stdout, stderr=stderr)\n        return proc.returncode\n    else:\n        return None\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 45,
    "task_id": "BigCodeBench/360",
    "mt_data": [
      {
        "task_id": "BigCodeBench/360_1",
        "turn": "1",
        "instruct_prompt": "Load data from an Excel spreadsheet (.xlsx) into a pandas DataFrame. You should write self-contained code starting with:```import pandas as pd\nimport os\ndef task_func(file_location, sheet_name):```",
        "test": "import unittest\nimport pandas as pd\nimport os\nfrom io import BytesIO\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a sample Excel file in memory\n        self.file_path = 'test_excel.xlsx'\n        df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n        with pd.ExcelWriter(self.file_path) as writer:\n            df.to_excel(writer, sheet_name='Sheet1', index=False)\n            df.to_excel(writer, sheet_name='Sheet2', index=False)\n\n    def tearDown(self):\n        if os.path.exists(self.file_path):\n            os.remove(self.file_path)\n\n    def test_load_existing_sheet(self):\n        df = task_func(self.file_path, 'Sheet1')\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertListEqual(list(df.columns), ['A', 'B'])\n        self.assertEqual(df.iloc[0]['A'], 1)\n\n    def test_load_another_sheet(self):\n        df = task_func(self.file_path, 'Sheet2')\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertListEqual(list(df.columns), ['A', 'B'])\n        self.assertEqual(df.iloc[1]['B'], 4)\n\n    def test_file_not_exist(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('nonexistent_file.xlsx', 'Sheet1')\n\n    def test_sheet_not_exist(self):\n        with self.assertRaises(ValueError):\n            task_func(self.file_path, 'NonexistentSheet')\n",
        "code": "import pandas as pd\nimport os\n\ndef task_func(file_location, sheet_name):\n    if not os.path.isfile(file_location):\n        raise FileNotFoundError(f\"The file {file_location} does not exist.\")\n    df = pd.read_excel(file_location, sheet_name=sheet_name)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/360_2",
        "turn": "2",
        "instruct_prompt": "If the Excel file does not exist at the specified path, raise a FileNotFoundError.",
        "test": "import unittest\nimport os\nimport tempfile\nimport pandas as pd\nfrom pandas.testing import assert_frame_equal\n\nclass TestCases(unittest.TestCase):\n    def test_file_not_found_error_message(self):\n        # The error message must match exactly to pass\n        expected_message = \"Error: File not found at path non_existent_file.xlsx\"\n        with self.assertRaises(FileNotFoundError) as context:\n            task_func('non_existent_file.xlsx', 'Sheet1')\n        self.assertEqual(str(context.exception), expected_message)\n\n    def test_existing_file(self):\n        df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n        with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as tmp:\n            temp_path = tmp.name\n        try:\n            df.to_excel(temp_path, sheet_name='Sheet1', index=False)\n            result_df = task_func(temp_path, 'Sheet1')\n            assert_frame_equal(result_df, df)\n        finally:\n            os.remove(temp_path)\n",
        "code": "import pandas as pd\nimport os\n\ndef task_func(file_location, sheet_name):\n    if not os.path.isfile(file_location):\n        raise FileNotFoundError(f\"Error: File not found at path {file_location}\")\n    df = pd.read_excel(file_location, sheet_name=sheet_name)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/360_3",
        "turn": "3",
        "instruct_prompt": "Read the specified sheet from the Excel file. If the sheet does not exist, raise a ValueError.",
        "test": "import unittest\nimport pandas as pd\nimport tempfile\nimport os\nfrom pandas import ExcelWriter\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary Excel file with two sheets\n        self.temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx')\n        with ExcelWriter(self.temp_file.name) as writer:\n            pd.DataFrame({'A': [1, 2], 'B': [3, 4]}).to_excel(writer, sheet_name='Sheet1', index=False)\n            pd.DataFrame({'X': [9, 8], 'Y': [7, 6]}).to_excel(writer, sheet_name='Sheet2', index=False)\n\n    def tearDown(self):\n        os.unlink(self.temp_file.name)\n\n    def test_read_existing_sheet(self):\n        df = task_func(self.temp_file.name, 'Sheet1')\n        self.assertTrue('A' in df.columns)\n        self.assertTrue('B' in df.columns)\n\n    def test_read_nonexistent_sheet_raises_value_error(self):\n        with self.assertRaises(ValueError) as context:\n            task_func(self.temp_file.name, 'NonExistentSheet')\n        self.assertIn(\"does not exist\", str(context.exception))\n\n    def test_file_not_found_raises_file_not_found_error(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('non_existing_file.xlsx', 'Sheet1')\n",
        "code": "import pandas as pd\nimport os\n\ndef task_func(file_location, sheet_name):\n    if not os.path.isfile(file_location):\n        raise FileNotFoundError(f\"Error: File not found at path {file_location}\")\n    xls = pd.ExcelFile(file_location)\n    if sheet_name not in xls.sheet_names:\n        raise ValueError(f\"Sheet '{sheet_name}' does not exist in the Excel file.\")\n    df = pd.read_excel(file_location, sheet_name=sheet_name)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/360_4",
        "turn": "4",
        "instruct_prompt": "Calculate the mean and standard deviation of each column in the DataFrame and return a dictionary with this data.",
        "test": "import unittest\nimport pandas as pd\nimport os\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def test_mean_std_calculation(self):\n        data = {\n            'A': [1, 2, 3, 4, 5],\n            'B': [10, 20, 30, 40, 50],\n            'C': ['x', 'y', 'z', 'w', 'v']  # Non-numeric\n        }\n        df = pd.DataFrame(data)\n\n        with NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:\n            file_path = tmp.name\n            df.to_excel(file_path, sheet_name='Sheet1', index=False)\n\n        result = task_func(file_path, 'Sheet1')\n\n        expected_A_mean = sum(data['A']) / len(data['A'])\n        expected_A_std = pd.Series(data['A']).std()\n        expected_B_mean = sum(data['B']) / len(data['B'])\n        expected_B_std = pd.Series(data['B']).std()\n\n        self.assertIn('A', result)\n        self.assertIn('B', result)\n        self.assertNotIn('C', result)  # Non-numeric column\n\n        self.assertAlmostEqual(result['A']['mean'], expected_A_mean)\n        self.assertAlmostEqual(result['A']['std'], expected_A_std)\n        self.assertAlmostEqual(result['B']['mean'], expected_B_mean)\n        self.assertAlmostEqual(result['B']['std'], expected_B_std)\n\n        os.remove(file_path)\n\n    def test_file_not_found(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('non_existent_file.xlsx', 'Sheet1')\n\n    def test_sheet_not_exist(self):\n        df = pd.DataFrame({'A': [1, 2, 3]})\n        with NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:\n            file_path = tmp.name\n            df.to_excel(file_path, sheet_name='Sheet1', index=False)\n\n        with self.assertRaises(ValueError):\n            task_func(file_path, 'NonExistentSheet')\n\n        os.remove(file_path)\n",
        "code": "import pandas as pd\nimport os\n\ndef task_func(file_location, sheet_name):\n    if not os.path.isfile(file_location):\n        raise FileNotFoundError(f\"Error: File not found at path {file_location}\")\n    xls = pd.ExcelFile(file_location)\n    if sheet_name not in xls.sheet_names:\n        raise ValueError(f\"Sheet '{sheet_name}' does not exist in the Excel file.\")\n    df = pd.read_excel(file_location, sheet_name=sheet_name)\n    # Calculate mean and std dev for each numeric column\n    result = {}\n    for col in df.columns:\n        if pd.api.types.is_numeric_dtype(df[col]):\n            mean_val = df[col].mean()\n            std_val = df[col].std()\n            result[col] = {'mean': mean_val, 'std': std_val}\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/360_5",
        "turn": "5",
        "instruct_prompt": "Draw a bar chart using matplotlib with the mean and standard deviation of each column. The chart should have the title 'Mean and Standard Deviation', the X-axis labeled 'Columns', and the Y-axis labeled 'Values'. Return the matplotlib figure object along with the dictionary.",
        "test": "import unittest\nimport tempfile\nimport pandas as pd\nimport os\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nfrom matplotlib.figure import Figure\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary Excel file with sample data\n        self.temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx')\n        df = pd.DataFrame({\n            'A': [1, 2, 3, 4, 5],\n            'B': [2, 3, 4, 5, 6],\n            'C': ['x', 'y', 'z', 'w', 'v']\n        })\n        df.to_excel(self.temp_file.name, sheet_name='Sheet1', index=False)\n        self.file_location = self.temp_file.name\n        self.sheet_name = 'Sheet1'\n\n    def tearDown(self):\n        os.unlink(self.temp_file.name)\n\n    def test_task_func_returns_figure_and_correct_dict(self):\n        fig, result = task_func(self.file_location, self.sheet_name)\n\n        # Check returned figure is matplotlib figure\n        self.assertIsInstance(fig, Figure)\n\n        # Check result is dict with correct keys and values\n        self.assertIsInstance(result, dict)\n        self.assertIn('A', result)\n        self.assertIn('B', result)\n        self.assertNotIn('C', result)  # Non-numeric column\n\n        # Check mean and std values are floats\n        self.assertIsInstance(result['A']['mean'], float)\n        self.assertIsInstance(result['A']['std'], float)\n\n        # Check figure has correct title and labels\n        ax = fig.axes[0]\n        self.assertEqual(ax.get_title(), 'Mean and Standard Deviation')\n        self.assertEqual(ax.get_xlabel(), 'Columns')\n        self.assertEqual(ax.get_ylabel(), 'Values')\n\n        # Check x tick labels correspond to numeric columns\n        tick_labels = [tick.get_text() for tick in ax.get_xticklabels()]\n        self.assertIn('A', tick_labels)\n        self.assertIn('B', tick_labels)\n        self.assertNotIn('C', tick_labels)\n",
        "code": "import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\ndef task_func(file_location, sheet_name):\n    if not os.path.isfile(file_location):\n        raise FileNotFoundError(f\"Error: File not found at path {file_location}\")\n    xls = pd.ExcelFile(file_location)\n    if sheet_name not in xls.sheet_names:\n        raise ValueError(f\"Sheet '{sheet_name}' does not exist in the Excel file.\")\n    df = pd.read_excel(file_location, sheet_name=sheet_name)\n    # Calculate mean and std dev for each numeric column\n    result = {}\n    numeric_cols = []\n    means = []\n    stds = []\n    for col in df.columns:\n        if pd.api.types.is_numeric_dtype(df[col]):\n            mean_val = df[col].mean()\n            std_val = df[col].std()\n            result[col] = {'mean': mean_val, 'std': std_val}\n            numeric_cols.append(col)\n            means.append(mean_val)\n            stds.append(std_val)\n\n    # Draw bar chart with mean and std dev\n    fig, ax = plt.subplots()\n    x = range(len(numeric_cols))\n    ax.bar(x, means, yerr=stds, capsize=5, alpha=0.7, color='blue')\n    ax.set_xticks(x)\n    ax.set_xticklabels(numeric_cols)\n    ax.set_title('Mean and Standard Deviation')\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Values')\n\n    return fig, result\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 46,
    "task_id": "BigCodeBench/367",
    "mt_data": [
      {
        "task_id": "BigCodeBench/367_1",
        "turn": "1",
        "instruct_prompt": "Return a bar chart showing the count of activities for each day of the week from a given list of activities. You should write self-contained code starting with:\n```python\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\ndef task_func(activities):\n```",
        "test": "import unittest\nfrom unittest.mock import patch\nimport matplotlib.pyplot as plt\nfrom io import BytesIO\n\nclass TestCases(unittest.TestCase):\n    def test_basic_counts(self):\n        activities = [\n            {'date': '2024-04-22'},  # Monday\n            {'date': '2024-04-22'},  # Monday\n            {'date': '2024-04-23'},  # Tuesday\n            {'date': '2024-04-25'},  # Thursday\n            {'date': '2024-04-28'},  # Sunday\n        ]\n\n        with patch('matplotlib.pyplot.show') as mock_show:\n            task_func(activities)\n            mock_show.assert_called_once()\n\n    def test_empty_list(self):\n        activities = []\n        with patch('matplotlib.pyplot.show') as mock_show:\n            task_func(activities)\n            mock_show.assert_called_once()\n\n    def test_invalid_dates(self):\n        activities = [\n            {'date': '2024-04-22'},  # valid Monday\n            {'date': 'invalid-date'},\n            {'date': None},\n            {},\n            {'date': '2024-04-23'}  # valid Tuesday\n        ]\n        with patch('matplotlib.pyplot.show') as mock_show:\n            task_func(activities)\n            mock_show.assert_called_once()\n\n    def test_all_days(self):\n        # Dates covering all days of the week (Monday to Sunday)\n        activities = [\n            {'date': '2024-04-22'},  # Monday\n            {'date': '2024-04-23'},  # Tuesday\n            {'date': '2024-04-24'},  # Wednesday\n            {'date': '2024-04-25'},  # Thursday\n            {'date': '2024-04-26'},  # Friday\n            {'date': '2024-04-27'},  # Saturday\n            {'date': '2024-04-28'},  # Sunday\n        ]\n        with patch('matplotlib.pyplot.show') as mock_show:\n            task_func(activities)\n            mock_show.assert_called_once()\n",
        "code": "from datetime import datetime\nimport matplotlib.pyplot as plt\n\ndef task_func(activities):\n    # Count activities per day of the week\n    day_counts = {day: 0 for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']}\n    for activity in activities:\n        # Assume activity is a dict with a 'date' key as a string in ISO format\n        date_str = activity.get('date')\n        if date_str:\n            try:\n                date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n                day_name = date_obj.strftime('%A')\n                if day_name in day_counts:\n                    day_counts[day_name] += 1\n            except ValueError:\n                # skip invalid date formats\n                pass\n\n    # Prepare data for plotting\n    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    counts = [day_counts[day] for day in days]\n\n    # Plot bar chart\n    plt.figure(figsize=(8, 5))\n    plt.bar(days, counts, color='skyblue')\n    plt.xlabel('Day of the Week')\n    plt.ylabel('Activity Count')\n    plt.title('Count of Activities by Day of the Week')\n    plt.tight_layout()\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/367_2",
        "turn": "2",
        "instruct_prompt": "If any item in the activities list is not a datetime object, raise a TypeError with the message 'All activities must be datetime objects'.",
        "test": "import unittest\nfrom datetime import datetime\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    def test_valid_datetime_activities(self):\n        activities = [\n            datetime(2023, 6, 10),  # Saturday\n            datetime(2023, 6, 11),  # Sunday\n            datetime(2023, 6, 12),  # Monday\n            datetime(2023, 6, 12),  # Monday\n        ]\n        # Should not raise\n        try:\n            task_func(activities)\n        except Exception as e:\n            self.fail(f'task_func raised an exception unexpectedly: {e}')\n\n    def test_invalid_activity_type(self):\n        activities = [\n            datetime(2023, 6, 10),\n            '2023-06-11',  # string, invalid\n            datetime(2023, 6, 12),\n        ]\n        with self.assertRaises(TypeError) as context:\n            task_func(activities)\n        self.assertEqual(str(context.exception), 'All activities must be datetime objects')\n\n    def test_empty_activities(self):\n        activities = []\n        # Should not raise\n        try:\n            task_func(activities)\n        except Exception as e:\n            self.fail(f'task_func raised an exception unexpectedly on empty list: {e}')\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from datetime import datetime\nimport matplotlib.pyplot as plt\n\ndef task_func(activities):\n    # Check that all items in activities are datetime objects\n    for activity in activities:\n        if not isinstance(activity, datetime):\n            raise TypeError('All activities must be datetime objects')\n\n    # Count activities per day of the week\n    day_counts = {day: 0 for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']}\n    for activity in activities:\n        day_name = activity.strftime('%A')\n        if day_name in day_counts:\n            day_counts[day_name] += 1\n\n    # Prepare data for plotting\n    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    counts = [day_counts[day] for day in days]\n\n    # Plot bar chart\n    plt.figure(figsize=(8, 5))\n    plt.bar(days, counts, color='skyblue')\n    plt.xlabel('Day of the Week')\n    plt.ylabel('Activity Count')\n    plt.title('Count of Activities by Day of the Week')\n    plt.tight_layout()\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/367_3",
        "turn": "3",
        "instruct_prompt": "The bar chart should have the x-axis labeled as 'Day of the Week', the y-axis labeled as 'Number of Activities', and the title should be 'Weekly Activity'. Return the matplotlib.axes.Axes object representing this bar chart.",
        "test": "import unittest\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_labels_and_title(self):\n        activities = [\n            datetime(2024, 4, 22),  # Monday\n            datetime(2024, 4, 23),  # Tuesday\n            datetime(2024, 4, 23),  # Tuesday\n            datetime(2024, 4, 24),  # Wednesday\n            datetime(2024, 4, 27),  # Saturday\n            datetime(2024, 4, 28),  # Sunday\n            datetime(2024, 4, 28),  # Sunday\n            datetime(2024, 4, 28),  # Sunday\n        ]\n        ax = task_func(activities)\n\n        # Check x-axis label\n        self.assertEqual(ax.get_xlabel(), 'Day of the Week')\n        # Check y-axis label\n        self.assertEqual(ax.get_ylabel(), 'Number of Activities')\n        # Check title\n        self.assertEqual(ax.get_title(), 'Weekly Activity')\n\n    def test_return_type(self):\n        activities = []\n        ax = task_func(activities)\n        self.assertIsInstance(ax, plt.Axes)\n\n    def test_counts_correctness(self):\n        activities = [\n            datetime(2024, 4, 22),  # Monday\n            datetime(2024, 4, 22),  # Monday\n            datetime(2024, 4, 23),  # Tuesday\n            datetime(2024, 4, 25),  # Thursday\n            datetime(2024, 4, 25),  # Thursday\n            datetime(2024, 4, 25),  # Thursday\n        ]\n        ax = task_func(activities)\n        bars = ax.patches\n        days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n        expected_counts = [2, 1, 0, 3, 0, 0, 0]\n        actual_counts = [bar.get_height() for bar in bars]\n        self.assertEqual(actual_counts, expected_counts)\n\n    def test_type_error_for_invalid_input(self):\n        with self.assertRaises(TypeError):\n            task_func([\"not a datetime\"])\n",
        "code": "from datetime import datetime\nimport matplotlib.pyplot as plt\n\ndef task_func(activities):\n    # Check that all items in activities are datetime objects\n    for activity in activities:\n        if not isinstance(activity, datetime):\n            raise TypeError('All activities must be datetime objects')\n\n    # Count activities per day of the week\n    day_counts = {day: 0 for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']}\n    for activity in activities:\n        day_name = activity.strftime('%A')\n        if day_name in day_counts:\n            day_counts[day_name] += 1\n\n    # Prepare data for plotting\n    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    counts = [day_counts[day] for day in days]\n\n    # Plot bar chart\n    fig, ax = plt.subplots(figsize=(8, 5))\n    ax.bar(days, counts, color='skyblue')\n    ax.set_xlabel('Day of the Week')\n    ax.set_ylabel('Number of Activities')\n    ax.set_title('Weekly Activity')\n    plt.tight_layout()\n\n    return ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 47,
    "task_id": "BigCodeBench/368",
    "mt_data": [
      {
        "task_id": "BigCodeBench/368_1",
        "turn": "1",
        "instruct_prompt": "Move a file from the source directory to the destination directory. You should write self-contained code starting with:\n```\nimport os\nimport shutil\ndef task_func(src_dir: str, dest_dir: str, seed:int = 100) -> str:\n```",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.src_dir = tempfile.mkdtemp()\n        self.dest_dir = tempfile.mkdtemp()\n        self.test_filename = 'testfile.txt'\n        self.test_filepath = os.path.join(self.src_dir, self.test_filename)\n        with open(self.test_filepath, 'w') as f:\n            f.write('test content')\n\n    def tearDown(self):\n        # Clean up any files in dest_dir\n        for d in [self.src_dir, self.dest_dir]:\n            for f in os.listdir(d):\n                os.remove(os.path.join(d, f))\n            os.rmdir(d)\n\n    def test_move_file(self):\n        result = task_func(self.src_dir, self.dest_dir)\n        self.assertEqual(result, self.test_filename)\n        self.assertFalse(os.path.exists(self.test_filepath))\n        self.assertTrue(os.path.exists(os.path.join(self.dest_dir, self.test_filename)))\n\n    def test_no_file_to_move(self):\n        # Remove the file first\n        os.remove(self.test_filepath)\n        with self.assertRaises(FileNotFoundError):\n            task_func(self.src_dir, self.dest_dir)\n",
        "code": "import os\nimport shutil\ndef task_func(src_dir: str, dest_dir: str, seed:int = 100) -> str:\n    \"\"\"\n    Moves a file from src_dir to dest_dir. Returns the name of the moved file.\n    If there are multiple files, moves the first one found.\n    \"\"\"\n    for filename in os.listdir(src_dir):\n        src_path = os.path.join(src_dir, filename)\n        if os.path.isfile(src_path):\n            dest_path = os.path.join(dest_dir, filename)\n            shutil.move(src_path, dest_path)\n            return filename\n    raise FileNotFoundError(\"No file found in source directory to move.\")\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/368_2",
        "turn": "2",
        "instruct_prompt": "Select a file at random from the source directory to move, and ensure the function returns the name of the file moved in the format 'filename.extension'.",
        "test": "import unittest\nimport tempfile\nimport os\nimport shutil\nimport random\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.src_dir = tempfile.mkdtemp()\n        self.dest_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.src_dir)\n        shutil.rmtree(self.dest_dir)\n\n    def create_files(self, filenames):\n        for fname in filenames:\n            with open(os.path.join(self.src_dir, fname), 'w') as f:\n                f.write('test')\n\n    def test_random_file_selection_by_seed(self):\n        files = ['a.txt', 'b.txt', 'c.txt']\n        self.create_files(files)\n        # The order of os.listdir is not guaranteed, so sort to make deterministic\n        sorted_files = sorted(files)\n        random.seed(42)\n        expected = random.choice(sorted_files)\n        # Patch os.listdir to return sorted list for deterministic test\n        orig_listdir = os.listdir\n        try:\n            os.listdir = lambda d: sorted_files if d == self.src_dir else orig_listdir(d)\n            result = task_func(self.src_dir, self.dest_dir, seed=42)\n            self.assertEqual(result, expected)\n            self.assertFalse(os.path.exists(os.path.join(self.src_dir, result)))\n            self.assertTrue(os.path.exists(os.path.join(self.dest_dir, result)))\n        finally:\n            os.listdir = orig_listdir\n\n    def test_no_files_raises(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func(self.src_dir, self.dest_dir)\n",
        "code": "import os\nimport shutil\nimport random\n\ndef task_func(src_dir: str, dest_dir: str, seed: int = 100) -> str:\n    \"\"\"\n    Selects a file at random from src_dir, moves it to dest_dir, and returns the name of the moved file.\n    \"\"\"\n    files = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n    if not files:\n        raise FileNotFoundError(\"No file found in source directory to move.\")\n    random.seed(seed)\n    chosen = random.choice(files)\n    src_path = os.path.join(src_dir, chosen)\n    dest_path = os.path.join(dest_dir, chosen)\n    shutil.move(src_path, dest_path)\n    return chosen\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/368_3",
        "turn": "3",
        "instruct_prompt": "Set the random seed for reproducibility and raise a FileNotFoundError if the source directory contains no files.",
        "test": "import unittest\nimport tempfile\nimport os\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.src_dir = tempfile.mkdtemp()\n        self.dest_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.src_dir)\n        shutil.rmtree(self.dest_dir)\n\n    def create_files(self, filenames):\n        for fname in filenames:\n            with open(os.path.join(self.src_dir, fname), 'w') as f:\n                f.write('test')\n\n    def test_moves_file_with_seed(self):\n        # With seed=42, the file selected should always be the same\n        files = ['a.txt', 'b.txt', 'c.txt']\n        self.create_files(files)\n        moved = task_func(self.src_dir, self.dest_dir, seed=42)\n        # With sorted files and seed=42, the result is deterministic\n        # Let's check which file is moved\n        expected_files_sorted = sorted(files)\n        random = __import__('random')\n        random.seed(42)\n        expected_moved = random.choice(expected_files_sorted)\n        self.assertEqual(moved, expected_moved)\n        # It should now exist in dest_dir, not in src_dir\n        self.assertTrue(os.path.exists(os.path.join(self.dest_dir, moved)))\n        self.assertFalse(os.path.exists(os.path.join(self.src_dir, moved)))\n        # The other files remain in src_dir\n        remaining = set(files) - {moved}\n        for f in remaining:\n            self.assertTrue(os.path.exists(os.path.join(self.src_dir, f)))\n\n    def test_no_files_raises(self):\n        # No files in src_dir\n        with self.assertRaises(FileNotFoundError):\n            task_func(self.src_dir, self.dest_dir, seed=123)\n",
        "code": "import os\nimport shutil\nimport random\n\ndef task_func(src_dir: str, dest_dir: str, seed: int = 100) -> str:\n    \"\"\"\n    Sets the random seed for reproducibility, selects a file at random from src_dir,\n    moves it to dest_dir, and returns the name of the moved file.\n    Raises FileNotFoundError if src_dir contains no files.\n    \"\"\"\n    random.seed(seed)\n    files = sorted([f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))])\n    if not files:\n        raise FileNotFoundError(\"No file found in source directory to move.\")\n    chosen = random.choice(files)\n    src_path = os.path.join(src_dir, chosen)\n    dest_path = os.path.join(dest_dir, chosen)\n    shutil.move(src_path, dest_path)\n    return chosen\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 48,
    "task_id": "BigCodeBench/374",
    "mt_data": [
      {
        "task_id": "BigCodeBench/374_1",
        "turn": "1",
        "instruct_prompt": "Write a function that counts how many Excel (.xlsx) files are in a specified directory and returns this count. You should write self-contained code starting with:\n```\nimport glob\nimport os\nfrom openpyxl import load_workbook\ndef task_func(directory_path='./xlsx_files/'):\n```",
        "test": "import unittest\nimport tempfile\nimport os\nfrom openpyxl import Workbook\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.TemporaryDirectory()\n        self.dir_path = self.test_dir.name\n    \n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def create_xlsx(self, filename):\n        path = os.path.join(self.dir_path, filename)\n        wb = Workbook()\n        wb.save(path)\n        return path\n\n    def test_no_xlsx_files(self):\n        self.assertEqual(task_func(self.dir_path), 0)\n\n    def test_one_xlsx_file(self):\n        self.create_xlsx('file1.xlsx')\n        self.assertEqual(task_func(self.dir_path), 1)\n\n    def test_multiple_xlsx_files(self):\n        self.create_xlsx('file1.xlsx')\n        self.create_xlsx('file2.xlsx')\n        self.create_xlsx('file3.xlsx')\n        self.assertEqual(task_func(self.dir_path), 3)\n\n    def test_ignore_non_xlsx_files(self):\n        self.create_xlsx('file1.xlsx')\n        with open(os.path.join(self.dir_path, 'file2.txt'), 'w') as f:\n            f.write('not an excel file')\n        with open(os.path.join(self.dir_path, 'file3.xls'), 'w') as f:\n            f.write('not an xlsx file')\n        self.assertEqual(task_func(self.dir_path), 1)\n\n    def test_ignore_xlsx_in_subdirs(self):\n        self.create_xlsx('file1.xlsx')\n        subdir = os.path.join(self.dir_path, 'subfolder')\n        os.makedirs(subdir)\n        wb = Workbook()\n        wb.save(os.path.join(subdir, 'file2.xlsx'))\n        self.assertEqual(task_func(self.dir_path), 1)\n",
        "code": "import glob\nimport os\nfrom openpyxl import load_workbook\ndef task_func(directory_path='./xlsx_files/'):\n    pattern = os.path.join(directory_path, '*.xlsx')\n    files = glob.glob(pattern)\n    return len(files)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/374_2",
        "turn": "2",
        "instruct_prompt": "Modify the function to open each Excel file found in the directory and iterate through all sheets and cells without changing any cell values.",
        "test": "import unittest\nimport os\nimport tempfile\nfrom openpyxl import Workbook, load_workbook\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = tempfile.TemporaryDirectory()\n        # Create 2 Excel files with 2 sheets and 2x2 cells in each sheet\n        for i in range(2):\n            wb = Workbook()\n            ws1 = wb.active\n            ws1.title = 'Sheet1'\n            ws2 = wb.create_sheet(title='Sheet2')\n            for ws, sname in [(ws1, 'Sheet1'), (ws2, 'Sheet2')]:\n                ws['A1'] = f'File{i}_{sname}_CellA1'\n                ws['A2'] = f'File{i}_{sname}_CellA2'\n                ws['B1'] = f'File{i}_{sname}_CellB1'\n                ws['B2'] = f'File{i}_{sname}_CellB2'\n            file_path = os.path.join(self.test_dir.name, f'test{i}.xlsx')\n            wb.save(file_path)\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def test_iterate_all_sheets_and_cells_with_callback(self):\n        # Count how many times the callback is called\n        cell_visits = []\n        def cell_callback(file, sheet, coord, value):\n            cell_visits.append((file, sheet, coord, value))\n        result = task_func(self.test_dir.name, cell_callback=cell_callback)\n        self.assertEqual(result, 2)\n        # Expect 2 files * 2 sheets * 4 cells = 16 visits\n        self.assertEqual(len(cell_visits), 16)\n        # Additionally verify that all expected coordinates are visited\n        expected_coords = {'A1', 'A2', 'B1', 'B2'}\n        for i in range(2):\n            file_path = os.path.join(self.test_dir.name, f'test{i}.xlsx')\n            for sheet in ['Sheet1', 'Sheet2']:\n                for coord in expected_coords:\n                    found = any((file==file_path and s==sheet and c==coord) for file,s,c,v in cell_visits)\n                    self.assertTrue(found, f'Missing cell {file_path} {sheet} {coord}')\n        # Also verify that no cell values changed\n        for i in range(2):\n            file_path = os.path.join(self.test_dir.name, f'test{i}.xlsx')\n            wb = load_workbook(file_path)\n            for sheet in ['Sheet1', 'Sheet2']:\n                ws = wb[sheet]\n                self.assertEqual(ws['A1'].value, f'File{i}_{sheet}_CellA1')\n                self.assertEqual(ws['A2'].value, f'File{i}_{sheet}_CellA2')\n                self.assertEqual(ws['B1'].value, f'File{i}_{sheet}_CellB1')\n                self.assertEqual(ws['B2'].value, f'File{i}_{sheet}_CellB2')\n",
        "code": "import glob\nimport os\nfrom openpyxl import load_workbook\n\ndef task_func(directory_path='./xlsx_files/', cell_callback=None):\n    pattern = os.path.join(directory_path, '*.xlsx')\n    files = glob.glob(pattern)\n    visited = []\n    for file in files:\n        wb = load_workbook(file, data_only=True)\n        for ws in wb.worksheets:\n            for row in ws.iter_rows():\n                for cell in row:\n                    if cell_callback:\n                        cell_callback(file, ws.title, cell.coordinate, cell.value)\n                    _ = cell.value  # Access cell value, do not change\n        visited.append(file)\n    return len(visited)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/374_3",
        "turn": "3",
        "instruct_prompt": "Update the function so that for each cell containing a string, it prefixes every double quote (\") with a double backslash (\\\\) to protect the quotes.",
        "test": "import unittest\nimport os\nimport tempfile\nfrom openpyxl import Workbook\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory and xlsx file\n        self.test_dir = tempfile.TemporaryDirectory()\n        self.xlsx_path = os.path.join(self.test_dir.name, 'test.xlsx')\n        wb = Workbook()\n        ws = wb.active\n        ws.title = 'Sheet1'\n        # Write test data\n        ws['A1'] = 'foo'\n        ws['B1'] = 'bar\"baz'\n        ws['C1'] = 'qux\"\"quux'\n        ws['D1'] = 123\n        ws['E1'] = None\n        ws['A2'] = 'simple'\n        ws['B2'] = 'noquotes'\n        ws['C2'] = '\"start'\n        ws['D2'] = 'end\"'\n        ws['E2'] = 'mid\"dle'\n        wb.save(self.xlsx_path)\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def test_quote_prefixing(self):\n        captured = []\n        def cb(file, sheet, coord, value):\n            captured.append((coord, value))\n        count = task_func(directory_path=self.test_dir.name, cell_callback=cb)\n        self.assertEqual(count, 1)\n        result = dict(captured)\n        # Check that double quotes are prefixed with double backslash in all string cells\n        self.assertEqual(result['A1'], 'foo')\n        self.assertEqual(result['B1'], 'bar\\\\\"baz')\n        self.assertEqual(result['C1'], 'qux\\\\\"\\\\\"quux')\n        self.assertEqual(result['D1'], 123)\n        self.assertIsNone(result['E1'])\n        self.assertEqual(result['A2'], 'simple')\n        self.assertEqual(result['B2'], 'noquotes')\n        self.assertEqual(result['C2'], '\\\\\"start')\n        self.assertEqual(result['D2'], 'end\\\\\"')\n        self.assertEqual(result['E2'], 'mid\\\\\"dle')\n",
        "code": "import glob\nimport os\nfrom openpyxl import load_workbook\n\ndef task_func(directory_path='./xlsx_files/', cell_callback=None):\n    pattern = os.path.join(directory_path, '*.xlsx')\n    files = glob.glob(pattern)\n    visited = []\n    for file in files:\n        wb = load_workbook(file, data_only=True)\n        for ws in wb.worksheets:\n            for row in ws.iter_rows():\n                for cell in row:\n                    value = cell.value\n                    if isinstance(value, str):\n                        # Prefix every double quote with double backslash\n                        value = value.replace('\"', '\\\\\"')\n                    if cell_callback:\n                        cell_callback(file, ws.title, cell.coordinate, value)\n        visited.append(file)\n    return len(visited)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/374_4",
        "turn": "4",
        "instruct_prompt": "Ensure the function saves each modified Excel file after processing and returns the total number of Excel files processed.",
        "test": "import unittest\nimport os\nimport shutil\nfrom openpyxl import Workbook, load_workbook\nfrom tempfile import mkdtemp\n\n\ndef create_test_excel(file_path, data):\n    wb = Workbook()\n    ws = wb.active\n    for row in data:\n        ws.append(row)\n    wb.save(file_path)\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = mkdtemp()\n        # Create two Excel files\n        self.file1 = os.path.join(self.test_dir, 'test1.xlsx')\n        self.file2 = os.path.join(self.test_dir, 'test2.xlsx')\n        create_test_excel(self.file1, [[\"He said: \\\"Hello!\\\"\", 123], [\"No quotes\", \"A \\\"B\\\"\"]])\n        create_test_excel(self.file2, [[\"Foo\", \"Bar\"], [\"\\\"Quote\\\"\", 456]])\n\n    def tearDown(self):\n        shutil.rmtree(self.test_dir)\n\n    def test_modified_and_count(self):\n        callback_calls = []\n        def cb(file, sheet, coord, value):\n            callback_calls.append((file, sheet, coord, value))\n        count = task_func(directory_path=self.test_dir, cell_callback=cb)\n        # Check that 2 files were processed\n        self.assertEqual(count, 2)\n        # Check that the Excel files were modified\n        wb1 = load_workbook(self.file1)\n        ws1 = wb1.active\n        self.assertEqual(ws1['A1'].value, 'He said: \\\\\"Hello!\\\\\"')\n        self.assertEqual(ws1['A2'].value, 'No quotes')  # unchanged\n        self.assertEqual(ws1['B2'].value, 'A \\\\\"B\\\\\"')\n        wb2 = load_workbook(self.file2)\n        ws2 = wb2.active\n        self.assertEqual(ws2['A1'].value, 'Foo')\n        self.assertEqual(ws2['A2'].value, '\\\\\"Quote\\\\\"')\n        # Callback should have been called for each cell\n        self.assertTrue(any('\\\\\"' in v for _, _, _, v in callback_calls if isinstance(v, str)))\n\n    def test_no_files(self):\n        # New empty directory\n        empty_dir = mkdtemp()\n        try:\n            count = task_func(directory_path=empty_dir)\n            self.assertEqual(count, 0)\n        finally:\n            shutil.rmtree(empty_dir)\n",
        "code": "import glob\nimport os\nfrom openpyxl import load_workbook\n\ndef task_func(directory_path='./xlsx_files/', cell_callback=None):\n    pattern = os.path.join(directory_path, '*.xlsx')\n    files = glob.glob(pattern)\n    visited = []\n    for file in files:\n        wb = load_workbook(file, data_only=True)\n        modified = False\n        for ws in wb.worksheets:\n            for row in ws.iter_rows():\n                for cell in row:\n                    value = cell.value\n                    if isinstance(value, str):\n                        new_value = value.replace('\"', '\\\\\"')\n                        if new_value != value:\n                            cell.value = new_value\n                            modified = True\n                            value = new_value\n                    if cell_callback:\n                        cell_callback(file, ws.title, cell.coordinate, value)\n        if modified:\n            wb.save(file)\n        visited.append(file)\n    return len(visited)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 49,
    "task_id": "BigCodeBench/399",
    "mt_data": [
      {
        "task_id": "BigCodeBench/399_1",
        "turn": "1",
        "instruct_prompt": "Create a function task_func that plots both sine and cosine waves for a given frequency over the interval [0, 2]. You should write self-contained code starting with:\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\ndef task_func(frequency, sample_size=10000):\n```",
        "test": "import unittest\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_plots_correctly(self):\n        # Patch plt.show to prevent actual plot display during testing\n        with patch('matplotlib.pyplot.show') as mock_show:\n            task_func(1, sample_size=1000)\n            # Check if plt.show() was called\n            mock_show.assert_called_once()\n\n    def test_task_func_data_values(self):\n        # Test the computed sine and cosine values for a known input\n        frequency = 1\n        sample_size = 5\n        x = np.linspace(0, 2 * math.pi, sample_size)\n        expected_sin = np.sin(frequency * x)\n        expected_cos = np.cos(frequency * x)\n\n        # We replicate the function's internal calculation here\n        y_sin = np.sin(frequency * x)\n        y_cos = np.cos(frequency * x)\n\n        np.testing.assert_array_almost_equal(y_sin, expected_sin)\n        np.testing.assert_array_almost_equal(y_cos, expected_cos)\n",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\ndef task_func(frequency, sample_size=10000):\n    x = np.linspace(0, 2 * math.pi, sample_size)\n    y_sin = np.sin(frequency * x)\n    y_cos = np.cos(frequency * x)\n\n    plt.plot(x, y_sin, label='sin')\n    plt.plot(x, y_cos, label='cos')\n    plt.legend()\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title(f'Sine and Cosine waves for frequency {frequency}')\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/399_2",
        "turn": "2",
        "instruct_prompt": "Raise a ValueError if the frequency is negative or if the sample size is less than or equal to zero.",
        "test": "import unittest\nimport matplotlib\nmatplotlib.use('Agg')  # Use a non-interactive backend for testing\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_negative_frequency_raises(self):\n        with self.assertRaises(ValueError):\n            task_func(-1)\n\n    def test_zero_sample_size_raises(self):\n        with self.assertRaises(ValueError):\n            task_func(1, 0)\n\n    def test_negative_sample_size_raises(self):\n        with self.assertRaises(ValueError):\n            task_func(1, -100)\n\n    def test_valid_inputs(self):\n        # This should run without exceptions\n        try:\n            task_func(1, 100)\n        except Exception as e:\n            self.fail(f\"task_func raised an exception unexpectedly: {e}\")\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency must be non-negative\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be greater than zero\")\n\n    x = np.linspace(0, 2 * math.pi, sample_size)\n    y_sin = np.sin(frequency * x)\n    y_cos = np.cos(frequency * x)\n\n    plt.plot(x, y_sin, label='sin')\n    plt.plot(x, y_cos, label='cos')\n    plt.legend()\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title(f'Sine and Cosine waves for frequency {frequency}')\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/399_3",
        "turn": "3",
        "instruct_prompt": "Return the matplotlib.figure.Figure object and matplotlib.axes.Axes object corresponding to the plot.",
        "test": "import unittest\nimport matplotlib.figure\nimport matplotlib.axes\n\nclass TestCases(unittest.TestCase):\n    def test_return_types(self):\n        fig, ax = task_func(1)\n        self.assertIsInstance(fig, matplotlib.figure.Figure)\n        self.assertIsInstance(ax, matplotlib.axes.Axes)\n\n    def test_invalid_frequency(self):\n        with self.assertRaises(ValueError):\n            task_func(-1)\n\n    def test_invalid_sample_size(self):\n        with self.assertRaises(ValueError):\n            task_func(1, 0)\n\n    def test_plot_content(self):\n        fig, ax = task_func(2, 100)\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 2)\n        labels = [line.get_label() for line in lines]\n        self.assertIn('sin', labels)\n        self.assertIn('cos', labels)\n\n    def test_axes_labels_and_title(self):\n        fig, ax = task_func(3)\n        self.assertEqual(ax.get_xlabel(), 'x')\n        self.assertEqual(ax.get_ylabel(), 'y')\n        self.assertEqual(ax.get_title(), 'Sine and Cosine waves for frequency 3')\n",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\ndef task_func(frequency, sample_size=10000):\n    if frequency < 0:\n        raise ValueError(\"Frequency must be non-negative\")\n    if sample_size <= 0:\n        raise ValueError(\"Sample size must be greater than zero\")\n\n    x = np.linspace(0, 2 * math.pi, sample_size)\n    y_sin = np.sin(frequency * x)\n    y_cos = np.cos(frequency * x)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, y_sin, label='sin')\n    ax.plot(x, y_cos, label='cos')\n    ax.legend()\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title(f'Sine and Cosine waves for frequency {frequency}')\n\n    return fig, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 50,
    "task_id": "BigCodeBench/401",
    "mt_data": [
      {
        "task_id": "BigCodeBench/401_1",
        "turn": "1",
        "instruct_prompt": "Initialize a Flask application with the given app_name. You should write self-contained code starting with:\n```\nfrom flask import Flask\nimport os\nfrom flask_mail import Mail\ndef task_func(app_name):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_app_initialization(self):\n        app_name = 'test_app'\n        app = task_func(app_name)\n        from flask import Flask\n        self.assertIsInstance(app, Flask)\n        self.assertEqual(app.name, app_name)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "from flask import Flask\nimport os\nfrom flask_mail import Mail\n\ndef task_func(app_name):\n    app = Flask(app_name)\n    return app\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/401_2",
        "turn": "2",
        "instruct_prompt": "Configure the Flask app's mail settings by retrieving the following environment variables: 'MAIL_SERVER', 'MAIL_PORT', 'MAIL_USE_TLS', 'MAIL_USERNAME', and 'MAIL_PASSWORD'. If any variable is missing, use these defaults: 'MAIL_SERVER' = 'localhost', 'MAIL_PORT' = 25, 'MAIL_USE_TLS' = False (boolean), 'MAIL_USERNAME' = None, 'MAIL_PASSWORD' = None.",
        "test": "import unittest\nimport os\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Backup environment variables\n        self.env_backup = {\n            'MAIL_SERVER': os.environ.get('MAIL_SERVER'),\n            'MAIL_PORT': os.environ.get('MAIL_PORT'),\n            'MAIL_USE_TLS': os.environ.get('MAIL_USE_TLS'),\n            'MAIL_USERNAME': os.environ.get('MAIL_USERNAME'),\n            'MAIL_PASSWORD': os.environ.get('MAIL_PASSWORD')\n        }\n\n    def tearDown(self):\n        # Restore environment variables\n        for key, value in self.env_backup.items():\n            if value is None:\n                if key in os.environ:\n                    del os.environ[key]\n            else:\n                os.environ[key] = value\n\n    def test_defaults_when_env_missing(self):\n        for key in ['MAIL_SERVER', 'MAIL_PORT', 'MAIL_USE_TLS', 'MAIL_USERNAME', 'MAIL_PASSWORD']:\n            if key in os.environ:\n                del os.environ[key]\n        app = task_func('testapp')\n        self.assertEqual(app.config['MAIL_SERVER'], 'localhost')\n        self.assertEqual(app.config['MAIL_PORT'], 25)\n        self.assertFalse(app.config['MAIL_USE_TLS'])\n        self.assertIsNone(app.config['MAIL_USERNAME'])\n        self.assertIsNone(app.config['MAIL_PASSWORD'])\n\n    def test_env_variables_are_used(self):\n        os.environ['MAIL_SERVER'] = 'smtp.example.com'\n        os.environ['MAIL_PORT'] = '587'\n        os.environ['MAIL_USE_TLS'] = 'True'\n        os.environ['MAIL_USERNAME'] = 'user@example.com'\n        os.environ['MAIL_PASSWORD'] = 'securepassword'\n\n        app = task_func('testapp')\n        self.assertEqual(app.config['MAIL_SERVER'], 'smtp.example.com')\n        self.assertEqual(app.config['MAIL_PORT'], 587)\n        self.assertTrue(app.config['MAIL_USE_TLS'])\n        self.assertEqual(app.config['MAIL_USERNAME'], 'user@example.com')\n        self.assertEqual(app.config['MAIL_PASSWORD'], 'securepassword')\n\n    def test_mail_use_tls_false_variants(self):\n        false_values = ['False', 'false', '0', 'no', '']\n        for val in false_values:\n            os.environ['MAIL_USE_TLS'] = val\n            app = task_func('testapp')\n            self.assertFalse(app.config['MAIL_USE_TLS'], msg=f'Failed for MAIL_USE_TLS=\"{val}\"')\n\n    def test_mail_use_tls_true_variants(self):\n        true_values = ['True', 'true', '1', 't', 'T']\n        for val in true_values:\n            os.environ['MAIL_USE_TLS'] = val\n            app = task_func('testapp')\n            self.assertTrue(app.config['MAIL_USE_TLS'], msg=f'Failed for MAIL_USE_TLS=\"{val}\"')\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from flask import Flask\nimport os\nfrom flask_mail import Mail\n\ndef task_func(app_name):\n    app = Flask(app_name)\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'localhost')\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', 25))\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'False').lower() in ['true', '1', 't']\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', None)\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', None)\n    return app\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/401_3",
        "turn": "3",
        "instruct_prompt": "Create a Flask-Mail instance using the configured Flask app.",
        "test": "import unittest\nfrom flask_mail import Mail\nfrom flask import Flask\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_mail_instance_creation(self):\n        app_name = 'test_app'\n        app, mail = task_func(app_name)\n        self.assertIsInstance(app, Flask)\n        self.assertIsInstance(mail, Mail)\n        self.assertIs(mail.app, app)\n\n    def test_mail_config_values(self):\n        os.environ['MAIL_SERVER'] = 'smtp.example.com'\n        os.environ['MAIL_PORT'] = '587'\n        os.environ['MAIL_USE_TLS'] = 'True'\n        os.environ['MAIL_USERNAME'] = 'user@example.com'\n        os.environ['MAIL_PASSWORD'] = 'password123'\n\n        app, mail = task_func('test_app_env')\n\n        self.assertEqual(app.config['MAIL_SERVER'], 'smtp.example.com')\n        self.assertEqual(app.config['MAIL_PORT'], 587)\n        self.assertTrue(app.config['MAIL_USE_TLS'])\n        self.assertEqual(app.config['MAIL_USERNAME'], 'user@example.com')\n        self.assertEqual(app.config['MAIL_PASSWORD'], 'password123')\n\n        del os.environ['MAIL_SERVER']\n        del os.environ['MAIL_PORT']\n        del os.environ['MAIL_USE_TLS']\n        del os.environ['MAIL_USERNAME']\n        del os.environ['MAIL_PASSWORD']\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from flask import Flask\nimport os\nfrom flask_mail import Mail\n\ndef task_func(app_name):\n    app = Flask(app_name)\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'localhost')\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', 25))\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'False').lower() in ['true', '1', 't']\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', None)\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', None)\n    mail = Mail(app)\n    return app, mail\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/401_4",
        "turn": "4",
        "instruct_prompt": "Return a tuple containing the Flask-Mail instance and a dictionary of the mail configuration values used by the Flask app.",
        "test": "import unittest\nimport os\nfrom flask_mail import Mail\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Clear environment variables to test defaults\n        os.environ.pop('MAIL_SERVER', None)\n        os.environ.pop('MAIL_PORT', None)\n        os.environ.pop('MAIL_USE_TLS', None)\n        os.environ.pop('MAIL_USERNAME', None)\n        os.environ.pop('MAIL_PASSWORD', None)\n\n    def test_return_type_and_values_default(self):\n        mail, mail_config = task_func('test_app')\n        self.assertIsInstance(mail, Mail)\n        self.assertIsInstance(mail_config, dict)\n        self.assertEqual(mail_config['MAIL_SERVER'], 'localhost')\n        self.assertEqual(mail_config['MAIL_PORT'], 25)\n        self.assertFalse(mail_config['MAIL_USE_TLS'])\n        self.assertIsNone(mail_config['MAIL_USERNAME'])\n        self.assertIsNone(mail_config['MAIL_PASSWORD'])\n\n    def test_return_type_and_values_with_env(self):\n        os.environ['MAIL_SERVER'] = 'smtp.example.com'\n        os.environ['MAIL_PORT'] = '587'\n        os.environ['MAIL_USE_TLS'] = 'True'\n        os.environ['MAIL_USERNAME'] = 'user'\n        os.environ['MAIL_PASSWORD'] = 'pass'\n\n        mail, mail_config = task_func('test_app')\n\n        self.assertIsInstance(mail, Mail)\n        self.assertIsInstance(mail_config, dict)\n        self.assertEqual(mail_config['MAIL_SERVER'], 'smtp.example.com')\n        self.assertEqual(mail_config['MAIL_PORT'], 587)\n        self.assertTrue(mail_config['MAIL_USE_TLS'])\n        self.assertEqual(mail_config['MAIL_USERNAME'], 'user')\n        self.assertEqual(mail_config['MAIL_PASSWORD'], 'pass')\n\n    def test_previous_code_should_fail(self):\n        # Previous code returns (app, mail), not (mail, mail_config)\n        # We simulate previous code behavior here\n        from flask import Flask\n        from flask_mail import Mail\n        def old_task_func(app_name):\n            app = Flask(app_name)\n            app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'localhost')\n            app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', 25))\n            app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'False').lower() in ['true', '1', 't']\n            app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', None)\n            app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', None)\n            mail = Mail(app)\n            return app, mail\n\n        result = old_task_func('test_app')\n        # The old function returns a tuple with Flask app as first element, not Mail instance\n        self.assertNotIsInstance(result[0], Mail)\n        self.assertIsInstance(result[1], Mail)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from flask import Flask\nimport os\nfrom flask_mail import Mail\n\ndef task_func(app_name):\n    app = Flask(app_name)\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'localhost')\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', 25))\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'False').lower() in ['true', '1', 't']\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', None)\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', None)\n    mail = Mail(app)\n    mail_config = {\n        'MAIL_SERVER': app.config['MAIL_SERVER'],\n        'MAIL_PORT': app.config['MAIL_PORT'],\n        'MAIL_USE_TLS': app.config['MAIL_USE_TLS'],\n        'MAIL_USERNAME': app.config['MAIL_USERNAME'],\n        'MAIL_PASSWORD': app.config['MAIL_PASSWORD']\n    }\n    return mail, mail_config\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 51,
    "task_id": "BigCodeBench/409",
    "mt_data": [
      {
        "task_id": "BigCodeBench/409_1",
        "turn": "1",
        "instruct_prompt": "Write a function named task_func that takes three parameters: excel_file_path, file_name, and column_name. The function should read the Excel file specified by joining excel_file_path and file_name, and calculate the mean, median, and standard deviation of the values in the specified column_name. You should write self-contained code starting with:\n```python\nimport os\nimport pandas as pd\nimport numpy as np\ndef task_func(excel_file_path, file_name, column_name):\n```",
        "test": "import unittest\nimport os\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary Excel file for testing\n        self.test_dir = os.path.dirname(os.path.abspath(__file__))\n        self.file_name = 'test_data.xlsx'\n        self.file_path = os.path.join(self.test_dir, self.file_name)\n        data = {\n            'A': [1, 2, 3, 4, 5],\n            'B': [10, 20, 30, 40, 50]\n        }\n        df = pd.DataFrame(data)\n        df.to_excel(self.file_path, index=False)\n\n    def tearDown(self):\n        # Remove the temporary Excel file\n        if os.path.exists(self.file_path):\n            os.remove(self.file_path)\n\n    def test_task_func_column_A(self):\n        mean_val, median_val, std_val = task_func(self.test_dir, self.file_name, 'A')\n        self.assertAlmostEqual(mean_val, 3.0)\n        self.assertAlmostEqual(median_val, 3.0)\n        self.assertAlmostEqual(std_val, np.std([1,2,3,4,5], ddof=1))\n\n    def test_task_func_column_B(self):\n        mean_val, median_val, std_val = task_func(self.test_dir, self.file_name, 'B')\n        self.assertAlmostEqual(mean_val, 30.0)\n        self.assertAlmostEqual(median_val, 30.0)\n        self.assertAlmostEqual(std_val, np.std([10,20,30,40,50], ddof=1))\n",
        "code": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(excel_file_path, file_name, column_name):\n    file_path = os.path.join(excel_file_path, file_name)\n    df = pd.read_excel(file_path)\n    data = df[column_name]\n    mean_val = data.mean()\n    median_val = data.median()\n    std_val = data.std()\n    return mean_val, median_val, std_val\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/409_2",
        "turn": "2",
        "instruct_prompt": "The function should raise a FileNotFoundError if the Excel file does not exist at the specified path.",
        "test": "import unittest\nimport tempfile\nimport os\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_file_not_found(self):\n        # Use a non-existing file path\n        non_exist_dir = '/non/existing/path'\n        non_exist_file = 'nofile.xlsx'\n        expected_message_part = 'does not exist'\n        with self.assertRaises(FileNotFoundError) as cm:\n            task_func(non_exist_dir, non_exist_file, 'A')\n        self.assertIn(expected_message_part, str(cm.exception))\n\n    def test_existing_file(self):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            file_path = os.path.join(tmpdirname, 'test.xlsx')\n            df = pd.DataFrame({'A': [1, 2, 3, 4, 5]})\n            df.to_excel(file_path, index=False)\n            mean_val, median_val, std_val = task_func(tmpdirname, 'test.xlsx', 'A')\n            self.assertAlmostEqual(mean_val, 3.0)\n            self.assertAlmostEqual(median_val, 3.0)\n            self.assertAlmostEqual(std_val, df['A'].std())\n",
        "code": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(excel_file_path, file_name, column_name):\n    file_path = os.path.join(excel_file_path, file_name)\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n    df = pd.read_excel(file_path)\n    data = df[column_name]\n    mean_val = data.mean()\n    median_val = data.median()\n    std_val = data.std()\n    return mean_val, median_val, std_val\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/409_3",
        "turn": "3",
        "instruct_prompt": "The function should raise a ValueError if the specified column_name is not found in the Excel file.",
        "test": "import unittest\nimport tempfile\nimport os\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory to store test Excel files\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        # Cleanup temporary directory\n        self.test_dir.cleanup()\n\n    def create_excel_file(self, data_dict, file_name):\n        df = pd.DataFrame(data_dict)\n        file_path = os.path.join(self.test_dir.name, file_name)\n        df.to_excel(file_path, index=False)\n        return file_path\n\n    def test_column_not_found_raises_value_error(self):\n        # Create an Excel file with columns 'A' and 'B'\n        file_name = 'test.xlsx'\n        self.create_excel_file({'A': [1, 2, 3], 'B': [4, 5, 6]}, file_name)\n        # Call task_func with a column that does not exist\n        with self.assertRaises(ValueError) as context:\n            task_func(self.test_dir.name, file_name, 'C')\n        self.assertIn(\"Column 'C' not found\", str(context.exception))\n",
        "code": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(excel_file_path, file_name, column_name):\n    file_path = os.path.join(excel_file_path, file_name)\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n    df = pd.read_excel(file_path)\n    if column_name not in df.columns:\n        raise ValueError(f\"Column '{column_name}' not found in the Excel file.\")\n    data = df[column_name]\n    mean_val = data.mean()\n    median_val = data.median()\n    std_val = data.std()\n    return mean_val, median_val, std_val\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/409_4",
        "turn": "4",
        "instruct_prompt": "The function should return a dictionary with keys 'mean', 'median', and 'std_dev' corresponding to the calculated mean, median, and standard deviation of the data in the specified column.",
        "test": "import unittest\nimport tempfile\nimport os\nimport pandas as pd\nfrom math import isclose\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.TemporaryDirectory()\n        self.file_path = self.test_dir.name\n        self.file_name = 'test.xlsx'\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def create_excel_file(self, data_dict):\n        df = pd.DataFrame(data_dict)\n        full_path = os.path.join(self.file_path, self.file_name)\n        df.to_excel(full_path, index=False)\n\n    def test_correct_statistics_returned(self):\n        data = {'A': [1, 2, 3, 4, 5], 'B': [2, 3, 4, 5, 6]}\n        self.create_excel_file(data)\n        result = task_func(self.file_path, self.file_name, 'A')\n        expected_mean = 3.0\n        expected_median = 3.0\n        expected_std = pd.Series(data['A']).std()\n        self.assertIsInstance(result, dict)\n        self.assertIn('mean', result)\n        self.assertIn('median', result)\n        self.assertIn('std_dev', result)\n        self.assertTrue(isclose(result['mean'], expected_mean))\n        self.assertTrue(isclose(result['median'], expected_median))\n        self.assertTrue(isclose(result['std_dev'], expected_std))\n\n    def test_file_not_found_raises(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func(self.file_path, 'nonexistent.xlsx', 'A')\n\n    def test_column_not_found_raises(self):\n        data = {'A': [1, 2, 3]}\n        self.create_excel_file(data)\n        with self.assertRaises(ValueError):\n            task_func(self.file_path, self.file_name, 'B')\n",
        "code": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(excel_file_path, file_name, column_name):\n    file_path = os.path.join(excel_file_path, file_name)\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n    df = pd.read_excel(file_path)\n    if column_name not in df.columns:\n        raise ValueError(f\"Column '{column_name}' not found in the Excel file.\")\n    data = df[column_name]\n    mean_val = data.mean()\n    median_val = data.median()\n    std_val = data.std()\n    return {'mean': mean_val, 'median': median_val, 'std_dev': std_val}\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 52,
    "task_id": "BigCodeBench/417",
    "mt_data": [
      {
        "task_id": "BigCodeBench/417_1",
        "turn": "1",
        "instruct_prompt": "Train a simple neural network on given input data and target labels, and return the trained model. You should write self-contained code starting with:\n```\nfrom keras.models import Sequential\nfrom keras.layers import Dense\ndef task_func(X, Y):\n```",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_model_training(self):\n        # Simple binary classification dataset\n        X = np.array([[0,0], [0,1], [1,0], [1,1]])\n        Y = np.array([0, 1, 1, 0])  # XOR problem\n        model = task_func(X, Y)\n        # Check model is a keras Sequential model\n        from keras.models import Sequential\n        self.assertIsInstance(model, Sequential)\n        # Check model can make predictions\n        preds = model.predict(X)\n        self.assertEqual(preds.shape, (4,1))\n        # Check that the model has been trained (weights are not None)\n        weights = model.get_weights()\n        self.assertTrue(all([w is not None for w in weights]))\n",
        "code": "from keras.models import Sequential\nfrom keras.layers import Dense\ndef task_func(X, Y):\n    model = Sequential()\n    model.add(Dense(8, input_dim=X.shape[1], activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.fit(X, Y, epochs=10, batch_size=4, verbose=0)\n    return model\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/417_2",
        "turn": "2",
        "instruct_prompt": "Split the data into a training set (75%) and a test set (25%) before training the model.",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_split_and_train(self):\n        # Generate dummy data\n        X = np.random.rand(40, 3)\n        Y = np.random.randint(0, 2, size=(40,))\n        model, (X_train, X_test, Y_train, Y_test) = task_func(X, Y)\n        # Check split sizes\n        self.assertEqual(X_train.shape[0], 30)\n        self.assertEqual(X_test.shape[0], 10)\n        self.assertEqual(Y_train.shape[0], 30)\n        self.assertEqual(Y_test.shape[0], 10)\n        # Check model is trained and can predict\n        preds = model.predict(X_test)\n        self.assertEqual(preds.shape[0], 10)\n",
        "code": "from keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.model_selection import train_test_split\ndef task_func(X, Y):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n    model = Sequential()\n    model.add(Dense(8, input_dim=X.shape[1], activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.fit(X_train, Y_train, epochs=10, batch_size=4, verbose=0)\n    return model, (X_train, X_test, Y_train, Y_test)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/417_3",
        "turn": "3",
        "instruct_prompt": "Ensure the input dimension of X is always 2, and construct a Sequential model with only one dense hidden layer and a sigmoid activation function. Compile the model using binary cross-entropy loss and SGD optimizer with a specified learning rate.",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_input_dimension(self):\n        X = np.random.rand(10, 3)\n        Y = np.random.randint(0, 2, size=(10,))\n        with self.assertRaises(ValueError):\n            task_func(X, Y)\n        X = np.random.rand(10,)\n        with self.assertRaises(ValueError):\n            task_func(X, Y)\n        X = np.random.rand(10, 2)\n        Y = np.random.randint(0, 2, size=(10,))\n        # Should not raise\n        try:\n            model, data = task_func(X, Y)\n        except ValueError:\n            self.fail(\"task_func() raised ValueError unexpectedly!\")\n    def test_model_structure(self):\n        X = np.random.rand(20, 2)\n        Y = np.random.randint(0, 2, size=(20,))\n        model, _ = task_func(X, Y, learning_rate=0.05)\n        # Check number of layers: 2 (1 hidden, 1 output)\n        self.assertEqual(len(model.layers), 2)\n        # Check first layer is Dense with sigmoid\n        self.assertIsInstance(model.layers[0], Dense)\n        self.assertEqual(model.layers[0].activation.__name__, 'sigmoid')\n        # Check output layer is Dense with sigmoid\n        self.assertIsInstance(model.layers[1], Dense)\n        self.assertEqual(model.layers[1].activation.__name__, 'sigmoid')\n    def test_model_compile(self):\n        X = np.random.rand(20, 2)\n        Y = np.random.randint(0, 2, size=(20,))\n        lr = 0.123\n        model, _ = task_func(X, Y, learning_rate=lr)\n        # Check loss\n        self.assertEqual(model.loss, 'binary_crossentropy')\n        # Check optimizer is SGD and learning rate is as specified\n        self.assertEqual(model.optimizer.__class__.__name__, 'SGD')\n        self.assertAlmostEqual(float(model.optimizer.learning_rate), lr, places=6)\n",
        "code": "from keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import SGD\ndef task_func(X, Y, learning_rate=0.01):\n    if len(X.shape) != 2 or X.shape[1] != 2:\n        raise ValueError('Input X must have shape (n_samples, 2)')\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n    model = Sequential()\n    model.add(Dense(8, input_dim=2, activation='sigmoid'))\n    model.add(Dense(1, activation='sigmoid'))\n    optimizer = SGD(learning_rate=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    model.fit(X_train, Y_train, epochs=10, batch_size=4, verbose=0)\n    return model, (X_train, X_test, Y_train, Y_test)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/417_4",
        "turn": "4",
        "instruct_prompt": "Fit the model to the training data without verbose output, using the test set as validation data. Plot the model's training and validation loss over epochs, and return the trained model and the matplotlib Axes object of the plot. The plot must have the title 'Model loss', x-axis label 'Epoch', y-axis label 'Loss', and a legend distinguishing 'Train' and 'Test' losses.",
        "test": "import unittest\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')\n\nclass TestCases(unittest.TestCase):\n    def test_training_and_plot(self):\n        np.random.seed(0)\n        X = np.random.rand(40, 2)\n        Y = (X[:, 0] + X[:, 1] > 1).astype(int)\n        model, ax = task_func(X, Y)\n        # Check model is trained\n        self.assertTrue(hasattr(model, 'predict'))\n        # Check ax is a matplotlib Axes object\n        import matplotlib.axes\n        self.assertIsInstance(ax, matplotlib.axes.Axes)\n        # Check plot labels and title\n        self.assertEqual(ax.get_title(), 'Model loss')\n        self.assertEqual(ax.get_xlabel(), 'Epoch')\n        self.assertEqual(ax.get_ylabel(), 'Loss')\n        # Check legend labels\n        legend = ax.get_legend()\n        self.assertIsNotNone(legend)\n        labels = [t.get_text() for t in legend.get_texts()]\n        self.assertIn('Train', labels)\n        self.assertIn('Test', labels)\n        # Check that both train and validation loss curves are plotted\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 2)\n        # Check that the model was trained for 10 epochs\n        self.assertEqual(len(lines[0].get_xdata()), 10)\n        self.assertEqual(len(lines[1].get_xdata()), 10)\n",
        "code": "from keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import SGD\nimport matplotlib.pyplot as plt\n\ndef task_func(X, Y, learning_rate=0.01):\n    if len(X.shape) != 2 or X.shape[1] != 2:\n        raise ValueError('Input X must have shape (n_samples, 2)')\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n    model = Sequential()\n    model.add(Dense(8, input_dim=2, activation='sigmoid'))\n    model.add(Dense(1, activation='sigmoid'))\n    optimizer = SGD(learning_rate=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    history = model.fit(\n        X_train, Y_train,\n        epochs=10,\n        batch_size=4,\n        verbose=0,\n        validation_data=(X_test, Y_test)\n    )\n    fig, ax = plt.subplots()\n    ax.plot(history.history['loss'], label='Train')\n    ax.plot(history.history['val_loss'], label='Test')\n    ax.set_title('Model loss')\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Loss')\n    ax.legend()\n    return model, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 53,
    "task_id": "BigCodeBench/418",
    "mt_data": [
      {
        "task_id": "BigCodeBench/418_1",
        "turn": "1",
        "instruct_prompt": "Split the input data X and Y into training and test sets with 70% of data for training and 30% for testing. You should write self-contained code starting with:```python\nfrom sklearn.model_selection import train_test_split\n\ndef task_func(X, Y):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n    return X_train, X_test, Y_train, Y_test\n```",
        "test": "import unittest\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nclass TestCases(unittest.TestCase):\n    def test_split_ratio(self):\n        X = np.arange(10).reshape((10, 1))\n        Y = np.arange(10)\n        X_train, X_test, Y_train, Y_test = task_func(X, Y)\n        # Check the split sizes\n        self.assertEqual(len(X_train), 7)\n        self.assertEqual(len(X_test), 3)\n        self.assertEqual(len(Y_train), 7)\n        self.assertEqual(len(Y_test), 3)\n\n    def test_split_content(self):\n        X = np.array([[i] for i in range(10)])\n        Y = np.array([i for i in range(10)])\n        X_train, X_test, Y_train, Y_test = task_func(X, Y)\n        # Check that all elements are present after splitting\n        all_X = np.concatenate((X_train, X_test), axis=0)\n        all_Y = np.concatenate((Y_train, Y_test), axis=0)\n        self.assertCountEqual(all_X.flatten(), X.flatten())\n        self.assertCountEqual(all_Y, Y)\n\n    def test_random_state_default(self):\n        # Without random_state, subsequent calls may produce different splits\n        X = np.arange(10).reshape((10,1))\n        Y = np.arange(10)\n        result1 = task_func(X, Y)\n        result2 = task_func(X, Y)\n        # It is possible they differ, so test that results are not always equal\n        # This test will pass if at least one dimension differs\n        self.assertTrue(\n            not all(np.array_equal(a,b) for a,b in zip(result1, result2)) or\n            all(np.array_equal(a,b) for a,b in zip(result1, result2))\n        )\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from sklearn.model_selection import train_test_split\n\ndef task_func(X, Y):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n    return X_train, X_test, Y_train, Y_test\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/418_2",
        "turn": "2",
        "instruct_prompt": "Create a Keras Sequential model with one hidden layer having a sigmoid activation function. Compile the model with binary cross-entropy loss and an SGD optimizer with a specified learning rate.",
        "test": "import unittest\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import SGD\n\nclass TestCases(unittest.TestCase):\n    def test_create_model_structure_and_compile(self):\n        input_dim = 10\n        hidden_units = 5\n        learning_rate = 0.01\n        model = create_model(input_dim, hidden_units, learning_rate)\n\n        # Check model is Sequential\n        self.assertEqual(model.__class__.__name__, 'Sequential')\n\n        # Check layers count\n        self.assertEqual(len(model.layers), 2)\n\n        # Check first layer is Dense with sigmoid activation\n        first_layer = model.layers[0]\n        self.assertIsInstance(first_layer, Dense)\n        self.assertEqual(first_layer.activation.__name__, 'sigmoid')\n        self.assertEqual(first_layer.input_shape[1], input_dim)\n        self.assertEqual(first_layer.units, hidden_units)\n\n        # Check output layer activation is sigmoid\n        output_layer = model.layers[1]\n        self.assertIsInstance(output_layer, Dense)\n        self.assertEqual(output_layer.activation.__name__, 'sigmoid')\n        self.assertEqual(output_layer.units, 1)\n\n        # Check loss function\n        self.assertEqual(model.loss, 'binary_crossentropy')\n\n        # Check optimizer type and learning rate\n        self.assertIsInstance(model.optimizer, SGD)\n        self.assertAlmostEqual(K.get_value(model.optimizer.learning_rate), learning_rate)\n",
        "code": "from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import SGD\n\ndef create_model(input_dim, hidden_units, learning_rate):\n    model = Sequential()\n    model.add(Dense(hidden_units, input_dim=input_dim, activation='sigmoid'))\n    model.add(Dense(1, activation='sigmoid'))\n    optimizer = SGD(learning_rate=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n    return model\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/418_3",
        "turn": "3",
        "instruct_prompt": "Train the compiled Keras model on the training data with verbose mode off.",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_train_model_verbose_off(self):\n        x_train = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n        y_train = np.array([0, 1, 1, 0])\n\n        # Call the task_func which creates, compiles, and trains the model with verbose=0\n        model = task_func(input_dim=2, hidden_units=2, learning_rate=0.1, x_train=x_train, y_train=y_train, epochs=2, batch_size=1)\n\n        # Create a fresh model to compare weights\n        from tensorflow.keras.models import Sequential\n        from tensorflow.keras.layers import Dense\n        from tensorflow.keras.optimizers import SGD\n\n        initial_model = Sequential()\n        initial_model.add(Dense(2, input_dim=2, activation='sigmoid'))\n        initial_model.add(Dense(1, activation='sigmoid'))\n        optimizer = SGD(learning_rate=0.1)\n        initial_model.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n        initial_weights = initial_model.get_weights()\n        trained_weights = model.get_weights()\n\n        weights_changed = any(not np.array_equal(iw, tw) for iw, tw in zip(initial_weights, trained_weights))\n        self.assertTrue(weights_changed, \"Weights should be updated after training\")\n\n    def test_train_model_invalid_input(self):\n        # Test that calling task_func with None arguments raises an exception\n        with self.assertRaises(Exception):\n            task_func(None, None, None, None, None)\n",
        "code": "from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import SGD\n\ndef task_func(input_dim, hidden_units, learning_rate, x_train, y_train, epochs=10, batch_size=32):\n    model = Sequential()\n    model.add(Dense(hidden_units, input_dim=input_dim, activation='sigmoid'))\n    model.add(Dense(1, activation='sigmoid'))\n    optimizer = SGD(learning_rate=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n    return model\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/418_4",
        "turn": "4",
        "instruct_prompt": "Plot the ROC curve of the trained model on the test set, labeling the axes as follows: title 'ROC curve', x-axis 'False positive rate', y-axis 'True positive rate'. Include the AUC score in the legend of the plot. Return the trained model and the matplotlib Axes object of the plot.",
        "test": "import unittest\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_returns_model_and_axes(self):\n        # Generate a simple binary classification dataset\n        np.random.seed(0)\n        x_train = np.random.randn(100, 5)\n        y_train = (np.sum(x_train, axis=1) > 0).astype(int)\n        x_test = np.random.randn(50, 5)\n        y_test = (np.sum(x_test, axis=1) > 0).astype(int)\n\n        from matplotlib.axes import Axes\n        model, ax = task_func(\n            input_dim=5,\n            hidden_units=4,\n            learning_rate=0.1,\n            x_train=x_train,\n            y_train=y_train,\n            x_test=x_test,\n            y_test=y_test,\n            epochs=5,\n            batch_size=10\n        )\n\n        # Check returned types\n        self.assertTrue(hasattr(model, 'predict'))\n        self.assertIsInstance(ax, Axes)\n\n        # Check axes labels and title\n        self.assertEqual(ax.get_title(), 'ROC curve')\n        self.assertEqual(ax.get_xlabel(), 'False positive rate')\n        self.assertEqual(ax.get_ylabel(), 'True positive rate')\n\n        # Check legend contains AUC\n        legend_texts = [text.get_text() for text in ax.get_legend().get_texts()]\n        self.assertTrue(any('AUC' in text for text in legend_texts))\n\n    def test_previous_round_code_fails(self):\n        # This test ensures previous round's code will fail because it doesn't plot ROC curve or return axes\n        from tensorflow.keras.models import Sequential\n        from tensorflow.keras.layers import Dense\n        from tensorflow.keras.optimizers import SGD\n\n        def old_task_func(input_dim, hidden_units, learning_rate, x_train, y_train, epochs=10, batch_size=32):\n            model = Sequential()\n            model.add(Dense(hidden_units, input_dim=input_dim, activation='sigmoid'))\n            model.add(Dense(1, activation='sigmoid'))\n            optimizer = SGD(learning_rate=learning_rate)\n            model.compile(loss='binary_crossentropy', optimizer=optimizer)\n            model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n            return model\n\n        np.random.seed(0)\n        x_train = np.random.randn(100, 5)\n        y_train = (np.sum(x_train, axis=1) > 0).astype(int)\n        x_test = np.random.randn(50, 5)\n        y_test = (np.sum(x_test, axis=1) > 0).astype(int)\n\n        model = old_task_func(5, 4, 0.1, x_train, y_train, epochs=5, batch_size=10)\n\n        # old_task_func does not return axes, so it should raise an error if we try to unpack two values\n        with self.assertRaises(TypeError):\n            _model, _ax = old_task_func(5, 4, 0.1, x_train, y_train, epochs=5, batch_size=10)\n",
        "code": "import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import SGD\n\n\ndef task_func(input_dim, hidden_units, learning_rate, x_train, y_train, x_test, y_test, epochs=10, batch_size=32):\n    model = Sequential()\n    model.add(Dense(hidden_units, input_dim=input_dim, activation='sigmoid'))\n    model.add(Dense(1, activation='sigmoid'))\n    optimizer = SGD(learning_rate=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n\n    # Predict probabilities on test set\n    y_probs = model.predict(x_test).ravel()\n\n    # Compute ROC curve and AUC\n    fpr, tpr, _ = roc_curve(y_test, y_probs)\n    roc_auc = auc(fpr, tpr)\n\n    # Plot ROC curve\n    fig, ax = plt.subplots()\n    ax.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {roc_auc:.2f}')\n    ax.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n    ax.set_title('ROC curve')\n    ax.set_xlabel('False positive rate')\n    ax.set_ylabel('True positive rate')\n    ax.legend(loc='lower right')\n\n    return model, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 54,
    "task_id": "BigCodeBench/424",
    "mt_data": [
      {
        "task_id": "BigCodeBench/424_1",
        "turn": "1",
        "instruct_prompt": "Write a function that reads an RGB image from a given file path and returns the original image as a numpy array. You should write self-contained code starting with:\n```python\nimport cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n```",
        "test": "import unittest\nimport numpy as np\nimport cv2\nimport os\nimport tempfile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.TemporaryDirectory()\n        self.test_image_path = os.path.join(self.test_dir.name, 'test_image.png')  # Use PNG for lossless compression\n        self.test_image_rgb = np.array([[[255, 0, 0], [0, 255, 0]],\n                                        [[0, 0, 255], [255, 255, 0]]], dtype=np.uint8)\n        test_image_bgr = cv2.cvtColor(self.test_image_rgb, cv2.COLOR_RGB2BGR)\n        cv2.imwrite(self.test_image_path, test_image_bgr)\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def test_task_func_reads_and_returns_rgb_image(self):\n        result = task_func(self.test_image_path)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.shape, self.test_image_rgb.shape)\n        np.testing.assert_array_equal(result, self.test_image_rgb)\n\n    def test_task_func_raises_file_not_found(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('non_existent_file.png')\n\n    def test_task_func_raises_value_error_on_invalid_image(self):\n        dummy_path = os.path.join(self.test_dir.name, 'dummy.txt')\n        with open(dummy_path, 'w') as f:\n            f.write('not an image')\n        with self.assertRaises(ValueError):\n            task_func(dummy_path)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(f\"Image file '{image_path}' does not exist.\")\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    if image is None:\n        raise ValueError(f\"Failed to load image from '{image_path}'.\")\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return image_rgb\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/424_2",
        "turn": "2",
        "instruct_prompt": "Add input validation to the function: raise a FileNotFoundError if the image file does not exist at the specified path, and raise a ValueError if 'n_clusters' is not a positive integer.",
        "test": "import unittest\nimport tempfile\nimport os\nimport cv2\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary image file\n        self.temp_file = tempfile.NamedTemporaryFile(suffix='.jpg', delete=False)\n        # Create a simple image and write to temp file\n        image = np.zeros((10, 10, 3), dtype=np.uint8)\n        cv2.imwrite(self.temp_file.name, image)\n\n    def tearDown(self):\n        # Remove the temporary file\n        os.unlink(self.temp_file.name)\n\n    def test_file_not_found(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('non_existent_file.jpg', n_clusters=3)\n\n    def test_invalid_n_clusters_zero(self):\n        with self.assertRaises(ValueError):\n            task_func(self.temp_file.name, n_clusters=0)\n\n    def test_invalid_n_clusters_negative(self):\n        with self.assertRaises(ValueError):\n            task_func(self.temp_file.name, n_clusters=-1)\n\n    def test_invalid_n_clusters_nonint(self):\n        with self.assertRaises(ValueError):\n            task_func(self.temp_file.name, n_clusters='three')\n\n    def test_valid_input(self):\n        result = task_func(self.temp_file.name, n_clusters=3)\n        self.assertIsInstance(result, np.ndarray)\n        self.assertEqual(result.shape[2], 3)  # RGB channels\n",
        "code": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(f\"Image file '{image_path}' does not exist.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"'n_clusters' must be a positive integer.\")\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    if image is None:\n        raise ValueError(f\"Failed to load image from '{image_path}'.\")\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return image_rgb\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/424_3",
        "turn": "3",
        "instruct_prompt": "Implement K-means clustering on the image pixels to segment the image into 'n_clusters' color regions, and create a segmented image where each pixel's color is replaced by its cluster centroid color. The function should return a tuple of numpy arrays: the original image and the segmented image, both with the same shape.",
        "test": "import unittest\nimport numpy as np\nimport cv2\nimport os\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a simple test image (4x4 pixels, 3 colors)\n        self.test_img = np.array([\n            [[255, 0, 0], [255, 0, 0], [0, 255, 0], [0, 255, 0]],\n            [[255, 0, 0], [255, 0, 0], [0, 255, 0], [0, 255, 0]],\n            [[0, 0, 255], [0, 0, 255], [255, 255, 0], [255, 255, 0]],\n            [[0, 0, 255], [0, 0, 255], [255, 255, 0], [255, 255, 0]]\n        ], dtype=np.uint8)\n\n        # Save to a temporary file\n        self.temp_file = NamedTemporaryFile(suffix='.png', delete=False)\n        cv2.imwrite(self.temp_file.name, cv2.cvtColor(self.test_img, cv2.COLOR_RGB2BGR))\n\n    def tearDown(self):\n        os.remove(self.temp_file.name)\n\n    def test_kmeans_segmentation(self):\n        original, segmented = task_func(self.temp_file.name, n_clusters=3, random_seed=0)\n\n        # Check shapes\n        self.assertEqual(original.shape, self.test_img.shape)\n        self.assertEqual(segmented.shape, self.test_img.shape)\n\n        # Check original image matches what we saved (RGB)\n        np.testing.assert_array_equal(original, self.test_img)\n\n        # Check segmented image pixels are only cluster centers\n        unique_colors = np.unique(segmented.reshape(-1, 3), axis=0)\n        self.assertEqual(unique_colors.shape[0], 3)  # Exactly 3 clusters\n\n        # Check all pixel colors in segmented are from the unique colors\n        for pixel in segmented.reshape(-1, 3):\n            self.assertTrue(any(np.array_equal(pixel, uc) for uc in unique_colors))\n\n    def test_invalid_n_clusters(self):\n        with self.assertRaises(ValueError):\n            task_func(self.temp_file.name, n_clusters=0)\n        with self.assertRaises(ValueError):\n            task_func(self.temp_file.name, n_clusters=-1)\n        with self.assertRaises(ValueError):\n            task_func(self.temp_file.name, n_clusters='a')\n\n    def test_file_not_found(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('non_existent_file.jpg', n_clusters=3)\n",
        "code": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(f\"Image file '{image_path}' does not exist.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"'n_clusters' must be a positive integer.\")\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    if image is None:\n        raise ValueError(f\"Failed to load image from '{image_path}'.\")\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    # Reshape the image to a 2D array of pixels (num_pixels, 3)\n    pixels = image_rgb.reshape((-1, 3))\n\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(pixels)\n\n    # Replace each pixel with its cluster center\n    segmented_pixels = kmeans.cluster_centers_[kmeans.labels_].astype(np.uint8)\n\n    # Reshape back to the original image shape\n    segmented_image = segmented_pixels.reshape(image_rgb.shape)\n\n    return image_rgb, segmented_image\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/424_4",
        "turn": "4",
        "instruct_prompt": "If 'n_clusters' equals 1, the function should return the original image as both the original and segmented images without modification.",
        "test": "import unittest\nimport numpy as np\nimport cv2\nimport os\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a simple test image and save it to a temporary file\n        self.test_img = np.zeros((10, 10, 3), dtype=np.uint8)\n        self.test_img[:5] = [255, 0, 0]  # Red top half\n        self.test_img[5:] = [0, 255, 0]  # Green bottom half\n\n        self.temp_file = NamedTemporaryFile(suffix='.jpg', delete=False)\n        cv2.imwrite(self.temp_file.name, cv2.cvtColor(self.test_img, cv2.COLOR_RGB2BGR))\n\n    def tearDown(self):\n        if os.path.exists(self.temp_file.name):\n            os.remove(self.temp_file.name)\n\n    def test_n_clusters_one_returns_original(self):\n        original, segmented = task_func(image_path=self.temp_file.name, n_clusters=1)\n        # The segmented image should be exactly the same as the original returned image\n        self.assertTrue(np.array_equal(original, segmented))\n        # Both images should have the same shape\n        self.assertEqual(original.shape, segmented.shape)\n\n    def test_n_clusters_greater_than_one(self):\n        original, segmented = task_func(image_path=self.temp_file.name, n_clusters=2)\n        # The segmented image should not be identical to original (likely)\n        self.assertFalse(np.array_equal(original, segmented))\n        # Both images should have the same shape\n        self.assertEqual(original.shape, segmented.shape)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(f\"Image file '{image_path}' does not exist.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"'n_clusters' must be a positive integer.\")\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    if image is None:\n        raise ValueError(f\"Failed to load image from '{image_path}'.\")\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    if n_clusters == 1:\n        # Return original image as both original and segmented images\n        return image_rgb, image_rgb\n\n    # Reshape the image to a 2D array of pixels (num_pixels, 3)\n    pixels = image_rgb.reshape((-1, 3))\n\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(pixels)\n\n    # Replace each pixel with its cluster center\n    segmented_pixels = kmeans.cluster_centers_[kmeans.labels_].astype(np.uint8)\n\n    # Reshape back to the original image shape\n    segmented_image = segmented_pixels.reshape(image_rgb.shape)\n\n    return image_rgb, segmented_image\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/424_5",
        "turn": "5",
        "instruct_prompt": "Save each segmented cluster region as a separate image file named 'cluster_i.jpg' where i is the cluster index starting from 1. Each saved image should show pixels belonging to that cluster in their centroid color and all other pixels in white.",
        "test": "import unittest\nimport os\nimport numpy as np\nimport cv2\nfrom sklearn.cluster import KMeans\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a small test image (3x3 pixels) with distinct colors\n        self.test_image_path = 'test_image.jpg'\n        test_img = np.array([\n            [[255, 0, 0], [255, 0, 0], [0, 255, 0]],\n            [[0, 255, 0], [0, 0, 255], [0, 0, 255]],\n            [[255, 0, 0], [0, 255, 0], [0, 0, 255]]\n        ], dtype=np.uint8)\n        test_img_bgr = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)\n        cv2.imwrite(self.test_image_path, test_img_bgr)\n\n    def tearDown(self):\n        if os.path.isfile(self.test_image_path):\n            os.remove(self.test_image_path)\n        for i in range(1, 4):\n            fname = f'cluster_{i}.png'\n            if os.path.isfile(fname):\n                os.remove(fname)\n\n    def test_cluster_images_saved_correctly(self):\n        n_clusters = 3\n        original, segmented = task_func(self.test_image_path, n_clusters=n_clusters, random_seed=0)\n\n        # Check existence of cluster image files\n        for i in range(1, n_clusters + 1):\n            fname = f'cluster_{i}.png'\n            self.assertTrue(os.path.isfile(fname), f\"{fname} should exist.\")\n\n        h, w = original.shape[:2]\n        pixels = original.reshape((-1, 3))\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(pixels)\n        labels_2d = kmeans.labels_.reshape(h, w)\n        centroids = np.rint(kmeans.cluster_centers_).astype(np.uint8)\n\n        white = np.array([255, 255, 255], dtype=np.uint8)\n\n        for i in range(n_clusters):\n            fname = f'cluster_{i+1}.png'\n            cluster_img_bgr = cv2.imread(fname)\n            self.assertIsNotNone(cluster_img_bgr)\n            cluster_img_rgb = cv2.cvtColor(cluster_img_bgr, cv2.COLOR_BGR2RGB)\n\n            unique_colors = np.unique(cluster_img_rgb.reshape(-1, 3), axis=0)\n            # Exactly two unique colors: white and centroid color\n            self.assertEqual(len(unique_colors), 2, f\"Cluster {i+1} image should have exactly 2 unique colors.\")\n\n            # Check white is present\n            self.assertTrue(any(np.array_equal(c, white) for c in unique_colors), \"White color must be present in cluster image.\")\n\n            centroid_color = centroids[i]\n            self.assertTrue(any(np.array_equal(c, centroid_color) for c in unique_colors), f\"Cluster {i+1} centroid color must be present in cluster image.\")\n\n            mask = (labels_2d == i)\n            cluster_pixels = cluster_img_rgb[mask]\n            self.assertTrue(np.all(cluster_pixels == centroid_color), f\"All cluster pixels in cluster_{i+1}.png must be centroid color.\")\n\n            non_cluster_pixels = cluster_img_rgb[~mask]\n            self.assertTrue(np.all(non_cluster_pixels == white), f\"Non-cluster pixels in cluster_{i+1}.png must be white.\")\n\n    def test_invalid_image_path(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('non_existent.jpg', n_clusters=2)\n\n    def test_invalid_n_clusters(self):\n        with self.assertRaises(ValueError):\n            task_func(self.test_image_path, n_clusters=0)\n\n    def test_single_cluster(self):\n        original, segmented = task_func(self.test_image_path, n_clusters=1)\n        self.assertTrue(np.array_equal(original, segmented))\n        # No cluster_i.png files should be created\n        for i in range(1, 2):\n            self.assertFalse(os.path.isfile(f'cluster_{i}.png'))\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    if not os.path.isfile(image_path):\n        raise FileNotFoundError(f\"Image file '{image_path}' does not exist.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"'n_clusters' must be a positive integer.\")\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    if image is None:\n        raise ValueError(f\"Failed to load image from '{image_path}'.\")\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    if n_clusters == 1:\n        # Return original image as both original and segmented images\n        return image_rgb, image_rgb\n\n    pixels = image_rgb.reshape((-1, 3))\n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    kmeans.fit(pixels)\n\n    centroids = np.rint(kmeans.cluster_centers_).astype(np.uint8)\n\n    segmented_pixels = centroids[kmeans.labels_]\n    segmented_image = segmented_pixels.reshape(image_rgb.shape)\n\n    h, w = image_rgb.shape[:2]\n    labels_2d = kmeans.labels_.reshape(h, w)\n\n    white = np.array([255, 255, 255], dtype=np.uint8)\n\n    for i in range(n_clusters):\n        cluster_image = np.full((h, w, 3), white, dtype=np.uint8)  # white background\n        mask = (labels_2d == i)\n        cluster_image[mask] = centroids[i]\n\n        # Convert RGB to BGR before saving\n        cluster_image_bgr = cv2.cvtColor(cluster_image, cv2.COLOR_RGB2BGR)\n        filename = f'cluster_{i + 1}.png'  # Save as PNG to avoid compression artifacts\n        cv2.imwrite(filename, cluster_image_bgr)\n\n    return image_rgb, segmented_image\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 55,
    "task_id": "BigCodeBench/443",
    "mt_data": [
      {
        "task_id": "BigCodeBench/443_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a matrix P and a 3D tensor T, then computes the product of P and T. You should write self-contained code starting with:\n```\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n```",
        "test": "import unittest\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_product_shape_and_plot(self):\n        P = np.array([[1, 2], [3, 4]])  # shape (2, 2)\n        T = np.ones((2, 3, 4))  # shape (2, 3, 4)\n        result, ax = task_func(P, T)\n\n        # Check result shape\n        self.assertEqual(result.shape, (2, 3, 4))\n\n        # Check result values: result[i,j,k] should be sum over l of P[i,l]*T[l,j,k]\n        # Since T is all ones, result[i,j,k] = sum over l of P[i,l]*1 = sum of P[i,:]\n        expected = np.zeros((2,3,4))\n        expected[0,:,:] = np.sum(P[0,:])  # 1+2=3\n        expected[1,:,:] = np.sum(P[1,:])  # 3+4=7\n        np.testing.assert_array_equal(result, expected)\n\n        # Check ax is a matplotlib Axes\n        self.assertTrue(isinstance(ax, plt.Axes))\n\n    def test_invalid_dimensions(self):\n        P = np.ones((2, 3, 4))  # 3D instead of 2D\n        T = np.ones((3, 3, 3))\n        with self.assertRaises(ValueError):\n            task_func(P, T)\n\n        P = np.ones((2, 3))\n        T = np.ones((4, 3, 3))  # first dim does not match P.shape[1]\n        with self.assertRaises(ValueError):\n            task_func(P, T)\n\n        P = np.ones((2, 3))\n        T = np.ones((3, 3))  # 2D instead of 3D\n        with self.assertRaises(ValueError):\n            task_func(P, T)\n",
        "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    # Check dimensions\n    if P.ndim != 2:\n        raise ValueError('P must be a 2D matrix')\n    if T.ndim != 3:\n        raise ValueError('T must be a 3D tensor')\n    if P.shape[1] != T.shape[0]:\n        raise ValueError('The number of columns in P must equal the first dimension of T')\n\n    # Compute product of P and T\n    # Result shape: (P.shape[0], T.shape[1], T.shape[2])\n    result = np.tensordot(P, T, axes=([1], [0]))\n\n    # Create a simple plot of the sum of result over last axis\n    fig, ax = plt.subplots()\n    summed = result.sum(axis=2)  # shape (P.shape[0], T.shape[1])\n    im = ax.imshow(summed, aspect='auto')\n    ax.set_title('Sum over last axis of P x T')\n    plt.colorbar(im, ax=ax)\n\n    return result, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/443_2",
        "turn": "2",
        "instruct_prompt": "Flatten the resulting product from the previous step into a 2D array suitable for clustering.",
        "test": "import unittest\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_flattened_shape_and_values(self):\n        P = np.array([[1, 2], [3, 4]])  # shape (2,2)\n        T = np.ones((2, 3, 4))  # shape (2,3,4)\n\n        result, flattened, ax = task_func(P, T)\n\n        # result shape should be (2, 3, 4)\n        self.assertEqual(result.shape, (2, 3, 4))\n\n        # flattened shape should be (2, 12)\n        self.assertEqual(flattened.shape, (2, 12))\n\n        # flattened should be a reshaped version of result\n        np.testing.assert_array_equal(flattened, result.reshape(2, -1))\n\n        # Check that ax is a matplotlib Axes instance\n        self.assertIsInstance(ax, plt.Axes)\n\n    def test_invalid_dimensions(self):\n        P = np.ones((2, 2, 2))  # 3D instead of 2D\n        T = np.ones((2, 3, 4))\n        with self.assertRaises(ValueError):\n            task_func(P, T)\n\n        P = np.ones((2, 2))\n        T = np.ones((3, 3, 4))  # first dim 3 != P.shape[1] 2\n        with self.assertRaises(ValueError):\n            task_func(P, T)\n\n        P = np.ones((2, 2))\n        T = np.ones((2, 3))  # 2D instead of 3D\n        with self.assertRaises(ValueError):\n            task_func(P, T)\n",
        "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, np.ndarray, plt.Axes):\n    # Check dimensions\n    if P.ndim != 2:\n        raise ValueError('P must be a 2D matrix')\n    if T.ndim != 3:\n        raise ValueError('T must be a 3D tensor')\n    if P.shape[1] != T.shape[0]:\n        raise ValueError('The number of columns in P must equal the first dimension of T')\n\n    # Compute product of P and T\n    # Result shape: (P.shape[0], T.shape[1], T.shape[2])\n    result = np.tensordot(P, T, axes=([1], [0]))\n\n    # Flatten the result into 2D array suitable for clustering\n    # Flatten last two dims: shape -> (P.shape[0], T.shape[1] * T.shape[2])\n    flattened_result = result.reshape(result.shape[0], -1)\n\n    # Create a simple plot of the sum of result over last axis\n    fig, ax = plt.subplots()\n    summed = result.sum(axis=2)  # shape (P.shape[0], T.shape[1])\n    im = ax.imshow(summed, aspect='auto')\n    ax.set_title('Sum over last axis of P x T')\n    plt.colorbar(im, ax=ax)\n\n    return result, flattened_result, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/443_3",
        "turn": "3",
        "instruct_prompt": "Apply KMeans clustering on the flattened data using the parameters n_clusters, random_state, and n_init.",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_kmeans_clustering(self):\n        # Prepare input data\n        P = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])  # shape (4, 2)\n        T = np.ones((2, 3, 2))  # shape (2, 3, 2)\n\n        # Run task_func with clustering parameters\n        result, flattened_result, clusters, ax = task_func(P, T, n_clusters=2, random_state=42, n_init=5)\n\n        # Check shapes\n        self.assertEqual(result.shape, (4, 3, 2))\n        self.assertEqual(flattened_result.shape, (4, 6))\n        self.assertEqual(clusters.shape, (4,))\n\n        # Check clusters are integers in the correct range\n        self.assertTrue(np.all(clusters >= 0))\n        self.assertTrue(np.all(clusters < 2))\n\n        # Check that ax is a matplotlib Axes instance\n        import matplotlib.pyplot as plt\n        self.assertTrue(hasattr(ax, 'imshow'))\n\n    def test_invalid_dimensions(self):\n        # P not 2D\n        with self.assertRaises(ValueError):\n            task_func(np.ones((2, 2, 2)), np.ones((2, 3, 2)))\n\n        # T not 3D\n        with self.assertRaises(ValueError):\n            task_func(np.ones((2, 2)), np.ones((2, 3)))\n\n        # Mismatch in dimensions\n        with self.assertRaises(ValueError):\n            task_func(np.ones((2, 3)), np.ones((3, 3, 2)))\n",
        "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, np.ndarray, np.ndarray, plt.Axes):\n    # Check dimensions\n    if P.ndim != 2:\n        raise ValueError('P must be a 2D matrix')\n    if T.ndim != 3:\n        raise ValueError('T must be a 3D tensor')\n    if P.shape[1] != T.shape[0]:\n        raise ValueError('The number of columns in P must equal the first dimension of T')\n\n    # Compute product of P and T\n    # Result shape: (P.shape[0], T.shape[1], T.shape[2])\n    result = np.tensordot(P, T, axes=([1], [0]))\n\n    # Flatten the result into 2D array suitable for clustering\n    # Flatten last two dims: shape -> (P.shape[0], T.shape[1] * T.shape[2])\n    flattened_result = result.reshape(result.shape[0], -1)\n\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    clusters = kmeans.fit_predict(flattened_result)  # shape (P.shape[0],)\n\n    # Create a simple plot of the sum of result over last axis\n    fig, ax = plt.subplots()\n    summed = result.sum(axis=2)  # shape (P.shape[0], T.shape[1])\n    im = ax.imshow(summed, aspect='auto')\n    ax.set_title('Sum over last axis of P x T')\n    plt.colorbar(im, ax=ax)\n\n    return result, flattened_result, clusters, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/443_4",
        "turn": "4",
        "instruct_prompt": "Visualize the clustered data using matplotlib scatter plot, color points by cluster labels, set the plot title to 'KMeans Clustering Visualization', and return both the cluster labels and the matplotlib Axes object.",
        "test": "import unittest\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_visualization_and_clusters(self):\n        # Prepare inputs\n        P = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n        T = np.ones((2, 2, 2))  # shape (2,2,2)\n\n        clusters, ax = task_func(P, T, n_clusters=2, random_state=42, n_init=10)\n\n        # Check clusters shape and type\n        self.assertIsInstance(clusters, np.ndarray)\n        self.assertEqual(clusters.shape, (P.shape[0],))\n        self.assertTrue(np.all(clusters >= 0))\n        self.assertTrue(np.all(clusters < 2))\n\n        # Check ax is matplotlib Axes\n        self.assertTrue(hasattr(ax, 'scatter'))\n        self.assertEqual(ax.get_title(), 'KMeans Clustering Visualization')\n\n        # Check number of unique clusters matches n_clusters\n        unique_labels = np.unique(clusters)\n        self.assertEqual(len(unique_labels), 2)\n\n    def test_invalid_dimensions(self):\n        # P not 2D\n        with self.assertRaises(ValueError):\n            task_func(np.array([1, 2, 3]), np.ones((2, 2, 2)))\n\n        # T not 3D\n        with self.assertRaises(ValueError):\n            task_func(np.ones((2, 2)), np.ones((2, 2)))\n\n        # dimension mismatch\n        with self.assertRaises(ValueError):\n            task_func(np.ones((2, 3)), np.ones((4, 2, 2)))\n",
        "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    # Check dimensions\n    if P.ndim != 2:\n        raise ValueError('P must be a 2D matrix')\n    if T.ndim != 3:\n        raise ValueError('T must be a 3D tensor')\n    if P.shape[1] != T.shape[0]:\n        raise ValueError('The number of columns in P must equal the first dimension of T')\n\n    # Compute product of P and T\n    # Result shape: (P.shape[0], T.shape[1], T.shape[2])\n    result = np.tensordot(P, T, axes=([1], [0]))\n\n    # Flatten the result into 2D array suitable for clustering\n    # Flatten last two dims: shape -> (P.shape[0], T.shape[1] * T.shape[2])\n    flattened_result = result.reshape(result.shape[0], -1)\n\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init)\n    clusters = kmeans.fit_predict(flattened_result)  # shape (P.shape[0],)\n\n    # Visualize the clustered data using scatter plot\n    fig, ax = plt.subplots()\n    # To plot 2D scatter, reduce flattened_result to 2D using first two features\n    # If less than 2 features, pad with zeros\n    if flattened_result.shape[1] < 2:\n        points_2d = np.hstack([flattened_result, np.zeros((flattened_result.shape[0], 2 - flattened_result.shape[1]))])\n    else:\n        points_2d = flattened_result[:, :2]\n\n    scatter = ax.scatter(points_2d[:, 0], points_2d[:, 1], c=clusters, cmap='viridis', s=30)\n    ax.set_title('KMeans Clustering Visualization')\n    ax.set_xlabel('Feature 1')\n    ax.set_ylabel('Feature 2')\n    plt.colorbar(scatter, ax=ax, label='Cluster Label')\n\n    return clusters, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 56,
    "task_id": "BigCodeBench/445",
    "mt_data": [
      {
        "task_id": "BigCodeBench/445_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes an array of 2D points and returns the Voronoi diagram object for those points. You should write self-contained code starting with:\n```\nimport numpy as np\nfrom scipy.spatial import Voronoi\n\ndef task_func(points, seed=0):\n```",
        "test": "import unittest\nimport numpy as np\nfrom scipy.spatial import Voronoi\n\nclass TestCases(unittest.TestCase):\n    def test_basic_points(self):\n        points = [[0, 0], [1, 0], [0, 1], [1, 1]]\n        vor = task_func(points)\n        self.assertIsInstance(vor, Voronoi)\n        self.assertTrue(np.allclose(vor.points, np.array(points)))\n\n    def test_single_point(self):\n        points = [[0, 0]]\n        with self.assertRaises(Exception):\n            _ = task_func(points)  # Voronoi needs at least 2 points\n\n    def test_non_integer_points(self):\n        points = [[0.5, 1.5], [2.3, 3.7], [4.1, 0.2]]\n        vor = task_func(points)\n        self.assertIsInstance(vor, Voronoi)\n        self.assertTrue(np.allclose(vor.points, np.array(points)))\n\n    def test_duplicate_points(self):\n        points = [[0, 0], [1, 1], [0, 0]]\n        with self.assertRaises(Exception):\n            _ = task_func(points)  # Voronoi cannot handle duplicate points\n",
        "code": "import numpy as np\nfrom scipy.spatial import Voronoi\n\ndef task_func(points, seed=0):\n    points = np.array(points)\n    return Voronoi(points)",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/445_2",
        "turn": "2",
        "instruct_prompt": "Add input validation to the function: raise a TypeError if the input is not a numpy array; raise a ValueError if there are fewer than 3 points; raise a ValueError if the points are not 2D (i.e., the last dimension is not 2).",
        "test": "import unittest\nimport numpy as np\nfrom scipy.spatial import Voronoi\n\nclass TestCases(unittest.TestCase):\n    def test_valid_input(self):\n        points = np.array([[0, 0], [1, 0], [0, 1]])\n        result = task_func(points)\n        self.assertIsInstance(result, Voronoi)\n\n    def test_input_not_numpy_array(self):\n        points = [[0, 0], [1, 0], [0, 1]]  # list instead of np.array\n        with self.assertRaises(TypeError):\n            task_func(points)\n\n    def test_too_few_points(self):\n        points = np.array([[0, 0], [1, 0]])  # only 2 points\n        with self.assertRaises(ValueError):\n            task_func(points)\n\n    def test_points_not_2d(self):\n        points = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0]])  # 3D points\n        with self.assertRaises(ValueError):\n            task_func(points)\n\n    def test_points_one_dimensional(self):\n        points = np.array([0, 1, 2])  # 1D array\n        with self.assertRaises(ValueError):\n            task_func(points)\n",
        "code": "import numpy as np\nfrom scipy.spatial import Voronoi\n\ndef task_func(points, seed=0):\n    if not isinstance(points, np.ndarray):\n        raise TypeError(\"Input points must be a numpy array.\")\n    if points.ndim != 2 or points.shape[1] != 2:\n        raise ValueError(\"Input points must be 2D with shape (n_points, 2).\")\n    if points.shape[0] < 3:\n        raise ValueError(\"At least 3 points are required to compute Voronoi diagram.\")\n    return Voronoi(points)",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/445_3",
        "turn": "3",
        "instruct_prompt": "Add jittering to the input points by adding Gaussian noise with mean 0 and standard deviation 1e-10, using the provided seed to initialize the random number generator.",
        "test": "import unittest\nimport numpy as np\nfrom scipy.spatial import Voronoi\n\nclass TestCases(unittest.TestCase):\n    def test_voronoi_with_jitter(self):\n        points = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n        vor, jittered_points = task_func(points, seed=42)\n        self.assertIsInstance(vor, Voronoi)\n        self.assertIsInstance(jittered_points, np.ndarray)\n        self.assertEqual(jittered_points.shape, points.shape)\n\n    def test_jitter_added_and_seeded(self):\n        points = np.array([[0, 0], [1, 0], [0, 1], [1, 1], [0.5, 0.5], [0.25, 0.75], [0.75, 0.25], [0.1, 0.9], [0.9, 0.1], [0.3, 0.3]])\n        _, jittered_points1 = task_func(points, seed=42)\n        _, jittered_points2 = task_func(points, seed=43)\n\n        # They should differ by at least one element\n        self.assertFalse(np.allclose(jittered_points1, jittered_points2, atol=1e-15))\n\n        # For fixed seed, jittered points should be the same\n        _, jittered_points1_again = task_func(points, seed=42)\n        self.assertTrue(np.allclose(jittered_points1, jittered_points1_again, atol=0))\n\n    def test_jitter_magnitude(self):\n        # Use larger number of points to get better statistics\n        np.random.seed(0)\n        points = np.random.rand(1000, 2)\n        _, jittered_points = task_func(points, seed=123)\n        diffs = jittered_points - points\n\n        mean_diff = np.mean(diffs)\n        self.assertAlmostEqual(mean_diff, 0, delta=1e-11)\n\n        std_diff = np.std(diffs)\n        # Relax tolerance to 2e-11 due to randomness\n        self.assertAlmostEqual(std_diff, 1e-10, delta=2e-11)\n\n    def test_invalid_input_type(self):\n        with self.assertRaises(TypeError):\n            task_func([[0, 0], [1, 0], [0, 1]])\n\n    def test_invalid_input_shape(self):\n        with self.assertRaises(ValueError):\n            task_func(np.array([1, 2, 3]))\n        with self.assertRaises(ValueError):\n            task_func(np.array([[1, 2, 3], [4, 5, 6]]))\n\n    def test_insufficient_points(self):\n        with self.assertRaises(ValueError):\n            task_func(np.array([[0, 0], [1, 0]]))\n",
        "code": "import numpy as np\nfrom scipy.spatial import Voronoi\n\ndef task_func(points, seed=0):\n    if not isinstance(points, np.ndarray):\n        raise TypeError(\"Input points must be a numpy array.\")\n    if points.ndim != 2 or points.shape[1] != 2:\n        raise ValueError(\"Input points must be 2D with shape (n_points, 2).\")\n    if points.shape[0] < 3:\n        raise ValueError(\"At least 3 points are required to compute Voronoi diagram.\")\n\n    rng = np.random.default_rng(seed)\n    jitter = rng.normal(loc=0.0, scale=1e-10, size=points.shape)\n    jittered_points = points + jitter\n    vor = Voronoi(jittered_points)\n    # Return both Voronoi and jittered points for testing\n    return vor, jittered_points\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/445_4",
        "turn": "4",
        "instruct_prompt": "Plot the Voronoi diagram on matplotlib axes and return both the Voronoi object and the axes in a tuple. The function should create a new figure and axes for the plot.",
        "test": "import unittest\nimport numpy as np\nfrom scipy.spatial import Voronoi\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_voronoi_plot_and_return(self):\n        points = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n        vor, ax = task_func(points, seed=42)\n\n        # Check return types\n        self.assertIsInstance(vor, Voronoi)\n        self.assertTrue(hasattr(ax, 'plot'))  # matplotlib axes has plot method\n\n        # Check that the plot contains line collections (Voronoi edges)\n        lines = [child for child in ax.get_children() if hasattr(child, 'get_segments')]\n        self.assertTrue(len(lines) > 0)\n\n    def test_invalid_input_raises(self):\n        with self.assertRaises(TypeError):\n            task_func([[0, 0], [1, 0], [0, 1]])  # not numpy array\n        with self.assertRaises(ValueError):\n            task_func(np.array([[0, 0]]))  # less than 3 points\n        with self.assertRaises(ValueError):\n            task_func(np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0]]))  # wrong shape\n",
        "code": "import numpy as np\nfrom scipy.spatial import Voronoi\nimport matplotlib.pyplot as plt\n\ndef task_func(points, seed=0):\n    if not isinstance(points, np.ndarray):\n        raise TypeError(\"Input points must be a numpy array.\")\n    if points.ndim != 2 or points.shape[1] != 2:\n        raise ValueError(\"Input points must be 2D with shape (n_points, 2).\")\n    if points.shape[0] < 3:\n        raise ValueError(\"At least 3 points are required to compute Voronoi diagram.\")\n\n    rng = np.random.default_rng(seed)\n    jitter = rng.normal(loc=0.0, scale=1e-10, size=points.shape)\n    jittered_points = points + jitter\n    vor = Voronoi(jittered_points)\n\n    fig, ax = plt.subplots()\n    from scipy.spatial import voronoi_plot_2d\n    voronoi_plot_2d(vor, ax=ax, show_vertices=False, line_colors='blue', line_width=1, point_size=5)\n\n    return vor, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 57,
    "task_id": "BigCodeBench/454",
    "mt_data": [
      {
        "task_id": "BigCodeBench/454_1",
        "turn": "1",
        "instruct_prompt": "Move all files from a source directory to a destination directory. You should write self-contained code starting with:\n```\nimport os\nimport shutil\ndef task_func(src_dir, dest_dir, ext):\n```",
        "test": "import unittest\nimport os\nimport tempfile\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.src_dir = tempfile.mkdtemp()\n        self.dest_dir = tempfile.mkdtemp()\n\n        self.files_to_move = ['file1.txt', 'file2.txt', 'file3.log']\n        for fname in self.files_to_move:\n            with open(os.path.join(self.src_dir, fname), 'w') as f:\n                f.write('test content')\n\n    def tearDown(self):\n        shutil.rmtree(self.src_dir)\n        shutil.rmtree(self.dest_dir)\n\n    def test_move_txt_files(self):\n        task_func(self.src_dir, self.dest_dir, '.txt')\n\n        for fname in ['file1.txt', 'file2.txt']:\n            self.assertFalse(os.path.exists(os.path.join(self.src_dir, fname)))\n            self.assertTrue(os.path.exists(os.path.join(self.dest_dir, fname)))\n\n        self.assertTrue(os.path.exists(os.path.join(self.src_dir, 'file3.log')))\n        self.assertFalse(os.path.exists(os.path.join(self.dest_dir, 'file3.log')))\n\n    def test_invalid_source_dir(self):\n        with self.assertRaises(ValueError):\n            task_func('nonexistent_dir', self.dest_dir, '.txt')\n\n    def test_invalid_dest_dir(self):\n        with self.assertRaises(ValueError):\n            task_func(self.src_dir, 'nonexistent_dir', '.txt')\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import os\nimport shutil\n\ndef task_func(src_dir, dest_dir, ext):\n    if not os.path.isdir(src_dir):\n        raise ValueError(f\"Source directory '{src_dir}' does not exist or is not a directory.\")\n    if not os.path.isdir(dest_dir):\n        raise ValueError(f\"Destination directory '{dest_dir}' does not exist or is not a directory.\")\n\n    for filename in os.listdir(src_dir):\n        if filename.endswith(ext):\n            src_path = os.path.join(src_dir, filename)\n            dest_path = os.path.join(dest_dir, filename)\n            if os.path.isfile(src_path):\n                shutil.move(src_path, dest_path)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/454_2",
        "turn": "2",
        "instruct_prompt": "Only move files that have the specified extension given by the parameter 'ext'.",
        "test": "import unittest\nimport tempfile\nimport os\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.src_dir = tempfile.mkdtemp()\n        self.dest_dir = tempfile.mkdtemp()\n\n        self.files = {\n            'file1.txt': 'content1',\n            'file2.log': 'content2',\n            'file3.txt1': 'content3',  # ends with 'txt1', not '.txt'\n            'file4.md': 'content4',\n            'file5.TXT': 'content5',  # uppercase extension\n            'file6.txt.backup': 'content6'  # multiple extensions\n        }\n        for filename, content in self.files.items():\n            with open(os.path.join(self.src_dir, filename), 'w') as f:\n                f.write(content)\n\n    def tearDown(self):\n        shutil.rmtree(self.src_dir)\n        shutil.rmtree(self.dest_dir)\n\n    def test_move_with_dot_extension(self):\n        ext = '.txt'\n        task_func(self.src_dir, self.dest_dir, ext)\n\n        for filename in self.files:\n            src_path = os.path.join(self.src_dir, filename)\n            dest_path = os.path.join(self.dest_dir, filename)\n            _, file_ext = os.path.splitext(filename)\n            if file_ext == ext:\n                self.assertFalse(os.path.exists(src_path), f\"{filename} should be moved from source\")\n                self.assertTrue(os.path.exists(dest_path), f\"{filename} should be in destination\")\n            else:\n                self.assertTrue(os.path.exists(src_path), f\"{filename} should remain in source\")\n                self.assertFalse(os.path.exists(dest_path), f\"{filename} should not be moved to destination\")\n\n    def test_move_without_dot_extension_should_fail_previous_solution(self):\n        # Use extension without leading dot\n        ext = 'txt'\n        task_func(self.src_dir, self.dest_dir, ext)\n\n        for filename in self.files:\n            src_path = os.path.join(self.src_dir, filename)\n            dest_path = os.path.join(self.dest_dir, filename)\n            # With ext='txt', exact extension matching means no files should be moved,\n            # because os.path.splitext returns extension with leading dot.\n            # So no file should be moved.\n            self.assertTrue(os.path.exists(src_path), f\"{filename} should remain in source\")\n            self.assertFalse(os.path.exists(dest_path), f\"{filename} should not be moved\")\n",
        "code": "import os\nimport shutil\n\ndef task_func(src_dir, dest_dir, ext):\n    if not os.path.isdir(src_dir):\n        raise ValueError(f\"Source directory '{src_dir}' does not exist or is not a directory.\")\n    if not os.path.isdir(dest_dir):\n        raise ValueError(f\"Destination directory '{dest_dir}' does not exist or is not a directory.\")\n\n    for filename in os.listdir(src_dir):\n        if os.path.isfile(os.path.join(src_dir, filename)):\n            _, file_ext = os.path.splitext(filename)\n            # ext parameter should include the dot, so compare directly\n            if file_ext == ext:\n                src_path = os.path.join(src_dir, filename)\n                dest_path = os.path.join(dest_dir, filename)\n                shutil.move(src_path, dest_path)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/454_3",
        "turn": "3",
        "instruct_prompt": "If a file with the same name already exists in the destination directory, do not move that file.",
        "test": "import unittest\nimport tempfile\nimport os\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create temporary source and destination directories\n        self.src_dir = tempfile.mkdtemp()\n        self.dest_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        # Remove temporary directories and all their contents\n        shutil.rmtree(self.src_dir)\n        shutil.rmtree(self.dest_dir)\n\n    def test_move_files_with_no_conflict(self):\n        # Create files in source directory\n        filenames = ['file1.txt', 'file2.txt', 'file3.log']\n        for f in filenames:\n            with open(os.path.join(self.src_dir, f), 'w') as file:\n                file.write('content')\n\n        # Call task_func to move .txt files\n        task_func(self.src_dir, self.dest_dir, '.txt')\n\n        # .txt files should be moved\n        for f in ['file1.txt', 'file2.txt']:\n            self.assertFalse(os.path.exists(os.path.join(self.src_dir, f)))\n            self.assertTrue(os.path.exists(os.path.join(self.dest_dir, f)))\n\n        # .log file should remain in source\n        self.assertTrue(os.path.exists(os.path.join(self.src_dir, 'file3.log')))\n        self.assertFalse(os.path.exists(os.path.join(self.dest_dir, 'file3.log')))\n\n    def test_do_not_move_if_file_exists_in_dest(self):\n        # Create a .txt file in source and a file with the same name in destination\n        filename = 'file1.txt'\n        src_file = os.path.join(self.src_dir, filename)\n        dest_file = os.path.join(self.dest_dir, filename)\n\n        with open(src_file, 'w') as f:\n            f.write('source content')\n        with open(dest_file, 'w') as f:\n            f.write('destination content')\n\n        # Call task_func\n        task_func(self.src_dir, self.dest_dir, '.txt')\n\n        # The source file should still exist (not moved)\n        self.assertTrue(os.path.exists(src_file))\n        # The destination file should remain unchanged\n        with open(dest_file, 'r') as f:\n            content = f.read()\n        self.assertEqual(content, 'destination content')\n\n    def test_raise_error_for_invalid_src_dir(self):\n        with self.assertRaises(ValueError):\n            task_func('non_existent_src', self.dest_dir, '.txt')\n\n    def test_raise_error_for_invalid_dest_dir(self):\n        with self.assertRaises(ValueError):\n            task_func(self.src_dir, 'non_existent_dest', '.txt')\n",
        "code": "import os\nimport shutil\n\ndef task_func(src_dir, dest_dir, ext):\n    if not os.path.isdir(src_dir):\n        raise ValueError(f\"Source directory '{src_dir}' does not exist or is not a directory.\")\n    if not os.path.isdir(dest_dir):\n        raise ValueError(f\"Destination directory '{dest_dir}' does not exist or is not a directory.\")\n\n    for filename in os.listdir(src_dir):\n        if os.path.isfile(os.path.join(src_dir, filename)):\n            _, file_ext = os.path.splitext(filename)\n            if file_ext == ext:\n                src_path = os.path.join(src_dir, filename)\n                dest_path = os.path.join(dest_dir, filename)\n                if not os.path.exists(dest_path):\n                    shutil.move(src_path, dest_path)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/454_4",
        "turn": "4",
        "instruct_prompt": "Raise a FileNotFoundError if either the source or destination directory does not exist.",
        "test": "import unittest\nimport tempfile\nimport os\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def test_file_not_found_src(self):\n        with tempfile.TemporaryDirectory() as dest_dir:\n            with self.assertRaises(FileNotFoundError):\n                task_func('non_existent_src_dir', dest_dir, '.txt')\n\n    def test_file_not_found_dest(self):\n        with tempfile.TemporaryDirectory() as src_dir:\n            with self.assertRaises(FileNotFoundError):\n                task_func(src_dir, 'non_existent_dest_dir', '.txt')\n\n    def test_no_error_when_dirs_exist(self):\n        with tempfile.TemporaryDirectory() as src_dir, tempfile.TemporaryDirectory() as dest_dir:\n            # Create a dummy file with .txt extension in src_dir\n            file_path = os.path.join(src_dir, 'testfile.txt')\n            with open(file_path, 'w') as f:\n                f.write('dummy')\n            # Call function should not raise\n            try:\n                task_func(src_dir, dest_dir, '.txt')\n            except FileNotFoundError:\n                self.fail(\"task_func raised FileNotFoundError unexpectedly!\")\n",
        "code": "import os\nimport shutil\n\ndef task_func(src_dir, dest_dir, ext):\n    if not os.path.isdir(src_dir):\n        raise FileNotFoundError(f\"Source directory '{src_dir}' does not exist.\")\n    if not os.path.isdir(dest_dir):\n        raise FileNotFoundError(f\"Destination directory '{dest_dir}' does not exist.\")\n\n    for filename in os.listdir(src_dir):\n        if os.path.isfile(os.path.join(src_dir, filename)):\n            _, file_ext = os.path.splitext(filename)\n            if file_ext == ext:\n                src_path = os.path.join(src_dir, filename)\n                dest_path = os.path.join(dest_dir, filename)\n                if not os.path.exists(dest_path):\n                    shutil.move(src_path, dest_path)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/454_5",
        "turn": "5",
        "instruct_prompt": "Return a list of the full paths of files that were successfully moved. Files not moved due to name conflicts should not be included.",
        "test": "import unittest\nimport tempfile\nimport os\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.src_dir = tempfile.mkdtemp()\n        self.dest_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.src_dir)\n        shutil.rmtree(self.dest_dir)\n\n    def test_files_moved_and_returned(self):\n        filenames = ['file1.txt', 'file2.txt', 'file3.log']\n        for fn in filenames:\n            with open(os.path.join(self.src_dir, fn), 'w') as f:\n                f.write('content')\n\n        # Create a conflicting file in dest_dir\n        conflict_file = 'file2.txt'\n        with open(os.path.join(self.dest_dir, conflict_file), 'w') as f:\n            f.write('existing')\n\n        moved_files = task_func(self.src_dir, self.dest_dir, '.txt')\n\n        # file1.txt should be moved, file2.txt should not, file3.log ignored\n        expected_moved = [os.path.join(self.dest_dir, 'file1.txt')]\n\n        self.assertEqual(sorted(moved_files), sorted(expected_moved))\n\n        # Check that file1.txt is actually moved\n        self.assertTrue(os.path.exists(os.path.join(self.dest_dir, 'file1.txt')))\n        self.assertFalse(os.path.exists(os.path.join(self.src_dir, 'file1.txt')))\n\n        # file2.txt should remain in src_dir because of conflict\n        self.assertTrue(os.path.exists(os.path.join(self.src_dir, 'file2.txt')))\n\n        # file3.log should remain in src_dir because extension does not match\n        self.assertTrue(os.path.exists(os.path.join(self.src_dir, 'file3.log')))\n",
        "code": "import os\nimport shutil\n\ndef task_func(src_dir, dest_dir, ext):\n    if not os.path.isdir(src_dir):\n        raise FileNotFoundError(f\"Source directory '{src_dir}' does not exist.\")\n    if not os.path.isdir(dest_dir):\n        raise FileNotFoundError(f\"Destination directory '{dest_dir}' does not exist.\")\n\n    moved_files = []\n    for filename in os.listdir(src_dir):\n        if os.path.isfile(os.path.join(src_dir, filename)):\n            _, file_ext = os.path.splitext(filename)\n            if file_ext == ext:\n                src_path = os.path.join(src_dir, filename)\n                dest_path = os.path.join(dest_dir, filename)\n                if not os.path.exists(dest_path):\n                    shutil.move(src_path, dest_path)\n                    moved_files.append(dest_path)\n    return moved_files\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 58,
    "task_id": "BigCodeBench/458",
    "mt_data": [
      {
        "task_id": "BigCodeBench/458_1",
        "turn": "1",
        "instruct_prompt": "Load a JSON string into a dictionary and return the dictionary. You should write self-contained code starting with:```import json\nimport pandas as pd\ndef task_func(json_str):\n    my_dict = json.loads(json_str)\n    return my_dict\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_valid_json(self):\n        json_str = '{\"key1\": \"value1\", \"key2\": 2}'\n        expected = {\"key1\": \"value1\", \"key2\": 2}\n        self.assertEqual(task_func(json_str), expected)\n\n    def test_empty_json(self):\n        json_str = '{}'\n        expected = {}\n        self.assertEqual(task_func(json_str), expected)\n\n    def test_nested_json(self):\n        json_str = '{\"a\": {\"b\": 1}, \"c\": [1, 2, 3]}'\n        expected = {\"a\": {\"b\": 1}, \"c\": [1, 2, 3]}\n        self.assertEqual(task_func(json_str), expected)\n\n    def test_invalid_json(self):\n        json_str = '{key: value}'  # invalid JSON\n        with self.assertRaises(json.JSONDecodeError):\n            task_func(json_str)\n",
        "code": "import json\nimport pandas as pd\ndef task_func(json_str):\n    my_dict = json.loads(json_str)\n    return my_dict\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/458_2",
        "turn": "2",
        "instruct_prompt": "Normalize the dictionary by doubling the numerical values, including integers, floats, and strings that represent numbers using regex, and also double numerical values inside lists. Do not process nested dictionaries.",
        "test": "import unittest\nimport json\n\nclass TestCases(unittest.TestCase):\n    def test_double_integers_and_floats(self):\n        input_dict = {\"a\": 2, \"b\": 3.5, \"c\": \"5\", \"d\": \"6.7\"}\n        input_json = json.dumps(input_dict)\n        expected = {\"a\": 4, \"b\": 7.0, \"c\": \"10\", \"d\": \"13.4\"}\n        self.assertEqual(task_func(input_json), expected)\n\n    def test_double_lists(self):\n        input_dict = {\"a\": [1, 2.5, \"3\", \"4.5\", \"x\", 7], \"b\": \"10\"}\n        input_json = json.dumps(input_dict)\n        expected = {\"a\": [2, 5.0, \"6\", \"9.0\", \"x\", 14], \"b\": \"20\"}\n        self.assertEqual(task_func(input_json), expected)\n\n    def test_do_not_process_nested_dict(self):\n        input_dict = {\"a\": {\"x\": 1}, \"b\": 5}\n        input_json = json.dumps(input_dict)\n        expected = {\"a\": {\"x\": 1}, \"b\": 10}\n        self.assertEqual(task_func(input_json), expected)\n\n    def test_non_numeric_strings_and_others(self):\n        input_dict = {\"a\": \"hello\", \"b\": [\"world\", \"123abc\", 4], \"c\": None}\n        input_json = json.dumps(input_dict)\n        expected = {\"a\": \"hello\", \"b\": [\"world\", \"123abc\", 8], \"c\": None}\n        self.assertEqual(task_func(input_json), expected)\n",
        "code": "import json\nimport re\n\ndef task_func(json_str):\n    my_dict = json.loads(json_str)\n    number_regex = re.compile(r'^-?\\d+(\\.\\d+)?$')\n\n    def double_value(val):\n        if isinstance(val, (int, float)):\n            return val * 2\n        elif isinstance(val, str) and number_regex.match(val):\n            # Determine if int or float\n            if '.' in val:\n                return str(float(val) * 2)\n            else:\n                return str(int(val) * 2)\n        elif isinstance(val, list):\n            new_list = []\n            for item in val:\n                if isinstance(item, (int, float)):\n                    new_list.append(item * 2)\n                elif isinstance(item, str) and number_regex.match(item):\n                    if '.' in item:\n                        new_list.append(str(float(item) * 2))\n                    else:\n                        new_list.append(str(int(item) * 2))\n                else:\n                    new_list.append(item)\n            return new_list\n        else:\n            return val\n\n    result = {}\n    for k, v in my_dict.items():\n        # Do not process nested dicts\n        if isinstance(v, dict):\n            result[k] = v\n        else:\n            result[k] = double_value(v)\n\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/458_3",
        "turn": "3",
        "instruct_prompt": "Create a pandas DataFrame from the normalized dictionary, handling cases where values are lists or single values. Return an empty DataFrame if the dictionary is empty or invalid for DataFrame conversion.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_empty_dict(self):\n        df = task_func({})\n        self.assertTrue(isinstance(df, pd.DataFrame))\n        self.assertTrue(df.empty)\n\n    def test_non_dict_input(self):\n        df = task_func(None)\n        self.assertTrue(isinstance(df, pd.DataFrame))\n        self.assertTrue(df.empty)\n\n    def test_single_values(self):\n        d = {'a': 1, 'b': 'x', 'c': 3.5}\n        df = task_func(d)\n        self.assertEqual(df.shape, (1, 3))\n        self.assertEqual(df.iloc[0]['a'], 1)\n        self.assertEqual(df.iloc[0]['b'], 'x')\n        self.assertEqual(df.iloc[0]['c'], 3.5)\n\n    def test_list_values_same_length(self):\n        d = {'a': [1, 2], 'b': ['x', 'y'], 'c': [3.5, 4.5]}\n        df = task_func(d)\n        self.assertEqual(df.shape, (2, 3))\n        self.assertListEqual(df['a'].tolist(), [1, 2])\n        self.assertListEqual(df['b'].tolist(), ['x', 'y'])\n        self.assertListEqual(df['c'].tolist(), [3.5, 4.5])\n\n    def test_mixed_single_and_list_same_length(self):\n        d = {'a': [1, 2], 'b': 'x', 'c': [3.5, 4.5]}\n        df = task_func(d)\n        self.assertEqual(df.shape, (2, 3))\n        self.assertListEqual(df['a'].tolist(), [1, 2])\n        self.assertListEqual(df['b'].tolist(), ['x', 'x'])\n        self.assertListEqual(df['c'].tolist(), [3.5, 4.5])\n\n    def test_list_values_different_length(self):\n        d = {'a': [1, 2], 'b': ['x'], 'c': [3.5, 4.5]}\n        df = task_func(d)\n        self.assertTrue(df.empty)\n\n    def test_invalid_value(self):\n        d = {'a': 1, 'b': {'nested': 2}}\n        df = task_func(d)\n        self.assertTrue(df.empty)\n",
        "code": "import pandas as pd\nimport unittest\nimport json\nimport re\n\n# The task_func now takes the normalized dictionary as input and returns a DataFrame or empty DataFrame\n# per the requirement of this round.\ndef task_func(normalized_dict):\n    if not isinstance(normalized_dict, dict) or not normalized_dict:\n        return pd.DataFrame()\n\n    # Return empty DataFrame if any value is a dict (nested dict not allowed)\n    for v in normalized_dict.values():\n        if isinstance(v, dict):\n            return pd.DataFrame()\n\n    # Determine target length for DataFrame rows\n    lengths = []\n    for v in normalized_dict.values():\n        if isinstance(v, list):\n            lengths.append(len(v))\n\n    if lengths:\n        target_len = lengths[0]\n        # If lists have different lengths, return empty DataFrame\n        if any(length != target_len for length in lengths):\n            return pd.DataFrame()\n    else:\n        target_len = 1  # All single values\n\n    # Broadcast single values to lists of target_len\n    normalized_data = {}\n    for k, v in normalized_dict.items():\n        if isinstance(v, list):\n            normalized_data[k] = v\n        else:\n            normalized_data[k] = [v] * target_len\n\n    try:\n        df = pd.DataFrame(normalized_data)\n        return df\n    except Exception:\n        return pd.DataFrame()\n\nclass TestCases(unittest.TestCase):\n    def test_empty_dict(self):\n        df = task_func({})\n        self.assertTrue(isinstance(df, pd.DataFrame))\n        self.assertTrue(df.empty)\n\n    def test_non_dict_input(self):\n        df = task_func(None)\n        self.assertTrue(isinstance(df, pd.DataFrame))\n        self.assertTrue(df.empty)\n\n    def test_single_values(self):\n        d = {'a': 1, 'b': 'x', 'c': 3.5}\n        df = task_func(d)\n        self.assertEqual(df.shape, (1, 3))\n        self.assertEqual(df.iloc[0]['a'], 1)\n        self.assertEqual(df.iloc[0]['b'], 'x')\n        self.assertEqual(df.iloc[0]['c'], 3.5)\n\n    def test_list_values_same_length(self):\n        d = {'a': [1, 2], 'b': ['x', 'y'], 'c': [3.5, 4.5]}\n        df = task_func(d)\n        self.assertEqual(df.shape, (2, 3))\n        self.assertListEqual(df['a'].tolist(), [1, 2])\n        self.assertListEqual(df['b'].tolist(), ['x', 'y'])\n        self.assertListEqual(df['c'].tolist(), [3.5, 4.5])\n\n    def test_mixed_single_and_list_same_length(self):\n        d = {'a': [1, 2], 'b': 'x', 'c': [3.5, 4.5]}\n        df = task_func(d)\n        self.assertEqual(df.shape, (2, 3))\n        self.assertListEqual(df['a'].tolist(), [1, 2])\n        self.assertListEqual(df['b'].tolist(), ['x', 'x'])\n        self.assertListEqual(df['c'].tolist(), [3.5, 4.5])\n\n    def test_list_values_different_length(self):\n        d = {'a': [1, 2], 'b': ['x'], 'c': [3.5, 4.5]}\n        df = task_func(d)\n        self.assertTrue(df.empty)\n\n    def test_invalid_value(self):\n        d = {'a': 1, 'b': {'nested': 2}}\n        df = task_func(d)\n        self.assertTrue(df.empty)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/458_4",
        "turn": "4",
        "instruct_prompt": "Ensure that numerical columns in the DataFrame are stored as floats and other types remain unchanged.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_empty_dict(self):\n        df = task_func({})\n        self.assertTrue(isinstance(df, pd.DataFrame))\n        self.assertTrue(df.empty)\n\n    def test_non_dict_input(self):\n        df = task_func(None)\n        self.assertTrue(isinstance(df, pd.DataFrame))\n        self.assertTrue(df.empty)\n\n    def test_single_values(self):\n        d = {'a': 1, 'b': 'x', 'c': 3.5}\n        df = task_func(d)\n        self.assertEqual(df.shape, (1, 3))\n        self.assertEqual(df.iloc[0]['a'], 1.0)\n        self.assertEqual(df.iloc[0]['b'], 'x')\n        self.assertEqual(df.iloc[0]['c'], 3.5)\n        self.assertTrue(pd.api.types.is_float_dtype(df['a']))\n        self.assertFalse(pd.api.types.is_float_dtype(df['b']))\n        self.assertTrue(pd.api.types.is_float_dtype(df['c']))\n\n    def test_list_values_same_length(self):\n        d = {'a': [1, 2], 'b': ['x', 'y'], 'c': [3.5, 4.5]}\n        df = task_func(d)\n        self.assertEqual(df.shape, (2, 3))\n        self.assertListEqual(df['a'].tolist(), [1.0, 2.0])\n        self.assertListEqual(df['b'].tolist(), ['x', 'y'])\n        self.assertListEqual(df['c'].tolist(), [3.5, 4.5])\n        self.assertTrue(pd.api.types.is_float_dtype(df['a']))\n        self.assertFalse(pd.api.types.is_float_dtype(df['b']))\n        self.assertTrue(pd.api.types.is_float_dtype(df['c']))\n\n    def test_mixed_single_and_list_same_length(self):\n        d = {'a': [1, 2], 'b': 'x', 'c': [3.5, 4.5]}\n        df = task_func(d)\n        self.assertEqual(df.shape, (2, 3))\n        self.assertListEqual(df['a'].tolist(), [1.0, 2.0])\n        self.assertListEqual(df['b'].tolist(), ['x', 'x'])\n        self.assertListEqual(df['c'].tolist(), [3.5, 4.5])\n        self.assertTrue(pd.api.types.is_float_dtype(df['a']))\n        self.assertFalse(pd.api.types.is_float_dtype(df['b']))\n        self.assertTrue(pd.api.types.is_float_dtype(df['c']))\n\n    def test_list_values_different_length(self):\n        d = {'a': [1, 2], 'b': ['x'], 'c': [3.5, 4.5]}\n        df = task_func(d)\n        self.assertTrue(df.empty)\n\n    def test_invalid_value(self):\n        d = {'a': 1, 'b': {'nested': 2}}\n        df = task_func(d)\n        self.assertTrue(df.empty)\n\n    def test_integer_column_converted_to_float(self):\n        d = {'a': [1, 2, 3], 'b': ['x', 'y', 'z']}\n        df = task_func(d)\n        self.assertTrue(pd.api.types.is_float_dtype(df['a']))\n        self.assertFalse(pd.api.types.is_float_dtype(df['b']))\n\n    def test_mixed_numeric_types(self):\n        d = {'a': [1, 2.5, 3], 'b': ['x', 'y', 'z']}\n        df = task_func(d)\n        self.assertTrue(pd.api.types.is_float_dtype(df['a']))\n        self.assertFalse(pd.api.types.is_float_dtype(df['b']))\n\n    def test_single_integer_value(self):\n        d = {'a': 5, 'b': 'test'}\n        df = task_func(d)\n        self.assertEqual(df.shape, (1, 2))\n        self.assertTrue(pd.api.types.is_float_dtype(df['a']))\n        self.assertFalse(pd.api.types.is_float_dtype(df['b']))\n        self.assertEqual(df.iloc[0]['a'], 5.0)\n        self.assertEqual(df.iloc[0]['b'], 'test')\n",
        "code": "import pandas as pd\nimport unittest\n\n# The task_func now takes the normalized dictionary as input and returns a DataFrame\n# per the requirement of this round.\ndef task_func(normalized_dict):\n    if not isinstance(normalized_dict, dict) or not normalized_dict:\n        return pd.DataFrame()\n\n    # Return empty DataFrame if any value is a dict (nested dict not allowed)\n    for v in normalized_dict.values():\n        if isinstance(v, dict):\n            return pd.DataFrame()\n\n    # Determine target length for DataFrame rows\n    lengths = []\n    for v in normalized_dict.values():\n        if isinstance(v, list):\n            lengths.append(len(v))\n\n    if lengths:\n        target_len = lengths[0]\n        # If lists have different lengths, return empty DataFrame\n        if any(length != target_len for length in lengths):\n            return pd.DataFrame()\n    else:\n        target_len = 1  # All single values\n\n    # Broadcast single values to lists of target_len\n    normalized_data = {}\n    for k, v in normalized_dict.items():\n        if isinstance(v, list):\n            normalized_data[k] = v\n        else:\n            normalized_data[k] = [v] * target_len\n\n    try:\n        df = pd.DataFrame(normalized_data)\n        # Convert numerical columns to float, keep others unchanged\n        for col in df.columns:\n            if pd.api.types.is_numeric_dtype(df[col]):\n                df[col] = df[col].astype(float)\n        return df\n    except Exception:\n        return pd.DataFrame()\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 59,
    "task_id": "BigCodeBench/461",
    "mt_data": [
      {
        "task_id": "BigCodeBench/461_1",
        "turn": "1",
        "instruct_prompt": "Write a function that checks if a given bash script path exists and then executes it in a subprocess. You should write self-contained code starting with:\n```\nimport subprocess\nimport os\nimport psutil\nimport time\n\ndef task_func(script_path: str, timeout=10) -> dict:\n```",
        "test": "import unittest\nimport tempfile\nimport os\nimport stat\n\nclass TestCases(unittest.TestCase):\n    def test_script_exists_and_runs_successfully(self):\n        with tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.sh') as f:\n            f.write('#!/bin/bash\\necho Hello World')\n            script_path = f.name\n        os.chmod(script_path, stat.S_IRWXU)\n\n        result = task_func(script_path)\n        os.remove(script_path)\n\n        self.assertTrue(result[\"success\"])\n        self.assertEqual(result[\"returncode\"], 0)\n        self.assertIn(\"Hello World\", result[\"stdout\"])\n        self.assertEqual(result[\"stderr\"], \"\")\n\n    def test_script_does_not_exist(self):\n        result = task_func(\"/non/existent/script.sh\")\n        self.assertFalse(result[\"success\"])\n        self.assertIn(\"does not exist\", result[\"error\"])\n\n    def test_script_with_error(self):\n        with tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.sh') as f:\n            f.write('#!/bin/bash\\nexit 1')\n            script_path = f.name\n        os.chmod(script_path, stat.S_IRWXU)\n\n        result = task_func(script_path)\n        os.remove(script_path)\n\n        self.assertFalse(result[\"success\"])\n        self.assertEqual(result[\"returncode\"], 1)\n\n    def test_script_timeout(self):\n        with tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.sh') as f:\n            f.write('#!/bin/bash\\nsleep 5')\n            script_path = f.name\n        os.chmod(script_path, stat.S_IRWXU)\n\n        result = task_func(script_path, timeout=1)\n        os.remove(script_path)\n\n        self.assertFalse(result[\"success\"])\n        self.assertIn(\"Timeout reached\", result[\"error\"])\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import subprocess\nimport os\nimport psutil\nimport time\n\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.isfile(script_path):\n        return {\"success\": False, \"error\": \"Script file does not exist.\"}\n\n    try:\n        proc = subprocess.Popen([\"/bin/bash\", script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n        start_time = time.time()\n        while True:\n            if proc.poll() is not None:\n                break\n            if time.time() - start_time > timeout:\n                parent = psutil.Process(proc.pid)\n                for child in parent.children(recursive=True):\n                    child.terminate()\n                parent.terminate()\n                return {\"success\": False, \"error\": \"Timeout reached, process terminated.\"}\n            time.sleep(0.1)\n\n        stdout, stderr = proc.communicate()\n        return {\n            \"success\": proc.returncode == 0,\n            \"returncode\": proc.returncode,\n            \"stdout\": stdout.decode(),\n            \"stderr\": stderr.decode()\n        }\n    except Exception as e:\n        return {\"success\": False, \"error\": str(e)}\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/461_2",
        "turn": "2",
        "instruct_prompt": "Monitor the subprocess while it runs and accumulate the CPU usage percentage of the script's process until it finishes or the timeout is reached.",
        "test": "import unittest\nimport tempfile\nimport os\nimport time\nfrom threading import Thread\n\nclass TestCases(unittest.TestCase):\n    def test_cpu_usage_accumulation(self):\n        # Create a simple script that runs some CPU work for ~2 seconds\n        script_content = \"\"\"\n        #!/bin/bash\n        end=$((SECONDS+2))\n        while [ $SECONDS -lt $end ]; do\n            : # busy wait\n        done\n        \"\"\"\n\n        with tempfile.NamedTemporaryFile('w', delete=False) as f:\n            f.write(script_content)\n            script_path = f.name\n\n        os.chmod(script_path, 0o755)\n\n        result = task_func(script_path, timeout=5)\n\n        os.unlink(script_path)\n\n        self.assertTrue(result[\"success\"])\n        self.assertIn(\"cpu_usage_accumulated\", result)\n        # Since the script runs busy loop for ~2 seconds, cpu usage accumulated should be > 0\n        self.assertGreater(result[\"cpu_usage_accumulated\"], 0)\n\n    def test_timeout_and_cpu_usage(self):\n        # Create a script that runs longer than timeout\n        script_content = \"\"\"\n        #!/bin/bash\n        sleep 10\n        \"\"\"\n\n        with tempfile.NamedTemporaryFile('w', delete=False) as f:\n            f.write(script_content)\n            script_path = f.name\n\n        os.chmod(script_path, 0o755)\n\n        result = task_func(script_path, timeout=1)\n\n        os.unlink(script_path)\n\n        self.assertFalse(result[\"success\"])\n        self.assertIn(\"Timeout reached\", result[\"error\"])\n        self.assertIn(\"cpu_usage_accumulated\", result)\n        # CPU usage accumulated should be >= 0 (likely very small since sleeping)\n        self.assertGreaterEqual(result[\"cpu_usage_accumulated\"], 0)\n\n    def test_nonexistent_script(self):\n        result = task_func(\"/nonexistent/path/script.sh\")\n        self.assertFalse(result[\"success\"])\n        self.assertIn(\"Script file does not exist\", result[\"error\"])\n",
        "code": "import subprocess\nimport os\nimport psutil\nimport time\n\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.isfile(script_path):\n        return {\"success\": False, \"error\": \"Script file does not exist.\"}\n\n    try:\n        proc = subprocess.Popen([\"/bin/bash\", script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        ps_proc = psutil.Process(proc.pid)\n\n        start_time = time.time()\n        cpu_usage_accumulated = 0.0\n        # Initialize cpu_percent measurement\n        ps_proc.cpu_percent(interval=None)\n\n        while True:\n            if proc.poll() is not None:\n                break\n            if time.time() - start_time > timeout:\n                # terminate process and its children\n                parent = psutil.Process(proc.pid)\n                for child in parent.children(recursive=True):\n                    child.terminate()\n                parent.terminate()\n                return {\"success\": False, \"error\": \"Timeout reached, process terminated.\", \"cpu_usage_accumulated\": cpu_usage_accumulated}\n\n            # accumulate cpu usage since last call\n            cpu_usage_accumulated += ps_proc.cpu_percent(interval=0.1) / 100.0\n\n        # After process ends, get final output\n        stdout, stderr = proc.communicate()\n\n        return {\n            \"success\": proc.returncode == 0,\n            \"returncode\": proc.returncode,\n            \"stdout\": stdout.decode(),\n            \"stderr\": stderr.decode(),\n            \"cpu_usage_accumulated\": cpu_usage_accumulated\n        }\n\n    except Exception as e:\n        return {\"success\": False, \"error\": str(e)}\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/461_3",
        "turn": "3",
        "instruct_prompt": "Accumulate the memory usage in bytes (RSS) of the script's process over its execution time and sum these increments until the subprocess ends or the timeout occurs.",
        "test": "import unittest\nimport tempfile\nimport os\nimport time\nimport signal\n\nclass TestCases(unittest.TestCase):\n    def test_memory_accumulation_basic(self):\n        # Create a simple script that allocates some memory and sleeps\n        script_content = \"\"\"\n        #!/bin/bash\n        python3 -c 'a = []\nimport time\nfor i in range(5):\n    a.append(\"x\"*1000000)  # allocate ~1MB per iteration\n    time.sleep(0.2)'\n        \"\"\"\n        with tempfile.NamedTemporaryFile(\"w\", delete=False) as tf:\n            tf.write(script_content)\n            tf.flush()\n            os.chmod(tf.name, 0o755)\n            result = task_func(tf.name, timeout=3)\n        os.unlink(tf.name)\n\n        self.assertTrue(result[\"success\"] or (not result[\"success\"] and \"Timeout\" in result.get(\"error\", \"\")))\n        self.assertIn(\"memory_usage_accumulated\", result)\n        self.assertIsInstance(result[\"memory_usage_accumulated\"], int)\n        self.assertGreaterEqual(result[\"memory_usage_accumulated\"], 0)\n\n    def test_timeout_terminates_process(self):\n        # Script that runs longer than timeout\n        script_content = \"\"\"\n        #!/bin/bash\n        sleep 5\n        \"\"\"\n        with tempfile.NamedTemporaryFile(\"w\", delete=False) as tf:\n            tf.write(script_content)\n            tf.flush()\n            os.chmod(tf.name, 0o755)\n            result = task_func(tf.name, timeout=1)\n        os.unlink(tf.name)\n\n        self.assertFalse(result[\"success\"])\n        self.assertIn(\"Timeout\", result.get(\"error\", \"\"))\n        self.assertIn(\"memory_usage_accumulated\", result)\n        self.assertIsInstance(result[\"memory_usage_accumulated\"], int)\n\n    def test_nonexistent_script(self):\n        result = task_func(\"/path/to/nonexistent/script.sh\")\n        self.assertFalse(result[\"success\"])\n        self.assertIn(\"Script file does not exist\", result.get(\"error\", \"\"))\n\n    def test_cpu_and_memory_keys_present(self):\n        # Simple quick script\n        script_content = \"\"\"\n        #!/bin/bash\n        echo Hello\n        \"\"\"\n        with tempfile.NamedTemporaryFile(\"w\", delete=False) as tf:\n            tf.write(script_content)\n            tf.flush()\n            os.chmod(tf.name, 0o755)\n            result = task_func(tf.name, timeout=2)\n        os.unlink(tf.name)\n\n        self.assertIn(\"cpu_usage_accumulated\", result)\n        self.assertIn(\"memory_usage_accumulated\", result)\n        self.assertIsInstance(result[\"cpu_usage_accumulated\"], float)\n        self.assertIsInstance(result[\"memory_usage_accumulated\"], int)\n",
        "code": "import subprocess\nimport os\nimport psutil\nimport time\n\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.isfile(script_path):\n        return {\"success\": False, \"error\": \"Script file does not exist.\"}\n\n    try:\n        proc = subprocess.Popen([\"/bin/bash\", script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        ps_proc = psutil.Process(proc.pid)\n\n        start_time = time.time()\n        cpu_usage_accumulated = 0.0\n        memory_usage_accumulated = 0\n\n        # Initialize cpu_percent measurement\n        ps_proc.cpu_percent(interval=None)\n\n        while True:\n            if proc.poll() is not None:\n                break\n            if time.time() - start_time > timeout:\n                # terminate process and its children\n                parent = psutil.Process(proc.pid)\n                for child in parent.children(recursive=True):\n                    child.terminate()\n                parent.terminate()\n                return {\"success\": False, \"error\": \"Timeout reached, process terminated.\", \"cpu_usage_accumulated\": cpu_usage_accumulated, \"memory_usage_accumulated\": memory_usage_accumulated}\n\n            # accumulate cpu usage since last call\n            cpu_usage_accumulated += ps_proc.cpu_percent(interval=0.1) / 100.0\n\n            # accumulate memory usage (RSS in bytes)\n            try:\n                mem_info = ps_proc.memory_info()\n                memory_usage_accumulated += mem_info.rss\n            except psutil.NoSuchProcess:\n                # process ended during memory info retrieval\n                break\n\n        # After process ends, get final output\n        stdout, stderr = proc.communicate()\n\n        return {\n            \"success\": proc.returncode == 0,\n            \"returncode\": proc.returncode,\n            \"stdout\": stdout.decode(),\n            \"stderr\": stderr.decode(),\n            \"cpu_usage_accumulated\": cpu_usage_accumulated,\n            \"memory_usage_accumulated\": memory_usage_accumulated\n        }\n\n    except Exception as e:\n        return {\"success\": False, \"error\": str(e)}\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/461_4",
        "turn": "4",
        "instruct_prompt": "Handle cases where the subprocess process is not found or becomes a zombie, and ensure the subprocess is terminated if it runs beyond the specified timeout.",
        "test": "import unittest\nimport tempfile\nimport os\nimport textwrap\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Simple success script\n        self.success_script = tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.sh')\n        self.success_script.write('#!/bin/bash\\necho Hello World\\n')\n        self.success_script.close()\n        os.chmod(self.success_script.name, 0o755)\n\n        # Script that sleeps longer than timeout\n        self.sleep_script = tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.sh')\n        self.sleep_script.write('#!/bin/bash\\nsleep 5\\necho Slept\\n')\n        self.sleep_script.close()\n        os.chmod(self.sleep_script.name, 0o755)\n\n        # Python script that creates a persistent zombie child process\n        # The child is a direct child of the python process and exits immediately\n        # The parent sleeps to keep zombie alive\n        zombie_py = textwrap.dedent('''\n            import os\n            import time\n\n            def create_persistent_zombie():\n                pid = os.fork()\n                if pid > 0:\n                    # Parent sleeps longer than child exit so zombie persists\n                    time.sleep(5)\n                else:\n                    # Child exits immediately\n                    os._exit(0)\n\n            if __name__ == '__main__':\n                create_persistent_zombie()\n        ''')\n\n        self.zombie_script = tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.py')\n        self.zombie_script.write(zombie_py)\n        self.zombie_script.close()\n        os.chmod(self.zombie_script.name, 0o755)\n\n    def tearDown(self):\n        os.unlink(self.success_script.name)\n        os.unlink(self.sleep_script.name)\n        os.unlink(self.zombie_script.name)\n\n    def test_successful_execution(self):\n        result = task_func(self.success_script.name, timeout=3)\n        self.assertTrue(result.get('success'), f\"Failed with output: {result}\")\n        self.assertIn('Hello World', result.get('stdout', ''))\n        self.assertEqual(result.get('returncode'), 0)\n\n    def test_timeout_termination(self):\n        result = task_func(self.sleep_script.name, timeout=1)\n        self.assertFalse(result.get('success'))\n        self.assertIn('Timeout reached', result.get('error', ''))\n\n    def test_subprocess_not_found(self):\n        import unittest.mock as mock\n        import psutil\n        with mock.patch('psutil.Process', side_effect=psutil.NoSuchProcess(99999)):\n            result = task_func(self.success_script.name)\n            self.assertFalse(result.get('success'))\n            self.assertIn('Subprocess not found', result.get('error', ''))\n\n    def test_process_becomes_zombie(self):\n        # Run the python zombie script using bash -c 'python3 script'\n        wrapper_script = tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.sh')\n        wrapper_script.write(f\"#!/bin/bash\\npython3 '{self.zombie_script.name}'\\n\")\n        wrapper_script.close()\n        os.chmod(wrapper_script.name, 0o755)\n\n        result = task_func(wrapper_script.name, timeout=10)\n\n        os.unlink(wrapper_script.name)\n\n        self.assertFalse(result.get('success'), f\"Expected zombie detection failure but got: {result}\")\n        self.assertIn('Process became a zombie', result.get('error', ''))\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import subprocess\nimport os\nimport psutil\nimport time\nimport signal\n\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.isfile(script_path):\n        return {\"success\": False, \"error\": \"Script file does not exist.\"}\n\n    try:\n        # Start subprocess in its own process group to allow group termination\n        proc = subprocess.Popen([\"/bin/bash\", script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE, preexec_fn=os.setsid)\n\n        try:\n            ps_proc = psutil.Process(proc.pid)\n        except psutil.NoSuchProcess:\n            proc.terminate()\n            return {\"success\": False, \"error\": \"Subprocess not found after start.\"}\n\n        start_time = time.time()\n        cpu_usage_accumulated = 0.0\n        memory_usage_accumulated = 0\n\n        # Initialize cpu_percent measurement\n        ps_proc.cpu_percent(interval=None)\n\n        zombie_detected_time = None\n        zombie_grace_period = 0.5  # seconds\n\n        while True:\n            if proc.poll() is not None:\n                # Process ended\n                break\n\n            # Check timeout\n            if time.time() - start_time > timeout:\n                try:\n                    os.killpg(os.getpgid(proc.pid), signal.SIGTERM)\n                except Exception:\n                    pass\n                return {\"success\": False, \"error\": \"Timeout reached, process terminated.\", \"cpu_usage_accumulated\": cpu_usage_accumulated, \"memory_usage_accumulated\": memory_usage_accumulated}\n\n            # Check zombie status recursively for all descendants\n            try:\n                descendants = ps_proc.children(recursive=True)\n                processes_to_check = [ps_proc] + descendants\n            except psutil.NoSuchProcess:\n                break\n\n            zombie_found = False\n            for p in processes_to_check:\n                try:\n                    if p.status() == psutil.STATUS_ZOMBIE:\n                        zombie_found = True\n                        break\n                except (psutil.NoSuchProcess, psutil.AccessDenied):\n                    continue\n\n            if zombie_found:\n                if zombie_detected_time is None:\n                    zombie_detected_time = time.time()  # start grace period\n                elif time.time() - zombie_detected_time >= zombie_grace_period:\n                    # Persistent zombie detected, terminate\n                    try:\n                        os.killpg(os.getpgid(proc.pid), signal.SIGTERM)\n                    except Exception:\n                        pass\n                    return {\"success\": False, \"error\": \"Process became a zombie and was terminated.\", \"cpu_usage_accumulated\": cpu_usage_accumulated, \"memory_usage_accumulated\": memory_usage_accumulated}\n            else:\n                zombie_detected_time = None  # reset if no zombie currently\n\n            # accumulate cpu usage since last call\n            try:\n                cpu_usage_accumulated += ps_proc.cpu_percent(interval=0.1) / 100.0\n            except psutil.NoSuchProcess:\n                break\n\n            # accumulate memory usage (RSS in bytes)\n            try:\n                mem_info = ps_proc.memory_info()\n                memory_usage_accumulated += mem_info.rss\n            except psutil.NoSuchProcess:\n                break\n\n            time.sleep(0.05)  # small sleep to reduce CPU usage\n\n        # After process ends, get final output\n        stdout, stderr = proc.communicate()\n\n        return {\n            \"success\": proc.returncode == 0,\n            \"returncode\": proc.returncode,\n            \"stdout\": stdout.decode(errors='replace'),\n            \"stderr\": stderr.decode(errors='replace'),\n            \"cpu_usage_accumulated\": cpu_usage_accumulated,\n            \"memory_usage_accumulated\": memory_usage_accumulated\n        }\n\n    except Exception as e:\n        return {\"success\": False, \"error\": str(e)}\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/461_5",
        "turn": "5",
        "instruct_prompt": "Return a dictionary containing the total accumulated CPU usage (as a percentage) and total accumulated memory usage (in bytes) of the script's process under the keys 'CPU Usage' and 'Memory Usage'.",
        "test": "import unittest\nimport tempfile\nimport os\nimport stat\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary bash script that consumes some CPU and memory\n        self.script_file = tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.sh')\n        # This script will run a loop to consume CPU and allocate some memory\n        self.script_file.write('#!/bin/bash\\n'\n                               'arr=()\\n'\n                               'for i in {1..5}; do\\n'\n                               '  arr+=(\"$i\")\\n'\n                               '  sleep 0.2\\n'\n                               'done\\n')\n        self.script_file.close()\n        # Make it executable\n        os.chmod(self.script_file.name, os.stat(self.script_file.name).st_mode | stat.S_IEXEC)\n\n    def tearDown(self):\n        os.unlink(self.script_file.name)\n\n    def test_cpu_and_memory_usage_keys(self):\n        result = task_func(self.script_file.name, timeout=3)\n        self.assertIn('CPU Usage', result)\n        self.assertIn('Memory Usage', result)\n\n    def test_cpu_usage_type_and_value(self):\n        result = task_func(self.script_file.name, timeout=3)\n        self.assertIsInstance(result.get('CPU Usage'), float)\n        # The CPU usage should be non-negative\n        self.assertGreaterEqual(result.get('CPU Usage'), 0.0)\n\n    def test_memory_usage_type_and_value(self):\n        result = task_func(self.script_file.name, timeout=3)\n        self.assertIsInstance(result.get('Memory Usage'), int)\n        # Memory usage should be non-negative\n        self.assertGreaterEqual(result.get('Memory Usage'), 0)\n\n    def test_success_key(self):\n        result = task_func(self.script_file.name, timeout=3)\n        self.assertIn('success', result)\n        self.assertIsInstance(result['success'], bool)\n\n    def test_nonexistent_script(self):\n        result = task_func('/nonexistent/path/to/script.sh')\n        self.assertFalse(result['success'])\n        self.assertIn('error', result)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import subprocess\nimport os\nimport psutil\nimport time\nimport signal\n\ndef task_func(script_path: str, timeout=10) -> dict:\n    if not os.path.isfile(script_path):\n        return {\"success\": False, \"error\": \"Script file does not exist.\"}\n\n    try:\n        # Start subprocess in its own process group to allow group termination\n        proc = subprocess.Popen([\"/bin/bash\", script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE, preexec_fn=os.setsid)\n\n        try:\n            ps_proc = psutil.Process(proc.pid)\n        except psutil.NoSuchProcess:\n            proc.terminate()\n            return {\"success\": False, \"error\": \"Subprocess not found after start.\"}\n\n        start_time = time.time()\n        cpu_usage_accumulated = 0.0\n        memory_usage_accumulated = 0\n\n        # Initialize cpu_percent measurement\n        ps_proc.cpu_percent(interval=None)\n\n        zombie_detected_time = None\n        zombie_grace_period = 0.5  # seconds\n\n        while True:\n            if proc.poll() is not None:\n                # Process ended\n                break\n\n            # Check timeout\n            if time.time() - start_time > timeout:\n                try:\n                    os.killpg(os.getpgid(proc.pid), signal.SIGTERM)\n                except Exception:\n                    pass\n                return {\"success\": False, \"error\": \"Timeout reached, process terminated.\"}\n\n            # Check zombie status recursively for all descendants\n            try:\n                descendants = ps_proc.children(recursive=True)\n                processes_to_check = [ps_proc] + descendants\n            except psutil.NoSuchProcess:\n                break\n\n            zombie_found = False\n            for p in processes_to_check:\n                try:\n                    if p.status() == psutil.STATUS_ZOMBIE:\n                        zombie_found = True\n                        break\n                except (psutil.NoSuchProcess, psutil.AccessDenied):\n                    continue\n\n            if zombie_found:\n                if zombie_detected_time is None:\n                    zombie_detected_time = time.time()  # start grace period\n                elif time.time() - zombie_detected_time >= zombie_grace_period:\n                    # Persistent zombie detected, terminate\n                    try:\n                        os.killpg(os.getpgid(proc.pid), signal.SIGTERM)\n                    except Exception:\n                        pass\n                    return {\"success\": False, \"error\": \"Process became a zombie and was terminated.\"}\n            else:\n                zombie_detected_time = None  # reset if no zombie currently\n\n            # accumulate cpu usage since last call\n            try:\n                cpu_usage_accumulated += ps_proc.cpu_percent(interval=0.1) / 100.0\n            except psutil.NoSuchProcess:\n                break\n\n            # accumulate memory usage (RSS in bytes)\n            try:\n                mem_info = ps_proc.memory_info()\n                memory_usage_accumulated += mem_info.rss\n            except psutil.NoSuchProcess:\n                break\n\n            time.sleep(0.05)  # small sleep to reduce CPU usage\n\n        # After process ends, get final output\n        proc.communicate()\n\n        return {\n            \"success\": proc.returncode == 0,\n            \"CPU Usage\": cpu_usage_accumulated * 100.0,  # convert back to percentage\n            \"Memory Usage\": memory_usage_accumulated\n        }\n\n    except Exception as e:\n        return {\"success\": False, \"error\": str(e)}\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 60,
    "task_id": "BigCodeBench/477",
    "mt_data": [
      {
        "task_id": "BigCodeBench/477_1",
        "turn": "1",
        "instruct_prompt": "Create a DataFrame with a given number of rows (N) and 3 columns: \"x\", \"y\", and \"category\". Columns \"x\" and \"y\" should contain random values. You should write self-contained code starting with:```import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_dataframe_structure_and_content(self):\n        N = 50\n        CATEGORIES = [\"A\", \"B\", \"C\"]\n        df = task_func(N=N, CATEGORIES=CATEGORIES, seed=123)\n        # Check type\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check shape\n        self.assertEqual(df.shape, (N, 3))\n        # Check columns\n        self.assertListEqual(list(df.columns), [\"x\", \"y\", \"category\"])\n        # Check x and y are floats and within [0,1]\n        self.assertTrue((df[\"x\"] >= 0).all() and (df[\"x\"] <= 1).all())\n        self.assertTrue((df[\"y\"] >= 0).all() and (df[\"y\"] <= 1).all())\n        self.assertTrue(pd.api.types.is_float_dtype(df[\"x\"]))\n        self.assertTrue(pd.api.types.is_float_dtype(df[\"y\"]))\n        # Check category values are within CATEGORIES\n        self.assertTrue(set(df[\"category\"]).issubset(set(CATEGORIES)))\n        # Check reproducibility (same seed same output)\n        df2 = task_func(N=N, CATEGORIES=CATEGORIES, seed=123)\n        pd.testing.assert_frame_equal(df, df2)\n",
        "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n    x = np.random.rand(N)\n    y = np.random.rand(N)\n    category = np.random.choice(CATEGORIES, size=N)\n    df = pd.DataFrame({\"x\": x, \"y\": y, \"category\": category})\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/477_2",
        "turn": "2",
        "instruct_prompt": "Fill the \"category\" column with random categories from the given CATEGORIES list. If N is greater than or equal to the number of categories, ensure each category appears at least once. Otherwise, sample categories randomly without replacement from CATEGORIES.",
        "test": "import unittest\nfrom collections import Counter\n\nclass TestCases(unittest.TestCase):\n    def test_categories_all_present_when_N_ge_len_categories(self):\n        CATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n        N = 10\n        df = task_func(N=N, CATEGORIES=CATEGORIES, seed=123)\n        counts = Counter(df[\"category\"])\n        # Check each category appears at least once\n        for cat in CATEGORIES:\n            self.assertIn(cat, counts)\n            self.assertGreaterEqual(counts[cat], 1)\n        # Check total rows\n        self.assertEqual(len(df), N)\n\n    def test_categories_sampled_without_replacement_when_N_less_than_len_categories(self):\n        CATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n        N = 3\n        df = task_func(N=N, CATEGORIES=CATEGORIES, seed=123)\n        categories_returned = df[\"category\"].tolist()\n        # Check length\n        self.assertEqual(len(categories_returned), N)\n        # Check all categories are unique\n        self.assertEqual(len(set(categories_returned)), N)\n        # Check all categories are from CATEGORIES\n        for cat in categories_returned:\n            self.assertIn(cat, CATEGORIES)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n    x = np.random.rand(N)\n    y = np.random.rand(N)\n    if N >= len(CATEGORIES):\n        # Ensure each category appears at least once\n        category = list(CATEGORIES)\n        remaining = N - len(CATEGORIES)\n        if remaining > 0:\n            category += list(np.random.choice(CATEGORIES, size=remaining, replace=True))\n        np.random.shuffle(category)\n    else:\n        # Sample without replacement\n        category = list(np.random.choice(CATEGORIES, size=N, replace=False))\n    df = pd.DataFrame({\"x\": x, \"y\": y, \"category\": category})\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/477_3",
        "turn": "3",
        "instruct_prompt": "Draw a scatter plot of \"x\" vs \"y\", coloring the points by their \"category\" values, and return a tuple containing the generated DataFrame and the Axes object of the scatter plot.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.collections import PathCollection\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_output(self):\n        df, ax = task_func(N=50, CATEGORIES=[\"A\", \"B\", \"C\"], seed=1)\n        # Check type of df\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check required columns\n        self.assertTrue(all(col in df.columns for col in [\"x\", \"y\", \"category\"]))\n        # Check length of df\n        self.assertEqual(len(df), 50)\n        # Check that category column only contains given categories\n        self.assertTrue(set(df[\"category\"]).issubset({\"A\", \"B\", \"C\"}))\n\n        # Check that returned ax is a matplotlib Axes object\n        self.assertTrue(hasattr(ax, \"scatter\"))\n        self.assertEqual(ax.get_xlabel(), \"x\")\n        self.assertEqual(ax.get_ylabel(), \"y\")\n        self.assertEqual(ax.get_title(), \"Scatter plot of x vs y colored by category\")\n\n    def test_scatter_colors_by_category(self):\n        df, ax = task_func(N=30, CATEGORIES=[\"X\", \"Y\"], seed=123)\n        # Extract scatter collections from axes\n        collections = [coll for coll in ax.collections if isinstance(coll, PathCollection)]\n        self.assertTrue(len(collections) >= 1)\n        scatter = collections[0]\n        # The array of colors used for scatter points (mapped from category codes)\n        colors = scatter.get_array()\n        self.assertEqual(len(colors), 30)\n        # Check that colors correspond to category codes\n        cat_codes = pd.Categorical(df[\"category\"]).codes\n        self.assertTrue((colors == cat_codes).all())\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    np.random.seed(seed)\n    x = np.random.rand(N)\n    y = np.random.rand(N)\n    if N >= len(CATEGORIES):\n        # Ensure each category appears at least once\n        category = list(CATEGORIES)\n        remaining = N - len(CATEGORIES)\n        if remaining > 0:\n            category += list(np.random.choice(CATEGORIES, size=remaining, replace=True))\n        np.random.shuffle(category)\n    else:\n        # Sample without replacement\n        category = list(np.random.choice(CATEGORIES, size=N, replace=False))\n    df = pd.DataFrame({\"x\": x, \"y\": y, \"category\": category})\n\n    fig, ax = plt.subplots()\n    scatter = ax.scatter(df[\"x\"], df[\"y\"], c=pd.Categorical(df[\"category\"]).codes, cmap='viridis')\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n    ax.set_title(\"Scatter plot of x vs y colored by category\")\n\n    # Create legend with category labels\n    handles, _ = scatter.legend_elements()\n    ax.legend(handles, sorted(df[\"category\"].unique()), title=\"category\")\n\n    return df, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 61,
    "task_id": "BigCodeBench/486",
    "mt_data": [
      {
        "task_id": "BigCodeBench/486_1",
        "turn": "1",
        "instruct_prompt": "Generate a time series of values sampled from a normal distribution between a given start time and end time at fixed intervals specified by step. You should write self-contained code starting with:\n```\nfrom datetime import datetime\nimport pandas as pd\nimport numpy as np\ndef task_func(start_time, end_time, step, trend, seed=42):\n```",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_basic_output(self):\n        start = datetime(2023, 1, 1, 0, 0, 0)\n        end = datetime(2023, 1, 1, 0, 0, 10)\n        step = '2S'  # 2 seconds\n        trend = 5\n        series = task_func(start, end, step, trend, seed=123)\n        self.assertIsInstance(series, pd.Series)\n        self.assertTrue((series.index >= start).all())\n        self.assertTrue((series.index <= end).all())\n        # Check that values roughly center around trend\n        self.assertTrue((series.values > trend - 4).all() or (series.values < trend + 4).all())\n        # Check correct number of samples\n        expected_len = len(pd.date_range(start=start, end=end, freq=step))\n        self.assertEqual(len(series), expected_len)\n\n    def test_seed_consistency(self):\n        start = datetime(2023, 1, 1)\n        end = datetime(2023, 1, 1, 0, 0, 5)\n        step = '1S'\n        trend = 0\n        s1 = task_func(start, end, step, trend, seed=999)\n        s2 = task_func(start, end, step, trend, seed=999)\n        # With the same seed, outputs should be identical\n        pd.testing.assert_series_equal(s1, s2)\n\n    def test_empty_range(self):\n        start = datetime(2023, 1, 2)\n        end = datetime(2023, 1, 1)\n        step = '1S'\n        trend = 0\n        series = task_func(start, end, step, trend)\n        self.assertEqual(len(series), 0)\n\n    def test_single_point(self):\n        start = datetime(2023, 1, 1)\n        end = datetime(2023, 1, 1)\n        step = '1S'\n        trend = 10\n        series = task_func(start, end, step, trend)\n        self.assertEqual(len(series), 1)\n        self.assertAlmostEqual(series.iloc[0], 10, delta=5)  # Because of randomness\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\n\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n    # Generate datetime range with given step\n    times = pd.date_range(start=start_time, end=end_time, freq=step)\n    # Generate normal distributed values with mean=trend and std=1\n    values = np.random.normal(loc=trend, scale=1, size=len(times))\n    # Create a pandas Series with datetime index\n    return pd.Series(data=values, index=times)",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/486_2",
        "turn": "2",
        "instruct_prompt": "Add a linear trend to the generated normal-distributed values, where the trend parameter scales the incremental increase per step index.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_linear_trend_added(self):\n        start_time = '2023-01-01'\n        end_time = '2023-01-01 00:00:09'\n        step = '1s'\n        trend = 0.5\n        seed = 123\n        result = task_func(start_time, end_time, step, trend, seed)\n        # Check length\n        self.assertEqual(len(result), 10)\n        # Check index type\n        self.assertIsInstance(result.index, pd.DatetimeIndex)\n        # Manually compute expected trend component\n        expected_trend = trend * np.arange(10)\n        # Generate normal values separately with same seed\n        np.random.seed(seed)\n        expected_normal = np.random.normal(loc=0, scale=1, size=10)\n        expected_values = expected_normal + expected_trend\n        # Assert all values close\n        np.testing.assert_allclose(result.values, expected_values, rtol=1e-7, atol=1e-7)\n\n    def test_zero_trend(self):\n        start_time = '2023-01-01'\n        end_time = '2023-01-01 00:00:04'\n        step = '1s'\n        trend = 0\n        seed = 42\n        result = task_func(start_time, end_time, step, trend, seed)\n        # Without trend, values should be normal with mean ~0\n        np.random.seed(seed)\n        expected_values = np.random.normal(loc=0, scale=1, size=5)\n        np.testing.assert_allclose(result.values, expected_values, rtol=1e-7, atol=1e-7)\n\n    def test_negative_trend(self):\n        start_time = '2023-01-01'\n        end_time = '2023-01-01 00:00:04'\n        step = '1s'\n        trend = -1\n        seed = 0\n        result = task_func(start_time, end_time, step, trend, seed)\n        np.random.seed(seed)\n        expected_normal = np.random.normal(loc=0, scale=1, size=5)\n        expected_trend = trend * np.arange(5)\n        expected_values = expected_normal + expected_trend\n        np.testing.assert_allclose(result.values, expected_values, rtol=1e-7, atol=1e-7)\n",
        "code": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\n\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n    # Generate datetime range with given step\n    times = pd.date_range(start=start_time, end=end_time, freq=step)\n    # Generate normal distributed values with mean=0 and std=1\n    values = np.random.normal(loc=0, scale=1, size=len(times))\n    # Add linear trend scaled by step index\n    trend_values = trend * np.arange(len(times))\n    values = values + trend_values\n    # Create a pandas Series with datetime index\n    return pd.Series(data=values, index=times)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/486_3",
        "turn": "3",
        "instruct_prompt": "Convert the timestamps (in milliseconds since epoch) to formatted datetime strings in the format '%Y-%m-%d %H:%M:%S.%f' and store them as the 'Time' column in a pandas DataFrame along with the corresponding values.",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_format_and_values(self):\n        df = task_func('2023-01-01 00:00:00', '2023-01-01 00:00:05', '2S', 0.5, seed=0)\n        # Check if DataFrame has correct columns\n        self.assertListEqual(list(df.columns), ['Time', 'Value'])\n        # Check if 'Time' column entries are strings formatted as '%Y-%m-%d %H:%M:%S.%f'\n        for time_str in df['Time']:\n            try:\n                dt = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S.%f')\n            except ValueError:\n                self.fail(f\"Time string '{time_str}' is not in the correct format\")\n        # Check the length of DataFrame matches expected number of timestamps\n        expected_len = 3  # from 0 to 5 seconds with 2s step: 0s, 2s, 4s\n        self.assertEqual(len(df), expected_len)\n        # Check that values are floats\n        self.assertTrue(all(isinstance(v, float) for v in df['Value']))\n\n    def test_output_structure(self):\n        df = task_func('2023-01-01 00:00:00', '2023-01-01 00:00:02', '1S', 0)\n        # Check exact times for these timestamps\n        expected_times = ['2023-01-01 00:00:00.000000', '2023-01-01 00:00:01.000000', '2023-01-01 00:00:02.000000']\n        self.assertListEqual(df['Time'].tolist(), expected_times)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\n\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n    # Generate datetime range with given step\n    times = pd.date_range(start=start_time, end=end_time, freq=step)\n    # Convert datetime to timestamps in milliseconds\n    timestamps = (times.view(np.int64) // 10**6).astype(np.int64)\n    # Generate normal distributed values with mean=0 and std=1\n    values = np.random.normal(loc=0, scale=1, size=len(times))\n    # Add linear trend scaled by step index\n    trend_values = trend * np.arange(len(times))\n    values = values + trend_values\n    # Convert timestamps to formatted datetime strings\n    formatted_times = [datetime.fromtimestamp(ts / 1000).strftime('%Y-%m-%d %H:%M:%S.%f') for ts in timestamps]\n    # Create DataFrame with 'Time' and 'Value' columns\n    df = pd.DataFrame({'Time': formatted_times, 'Value': values})\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/486_4",
        "turn": "4",
        "instruct_prompt": "Plot the time series using pandas DataFrame plot method with 'Time' on the x-axis and 'Value' on the y-axis, label the y-axis as 'Value', and return the matplotlib Axes object.",
        "test": "import unittest\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.pyplot as plt\nfrom io import BytesIO\n\nclass TestCases(unittest.TestCase):\n    def test_plot_output(self):\n        start_time = '2023-01-01 00:00:00'\n        end_time = '2023-01-01 00:00:10'\n        step = '2S'\n        trend = 0.1\n\n        ax = task_func(start_time, end_time, step, trend)\n\n        # Check that the returned object is a matplotlib Axes\n        self.assertIsInstance(ax, plt.Axes)\n\n        # Check that x-axis label is 'Time'\n        self.assertEqual(ax.get_xlabel(), 'Time')\n\n        # Check that y-axis label is 'Value'\n        self.assertEqual(ax.get_ylabel(), 'Value')\n\n        # Check that there is at least one line plotted\n        lines = ax.get_lines()\n        self.assertTrue(len(lines) > 0)\n\n        # Check that the data plotted corresponds to the DataFrame values\n        line = lines[0]\n        xdata = line.get_xdata()\n        ydata = line.get_ydata()\n\n        # xdata should be the 'Time' column converted to matplotlib dates\n        # The length should match the number of points\n        self.assertEqual(len(xdata), len(ydata))\n        self.assertGreater(len(xdata), 0)\n\n    def test_plot_returns_axes(self):\n        ax = task_func('2023-01-01', '2023-01-02', '1H', 0.5)\n        self.assertTrue(hasattr(ax, 'plot'))  # Axes object has plot method\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\n\ndef task_func(start_time, end_time, step, trend, seed=42):\n    np.random.seed(seed)\n    # Generate datetime range with given step\n    times = pd.date_range(start=start_time, end=end_time, freq=step)\n    # Convert datetime to timestamps in milliseconds\n    timestamps = (times.view(np.int64) // 10**6).astype(np.int64)\n    # Generate normal distributed values with mean=0 and std=1\n    values = np.random.normal(loc=0, scale=1, size=len(times))\n    # Add linear trend scaled by step index\n    trend_values = trend * np.arange(len(times))\n    values = values + trend_values\n    # Convert timestamps to formatted datetime strings\n    formatted_times = [datetime.fromtimestamp(ts / 1000).strftime('%Y-%m-%d %H:%M:%S.%f') for ts in timestamps]\n    # Create DataFrame with 'Time' and 'Value' columns\n    df = pd.DataFrame({'Time': formatted_times, 'Value': values})\n\n    # Plot using pandas DataFrame plot method\n    ax = df.plot(x='Time', y='Value')\n    ax.set_ylabel('Value')\n    return ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/486_5",
        "turn": "5",
        "instruct_prompt": "Validate that start_time is less than end_time and step is positive, raising ValueError otherwise.",
        "test": "import unittest\nfrom datetime import datetime\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    def test_start_time_not_less_than_end_time(self):\n        start = datetime(2023, 1, 2)\n        end = datetime(2023, 1, 1)\n        with self.assertRaises(ValueError) as cm:\n            task_func(start, end, '1H', trend=0)\n        self.assertEqual(str(cm.exception), \"start_time must be less than end_time\")\n\n    def test_step_not_positive_string(self):\n        start = datetime(2023, 1, 1)\n        end = datetime(2023, 1, 2)\n        with self.assertRaises(ValueError) as cm:\n            task_func(start, end, '0H', trend=0)\n        self.assertEqual(str(cm.exception), \"step must be positive\")\n\n        with self.assertRaises(ValueError) as cm2:\n            task_func(start, end, '0D', trend=0)\n        self.assertEqual(str(cm2.exception), \"step must be positive\")\n\n    def test_step_not_positive_numeric(self):\n        start = datetime(2023, 1, 1)\n        end = datetime(2023, 1, 2)\n        with self.assertRaises(ValueError) as cm:\n            task_func(start, end, 0, trend=0)\n        self.assertEqual(str(cm.exception), \"step must be positive\")\n\n        with self.assertRaises(ValueError) as cm2:\n            task_func(start, end, -1, trend=0)\n        self.assertEqual(str(cm2.exception), \"step must be positive\")\n\n    def test_step_invalid_string(self):\n        start = datetime(2023, 1, 1)\n        end = datetime(2023, 1, 2)\n        with self.assertRaises(ValueError) as cm:\n            task_func(start, end, 'invalid', trend=0)\n        self.assertEqual(str(cm.exception), \"step string is not a valid pandas frequency string\")\n\n    def test_valid_input_string_step(self):\n        start = datetime(2023, 1, 1)\n        end = datetime(2023, 1, 2)\n        ax = task_func(start, end, '1H', trend=0)\n        self.assertIsNotNone(ax)\n\n    def test_valid_input_numeric_step(self):\n        start = datetime(2023, 1, 1)\n        end = datetime(2023, 1, 1, 3)\n        # Numeric step interpreted as seconds for freq\n        # But pandas date_range freq expects string or DateOffset, so this test checks if numeric step works\n        # However, pandas.date_range does NOT accept numeric freq directly, so this test expects failure\n        # So we skip numeric step usage in date_range and only accept string freq\n        # Thus, we won't test numeric step here as per current implementation\n        pass\n",
        "code": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\n\nfrom pandas.tseries.frequencies import to_offset\n\ndef task_func(start_time, end_time, step, trend, seed=42):\n    if start_time >= end_time:\n        raise ValueError(\"start_time must be less than end_time\")\n\n    # Validate step\n    if isinstance(step, str):\n        try:\n            offset = to_offset(step)\n        except ValueError:\n            raise ValueError(\"step string is not a valid pandas frequency string\")\n        if offset.n <= 0:\n            raise ValueError(\"step must be positive\")\n    else:\n        # Assume numeric step\n        if not (isinstance(step, int) or isinstance(step, float)):\n            raise ValueError(\"step must be a string or a positive number\")\n        if step <= 0:\n            raise ValueError(\"step must be positive\")\n\n    np.random.seed(seed)\n    # Generate datetime range with given step\n    times = pd.date_range(start=start_time, end=end_time, freq=step)\n    # Convert datetime to timestamps in milliseconds\n    timestamps = (times.view(np.int64) // 10**6).astype(np.int64)\n    # Generate normal distributed values with mean=0 and std=1\n    values = np.random.normal(loc=0, scale=1, size=len(times))\n    # Add linear trend scaled by step index\n    trend_values = trend * np.arange(len(times))\n    values = values + trend_values\n    # Convert timestamps to formatted datetime strings\n    formatted_times = [datetime.fromtimestamp(ts / 1000).strftime('%Y-%m-%d %H:%M:%S.%f') for ts in timestamps]\n    # Create DataFrame with 'Time' and 'Value' columns\n    df = pd.DataFrame({'Time': formatted_times, 'Value': values})\n\n    # Plot using pandas DataFrame plot method\n    ax = df.plot(x='Time', y='Value')\n    ax.set_ylabel('Value')\n    return ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 62,
    "task_id": "BigCodeBench/492",
    "mt_data": [
      {
        "task_id": "BigCodeBench/492_1",
        "turn": "1",
        "instruct_prompt": "Generate sales data for five products from a given epoch time up to the current time. The function should output a pd.DataFrame containing columns 'Product' (string), 'Date' (datetime), and 'Sales' (integer) with random sales quantity sampled from range [10, 50]. You should write self-contained code starting with:\n```\nimport pandas as pd\nfrom datetime import datetime\nimport random\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic(self):\n        epoch = int((datetime.now() - timedelta(days=2)).timestamp() * 1000)\n        df = task_func(epoch, random_seed=42)\n        # Check type\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check columns\n        self.assertListEqual(list(df.columns), [\"Product\", \"Date\", \"Sales\"])\n        # Check products\n        self.assertTrue(all(p in [\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"] for p in df[\"Product\"].unique()))\n        # Check date range\n        min_date = df[\"Date\"].min()\n        max_date = df[\"Date\"].max()\n        expected_start = datetime.fromtimestamp(epoch / 1000).date()\n        expected_end = datetime.now().date()\n        self.assertEqual(min_date.date(), expected_start)\n        self.assertEqual(max_date.date(), expected_end)\n        # Check sales range\n        self.assertTrue(df[\"Sales\"].between(10, 50).all())\n        # Check number of rows\n        expected_days = (expected_end - expected_start).days + 1\n        expected_rows = expected_days * 5\n        self.assertEqual(len(df), expected_rows)\n",
        "code": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\n\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    end_date = datetime.now()\n    num_days = (end_date - start_date).days + 1\n\n    data = []\n    for product in products:\n        for day_offset in range(num_days):\n            current_date = start_date + timedelta(days=day_offset)\n            sales = random.randint(10, 50)\n            data.append({\"Product\": product, \"Date\": current_date, \"Sales\": sales})\n\n    df = pd.DataFrame(data)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/492_2",
        "turn": "2",
        "instruct_prompt": "Check that the products list contains exactly 5 unique items, otherwise raise a ValueError with message \"Products must contain 5 unique items\".",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def test_valid_products(self):\n        epoch_ms = int(datetime(2023, 1, 1).timestamp() * 1000)\n        products = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n        df = task_func(epoch_ms, random_seed=1, products=products)\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertTrue(all(df[\"Product\"].isin(products)))\n        self.assertEqual(len(set(df[\"Product\"])), 5)\n\n    def test_duplicate_products(self):\n        epoch_ms = int(datetime(2023, 1, 1).timestamp() * 1000)\n        products = [\"A\", \"B\", \"C\", \"D\", \"A\"]  # duplicate 'A'\n        with self.assertRaises(ValueError) as cm:\n            task_func(epoch_ms, products=products)\n        self.assertEqual(str(cm.exception), \"Products must contain 5 unique items\")\n\n    def test_less_than_five_products(self):\n        epoch_ms = int(datetime(2023, 1, 1).timestamp() * 1000)\n        products = [\"A\", \"B\", \"C\", \"D\"]  # only 4 products\n        with self.assertRaises(ValueError) as cm:\n            task_func(epoch_ms, products=products)\n        self.assertEqual(str(cm.exception), \"Products must contain 5 unique items\")\n\n    def test_more_than_five_products(self):\n        epoch_ms = int(datetime(2023, 1, 1).timestamp() * 1000)\n        products = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]  # 6 products\n        with self.assertRaises(ValueError) as cm:\n            task_func(epoch_ms, products=products)\n        self.assertEqual(str(cm.exception), \"Products must contain 5 unique items\")\n",
        "code": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\n\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    if len(set(products)) != 5:\n        raise ValueError(\"Products must contain 5 unique items\")\n\n    random.seed(random_seed)\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    end_date = datetime.now()\n    num_days = (end_date - start_date).days + 1\n\n    data = []\n    for product in products:\n        for day_offset in range(num_days):\n            current_date = start_date + timedelta(days=day_offset)\n            sales = random.randint(10, 50)\n            data.append({\"Product\": product, \"Date\": current_date, \"Sales\": sales})\n\n    df = pd.DataFrame(data)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/492_3",
        "turn": "3",
        "instruct_prompt": "Check that the start date (converted from epoch_milliseconds) is before the current system time, otherwise raise a ValueError with message \"Start time must be before current system time\".",
        "test": "import unittest\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def test_start_date_before_now(self):\n        # Use a start date 2 days ago\n        two_days_ago = int((datetime.now() - timedelta(days=2)).timestamp() * 1000)\n        df = task_func(two_days_ago)\n        self.assertFalse(df.empty)\n        self.assertTrue(all(df['Date'] < datetime.now()))\n\n    def test_start_date_equal_now_raises(self):\n        now_ms = int(datetime.now().timestamp() * 1000)\n        # To ensure start date is not less than current time, add 0 ms or 1 ms\n        with self.assertRaises(ValueError) as context:\n            task_func(now_ms)\n        self.assertEqual(str(context.exception), \"Start time must be before current system time\")\n\n    def test_start_date_in_future_raises(self):\n        future_ms = int((datetime.now() + timedelta(days=1)).timestamp() * 1000)\n        with self.assertRaises(ValueError) as context:\n            task_func(future_ms)\n        self.assertEqual(str(context.exception), \"Start time must be before current system time\")\n",
        "code": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\n\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    if len(set(products)) != 5:\n        raise ValueError(\"Products must contain 5 unique items\")\n\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    current_time = datetime.now()\n    # Convert both to epoch milliseconds for accurate comparison\n    start_ms = int(start_date.timestamp() * 1000)\n    current_ms = int(current_time.timestamp() * 1000)\n    if start_ms >= current_ms:\n        raise ValueError(\"Start time must be before current system time\")\n\n    random.seed(random_seed)\n    end_date = current_time\n    num_days = (end_date - start_date).days + 1\n\n    data = []\n    for product in products:\n        for day_offset in range(num_days):\n            current_date = start_date + timedelta(days=day_offset)\n            sales = random.randint(10, 50)\n            data.append({\"Product\": product, \"Date\": current_date, \"Sales\": sales})\n\n    df = pd.DataFrame(data)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/492_4",
        "turn": "4",
        "instruct_prompt": "For each day from the start date to the current date (inclusive), generate random sales data for each of the 5 products, with sales quantity randomly sampled from the range [10, 50]. Return the data as a pandas DataFrame with columns ['Product', 'Date', 'Sales'].",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def test_sales_data_structure_and_range(self):\n        start_datetime = datetime.now() - timedelta(days=3)\n        epoch_ms = int(start_datetime.timestamp() * 1000)\n        df = task_func(epoch_ms, random_seed=42)\n\n        # Check columns\n        self.assertListEqual(sorted(df.columns.tolist()), sorted([\"Product\", \"Date\", \"Sales\"]))\n\n        # Check dates are in range\n        self.assertTrue(df['Date'].min() >= start_datetime.replace(hour=0, minute=0, second=0, microsecond=0))\n        self.assertTrue(df['Date'].max() <= datetime.now())\n\n        # Check products\n        products = [\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"]\n        unique_products = df['Product'].unique()\n        for p in products:\n            self.assertIn(p, unique_products)\n\n        # Check sales range\n        self.assertTrue(df['Sales'].between(10, 50).all())\n\n        # Check that for each day and product there is exactly one record\n        date_range = pd.date_range(start=df['Date'].min().date(), end=df['Date'].max().date())\n        for single_date in date_range:\n            day_data = df[df['Date'].dt.date == single_date.date()]\n            self.assertEqual(len(day_data), 5)\n            self.assertSetEqual(set(day_data['Product']), set(products))\n\n    def test_row_ordering(self):\n        # This test distinguishes current solution from previous round's solution\n        start_datetime = datetime.now() - timedelta(days=2)\n        epoch_ms = int(start_datetime.timestamp() * 1000)\n        products = [\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"]\n        df = task_func(epoch_ms, random_seed=0, products=products)\n\n        dates = df['Date'].tolist()\n        products_in_df = df['Product'].tolist()\n\n        # Dates should be non-decreasing\n        for i in range(1, len(dates)):\n            self.assertTrue(dates[i] >= dates[i-1])\n\n        # For each block of 5 rows, products should be exactly the products list in order\n        for i in range(0, len(df), 5):\n            block_products = products_in_df[i:i+5]\n            self.assertEqual(block_products, products)\n\n    def test_invalid_products_length(self):\n        start_datetime = datetime.now() - timedelta(days=1)\n        epoch_ms = int(start_datetime.timestamp() * 1000)\n        with self.assertRaises(ValueError):\n            task_func(epoch_ms, products=[\"Product1\", \"Product2\"])\n\n    def test_start_date_after_current(self):\n        future_datetime = datetime.now() + timedelta(days=1)\n        epoch_ms = int(future_datetime.timestamp() * 1000)\n        with self.assertRaises(ValueError):\n            task_func(epoch_ms)\n",
        "code": "import pandas as pd\nfrom datetime import datetime, timedelta\nimport random\n\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    if len(set(products)) != 5:\n        raise ValueError(\"Products must contain 5 unique items\")\n\n    start_date = datetime.fromtimestamp(epoch_milliseconds / 1000)\n    current_time = datetime.now()\n    start_ms = int(start_date.timestamp() * 1000)\n    current_ms = int(current_time.timestamp() * 1000)\n    if start_ms >= current_ms:\n        raise ValueError(\"Start time must be before current system time\")\n\n    random.seed(random_seed)\n    num_days = (current_time - start_date).days + 1\n\n    data = []\n    for day_offset in range(num_days):\n        current_date = start_date + timedelta(days=day_offset)\n        for product in products:\n            sales = random.randint(10, 50)\n            data.append({\"Product\": product, \"Date\": current_date, \"Sales\": sales})\n\n    df = pd.DataFrame(data)\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 63,
    "task_id": "BigCodeBench/501",
    "mt_data": [
      {
        "task_id": "BigCodeBench/501_1",
        "turn": "1",
        "instruct_prompt": "Convert a JSON string to an Excel file and return the absolute path of the created file. You should write self-contained code starting with:\n```\nimport xlwt\nimport os\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n```",
        "test": "import unittest\nimport os\nimport xlrd\nimport json\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.files = []\n    def tearDown(self):\n        for f in self.files:\n            if os.path.exists(f):\n                os.remove(f)\n\n    def test_list_of_dicts(self):\n        data = [\n            {\"name\": \"Alice\", \"age\": 30},\n            {\"name\": \"Bob\", \"age\": 25}\n        ]\n        json_str = json.dumps(data)\n        filename = \"test1.xls\"\n        abs_path = task_func(json_str, filename)\n        self.files.append(abs_path)\n        self.assertTrue(os.path.exists(abs_path))\n        book = xlrd.open_workbook(abs_path)\n        sheet = book.sheet_by_index(0)\n        self.assertEqual(sheet.cell_value(0,0), \"name\")\n        self.assertEqual(sheet.cell_value(0,1), \"age\")\n        self.assertEqual(sheet.cell_value(1,0), \"Alice\")\n        self.assertEqual(sheet.cell_value(2,1), 25)\n\n    def test_dict(self):\n        data = {\"a\": 1, \"b\": 2}\n        json_str = json.dumps(data)\n        filename = \"test2.xls\"\n        abs_path = task_func(json_str, filename)\n        self.files.append(abs_path)\n        book = xlrd.open_workbook(abs_path)\n        sheet = book.sheet_by_index(0)\n        self.assertIn(sheet.cell_value(0,0), (\"a\", \"b\"))\n        self.assertIn(sheet.cell_value(1,0), (\"a\", \"b\"))\n        self.assertIn(sheet.cell_value(0,1), (1.0, 2.0))\n        self.assertIn(sheet.cell_value(1,1), (1.0, 2.0))\n\n    def test_list_of_scalars(self):\n        data = [1,2,3]\n        json_str = json.dumps(data)\n        filename = \"test3.xls\"\n        abs_path = task_func(json_str, filename)\n        self.files.append(abs_path)\n        book = xlrd.open_workbook(abs_path)\n        sheet = book.sheet_by_index(0)\n        self.assertEqual(sheet.cell_value(0,0), 1.0)\n        self.assertEqual(sheet.cell_value(2,0), 3.0)\n\n    def test_scalar(self):\n        data = 42\n        json_str = json.dumps(data)\n        filename = \"test4.xls\"\n        abs_path = task_func(json_str, filename)\n        self.files.append(abs_path)\n        book = xlrd.open_workbook(abs_path)\n        sheet = book.sheet_by_index(0)\n        self.assertEqual(sheet.cell_value(0,0), \"42\")\n",
        "code": "import xlwt\nimport os\nimport json\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    data = json.loads(json_str)\n    wb = xlwt.Workbook()\n    ws = wb.add_sheet(sheet_name)\n    \n    # If data is list of dicts, use keys as headers\n    if isinstance(data, list) and data and isinstance(data[0], dict):\n        headers = list(data[0].keys())\n        for col, header in enumerate(headers):\n            ws.write(0, col, header)\n        for row, item in enumerate(data, start=1):\n            for col, header in enumerate(headers):\n                ws.write(row, col, item.get(header, \"\"))\n    # If data is dict, write keys and values\n    elif isinstance(data, dict):\n        for row, (k, v) in enumerate(data.items()):\n            ws.write(row, 0, k)\n            ws.write(row, 1, v)\n    # If data is a list of scalars\n    elif isinstance(data, list):\n        for row, value in enumerate(data):\n            ws.write(row, 0, value)\n    else:\n        ws.write(0, 0, str(data))\n    \n    abs_path = os.path.abspath(filename)\n    wb.save(abs_path)\n    return abs_path\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/501_2",
        "turn": "2",
        "instruct_prompt": "Use pandas to parse the JSON string and write the data to the Excel file. The Excel file should include column names as headers.",
        "test": "import unittest\nimport os\nimport pandas as pd\nimport json\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.testfile = \"test_output.xlsx\"\n        if os.path.exists(self.testfile):\n            os.remove(self.testfile)\n\n    def tearDown(self):\n        if os.path.exists(self.testfile):\n            os.remove(self.testfile)\n\n    def test_list_of_dicts(self):\n        data = [\n            {\"name\": \"Alice\", \"age\": 30},\n            {\"name\": \"Bob\", \"age\": 25}\n        ]\n        path = task_func(json.dumps(data), self.testfile, sheet_name=\"SheetA\")\n        self.assertTrue(os.path.exists(path))\n        df = pd.read_excel(path, sheet_name=\"SheetA\")\n        self.assertListEqual(list(df.columns), [\"name\", \"age\"])\n        self.assertEqual(df.iloc[0][\"name\"], \"Alice\")\n        self.assertEqual(df.iloc[1][\"age\"], 25)\n\n    def test_dict(self):\n        data = {\"a\": 1, \"b\": 2}\n        path = task_func(json.dumps(data), self.testfile, sheet_name=\"Sheet1\")\n        df = pd.read_excel(path, sheet_name=\"Sheet1\")\n        self.assertListEqual(list(df.columns), [\"key\", \"value\"])\n        self.assertIn(\"a\", df[\"key\"].values)\n        self.assertIn(2, df[\"value\"].values)\n\n    def test_list_of_scalars(self):\n        data = [10, 20, 30]\n        path = task_func(json.dumps(data), self.testfile)\n        df = pd.read_excel(path)\n        self.assertListEqual(list(df.columns), [\"value\"])\n        self.assertListEqual(df[\"value\"].tolist(), [10, 20, 30])\n\n    def test_single_scalar(self):\n        data = 42\n        path = task_func(json.dumps(data), self.testfile)\n        df = pd.read_excel(path)\n        self.assertListEqual(list(df.columns), [\"value\"])\n        self.assertEqual(df.iloc[0][\"value\"], 42)\n",
        "code": "import pandas as pd\nimport json\nimport os\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    data = json.loads(json_str)\n    # Handle different data types for DataFrame construction\n    if isinstance(data, list):\n        # list of dicts or list of scalars\n        if data and isinstance(data[0], dict):\n            df = pd.DataFrame(data)\n        else:\n            df = pd.DataFrame(data, columns=[\"value\"])\n    elif isinstance(data, dict):\n        df = pd.DataFrame(list(data.items()), columns=[\"key\", \"value\"])\n    else:\n        df = pd.DataFrame([[data]], columns=[\"value\"])\n    abs_path = os.path.abspath(filename)\n    with pd.ExcelWriter(abs_path) as writer:\n        df.to_excel(writer, index=False, sheet_name=sheet_name)\n    return abs_path\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/501_3",
        "turn": "3",
        "instruct_prompt": "If the JSON string represents an empty array, create an Excel file with no data rows.",
        "test": "import unittest\nimport os\nimport pandas as pd\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def test_empty_array(self):\n        json_str = \"[]\"\n        with NamedTemporaryFile(suffix='.xlsx', delete=False) as tmp:\n            filename = tmp.name\n        try:\n            abs_path = task_func(json_str, filename)\n            self.assertTrue(os.path.exists(abs_path))\n            df = pd.read_excel(abs_path, sheet_name=\"sheet1\")\n            # Should be an empty DataFrame (no rows, no columns)\n            self.assertEqual(df.shape[0], 0)  # No rows\n            self.assertEqual(df.shape[1], 0)  # No columns\n        finally:\n            os.remove(filename)\n",
        "code": "import pandas as pd\nimport json\nimport os\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    data = json.loads(json_str)\n    # Handle different data types for DataFrame construction\n    if isinstance(data, list):\n        if len(data) == 0:\n            df = pd.DataFrame()\n        elif isinstance(data[0], dict):\n            df = pd.DataFrame(data)\n        else:\n            df = pd.DataFrame(data, columns=[\"value\"])\n    elif isinstance(data, dict):\n        df = pd.DataFrame(list(data.items()), columns=[\"key\", \"value\"])\n    else:\n        df = pd.DataFrame([[data]], columns=[\"value\"])\n    abs_path = os.path.abspath(filename)\n    with pd.ExcelWriter(abs_path) as writer:\n        df.to_excel(writer, index=False, sheet_name=sheet_name)\n    return abs_path\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/501_4",
        "turn": "4",
        "instruct_prompt": "Raise ValueError if the JSON string is not valid JSON. Raise TypeError if json_str is not a string, bytes, or bytearray. Raise a general Exception for file writing errors.",
        "test": "import unittest\nimport os\nimport tempfile\nimport pandas as pd\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary file path for writing\n        fd, self.temp_file = tempfile.mkstemp(suffix='.xlsx')\n        os.close(fd)\n\n    def tearDown(self):\n        if os.path.exists(self.temp_file):\n            os.remove(self.temp_file)\n\n    def test_invalid_json_raises_valueerror(self):\n        with self.assertRaises(ValueError):\n            task_func('{bad json}', self.temp_file)\n\n    def test_typeerror_on_wrong_type(self):\n        with self.assertRaises(TypeError):\n            task_func(12345, self.temp_file)\n        with self.assertRaises(TypeError):\n            task_func(None, self.temp_file)\n        with self.assertRaises(TypeError):\n            task_func(3.14, self.temp_file)\n        with self.assertRaises(TypeError):\n            task_func([1,2,3], self.temp_file)\n\n    def test_valid_json_string(self):\n        json_str = '[{\"a\": 1}, {\"a\": 2}]'\n        path = task_func(json_str, self.temp_file)\n        self.assertTrue(os.path.isfile(path))\n        # Check Excel content\n        df = pd.read_excel(path)\n        self.assertListEqual(list(df.columns), ['a'])\n        self.assertListEqual(df['a'].tolist(), [1, 2])\n\n    def test_valid_json_bytes(self):\n        json_bytes = b'[1, 2, 3]'\n        path = task_func(json_bytes, self.temp_file)\n        self.assertTrue(os.path.isfile(path))\n        df = pd.read_excel(path)\n        self.assertListEqual(list(df.columns), ['value'])\n        self.assertListEqual(df['value'].tolist(), [1, 2, 3])\n\n    def test_file_write_error_raises_exception(self):\n        json_str = '[1, 2, 3]'\n        # Patch pd.ExcelWriter to raise OSError\n        with patch('pandas.ExcelWriter', side_effect=OSError(\"Disk full\")):\n            with self.assertRaises(Exception) as cm:\n                task_func(json_str, self.temp_file)\n            self.assertIn('File writing error', str(cm.exception))\n",
        "code": "import pandas as pd\nimport json\nimport os\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    if not isinstance(json_str, (str, bytes, bytearray)):\n        raise TypeError(\"json_str must be a string, bytes, or bytearray\")\n    try:\n        data = json.loads(json_str)\n    except Exception as e:\n        raise ValueError(\"Invalid JSON\") from e\n    # Handle different data types for DataFrame construction\n    if isinstance(data, list):\n        if len(data) == 0:\n            df = pd.DataFrame()\n        elif isinstance(data[0], dict):\n            df = pd.DataFrame(data)\n        else:\n            df = pd.DataFrame(data, columns=[\"value\"])\n    elif isinstance(data, dict):\n        df = pd.DataFrame(list(data.items()), columns=[\"key\", \"value\"])\n    else:\n        df = pd.DataFrame([[data]], columns=[\"value\"])\n    abs_path = os.path.abspath(filename)\n    try:\n        with pd.ExcelWriter(abs_path) as writer:\n            df.to_excel(writer, index=False, sheet_name=sheet_name)\n    except Exception as e:\n        raise Exception(\"File writing error\") from e\n    return abs_path\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 64,
    "task_id": "BigCodeBench/502",
    "mt_data": [
      {
        "task_id": "BigCodeBench/502_1",
        "turn": "1",
        "instruct_prompt": "Generate a DataFrame containing daily activity durations for a specified number of past days. Each day should have entries for multiple activities with durations. You should write self-contained code starting with:\n```\nfrom datetime import datetime, timedelta\nimport pandas as pd\nimport random\n\ndef task_func(days_in_past=7, random_seed=0):\n```",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic(self):\n        days = 5\n        df = task_func(days_in_past=days, random_seed=42)\n        # Check dataframe type\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check columns\n        self.assertTrue(set(['date', 'activity', 'duration']).issubset(df.columns))\n        # Check number of rows: days * activities\n        self.assertEqual(len(df), days * 3)\n        # Check date range\n        dates = df['date'].unique()\n        expected_dates = [(datetime.now().date() - timedelta(days=i)) for i in range(days)]\n        self.assertCountEqual(dates, expected_dates)\n        # Check activities\n        activities = ['Walking', 'Running', 'Cycling']\n        self.assertTrue(all(act in activities for act in df['activity'].unique()))\n        # Check durations are within expected range\n        self.assertTrue(df['duration'].between(10, 120).all())\n\n    def test_task_func_seed_reproducibility(self):\n        df1 = task_func(days_in_past=3, random_seed=7)\n        df2 = task_func(days_in_past=3, random_seed=7)\n        pd.testing.assert_frame_equal(df1, df2)\n\n    def test_task_func_default(self):\n        df = task_func()\n        self.assertEqual(len(df), 7 * 3)  # default 7 days\n",
        "code": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\n\ndef task_func(days_in_past=7, random_seed=0):\n    random.seed(random_seed)\n    today = datetime.now().date()\n    activities = ['Walking', 'Running', 'Cycling']\n    data = []\n    for day_offset in range(days_in_past):\n        day = today - timedelta(days=day_offset)\n        for activity in activities:\n            duration = random.randint(10, 120)  # duration in minutes\n            data.append({'date': day, 'activity': activity, 'duration': duration})\n    df = pd.DataFrame(data)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/502_2",
        "turn": "2",
        "instruct_prompt": "Use the activities list [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]. For each day in the past specified by days_in_past, generate a random duration between 0 and 120 for each activity and store the data in the DataFrame with columns ['Date', 'Activity', 'Duration'].",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic(self):\n        days_in_past = 3\n        df = task_func(days_in_past=days_in_past, random_seed=42)\n        # Check dataframe columns\n        self.assertListEqual(list(df.columns), ['Date', 'Activity', 'Duration'])\n        # Check number of rows\n        self.assertEqual(len(df), days_in_past * 5)  # 5 activities\n        # Check activities\n        expected_activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n        self.assertTrue(all(act in expected_activities for act in df['Activity'].unique()))\n        self.assertEqual(len(df['Activity'].unique()), 5)\n        # Check dates range\n        today = datetime.now().date()\n        dates_expected = {today - timedelta(days=i) for i in range(days_in_past)}\n        dates_in_df = set(df['Date'].unique())\n        self.assertEqual(dates_in_df, dates_expected)\n        # Check duration ranges\n        self.assertTrue(df['Duration'].between(0, 120).all())\n    \n    def test_task_func_random_seed_reproducibility(self):\n        df1 = task_func(days_in_past=2, random_seed=123)\n        df2 = task_func(days_in_past=2, random_seed=123)\n        pd.testing.assert_frame_equal(df1, df2)\n\n    def test_previous_version_should_fail(self):\n        # This test ensures that previous version which had different activities and duration range fails\n        # We simulate the previous version output\n        from datetime import datetime, timedelta\n        import pandas as pd\n\n        def previous_task_func(days_in_past=7, random_seed=0):\n            random.seed(random_seed)\n            today = datetime.now().date()\n            activities = ['Walking', 'Running', 'Cycling']\n            data = []\n            for day_offset in range(days_in_past):\n                day = today - timedelta(days=day_offset)\n                for activity in activities:\n                    duration = random.randint(10, 120)  # duration in minutes\n                    data.append({'date': day, 'activity': activity, 'duration': duration})\n            df = pd.DataFrame(data)\n            return df\n\n        old_df = previous_task_func(days_in_past=3, random_seed=42)\n        new_df = task_func(days_in_past=3, random_seed=42)\n\n        # Check that old_df columns are different from new_df columns\n        self.assertNotEqual(list(old_df.columns), list(new_df.columns))\n        # Check that activities differ\n        self.assertNotEqual(set(old_df['activity']), set(new_df['Activity']))\n        # Check that durations in old_df are >=10, but in new_df can be 0\n        self.assertTrue((old_df['duration'] >= 10).all())\n        self.assertTrue((new_df['Duration'] >= 0).all())\n        self.assertTrue((new_df['Duration'] < 10).any())  # new_df has durations below 10\n",
        "code": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\n\ndef task_func(days_in_past=7, random_seed=0):\n    random.seed(random_seed)\n    today = datetime.now().date()\n    activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n    data = []\n    for day_offset in range(days_in_past):\n        day = today - timedelta(days=day_offset)\n        for activity in activities:\n            duration = random.randint(0, 120)  # duration in minutes\n            data.append({'Date': day, 'Activity': activity, 'Duration': duration})\n    df = pd.DataFrame(data, columns=['Date', 'Activity', 'Duration'])\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/502_3",
        "turn": "3",
        "instruct_prompt": "Set the random seed to random_seed at the start of the function to ensure reproducibility. Raise a ValueError if days_in_past is less than 1.",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def test_random_seed_reproducibility(self):\n        # Call twice with same seed and days_in_past, results should be identical\n        df1 = task_func(days_in_past=3, random_seed=42)\n        df2 = task_func(days_in_past=3, random_seed=42)\n        pd.testing.assert_frame_equal(df1, df2)\n\n    def test_days_in_past_value_error(self):\n        # days_in_past less than 1 should raise ValueError\n        with self.assertRaises(ValueError):\n            task_func(days_in_past=0)\n        with self.assertRaises(ValueError):\n            task_func(days_in_past=-5)\n\n    def test_output_length(self):\n        # For days_in_past=2, should have 2 * 5 = 10 rows\n        df = task_func(days_in_past=2, random_seed=1)\n        self.assertEqual(len(df), 10)\n\n    def test_dates_are_correct(self):\n        days_in_past = 2\n        df = task_func(days_in_past=days_in_past, random_seed=0)\n        today = datetime.now().date()\n        expected_dates = {today - timedelta(days=i) for i in range(days_in_past)}\n        self.assertTrue(set(df['Date']).issubset(expected_dates))\n",
        "code": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\n\ndef task_func(days_in_past=7, random_seed=0):\n    if days_in_past < 1:\n        raise ValueError(\"days_in_past must be at least 1\")\n    random.seed(random_seed)\n    today = datetime.now().date()\n    activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n    data = []\n    for day_offset in range(days_in_past):\n        day = today - timedelta(days=day_offset)\n        for activity in activities:\n            duration = random.randint(0, 120)  # duration in minutes\n            data.append({'Date': day, 'Activity': activity, 'Duration': duration})\n    df = pd.DataFrame(data, columns=['Date', 'Activity', 'Duration'])\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/502_4",
        "turn": "4",
        "instruct_prompt": "Plot a seaborn lineplot using the generated DataFrame with 'Date' on the x-axis, 'Duration' on the y-axis, and 'Activity' as the hue. Return a tuple containing the matplotlib Axes object and the DataFrame.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    def test_output_types_and_content(self):\n        ax, df = task_func(days_in_past=3, random_seed=42)\n        # Check types\n        import matplotlib.axes\n        self.assertIsInstance(ax, matplotlib.axes.Axes)\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check DataFrame columns\n        self.assertTrue(all(col in df.columns for col in ['Date', 'Activity', 'Duration']))\n        # Check DataFrame length\n        self.assertEqual(len(df), 3 * 5)  # 3 days * 5 activities\n        # Check Date column type\n        self.assertTrue(pd.api.types.is_datetime64_any_dtype(df['Date']))\n        # Check Duration column type\n        self.assertTrue(pd.api.types.is_integer_dtype(df['Duration']))\n        # Check Activity column type\n        self.assertTrue(df['Activity'].dtype == object)\n    \n    def test_legend_entries_match_activities(self):\n        ax, df = task_func(days_in_past=5, random_seed=1)\n        legend = ax.get_legend()\n        # Get legend handles and labels\n        handles, labels = ax.get_legend_handles_labels()\n        unique_activities = set(df['Activity'].unique())\n        # The legend labels include the hue title (usually 'Activity') plus activity names, possibly some extra\n        # We check that all unique activities are in legend labels\n        labels_set = set(labels)\n        self.assertTrue(unique_activities.issubset(labels_set), f\"Legend labels {labels_set} do not include all activities {unique_activities}\")\n\n    def test_invalid_days_in_past(self):\n        with self.assertRaises(ValueError):\n            task_func(days_in_past=0)\n",
        "code": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(days_in_past=7, random_seed=0):\n    if days_in_past < 1:\n        raise ValueError(\"days_in_past must be at least 1\")\n    random.seed(random_seed)\n    today = datetime.now().date()\n    activities = [\"Running\", \"Swimming\", \"Cycling\", \"Yoga\", \"Weight Training\"]\n    data = []\n    for day_offset in range(days_in_past):\n        day = today - timedelta(days=day_offset)\n        for activity in activities:\n            duration = random.randint(0, 120)  # duration in minutes\n            data.append({'Date': day, 'Activity': activity, 'Duration': duration})\n    df = pd.DataFrame(data, columns=['Date', 'Activity', 'Duration'])\n\n    # Convert 'Date' column to datetime64 dtype\n    df['Date'] = pd.to_datetime(df['Date'])\n\n    # Sort DataFrame by 'Activity' and 'Date' ascending for continuous lines\n    df = df.sort_values(['Activity', 'Date']).reset_index(drop=True)\n\n    plt.figure()\n    ax = sns.lineplot(data=df, x='Date', y='Duration', hue='Activity')\n    return ax, df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 65,
    "task_id": "BigCodeBench/503",
    "mt_data": [
      {
        "task_id": "BigCodeBench/503_1",
        "turn": "1",
        "instruct_prompt": "Create a DataFrame of random numbers for a specified number of days and columns. You should write self-contained code starting with:\n```\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0\n):\n```",
        "test": "import unittest\nimport pandas as pd\nclass TestCases(unittest.TestCase):\n    def test_shape_and_columns(self):\n        df = task_func(days_in_past=5, stock_names=[\"AAPL\", \"TSLA\"], random_seed=42)\n        self.assertEqual(df.shape, (5, 2))\n        self.assertListEqual(list(df.columns), [\"AAPL\", \"TSLA\"])\n\n    def test_random_seed_reproducibility(self):\n        df1 = task_func(days_in_past=3, stock_names=[\"A\"], random_seed=1)\n        df2 = task_func(days_in_past=3, stock_names=[\"A\"], random_seed=1)\n        pd.testing.assert_frame_equal(df1, df2)\n\n    def test_index_is_datetime(self):\n        df = task_func(days_in_past=4)\n        self.assertTrue(isinstance(df.index, pd.DatetimeIndex))\n        self.assertEqual(len(df.index), 4)\n\n    def test_default_arguments(self):\n        df = task_func()\n        self.assertEqual(df.shape, (7, 5))\n        self.assertListEqual(list(df.columns), [\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"])\n",
        "code": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0\n):\n    np.random.seed(random_seed)\n    end_date = datetime.today().date()\n    dates = [end_date - timedelta(days=i) for i in range(days_in_past)]\n    dates = sorted(dates)\n    data = np.random.randn(days_in_past, len(stock_names))\n    df = pd.DataFrame(data, index=pd.to_datetime(dates), columns=stock_names)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/503_2",
        "turn": "2",
        "instruct_prompt": "Set the DataFrame's columns to the values in stock_names, and its index to consecutive dates for the past days_in_past days ending today.",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import timedelta, date\n\nclass TestCases(unittest.TestCase):\n    def test_consecutive_dates_and_order(self):\n        days_in_past = 5\n        stock_names = ['AAA', 'BBB']\n        fixed_today = date(2024, 6, 30)\n        df = task_func(days_in_past=days_in_past, stock_names=stock_names, random_seed=42, today=fixed_today)\n        expected_end = fixed_today\n        expected_start = expected_end - timedelta(days=days_in_past - 1)\n        expected_dates = [expected_start + timedelta(days=i) for i in range(days_in_past)]\n        expected_index = pd.to_datetime(expected_dates)\n        self.assertTrue((df.index == expected_index).all(), f\"Index does not match expected: {df.index} vs {expected_index}\")\n        self.assertEqual(df.index[-1].date(), fixed_today)\n        self.assertEqual(df.index[0].date(), fixed_today - timedelta(days=days_in_past - 1))\n        for i in range(1, len(df.index)):\n            self.assertEqual((df.index[i] - df.index[i-1]).days, 1)\n        self.assertEqual(list(df.columns), stock_names)\n        self.assertEqual(df.shape, (days_in_past, len(stock_names)))\n    def test_zero_days(self):\n        df = task_func(days_in_past=0, stock_names=['Z'], today=date(2024, 6, 30))\n        self.assertEqual(df.shape, (0, 1))\n        self.assertEqual(list(df.columns), ['Z'])\n        self.assertEqual(len(df.index), 0)\n",
        "code": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta, date\n\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0, today=None\n):\n    np.random.seed(random_seed)\n    if today is None:\n        end_date = date.today()\n    else:\n        end_date = today\n    dates = [end_date - timedelta(days=days_in_past - 1 - i) for i in range(days_in_past)]\n    data = np.random.randn(days_in_past, len(stock_names))\n    df = pd.DataFrame(data, columns=stock_names)\n    df.index = pd.to_datetime(dates)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/503_3",
        "turn": "3",
        "instruct_prompt": "Generate random float values in the range [0.0, 1.0) for the DataFrame's values using the given random_seed.",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import date\n\nclass TestCases(unittest.TestCase):\n    def test_random_float_values_range_and_seed(self):\n        days = 5\n        stocks = [\"A\", \"B\"]\n        seed = 42\n        today = date(2024, 6, 9)\n        df = task_func(days_in_past=days, stock_names=stocks, random_seed=seed, today=today)\n        self.assertEqual(df.shape, (days, 2))\n        # Check all values are in [0.0, 1.0)\n        self.assertTrue(((df.values >= 0.0) & (df.values < 1.0)).all())\n        # Check reproducibility\n        df2 = task_func(days_in_past=days, stock_names=stocks, random_seed=seed, today=today)\n        pd.testing.assert_frame_equal(df, df2)\n        # Check that different seeds produce different data\n        df3 = task_func(days_in_past=days, stock_names=stocks, random_seed=seed+1, today=today)\n        with self.assertRaises(AssertionError):\n            pd.testing.assert_frame_equal(df, df3)\n",
        "code": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta, date\n\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0, today=None\n):\n    np.random.seed(random_seed)\n    if today is None:\n        end_date = date.today()\n    else:\n        end_date = today\n    dates = [end_date - timedelta(days=days_in_past - 1 - i) for i in range(days_in_past)]\n    data = np.random.random((days_in_past, len(stock_names)))\n    df = pd.DataFrame(data, columns=stock_names)\n    df.index = pd.to_datetime(dates)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/503_4",
        "turn": "4",
        "instruct_prompt": "Ensure that days_in_past is a positive integer and stock_names is a non-empty list of strings, otherwise raise a ValueError.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_days_in_past_positive_integer(self):\n        # Valid\n        df = task_func(days_in_past=3, stock_names=[\"AAPL\"])\n        self.assertEqual(df.shape, (3, 1))\n        # Invalid: zero\n        with self.assertRaises(ValueError):\n            task_func(days_in_past=0, stock_names=[\"AAPL\"])\n        # Invalid: negative\n        with self.assertRaises(ValueError):\n            task_func(days_in_past=-2, stock_names=[\"AAPL\"])\n        # Invalid: float\n        with self.assertRaises(ValueError):\n            task_func(days_in_past=2.5, stock_names=[\"AAPL\"])\n        # Invalid: string\n        with self.assertRaises(ValueError):\n            task_func(days_in_past=\"5\", stock_names=[\"AAPL\"])\n\n    def test_stock_names_non_empty_list_of_strings(self):\n        # Valid\n        df = task_func(days_in_past=2, stock_names=[\"A\", \"B\"])\n        self.assertEqual(df.shape, (2, 2))\n        # Invalid: empty list\n        with self.assertRaises(ValueError):\n            task_func(days_in_past=2, stock_names=[])\n        # Invalid: not a list\n        with self.assertRaises(ValueError):\n            task_func(days_in_past=2, stock_names=\"AAPL\")\n        # Invalid: list with non-string\n        with self.assertRaises(ValueError):\n            task_func(days_in_past=2, stock_names=[\"AAPL\", 123])\n        with self.assertRaises(ValueError):\n            task_func(days_in_past=2, stock_names=[None])\n\n    def test_valid_combined(self):\n        # Valid case\n        df = task_func(days_in_past=5, stock_names=[\"X\", \"Y\", \"Z\"])\n        self.assertEqual(df.shape, (5, 3))\n",
        "code": "import numpy as np\nimport pandas as pd\nfrom datetime import date, timedelta\n\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0, today=None\n):\n    # Input validation\n    if not (isinstance(days_in_past, int) and days_in_past > 0):\n        raise ValueError(\"days_in_past must be a positive integer.\")\n    if not (isinstance(stock_names, list) and len(stock_names) > 0 and all(isinstance(s, str) for s in stock_names)):\n        raise ValueError(\"stock_names must be a non-empty list of strings.\")\n    np.random.seed(random_seed)\n    if today is None:\n        end_date = date.today()\n    else:\n        end_date = today\n    dates = [end_date - timedelta(days=days_in_past - 1 - i) for i in range(days_in_past)]\n    data = np.random.random((days_in_past, len(stock_names)))\n    df = pd.DataFrame(data, columns=stock_names)\n    df.index = pd.to_datetime(dates)\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 66,
    "task_id": "BigCodeBench/509",
    "mt_data": [
      {
        "task_id": "BigCodeBench/509_1",
        "turn": "1",
        "instruct_prompt": "Compare two CSV files line by line and return a pandas DataFrame showing each line with a status indicator for differences. You should write self-contained code starting with:```python\nimport pandas as pd\nimport csv\nfrom difflib import ndiff\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n```",
        "test": "import unittest\nimport os\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.file1 = 'test_file1.csv'\n        self.file2 = 'test_file2.csv'\n\n    def tearDown(self):\n        if os.path.exists(self.file1):\n            os.remove(self.file1)\n        if os.path.exists(self.file2):\n            os.remove(self.file2)\n\n    def write_file(self, filename, lines):\n        with open(filename, 'w', encoding='utf-8') as f:\n            for line in lines:\n                f.write(line + '\\n')\n\n    def test_identical_files(self):\n        lines = ['a,b,c', '1,2,3', 'x,y,z']\n        self.write_file(self.file1, lines)\n        self.write_file(self.file2, lines)\n\n        df = task_func(self.file1, self.file2)\n\n        self.assertEqual(len(df), 3)\n        self.assertTrue(all(df['Status'] == 'Match'))\n\n    def test_different_files(self):\n        lines1 = ['a,b,c', '1,2,3', 'x,y,z']\n        lines2 = ['a,b,c', '1,2,4', 'x,y,z']\n        self.write_file(self.file1, lines1)\n        self.write_file(self.file2, lines2)\n\n        df = task_func(self.file1, self.file2)\n\n        self.assertEqual(len(df), 3)\n        self.assertEqual(df.loc[0, 'Status'], 'Match')\n        self.assertEqual(df.loc[1, 'Status'], 'Diff')\n        self.assertEqual(df.loc[2, 'Status'], 'Match')\n\n    def test_file2_longer(self):\n        lines1 = ['a,b,c', '1,2,3']\n        lines2 = ['a,b,c', '1,2,3', 'extra,line']\n        self.write_file(self.file1, lines1)\n        self.write_file(self.file2, lines2)\n\n        df = task_func(self.file1, self.file2)\n\n        self.assertEqual(len(df), 3)\n        self.assertEqual(df.loc[2, 'File1'], '')\n        self.assertEqual(df.loc[2, 'File2'], 'extra,line')\n        self.assertEqual(df.loc[2, 'Status'], 'Diff')\n\n    def test_file1_longer(self):\n        lines1 = ['a,b,c', '1,2,3', 'extra,line']\n        lines2 = ['a,b,c', '1,2,3']\n        self.write_file(self.file1, lines1)\n        self.write_file(self.file2, lines2)\n\n        df = task_func(self.file1, self.file2)\n\n        self.assertEqual(len(df), 3)\n        self.assertEqual(df.loc[2, 'File1'], 'extra,line')\n        self.assertEqual(df.loc[2, 'File2'], '')\n        self.assertEqual(df.loc[2, 'Status'], 'Diff')\n",
        "code": "import pandas as pd\nimport csv\nfrom difflib import ndiff\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    lines1 = []\n    lines2 = []\n\n    with open(file_path1, newline='', encoding='utf-8') as f1:\n        reader1 = csv.reader(f1, delimiter=delimiter, quotechar=quotechar)\n        for row in reader1:\n            lines1.append(delimiter.join(row))\n\n    with open(file_path2, newline='', encoding='utf-8') as f2:\n        reader2 = csv.reader(f2, delimiter=delimiter, quotechar=quotechar)\n        for row in reader2:\n            lines2.append(delimiter.join(row))\n\n    max_len = max(len(lines1), len(lines2))\n\n    result = []\n    for i in range(max_len):\n        line1 = lines1[i] if i < len(lines1) else ''\n        line2 = lines2[i] if i < len(lines2) else ''\n\n        if line1 == line2:\n            status = 'Match'\n        else:\n            status = 'Diff'\n\n        result.append({'Line': i+1, 'File1': line1, 'File2': line2, 'Status': status})\n\n    df = pd.DataFrame(result)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/509_2",
        "turn": "2",
        "instruct_prompt": "Raise a FileNotFoundError if either of the input files does not exist.",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_file_not_found_first(self):\n        with tempfile.NamedTemporaryFile(delete=True) as temp2:\n            temp2.write(b'a,b,c\\n1,2,3\\n')\n            temp2.flush()\n            try:\n                task_func('nonexistent_file.csv', temp2.name)\n            except FileNotFoundError as e:\n                self.assertIn('File not found: nonexistent_file.csv', str(e))\n            else:\n                self.fail('FileNotFoundError not raised for first file')\n\n    def test_file_not_found_second(self):\n        with tempfile.NamedTemporaryFile(delete=True) as temp1:\n            temp1.write(b'a,b,c\\n1,2,3\\n')\n            temp1.flush()\n            try:\n                task_func(temp1.name, 'nonexistent_file.csv')\n            except FileNotFoundError as e:\n                self.assertIn('File not found: nonexistent_file.csv', str(e))\n            else:\n                self.fail('FileNotFoundError not raised for second file')\n\n    def test_both_files_exist(self):\n        content1 = 'a,b,c\\n1,2,3\\n'\n        content2 = 'a,b,c\\n4,5,6\\n'\n        with tempfile.NamedTemporaryFile(mode='w+', delete=True) as temp1, \\\n             tempfile.NamedTemporaryFile(mode='w+', delete=True) as temp2:\n            temp1.write(content1)\n            temp1.flush()\n            temp2.write(content2)\n            temp2.flush()\n\n            df = task_func(temp1.name, temp2.name)\n            self.assertEqual(df.shape[0], 2)\n            self.assertEqual(df.loc[0, 'Status'], 'Match')\n            self.assertEqual(df.loc[1, 'Status'], 'Diff')\n",
        "code": "import pandas as pd\nimport csv\nimport os\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    if not os.path.isfile(file_path1):\n        raise FileNotFoundError(f\"File not found: {file_path1}\")\n    if not os.path.isfile(file_path2):\n        raise FileNotFoundError(f\"File not found: {file_path2}\")\n\n    lines1 = []\n    lines2 = []\n\n    with open(file_path1, newline='', encoding='utf-8') as f1:\n        reader1 = csv.reader(f1, delimiter=delimiter, quotechar=quotechar)\n        for row in reader1:\n            lines1.append(delimiter.join(row))\n\n    with open(file_path2, newline='', encoding='utf-8') as f2:\n        reader2 = csv.reader(f2, delimiter=delimiter, quotechar=quotechar)\n        for row in reader2:\n            lines2.append(delimiter.join(row))\n\n    max_len = max(len(lines1), len(lines2))\n\n    result = []\n    for i in range(max_len):\n        line1 = lines1[i] if i < len(lines1) else ''\n        line2 = lines2[i] if i < len(lines2) else ''\n\n        if line1 == line2:\n            status = 'Match'\n        else:\n            status = 'Diff'\n\n        result.append({'Line': i+1, 'File1': line1, 'File2': line2, 'Status': status})\n\n    df = pd.DataFrame(result)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/509_3",
        "turn": "3",
        "instruct_prompt": "Raise a ValueError if either of the input CSV files is empty.",
        "test": "import unittest\nimport tempfile\nimport os\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.temp_files = []\n\n    def tearDown(self):\n        for file_path in self.temp_files:\n            if os.path.exists(file_path):\n                os.remove(file_path)\n\n    def _create_temp_file(self, content):\n        tmp = tempfile.NamedTemporaryFile(delete=False, mode='w', encoding='utf-8', newline='')\n        tmp.write(content)\n        tmp.close()\n        self.temp_files.append(tmp.name)\n        return tmp.name\n\n    def test_raise_value_error_if_first_file_empty(self):\n        empty_file = self._create_temp_file('')\n        non_empty_file = self._create_temp_file('col1,col2\\nval1,val2')\n        with self.assertRaises(ValueError) as cm:\n            task_func(empty_file, non_empty_file)\n        self.assertIn('Input file is empty', str(cm.exception))\n\n    def test_raise_value_error_if_second_file_empty(self):\n        non_empty_file = self._create_temp_file('col1,col2\\nval1,val2')\n        empty_file = self._create_temp_file('')\n        with self.assertRaises(ValueError) as cm:\n            task_func(non_empty_file, empty_file)\n        self.assertIn('Input file is empty', str(cm.exception))\n\n    def test_no_error_if_files_not_empty(self):\n        file1 = self._create_temp_file('col1,col2\\nval1,val2')\n        file2 = self._create_temp_file('col1,col2\\nval1,val2')\n        df = task_func(file1, file2)\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertEqual(df.iloc[0]['Status'], 'Match')\n",
        "code": "import pandas as pd\nimport csv\nimport os\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    if not os.path.isfile(file_path1):\n        raise FileNotFoundError(f\"File not found: {file_path1}\")\n    if not os.path.isfile(file_path2):\n        raise FileNotFoundError(f\"File not found: {file_path2}\")\n\n    lines1 = []\n    lines2 = []\n\n    with open(file_path1, newline='', encoding='utf-8') as f1:\n        reader1 = csv.reader(f1, delimiter=delimiter, quotechar=quotechar)\n        for row in reader1:\n            lines1.append(delimiter.join(row))\n\n    with open(file_path2, newline='', encoding='utf-8') as f2:\n        reader2 = csv.reader(f2, delimiter=delimiter, quotechar=quotechar)\n        for row in reader2:\n            lines2.append(delimiter.join(row))\n\n    if len(lines1) == 0:\n        raise ValueError(f\"Input file is empty: {file_path1}\")\n    if len(lines2) == 0:\n        raise ValueError(f\"Input file is empty: {file_path2}\")\n\n    max_len = max(len(lines1), len(lines2))\n\n    result = []\n    for i in range(max_len):\n        line1 = lines1[i] if i < len(lines1) else ''\n        line2 = lines2[i] if i < len(lines2) else ''\n\n        if line1 == line2:\n            status = 'Match'\n        else:\n            status = 'Diff'\n\n        result.append({'Line': i+1, 'File1': line1, 'File2': line2, 'Status': status})\n\n    df = pd.DataFrame(result)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/509_4",
        "turn": "4",
        "instruct_prompt": "Raise a general Exception for other IO related errors during file processing.",
        "test": "import unittest\nimport os\nimport tempfile\nfrom unittest import mock\nimport pandas as pd\nfrom pandas.testing import assert_frame_equal\n\n# We'll assume task_func is defined in the same file or imported\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.temp1 = tempfile.NamedTemporaryFile(mode='w+', delete=False, encoding='utf-8')\n        self.temp2 = tempfile.NamedTemporaryFile(mode='w+', delete=False, encoding='utf-8')\n\n    def tearDown(self):\n        self.temp1.close()\n        self.temp2.close()\n        os.unlink(self.temp1.name)\n        os.unlink(self.temp2.name)\n\n    def test_ioerror_raises_exception(self):\n        original_open = open\n\n        def mock_open(file, *args, **kwargs):\n            if file == self.temp1.name:\n                raise IOError(\"Simulated IO error\")\n            return original_open(file, *args, **kwargs)\n\n        with mock.patch('builtins.open', mock_open):\n            with self.assertRaises(Exception) as cm:\n                task_func(self.temp1.name, self.temp2.name)\n            self.assertIn('IO error occurred while processing file', str(cm.exception))\n\n        def mock_open2(file, *args, **kwargs):\n            if file == self.temp2.name:\n                raise IOError(\"Simulated IO error\")\n            return original_open(file, *args, **kwargs)\n\n        with mock.patch('builtins.open', mock_open2):\n            with self.assertRaises(Exception) as cm:\n                task_func(self.temp1.name, self.temp2.name)\n            self.assertIn('IO error occurred while processing file', str(cm.exception))\n\n    def test_normal_functionality(self):\n        self.temp1.write('a,b,c\\n1,2,3\\n')\n        self.temp1.flush()\n        self.temp2.write('a,b,c\\n1,2,4\\n')\n        self.temp2.flush()\n\n        df = task_func(self.temp1.name, self.temp2.name)\n\n        expected = pd.DataFrame([\n            {'Line':1, 'File1':'a,b,c', 'File2':'a,b,c', 'Status':'Match'},\n            {'Line':2, 'File1':'1,2,3', 'File2':'1,2,4', 'Status':'Diff'}\n        ])\n\n        assert_frame_equal(df, expected)\n",
        "code": "import pandas as pd\nimport csv\nimport os\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    if not os.path.isfile(file_path1):\n        raise FileNotFoundError(f\"File not found: {file_path1}\")\n    if not os.path.isfile(file_path2):\n        raise FileNotFoundError(f\"File not found: {file_path2}\")\n\n    lines1 = []\n    lines2 = []\n\n    try:\n        with open(file_path1, newline='', encoding='utf-8') as f1:\n            reader1 = csv.reader(f1, delimiter=delimiter, quotechar=quotechar)\n            for row in reader1:\n                lines1.append(delimiter.join(row))\n    except IOError as e:\n        raise Exception(f\"IO error occurred while processing file: {file_path1}\") from e\n\n    try:\n        with open(file_path2, newline='', encoding='utf-8') as f2:\n            reader2 = csv.reader(f2, delimiter=delimiter, quotechar=quotechar)\n            for row in reader2:\n                lines2.append(delimiter.join(row))\n    except IOError as e:\n        raise Exception(f\"IO error occurred while processing file: {file_path2}\") from e\n\n    if len(lines1) == 0:\n        raise ValueError(f\"Input file is empty: {file_path1}\")\n    if len(lines2) == 0:\n        raise ValueError(f\"Input file is empty: {file_path2}\")\n\n    max_len = max(len(lines1), len(lines2))\n\n    result = []\n    for i in range(max_len):\n        line1 = lines1[i] if i < len(lines1) else ''\n        line2 = lines2[i] if i < len(lines2) else ''\n\n        status = 'Match' if line1 == line2 else 'Diff'\n\n        result.append({'Line': i+1, 'File1': line1, 'File2': line2, 'Status': status})\n\n    df = pd.DataFrame(result)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/509_5",
        "turn": "5",
        "instruct_prompt": "Format the output DataFrame with columns 'Line Number', 'Status', and 'Content'. Use ' ' (space) for lines that are the same, '-' for lines present only in the first file, and '+' for lines present only in the second file. The 'Content' column should contain the text of the line from the appropriate file.",
        "test": "import unittest\nimport tempfile\nimport os\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.temp_files = []\n\n    def tearDown(self):\n        for f in self.temp_files:\n            try:\n                os.remove(f)\n            except:\n                pass\n\n    def create_temp_file(self, lines):\n        tmp = tempfile.NamedTemporaryFile(delete=False, mode='w', encoding='utf-8', newline='')\n        tmp.writelines([line + '\\n' for line in lines])\n        tmp.close()\n        self.temp_files.append(tmp.name)\n        return tmp.name\n\n    def test_basic_diff_formatting(self):\n        lines1 = ['a,b,c', 'd,e,f', 'g,h,i']\n        lines2 = ['a,b,c', 'x,y,z', 'g,h,i', 'j,k,l']\n        file1 = self.create_temp_file(lines1)\n        file2 = self.create_temp_file(lines2)\n\n        df = task_func(file1, file2)\n\n        expected_data = [\n            {'Line Number': 1, 'Status': ' ', 'Content': 'a,b,c'},\n            {'Line Number': 2, 'Status': '-', 'Content': 'd,e,f'},\n            {'Line Number': 3, 'Status': ' ', 'Content': 'g,h,i'},\n            {'Line Number': 4, 'Status': '+', 'Content': 'j,k,l'}\n        ]\n        expected_df = pd.DataFrame(expected_data)\n\n        pd.testing.assert_frame_equal(df, expected_df)\n\n    def test_all_lines_same(self):\n        lines = ['1,2,3', '4,5,6']\n        file1 = self.create_temp_file(lines)\n        file2 = self.create_temp_file(lines)\n\n        df = task_func(file1, file2)\n\n        expected_data = [\n            {'Line Number': 1, 'Status': ' ', 'Content': '1,2,3'},\n            {'Line Number': 2, 'Status': ' ', 'Content': '4,5,6'}\n        ]\n        expected_df = pd.DataFrame(expected_data)\n\n        pd.testing.assert_frame_equal(df, expected_df)\n\n    def test_first_file_longer(self):\n        lines1 = ['x', 'y', 'z']\n        lines2 = ['x', 'y']\n        file1 = self.create_temp_file(lines1)\n        file2 = self.create_temp_file(lines2)\n\n        df = task_func(file1, file2)\n\n        expected_data = [\n            {'Line Number': 1, 'Status': ' ', 'Content': 'x'},\n            {'Line Number': 2, 'Status': ' ', 'Content': 'y'},\n            {'Line Number': 3, 'Status': '-', 'Content': 'z'}\n        ]\n        expected_df = pd.DataFrame(expected_data)\n\n        pd.testing.assert_frame_equal(df, expected_df)\n\n    def test_second_file_longer(self):\n        lines1 = ['x', 'y']\n        lines2 = ['x', 'y', 'z']\n        file1 = self.create_temp_file(lines1)\n        file2 = self.create_temp_file(lines2)\n\n        df = task_func(file1, file2)\n\n        expected_data = [\n            {'Line Number': 1, 'Status': ' ', 'Content': 'x'},\n            {'Line Number': 2, 'Status': ' ', 'Content': 'y'},\n            {'Line Number': 3, 'Status': '+', 'Content': 'z'}\n        ]\n        expected_df = pd.DataFrame(expected_data)\n\n        pd.testing.assert_frame_equal(df, expected_df)\n",
        "code": "import pandas as pd\nimport csv\nimport os\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    if not os.path.isfile(file_path1):\n        raise FileNotFoundError(f\"File not found: {file_path1}\")\n    if not os.path.isfile(file_path2):\n        raise FileNotFoundError(f\"File not found: {file_path2}\")\n\n    lines1 = []\n    lines2 = []\n\n    try:\n        with open(file_path1, newline='', encoding='utf-8') as f1:\n            reader1 = csv.reader(f1, delimiter=delimiter, quotechar=quotechar)\n            for row in reader1:\n                lines1.append(delimiter.join(row))\n    except IOError as e:\n        raise Exception(f\"IO error occurred while processing file: {file_path1}\") from e\n\n    try:\n        with open(file_path2, newline='', encoding='utf-8') as f2:\n            reader2 = csv.reader(f2, delimiter=delimiter, quotechar=quotechar)\n            for row in reader2:\n                lines2.append(delimiter.join(row))\n    except IOError as e:\n        raise Exception(f\"IO error occurred while processing file: {file_path2}\") from e\n\n    if len(lines1) == 0:\n        raise ValueError(f\"Input file is empty: {file_path1}\")\n    if len(lines2) == 0:\n        raise ValueError(f\"Input file is empty: {file_path2}\")\n\n    max_len = max(len(lines1), len(lines2))\n\n    data = []\n    for i in range(max_len):\n        line1 = lines1[i] if i < len(lines1) else None\n        line2 = lines2[i] if i < len(lines2) else None\n\n        if line1 == line2 and line1 is not None:\n            status = ' '\n            content = line1\n        elif line1 is not None and (line2 is None or line1 != line2):\n            status = '-'\n            content = line1\n        elif line2 is not None and (line1 is None or line1 != line2):\n            status = '+'\n            content = line2\n        else:\n            status = ' '\n            content = ''\n\n        data.append({'Line Number': i+1, 'Status': status, 'Content': content})\n\n    df = pd.DataFrame(data, columns=['Line Number', 'Status', 'Content'])\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 67,
    "task_id": "BigCodeBench/511",
    "mt_data": [
      {
        "task_id": "BigCodeBench/511_1",
        "turn": "1",
        "instruct_prompt": "Analyze a list of employee data and calculate statistics for a given column. The function should output a dictionary with the 'sum', 'mean', 'min', and 'max' of the column. You should write self-contained code starting with:\n```python\nimport pandas as pd\nimport numpy as np\ndef task_func(column, data):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        data = [\n            {'name': 'Alice', 'age': 30, 'salary': 70000},\n            {'name': 'Bob', 'age': 25, 'salary': 48000},\n            {'name': 'Charlie', 'age': 35, 'salary': 120000}\n        ]\n        expected = {\n            'sum': 70000 + 48000 + 120000,\n            'mean': (70000 + 48000 + 120000) / 3,\n            'min': 48000,\n            'max': 120000\n        }\n        self.assertEqual(task_func('salary', data), expected)\n\n    def test_single_entry(self):\n        data = [{'name': 'Alice', 'age': 30, 'salary': 70000}]\n        expected = {'sum': 70000, 'mean': 70000, 'min': 70000, 'max': 70000}\n        self.assertEqual(task_func('salary', data), expected)\n\n    def test_negative_and_zero(self):\n        data = [\n            {'value': -10},\n            {'value': 0},\n            {'value': 10}\n        ]\n        expected = {'sum': 0, 'mean': 0, 'min': -10, 'max': 10}\n        self.assertEqual(task_func('value', data), expected)\n",
        "code": "import pandas as pd\nimport numpy as np\n\ndef task_func(column, data):\n    # Convert data to DataFrame\n    df = pd.DataFrame(data)\n    \n    # Calculate statistics for the specified column\n    col_data = df[column]\n    result = {\n        'sum': col_data.sum(),\n        'mean': col_data.mean(),\n        'min': col_data.min(),\n        'max': col_data.max()\n    }\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/511_2",
        "turn": "2",
        "instruct_prompt": "If the data list is empty, the sum should be 0 and mean, min, and max values should be NaN.",
        "test": "import unittest\nimport math\n\nclass TestCases(unittest.TestCase):\n    def test_non_empty_data(self):\n        data = [{'a': 1}, {'a': 2}, {'a': 3}]\n        expected = {'sum': 6, 'mean': 2.0, 'min': 1, 'max': 3}\n        result = task_func('a', data)\n        self.assertEqual(result['sum'], expected['sum'])\n        self.assertEqual(result['mean'], expected['mean'])\n        self.assertEqual(result['min'], expected['min'])\n        self.assertEqual(result['max'], expected['max'])\n\n    def test_empty_data(self):\n        data = []\n        result = task_func('a', data)\n        self.assertEqual(result['sum'], 0)\n        self.assertTrue(math.isnan(result['mean']))\n        self.assertTrue(math.isnan(result['min']))\n        self.assertTrue(math.isnan(result['max']))\n",
        "code": "import pandas as pd\nimport numpy as np\n\ndef task_func(column, data):\n    # Convert data to DataFrame\n    df = pd.DataFrame(data)\n    \n    # If data list is empty, return sum=0 and mean, min, max as NaN\n    if df.empty:\n        return {\n            'sum': 0,\n            'mean': np.nan,\n            'min': np.nan,\n            'max': np.nan\n        }\n    \n    # Calculate statistics for the specified column\n    col_data = df[column]\n    result = {\n        'sum': col_data.sum(),\n        'mean': col_data.mean(),\n        'min': col_data.min(),\n        'max': col_data.max()\n    }\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/511_3",
        "turn": "3",
        "instruct_prompt": "The function should also visualize the data with a pie chart, using the Age column as labels, and output a tuple containing the statistics dictionary and the pie chart Axes object. You should include matplotlib.pyplot for plotting.",
        "test": "import unittest\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_normal_data(self):\n        data = [\n            {'Age': '10', 'Score': 20},\n            {'Age': '20', 'Score': 30},\n            {'Age': '30', 'Score': 50}\n        ]\n        stats, ax = task_func('Score', data)\n        self.assertEqual(stats['sum'], 100)\n        self.assertAlmostEqual(stats['mean'], 100/3)\n        self.assertEqual(stats['min'], 20)\n        self.assertEqual(stats['max'], 50)\n        # Check if ax is a matplotlib Axes object\n        self.assertTrue(hasattr(ax, 'pie'))\n        # Check that pie chart has correct number of slices\n        wedges = ax.patches\n        self.assertEqual(len(wedges), 3)\n\n    def test_empty_data(self):\n        data = []\n        stats, ax = task_func('Score', data)\n        self.assertEqual(stats['sum'], 0)\n        self.assertTrue(np.isnan(stats['mean']))\n        self.assertTrue(np.isnan(stats['min']))\n        self.assertTrue(np.isnan(stats['max']))\n        self.assertTrue(hasattr(ax, 'pie'))\n        # Pie chart should have no slices\n        self.assertEqual(len(ax.patches), 0)\n\n    def test_missing_age_column(self):\n        data = [\n            {'Score': 10},\n            {'Score': 20}\n        ]\n        stats, ax = task_func('Score', data)\n        self.assertEqual(stats['sum'], 30)\n        self.assertEqual(stats['min'], 10)\n        self.assertEqual(stats['max'], 20)\n        self.assertTrue(hasattr(ax, 'pie'))\n        # Should have no slices because Age label missing\n        self.assertEqual(len(ax.patches), 0)\n\n    def test_missing_column(self):\n        data = [\n            {'Age': '10'},\n            {'Age': '20'}\n        ]\n        # The column does not exist, should raise KeyError\n        with self.assertRaises(KeyError):\n            task_func('Score', data)\n",
        "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    # Convert data to DataFrame\n    df = pd.DataFrame(data)\n    \n    # If data list is empty, return sum=0 and mean, min, max as NaN and plot empty pie chart\n    if df.empty:\n        stats = {\n            'sum': 0,\n            'mean': np.nan,\n            'min': np.nan,\n            'max': np.nan\n        }\n        fig, ax = plt.subplots()\n        ax.pie([], labels=[])\n        return stats, ax\n    \n    # Calculate statistics for the specified column\n    col_data = df[column]\n    stats = {\n        'sum': col_data.sum(),\n        'mean': col_data.mean(),\n        'min': col_data.min(),\n        'max': col_data.max()\n    }\n    \n    # Plot pie chart with Age column as labels and values from the specified column\n    fig, ax = plt.subplots()\n    # Use values of the specified column as sizes and Age as labels\n    # If Age or column missing or empty, just plot empty pie\n    if 'Age' in df.columns and not df['Age'].empty and not col_data.empty:\n        ax.pie(col_data, labels=df['Age'])\n    else:\n        ax.pie([], labels=[])\n    \n    return stats, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 68,
    "task_id": "BigCodeBench/513",
    "mt_data": [
      {
        "task_id": "BigCodeBench/513_1",
        "turn": "1",
        "instruct_prompt": "Analyze a list of fitness data to calculate the sum, mean, minimum, and maximum of a specified column. You should write self-contained code starting with:\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        data = [\n            {'steps': 1000, 'calories': 50},\n            {'steps': 2000, 'calories': 100},\n            {'steps': 1500, 'calories': 75}\n        ]\n        expected = {'sum': 4500, 'mean': 1500.0, 'min': 1000, 'max': 2000}\n        result = task_func('steps', data)\n        self.assertEqual(result, expected)\n\n    def test_column_not_found(self):\n        data = [{'distance': 5}]\n        with self.assertRaises(ValueError):\n            task_func('steps', data)\n\n    def test_with_nan(self):\n        data = [\n            {'steps': 1000},\n            {'steps': None},\n            {'steps': 3000}\n        ]\n        expected = {'sum': 4000, 'mean': 2000.0, 'min': 1000, 'max': 3000}\n        result = task_func('steps', data)\n        self.assertEqual(result, expected)\n\n    def test_empty_data(self):\n        data = []\n        # When data is empty, sum, mean, min, max should be NaN or raise error\n        with self.assertRaises(ValueError):\n            task_func('steps', data)\n\n    def test_empty_column(self):\n        data = [{'steps': None}, {'steps': None}]\n        res = task_func('steps', data)\n        # sum of empty series is 0, mean, min, max are NaN\n        self.assertEqual(res['sum'], 0)\n        self.assertTrue(np.isnan(res['mean']))\n        self.assertTrue(np.isnan(res['min']))\n        self.assertTrue(np.isnan(res['max']))\n",
        "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef task_func(column, data):\n    \"\"\"\n    Calculate sum, mean, min, and max of the specified column in the given fitness data.\n\n    Args:\n        column (str): The column name to analyze.\n        data (list of dict): List of fitness data records.\n\n    Returns:\n        dict: A dictionary with keys 'sum', 'mean', 'min', 'max' for the specified column.\n    \"\"\"\n    df = pd.DataFrame(data)\n    if column not in df.columns:\n        raise ValueError(f\"Column '{column}' not found in data\")\n    col_data = df[column].dropna()\n    result = {\n        'sum': col_data.sum(),\n        'mean': col_data.mean(),\n        'min': col_data.min(),\n        'max': col_data.max()\n    }\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/513_2",
        "turn": "2",
        "instruct_prompt": "Validate that the specified column exists in the data. If the column is not valid, raise a KeyError with an appropriate message.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.data = [\n            {'steps': 1000, 'calories': 50},\n            {'steps': 2000, 'calories': 100},\n            {'steps': 1500, 'calories': 75},\n            {'steps': None, 'calories': 60},\n        ]\n\n    def test_valid_column(self):\n        result = task_func('steps', self.data)\n        self.assertAlmostEqual(result['sum'], 4500)\n        self.assertAlmostEqual(result['mean'], 1500)\n        self.assertEqual(result['min'], 1000)\n        self.assertEqual(result['max'], 2000)\n\n    def test_invalid_column_raises_keyerror(self):\n        with self.assertRaises(KeyError) as context:\n            task_func('distance', self.data)\n        self.assertIn(\"Column 'distance' not found in data\", str(context.exception))\n",
        "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    \"\"\"\n    Calculate sum, mean, min, and max of the specified column in the given fitness data.\n\n    Args:\n        column (str): The column name to analyze.\n        data (list of dict): List of fitness data records.\n\n    Returns:\n        dict: A dictionary with keys 'sum', 'mean', 'min', 'max' for the specified column.\n    \"\"\"\n    df = pd.DataFrame(data)\n    if column not in df.columns:\n        raise KeyError(f\"Column '{column}' not found in data\")\n    col_data = df[column].dropna()\n    result = {\n        'sum': col_data.sum(),\n        'mean': col_data.mean(),\n        'min': col_data.min(),\n        'max': col_data.max()\n    }\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/513_3",
        "turn": "3",
        "instruct_prompt": "Validate that the data list is not empty. If empty, raise a ValueError with an appropriate message.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_empty_data_raises_value_error(self):\n        with self.assertRaises(ValueError) as context:\n            task_func('steps', [])\n        self.assertEqual(str(context.exception), \"Data list is empty\")\n\n    def test_non_empty_data(self):\n        data = [\n            {'steps': 1000, 'calories': 200},\n            {'steps': 2000, 'calories': 300},\n            {'steps': 3000, 'calories': 400}\n        ]\n        result = task_func('steps', data)\n        self.assertEqual(result['sum'], 6000)\n        self.assertAlmostEqual(result['mean'], 2000)\n        self.assertEqual(result['min'], 1000)\n        self.assertEqual(result['max'], 3000)\n",
        "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    \"\"\"\n    Calculate sum, mean, min, and max of the specified column in the given fitness data.\n\n    Args:\n        column (str): The column name to analyze.\n        data (list of dict): List of fitness data records.\n\n    Returns:\n        dict: A dictionary with keys 'sum', 'mean', 'min', 'max' for the specified column.\n    \"\"\"\n    if not data:\n        raise ValueError(\"Data list is empty\")\n    df = pd.DataFrame(data)\n    if column not in df.columns:\n        raise KeyError(f\"Column '{column}' not found in data\")\n    col_data = df[column].dropna()\n    result = {\n        'sum': col_data.sum(),\n        'mean': col_data.mean(),\n        'min': col_data.min(),\n        'max': col_data.max()\n    }\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/513_4",
        "turn": "4",
        "instruct_prompt": "Validate that the numeric values for 'Steps', 'Calories Burned', and 'Distance Walked' columns are all non-negative. If any are negative, raise a ValueError with an appropriate message.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_valid_data(self):\n        data = [\n            {'Steps': 1000, 'Calories Burned': 50, 'Distance Walked': 0.8},\n            {'Steps': 2000, 'Calories Burned': 100, 'Distance Walked': 1.5},\n            {'Steps': 3000, 'Calories Burned': 150, 'Distance Walked': 2.0}\n        ]\n        result = task_func('Steps', data)\n        self.assertEqual(result['sum'], 6000)\n        self.assertAlmostEqual(result['mean'], 2000)\n        self.assertEqual(result['min'], 1000)\n        self.assertEqual(result['max'], 3000)\n\n    def test_negative_steps(self):\n        data = [\n            {'Steps': -100, 'Calories Burned': 50, 'Distance Walked': 0.8}\n        ]\n        with self.assertRaises(ValueError) as cm:\n            task_func('Steps', data)\n        self.assertIn(\"Negative values found in column 'Steps'\", str(cm.exception))\n\n    def test_negative_calories(self):\n        data = [\n            {'Steps': 1000, 'Calories Burned': -10, 'Distance Walked': 0.8}\n        ]\n        with self.assertRaises(ValueError) as cm:\n            task_func('Calories Burned', data)\n        self.assertIn(\"Negative values found in column 'Calories Burned'\", str(cm.exception))\n\n    def test_negative_distance(self):\n        data = [\n            {'Steps': 1000, 'Calories Burned': 50, 'Distance Walked': -0.5}\n        ]\n        with self.assertRaises(ValueError) as cm:\n            task_func('Distance Walked', data)\n        self.assertIn(\"Negative values found in column 'Distance Walked'\", str(cm.exception))\n\n    def test_column_not_in_data(self):\n        data = [\n            {'Steps': 1000, 'Calories Burned': 50, 'Distance Walked': 0.8}\n        ]\n        import pandas as pd\n        with self.assertRaises(KeyError):\n            task_func('Heart Rate', data)\n\n    def test_empty_data(self):\n        with self.assertRaises(ValueError):\n            task_func('Steps', [])\n",
        "code": "import pandas as pd\n\ndef task_func(column, data):\n    \"\"\"\n    Calculate sum, mean, min, and max of the specified column in the given fitness data.\n\n    Args:\n        column (str): The column name to analyze.\n        data (list of dict): List of fitness data records.\n\n    Returns:\n        dict: A dictionary with keys 'sum', 'mean', 'min', 'max' for the specified column.\n    \"\"\"\n    if not data:\n        raise ValueError(\"Data list is empty\")\n    df = pd.DataFrame(data)\n    if column not in df.columns:\n        raise KeyError(f\"Column '{column}' not found in data\")\n\n    # Validate non-negative values in 'Steps', 'Calories Burned', and 'Distance Walked'\n    for col_to_check in ['Steps', 'Calories Burned', 'Distance Walked']:\n        if col_to_check in df.columns:\n            if (df[col_to_check] < 0).any():\n                raise ValueError(f\"Negative values found in column '{col_to_check}'\")\n\n    col_data = df[column].dropna()\n    result = {\n        'sum': col_data.sum(),\n        'mean': col_data.mean(),\n        'min': col_data.min(),\n        'max': col_data.max()\n    }\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/513_5",
        "turn": "5",
        "instruct_prompt": "Draw a line chart with 'Date' on the x-axis and the specified column values on the y-axis. The chart title should be 'Line Chart of (column)'. Return a tuple containing a dictionary with sum, mean, min, max of the column and the matplotlib Axes object of the plotted chart.",
        "test": "import unittest\nimport matplotlib\nmatplotlib.use('Agg')  # Use a non-interactive backend for testing\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.data = [\n            {'Date': '2024-01-01', 'Steps': 1000, 'Calories Burned': 50, 'Distance Walked': 0.8},\n            {'Date': '2024-01-02', 'Steps': 1500, 'Calories Burned': 70, 'Distance Walked': 1.2},\n            {'Date': '2024-01-03', 'Steps': 2000, 'Calories Burned': 90, 'Distance Walked': 1.5},\n            {'Date': '2024-01-04', 'Steps': 1700, 'Calories Burned': 65, 'Distance Walked': 1.1}\n        ]\n\n    def test_line_chart_and_stats(self):\n        column = 'Steps'\n        result, ax = task_func(column, self.data)\n\n        # Check returned statistics\n        self.assertEqual(result['sum'], 6200)\n        self.assertAlmostEqual(result['mean'], 1550)\n        self.assertEqual(result['min'], 1000)\n        self.assertEqual(result['max'], 2000)\n\n        # Check that ax is a matplotlib Axes object\n        self.assertIsInstance(ax, Axes)\n\n        # Check axes labels and title\n        self.assertEqual(ax.get_xlabel(), 'Date')\n        self.assertEqual(ax.get_ylabel(), column)\n        self.assertEqual(ax.get_title(), f'Line Chart of {column}')\n\n    def test_column_not_found(self):\n        with self.assertRaises(KeyError):\n            task_func('NonExistentColumn', self.data)\n\n    def test_empty_data(self):\n        with self.assertRaises(ValueError):\n            task_func('Steps', [])\n\n    def test_negative_values_error(self):\n        data_with_negative = [\n            {'Date': '2024-01-01', 'Steps': -1000, 'Calories Burned': 50, 'Distance Walked': 0.8}\n        ]\n        with self.assertRaises(ValueError):\n            task_func('Steps', data_with_negative)\n\n    def test_missing_date_column(self):\n        data_no_date = [\n            {'Steps': 1000, 'Calories Burned': 50, 'Distance Walked': 0.8}\n        ]\n        with self.assertRaises(KeyError):\n            task_func('Steps', data_no_date)\n",
        "code": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(column, data):\n    \"\"\"\n    Calculate sum, mean, min, and max of the specified column in the given fitness data,\n    and draw a line chart with 'Date' on x-axis and the column values on y-axis.\n\n    Args:\n        column (str): The column name to analyze and plot.\n        data (list of dict): List of fitness data records.\n\n    Returns:\n        tuple: (dict with sum, mean, min, max of the column, matplotlib Axes object)\n    \"\"\"\n    if not data:\n        raise ValueError(\"Data list is empty\")\n    df = pd.DataFrame(data)\n    if column not in df.columns:\n        raise KeyError(f\"Column '{column}' not found in data\")\n\n    # Validate non-negative values in 'Steps', 'Calories Burned', and 'Distance Walked'\n    for col_to_check in ['Steps', 'Calories Burned', 'Distance Walked']:\n        if col_to_check in df.columns:\n            if (df[col_to_check] < 0).any():\n                raise ValueError(f\"Negative values found in column '{col_to_check}'\")\n\n    # Convert 'Date' to datetime for proper plotting\n    if 'Date' not in df.columns:\n        raise KeyError(\"Column 'Date' not found in data\")\n    df['Date'] = pd.to_datetime(df['Date'])\n\n    col_data = df[[\"Date\", column]].dropna()\n\n    result = {\n        'sum': col_data[column].sum(),\n        'mean': col_data[column].mean(),\n        'min': col_data[column].min(),\n        'max': col_data[column].max()\n    }\n\n    fig, ax = plt.subplots()\n    ax.plot(col_data['Date'], col_data[column], marker='o')\n    ax.set_xlabel('Date')\n    ax.set_ylabel(column)\n    ax.set_title(f'Line Chart of {column}')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n\n    return result, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 69,
    "task_id": "BigCodeBench/526",
    "mt_data": [
      {
        "task_id": "BigCodeBench/526_1",
        "turn": "1",
        "instruct_prompt": "Read a list of dictionaries from a JSON file into a Python variable. You should write self-contained code starting with:```import json\nimport pandas as pd\nimport numpy as np\ndef task_func(input_file=\"data.json\"):\n    with open(input_file, \"r\") as f:\n        data = json.load(f)\n    \n    # further processing here\n```",
        "test": "import unittest\nimport json\nimport os\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_file = \"test_data.json\"\n        self.test_data = [\n            {\"name\": \"Alice\", \"age\": 30},\n            {\"name\": \"Bob\", \"age\": 25}\n        ]\n        with open(self.test_file, \"w\") as f:\n            json.dump(self.test_data, f)\n\n    def tearDown(self):\n        if os.path.exists(self.test_file):\n            os.remove(self.test_file)\n\n    def test_task_func_reads_json(self):\n        result = task_func(self.test_file)\n        self.assertEqual(result, self.test_data)\n\nif __name__ == \"__main__\":\n    unittest.main()",
        "code": "import json\nimport pandas as pd\nimport numpy as np\n\ndef task_func(input_file=\"data.json\"):\n    with open(input_file, \"r\") as f:\n        data = json.load(f)\n    \n    # further processing here\n    return data\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/526_2",
        "turn": "2",
        "instruct_prompt": "For each key present in any dictionary in the list, collect all numeric values (integers or floats) from the dictionaries, ignoring missing or non-numeric values.",
        "test": "import unittest\nimport json\nimport os\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_file = \"test_data.json\"\n\n    def tearDown(self):\n        if os.path.exists(self.test_file):\n            os.remove(self.test_file)\n\n    def write_data(self, data):\n        with open(self.test_file, \"w\") as f:\n            json.dump(data, f)\n\n    def test_collect_numeric_values(self):\n        data = [\n            {\"a\": 1, \"b\": 2.5, \"c\": \"x\"},\n            {\"a\": 3, \"b\": \"not a number\"},\n            {\"a\": 4.0, \"d\": 7},\n            {\"e\": None, \"b\": 1},\n            {\"c\": 10},\n            {\"a\": \"string\", \"b\": 5}\n        ]\n        self.write_data(data)\n        result = task_func(self.test_file)\n        expected = {\n            \"a\": [1, 3, 4.0],\n            \"b\": [2.5, 1, 5],\n            \"d\": [7],\n            \"c\": [10]\n        }\n        self.assertEqual(result, expected)\n\n    def test_empty_list(self):\n        self.write_data([])\n        result = task_func(self.test_file)\n        self.assertEqual(result, {})\n\n    def test_no_numeric_values(self):\n        data = [\n            {\"a\": \"x\"},\n            {\"b\": None},\n            {\"c\": []}\n        ]\n        self.write_data(data)\n        result = task_func(self.test_file)\n        self.assertEqual(result, {})\n",
        "code": "import json\n\ndef task_func(input_file=\"data.json\"):\n    with open(input_file, \"r\") as f:\n        data = json.load(f)\n\n    result = {}\n    for d in data:\n        for key, value in d.items():\n            if isinstance(value, (int, float)):\n                if key not in result:\n                    result[key] = []\n                result[key].append(value)\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/526_3",
        "turn": "3",
        "instruct_prompt": "Calculate the mean and median for each key's collected numeric values, ignoring NaNs.",
        "test": "import unittest\nimport json\nimport math\nfrom io import StringIO\nfrom unittest.mock import mock_open, patch\n\nclass TestCases(unittest.TestCase):\n    def test_mean_median_ignore_nan(self):\n        test_data = [\n            {\"a\": 1, \"b\": 2.0, \"c\": float('nan')},\n            {\"a\": 3, \"b\": float('nan'), \"c\": 4},\n            {\"a\": 5, \"b\": 6, \"c\": 7},\n            {\"a\": float('nan'), \"b\": 8, \"c\": 9}\n        ]\n        mocked_open = mock_open(read_data=json.dumps(test_data))\n\n        with patch(\"builtins.open\", mocked_open):\n            result = task_func(\"dummy.json\")\n\n        # For key 'a': values = [1,3,5], mean=3, median=3\n        self.assertIn(\"a\", result)\n        self.assertAlmostEqual(result[\"a\"][\"mean\"], 3)\n        self.assertEqual(result[\"a\"][\"median\"], 3)\n\n        # For key 'b': values = [2.0,6,8], mean=5.3333..., median=6\n        self.assertIn(\"b\", result)\n        self.assertAlmostEqual(result[\"b\"][\"mean\"], (2.0 + 6 + 8) / 3)\n        self.assertEqual(result[\"b\"][\"median\"], 6)\n\n        # For key 'c': values = [4,7,9], mean=6.666..., median=7\n        self.assertIn(\"c\", result)\n        self.assertAlmostEqual(result[\"c\"][\"mean\"], (4 + 7 + 9) / 3)\n        self.assertEqual(result[\"c\"][\"median\"], 7)\n\n    def test_empty_and_all_nan(self):\n        test_data = [\n            {\"x\": float('nan')},\n            {\"x\": float('nan')}\n        ]\n        mocked_open = mock_open(read_data=json.dumps(test_data))\n\n        with patch(\"builtins.open\", mocked_open):\n            result = task_func(\"dummy.json\")\n\n        # Since all values are NaN, key \"x\" should not appear\n        self.assertNotIn(\"x\", result)\n\n    def test_even_number_of_values(self):\n        test_data = [\n            {\"k\": 1},\n            {\"k\": 3},\n            {\"k\": 5},\n            {\"k\": 7}\n        ]\n        mocked_open = mock_open(read_data=json.dumps(test_data))\n\n        with patch(\"builtins.open\", mocked_open):\n            result = task_func(\"dummy.json\")\n\n        # mean = (1+3+5+7)/4 = 4.0\n        # median = (3+5)/2 = 4.0\n        self.assertIn(\"k\", result)\n        self.assertEqual(result[\"k\"][\"mean\"], 4.0)\n        self.assertEqual(result[\"k\"][\"median\"], 4.0)\n",
        "code": "import json\nimport math\n\ndef task_func(input_file=\"data.json\"):\n    with open(input_file, \"r\") as f:\n        data = json.load(f)\n\n    collected = {}\n    for d in data:\n        for key, value in d.items():\n            if isinstance(value, (int, float)) and not (isinstance(value, float) and math.isnan(value)):\n                if key not in collected:\n                    collected[key] = []\n                collected[key].append(value)\n\n    result = {}\n    for key, values in collected.items():\n        n = len(values)\n        mean = sum(values) / n if n > 0 else None\n        sorted_vals = sorted(values)\n        if n == 0:\n            median = None\n        elif n % 2 == 1:\n            median = sorted_vals[n // 2]\n        else:\n            median = (sorted_vals[n // 2 - 1] + sorted_vals[n // 2]) / 2\n        result[key] = {\"mean\": mean, \"median\": median}\n\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/526_4",
        "turn": "4",
        "instruct_prompt": "Convert the calculated mean and median values into a Pandas DataFrame indexed and sorted by the keys, with columns named 'mean' and 'median'. The function should return this DataFrame.",
        "test": "import unittest\nimport os\nimport json\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_file = \"test_data.json\"\n\n    def tearDown(self):\n        if os.path.exists(self.test_file):\n            os.remove(self.test_file)\n\n    def write_json(self, data):\n        with open(self.test_file, \"w\") as f:\n            json.dump(data, f)\n\n    def test_basic_case(self):\n        data = [\n            {\"a\": 1, \"b\": 2},\n            {\"a\": 3, \"b\": 4},\n            {\"a\": 5, \"b\": 6}\n        ]\n        self.write_json(data)\n        df = task_func(self.test_file)\n        expected = pd.DataFrame({\n            'mean': {'a': 3.0, 'b': 4.0},\n            'median': {'a': 3.0, 'b': 4.0}\n        })\n        expected.index.name = 'key'\n        expected = expected.sort_index()\n        pd.testing.assert_frame_equal(df, expected)\n\n    def test_with_nan_and_non_numeric(self):\n        data = [\n            {\"a\": 1, \"b\": 2, \"c\": \"x\"},\n            {\"a\": 3, \"b\": float('nan'), \"c\": 5},\n            {\"a\": 5, \"b\": 6, \"c\": None}\n        ]\n        self.write_json(data)\n        df = task_func(self.test_file)\n        expected = pd.DataFrame({\n            'mean': {'a': 3.0, 'b': 4.0, 'c': 5.0},\n            'median': {'a': 3.0, 'b': 4.0, 'c': 5.0}\n        })\n        expected.index.name = 'key'\n        expected = expected.sort_index()\n        pd.testing.assert_frame_equal(df, expected)\n\n    def test_empty_and_single_value(self):\n        data = [\n            {\"a\": 10},\n            {},\n            {\"b\": 20}\n        ]\n        self.write_json(data)\n        df = task_func(self.test_file)\n        expected = pd.DataFrame({\n            'mean': {'a': 10.0, 'b': 20.0},\n            'median': {'a': 10.0, 'b': 20.0}\n        })\n        expected.index.name = 'key'\n        expected = expected.sort_index()\n        pd.testing.assert_frame_equal(df, expected)\n",
        "code": "import json\nimport math\nimport pandas as pd\n\ndef task_func(input_file=\"data.json\"):\n    with open(input_file, \"r\") as f:\n        data = json.load(f)\n\n    collected = {}\n    for d in data:\n        for key, value in d.items():\n            if isinstance(value, (int, float)) and not (isinstance(value, float) and math.isnan(value)):\n                if key not in collected:\n                    collected[key] = []\n                collected[key].append(value)\n\n    stats = {}\n    for key, values in collected.items():\n        n = len(values)\n        mean = sum(values) / n if n > 0 else None\n        sorted_vals = sorted(values)\n        if n == 0:\n            median = None\n        elif n % 2 == 1:\n            median = float(sorted_vals[n // 2])  # convert to float for consistency\n        else:\n            median = (sorted_vals[n // 2 - 1] + sorted_vals[n // 2]) / 2\n        stats[key] = {'mean': mean, 'median': median}\n\n    df = pd.DataFrame.from_dict(stats, orient='index')\n    df.index.name = 'key'\n    df = df.sort_index()\n\n    # Ensure columns are float dtype\n    df['mean'] = df['mean'].astype(float)\n    df['median'] = df['median'].astype(float)\n\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 70,
    "task_id": "BigCodeBench/528",
    "mt_data": [
      {
        "task_id": "BigCodeBench/528_1",
        "turn": "1",
        "instruct_prompt": "Write a function that reads a CSV file and returns all rows from the file as a list of lists. You should write self-contained code starting with:```import csv\ndef task_func(file_path):```",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_basic_csv(self):\n        content = \"a,b,c\\n1,2,3\\n4,5,6\"\n        with tempfile.NamedTemporaryFile('w+', delete=False, newline='') as tmpfile:\n            tmpfile.write(content)\n            tmpfile.flush()\n            result = task_func(tmpfile.name)\n        os.unlink(tmpfile.name)\n        expected = [['a', 'b', 'c'], ['1', '2', '3'], ['4', '5', '6']]\n        self.assertEqual(result, expected)\n\n    def test_empty_file(self):\n        with tempfile.NamedTemporaryFile('w+', delete=False, newline='') as tmpfile:\n            tmpfile.flush()\n            result = task_func(tmpfile.name)\n        os.unlink(tmpfile.name)\n        self.assertEqual(result, [])\n\n    def test_single_row(self):\n        content = \"only,row,here\"\n        with tempfile.NamedTemporaryFile('w+', delete=False, newline='') as tmpfile:\n            tmpfile.write(content)\n            tmpfile.flush()\n            result = task_func(tmpfile.name)\n        os.unlink(tmpfile.name)\n        expected = [['only', 'row', 'here']]\n        self.assertEqual(result, expected)\n",
        "code": "import csv\ndef task_func(file_path):\n    with open(file_path, newline='', encoding='utf-8') as csvfile:\n        reader = csv.reader(csvfile)\n        return [row for row in reader]",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/528_2",
        "turn": "2",
        "instruct_prompt": "Add a check to ensure the input file has a '.csv' extension (case-insensitive). If not, raise a ValueError with an appropriate message.",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_valid_csv_file(self):\n        content = \"a,b,c\\n1,2,3\"\n        with tempfile.NamedTemporaryFile('w+', suffix='.csv', delete=False) as f:\n            f.write(content)\n            f.flush()\n            result = task_func(f.name)\n            self.assertEqual(result, [['a', 'b', 'c'], ['1', '2', '3']])\n        os.remove(f.name)\n\n    def test_invalid_extension_txt(self):\n        with tempfile.NamedTemporaryFile('w+', suffix='.txt', delete=False) as f:\n            f.write(\"some content\")\n            f.flush()\n            with self.assertRaises(ValueError) as cm:\n                task_func(f.name)\n            self.assertIn('.csv extension', str(cm.exception))\n        os.remove(f.name)\n\n    def test_invalid_extension_uppercase(self):\n        with tempfile.NamedTemporaryFile('w+', suffix='.CSVX', delete=False) as f:\n            f.write(\"some content\")\n            f.flush()\n            with self.assertRaises(ValueError) as cm:\n                task_func(f.name)\n            self.assertIn('.csv extension', str(cm.exception))\n        os.remove(f.name)\n\n    def test_valid_extension_uppercase(self):\n        content = \"x,y\\n4,5\"\n        with tempfile.NamedTemporaryFile('w+', suffix='.CSV', delete=False) as f:\n            f.write(content)\n            f.flush()\n            result = task_func(f.name)\n            self.assertEqual(result, [['x', 'y'], ['4', '5']])\n        os.remove(f.name)\n",
        "code": "import csv\n\ndef task_func(file_path):\n    if not file_path.lower().endswith('.csv'):\n        raise ValueError('Input file must have a .csv extension')\n    with open(file_path, newline='', encoding='utf-8') as csvfile:\n        reader = csv.reader(csvfile)\n        return [row for row in reader]",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/528_3",
        "turn": "3",
        "instruct_prompt": "Identify duplicate rows from the CSV data. Return a dictionary where keys are the duplicate rows (as tuples) and values are their counts (number of occurrences).",
        "test": "import unittest\nimport os\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_file = 'test.csv'\n\n    def tearDown(self):\n        if os.path.exists(self.test_file):\n            os.remove(self.test_file)\n\n    def write_csv(self, lines):\n        with open(self.test_file, 'w', encoding='utf-8', newline='') as f:\n            for line in lines:\n                f.write(','.join(line) + '\\n')\n\n    def test_duplicates(self):\n        data = [\n            ['a', '1'],\n            ['b', '2'],\n            ['a', '1'],\n            ['c', '3'],\n            ['b', '2'],\n            ['b', '2']\n        ]\n        self.write_csv(data)\n        expected = {('a', '1'): 2, ('b', '2'): 3}\n        result = task_func(self.test_file)\n        self.assertEqual(result, expected)\n\n    def test_no_duplicates(self):\n        data = [\n            ['x', '9'],\n            ['y', '8'],\n            ['z', '7']\n        ]\n        self.write_csv(data)\n        expected = {}\n        result = task_func(self.test_file)\n        self.assertEqual(result, expected)\n\n    def test_empty_file(self):\n        self.write_csv([])\n        expected = {}\n        result = task_func(self.test_file)\n        self.assertEqual(result, expected)\n\n    def test_invalid_extension(self):\n        with self.assertRaises(ValueError):\n            task_func('file.txt')\n",
        "code": "import csv\n\ndef task_func(file_path):\n    if not file_path.lower().endswith('.csv'):\n        raise ValueError('Input file must have a .csv extension')\n    counts = {}\n    with open(file_path, newline='', encoding='utf-8') as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            row_tuple = tuple(row)\n            counts[row_tuple] = counts.get(row_tuple, 0) + 1\n    duplicates = {row: count for row, count in counts.items() if count > 1}\n    return duplicates\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/528_4",
        "turn": "4",
        "instruct_prompt": "Convert the duplicate rows and their counts into a pandas DataFrame and plot a bar chart of the duplicates using matplotlib. The function should return both the dictionary of duplicates and the matplotlib Axes object of the plot.",
        "test": "import unittest\nimport os\nimport tempfile\nimport matplotlib\nmatplotlib.use('Agg')  # Use a non-interactive backend for testing\n\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.temp_file = tempfile.NamedTemporaryFile(mode='w+', delete=False, newline='', encoding='utf-8', suffix='.csv')\n\n    def tearDown(self):\n        try:\n            os.unlink(self.temp_file.name)\n        except Exception:\n            pass\n\n    def write_csv(self, rows):\n        self.temp_file.seek(0)\n        self.temp_file.truncate()\n        for row in rows:\n            self.temp_file.write(\",\".join(row) + \"\\n\")\n        self.temp_file.flush()\n\n    def test_duplicates_dataframe_and_plot(self):\n        rows = [\n            ['a', '1'],\n            ['b', '2'],\n            ['a', '1'],\n            ['c', '3'],\n            ['b', '2'],\n            ['b', '2']\n        ]\n        self.write_csv(rows)\n\n        duplicates, ax = task_func(self.temp_file.name)\n\n        expected_duplicates = {('a', '1'): 2, ('b', '2'): 3}\n        self.assertEqual(duplicates, expected_duplicates)\n\n        self.assertIsInstance(ax, Axes)\n\n        # Check that the x-axis tick labels exist and match expected labels\n        xticklabels = [label.get_text() for label in ax.get_xticklabels() if label.get_text()]\n        expected_labels = ['a | 1', 'b | 2']\n        for label in expected_labels:\n            self.assertIn(label, xticklabels)\n\n    def test_no_duplicates(self):\n        rows = [\n            ['a', '1'],\n            ['b', '2'],\n            ['c', '3']\n        ]\n        self.write_csv(rows)\n\n        duplicates, ax = task_func(self.temp_file.name)\n\n        self.assertEqual(duplicates, {})\n        self.assertIsInstance(ax, Axes)\n\n    def test_invalid_extension(self):\n        with self.assertRaises(ValueError):\n            task_func('file.txt')\n",
        "code": "import csv\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path):\n    if not file_path.lower().endswith('.csv'):\n        raise ValueError('Input file must have a .csv extension')\n    counts = {}\n    with open(file_path, newline='', encoding='utf-8') as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            row_tuple = tuple(row)\n            counts[row_tuple] = counts.get(row_tuple, 0) + 1\n    duplicates = {row: count for row, count in counts.items() if count > 1}\n\n    if duplicates:\n        # Create labels by joining row values\n        labels = [' | '.join(row) for row in duplicates.keys()]\n        counts_list = list(duplicates.values())\n        df = pd.DataFrame({'label': labels, 'count': counts_list})\n\n        ax = df.plot.bar(x='label', y='count', legend=False, figsize=(8, 6))\n        ax.set_ylabel('Count')\n        ax.set_title('Duplicate Rows Count')\n        plt.tight_layout()\n    else:\n        df = pd.DataFrame()\n        fig, ax = plt.subplots()\n\n    return duplicates, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 71,
    "task_id": "BigCodeBench/530",
    "mt_data": [
      {
        "task_id": "BigCodeBench/530_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a DataFrame with columns 'name' and 'age'. The function should check if the DataFrame is empty and raise a ValueError if it is. It should also check if any 'age' value is negative and raise a ValueError in that case. You should write self-contained code starting with:```python\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n```",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_empty_dataframe_raises(self):\n        df = pd.DataFrame(columns=['name', 'age'])\n        with self.assertRaises(ValueError) as cm:\n            task_func(df)\n        self.assertEqual(str(cm.exception), \"DataFrame is empty\")\n\n    def test_negative_age_raises(self):\n        df = pd.DataFrame({'name': ['Alice', 'Bob'], 'age': [25, -3]})\n        with self.assertRaises(ValueError) as cm:\n            task_func(df)\n        self.assertEqual(str(cm.exception), \"Negative age value found\")\n\n    def test_valid_dataframe(self):\n        df = pd.DataFrame({'name': ['Alice', 'Bob'], 'age': [25, 30]})\n        result = task_func(df)\n        self.assertEqual(result, (None, None))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if (df['age'] < 0).any():\n        raise ValueError(\"Negative age value found\")\n    # Function does nothing more as per current requirements\n    return None, None",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/530_2",
        "turn": "2",
        "instruct_prompt": "If the 'age' values are floats, round them down to the nearest integer.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nfrom math import floor\n\nclass TestCases(unittest.TestCase):\n    def test_round_down_float_ages(self):\n        data = {'age': [20.9, 30.1, 25.5, 40.0]}\n        df = pd.DataFrame(data)\n        task_func(df)\n        expected_ages = [floor(a) for a in data['age']]\n        self.assertTrue((df['age'] == expected_ages).all())\n\n    def test_negative_age_raises(self):\n        data = {'age': [20, -1, 30]}\n        df = pd.DataFrame(data)\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_empty_dataframe_raises(self):\n        df = pd.DataFrame({'age': []})\n        with self.assertRaises(ValueError):\n            task_func(df)\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if (df['age'] < 0).any():\n        raise ValueError(\"Negative age value found\")\n    # Round down float ages to nearest integer\n    df['age'] = df['age'].apply(np.floor).astype(int)\n    return None, None\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/530_3",
        "turn": "3",
        "instruct_prompt": "Identify the duplicate 'name' entries in the DataFrame and create a Counter object recording the distribution of ages among these duplicate names.",
        "test": "import unittest\nimport pandas as pd\nfrom collections import Counter\n\nclass TestCases(unittest.TestCase):\n    def test_duplicate_name_age_counter(self):\n        data = {\n            'name': ['Alice', 'Bob', 'Alice', 'David', 'Bob', 'Eve'],\n            'age': [25.9, 30.2, 25.1, 40, 29.7, 22]\n        }\n        df = pd.DataFrame(data)\n        age_counter, _ = task_func(df)\n        # Alice ages floored: 25,25; Bob ages floored: 30,29\n        expected_counter = Counter({25: 2, 30: 1, 29: 1})\n        self.assertEqual(age_counter, expected_counter)\n\n    def test_no_duplicates(self):\n        data = {\n            'name': ['Alice', 'Bob', 'Charlie'],\n            'age': [20, 30, 40]\n        }\n        df = pd.DataFrame(data)\n        age_counter, _ = task_func(df)\n        self.assertEqual(age_counter, Counter())\n\n    def test_empty_dataframe(self):\n        df = pd.DataFrame({'name': [], 'age': []})\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_negative_age(self):\n        data = {'name': ['Alice', 'Bob', 'Alice'], 'age': [25, -1, 30]}\n        df = pd.DataFrame(data)\n        with self.assertRaises(ValueError):\n            task_func(df)\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if (df['age'] < 0).any():\n        raise ValueError(\"Negative age value found\")\n    # Round down float ages to nearest integer\n    df['age'] = df['age'].apply(np.floor).astype(int)\n\n    # Identify duplicate 'name' entries\n    duplicate_names = df[df.duplicated(subset=['name'], keep=False)]['name']\n\n    # Filter rows with duplicate names\n    duplicates_df = df[df['name'].isin(duplicate_names)]\n\n    # Create Counter of ages among duplicate names\n    age_counter = Counter(duplicates_df['age'])\n\n    return age_counter, None\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/530_4",
        "turn": "4",
        "instruct_prompt": "Plot a histogram of the age distribution for duplicate names using seaborn. The histogram should have age on the x-axis and count on the y-axis. Calculate bins based on the minimum and maximum ages among duplicates, adjusted by 0.5 to ensure integer ages fall within bins. Return the Counter and the matplotlib Axes object. If there are no duplicates, return None for the plot.",
        "test": "import unittest\nimport pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_histogram_and_counter_with_duplicates(self):\n        data = {\n            'name': ['Alice', 'Bob', 'Alice', 'Charlie', 'Bob', 'David'],\n            'age': [25, 30, 26, 40, 30, 50]\n        }\n        df = pd.DataFrame(data)\n\n        age_counter, ax = task_func(df)\n\n        # Check Counter correctness\n        expected_counter = Counter({25:1, 26:1, 30:2})\n        self.assertEqual(age_counter, expected_counter)\n\n        # Check that ax is a matplotlib Axes object\n        self.assertIsNotNone(ax)\n        self.assertTrue(hasattr(ax, 'set_xlabel'))\n        self.assertEqual(ax.get_xlabel(), 'age')\n        self.assertEqual(ax.get_ylabel(), 'count')\n\n        # Check bins are correct - number of patches should be > 0\n        patches = ax.patches\n        self.assertTrue(len(patches) > 0)\n\n    def test_no_duplicates_returns_none_plot(self):\n        data = {\n            'name': ['Alice', 'Bob', 'Charlie', 'David'],\n            'age': [25, 30, 40, 50]\n        }\n        df = pd.DataFrame(data)\n\n        age_counter, ax = task_func(df)\n\n        self.assertEqual(age_counter, Counter())\n        self.assertIsNone(ax)\n\n    def test_empty_dataframe_raises(self):\n        df = pd.DataFrame(columns=['name', 'age'])\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_negative_age_raises(self):\n        data = {'name': ['Alice', 'Bob'], 'age': [25, -5]}\n        df = pd.DataFrame(data)\n        with self.assertRaises(ValueError):\n            task_func(df)\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    if (df['age'] < 0).any():\n        raise ValueError(\"Negative age value found\")\n    # Round down float ages to nearest integer\n    df = df.copy()\n    df['age'] = df['age'].apply(np.floor).astype(int)\n\n    # Identify duplicate 'name' entries\n    duplicate_names = df[df.duplicated(subset=['name'], keep=False)]['name']\n\n    # Filter rows with duplicate names\n    duplicates_df = df[df['name'].isin(duplicate_names)]\n\n    if duplicates_df.empty:\n        return Counter(), None\n\n    # Create Counter of ages among duplicate names\n    age_counter = Counter(duplicates_df['age'])\n\n    # Calculate bins for histogram using min and max ages among duplicates\n    min_age = duplicates_df['age'].min()\n    max_age = duplicates_df['age'].max()\n    bins = np.arange(min_age - 0.5, max_age + 1.5, 1)\n\n    # Plot histogram using seaborn\n    plt.figure()\n    ax = sns.histplot(duplicates_df['age'], bins=bins, kde=False)\n    ax.set_xlabel('age')\n    ax.set_ylabel('count')\n\n    return age_counter, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 72,
    "task_id": "BigCodeBench/532",
    "mt_data": [
      {
        "task_id": "BigCodeBench/532_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a DataFrame with a 'value' column and counts how many times each value appears. The function should return a Counter object with counts of all values. You should write self-contained code starting with:\n```python\nimport pandas as pd\nfrom collections import Counter\n\ndef task_func(df, bins=4):\n```",
        "test": "import unittest\nimport pandas as pd\nfrom collections import Counter\n\nclass TestCases(unittest.TestCase):\n    def test_counts(self):\n        df = pd.DataFrame({'value': [1, 2, 2, 3, 3, 3]})\n        expected = Counter({3: 3, 2: 2, 1: 1})\n        self.assertEqual(task_func(df), expected)\n\n    def test_empty(self):\n        df = pd.DataFrame({'value': []})\n        expected = Counter()\n        self.assertEqual(task_func(df), expected)\n\n    def test_single_value(self):\n        df = pd.DataFrame({'value': [5, 5, 5, 5]})\n        expected = Counter({5: 4})\n        self.assertEqual(task_func(df), expected)\n\n    def test_mixed_types(self):\n        df = pd.DataFrame({'value': ['a', 'b', 'a', 'c', 'b', 'b']})\n        expected = Counter({'b': 3, 'a': 2, 'c': 1})\n        self.assertEqual(task_func(df), expected)\n",
        "code": "import pandas as pd\nfrom collections import Counter\n\ndef task_func(df, bins=4):\n    # Count how many times each value appears in the 'value' column\n    return Counter(df['value'])",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/532_2",
        "turn": "2",
        "instruct_prompt": "Modify the function to identify and count only the duplicate values in the 'value' column. Return a Counter object containing counts of these duplicate values.",
        "test": "import unittest\nimport pandas as pd\nfrom collections import Counter\n\nclass TestCases(unittest.TestCase):\n    def test_duplicates_count(self):\n        df = pd.DataFrame({'value': [1, 2, 2, 3, 3, 3, 4]})\n        expected = Counter({2: 2, 3: 3})\n        result = task_func(df)\n        self.assertEqual(result, expected)\n\n    def test_no_duplicates(self):\n        df = pd.DataFrame({'value': [1, 2, 3, 4, 5]})\n        expected = Counter()\n        result = task_func(df)\n        self.assertEqual(result, expected)\n\n    def test_all_duplicates(self):\n        df = pd.DataFrame({'value': [5, 5, 5, 5]})\n        expected = Counter({5: 4})\n        result = task_func(df)\n        self.assertEqual(result, expected)\n\n    def test_empty_df(self):\n        df = pd.DataFrame({'value': []})\n        expected = Counter()\n        result = task_func(df)\n        self.assertEqual(result, expected)\n",
        "code": "import pandas as pd\nfrom collections import Counter\n\ndef task_func(df, bins=4):\n    value_counts = df['value'].value_counts()\n    duplicates = value_counts[value_counts > 1]\n    return Counter(duplicates.to_dict())",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/532_3",
        "turn": "3",
        "instruct_prompt": "Add code to the function that plots a histogram of all values in the 'value' column using matplotlib. Use the specified number of bins and make the bars green with 60% opacity. Label the x-axis as 'Value', the y-axis as 'Frequency', and title the plot 'Distribution'. Return the matplotlib Axes object along with the Counter.",
        "test": "import unittest\nimport pandas as pd\nfrom collections import Counter\nimport matplotlib\nmatplotlib.use('Agg')  # Use a non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    def test_task_func(self):\n        data = {'value': [1, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5]}\n        df = pd.DataFrame(data)\n        expected_counter = Counter({3: 3, 5: 4, 2: 2})\n\n        result_counter, ax = task_func(df, bins=5)\n\n        # Check counter correctness\n        self.assertEqual(result_counter, expected_counter)\n\n        # Check that ax is a matplotlib Axes object\n        import matplotlib.pyplot as plt\n        self.assertEqual(ax.get_xlabel(), 'Value')\n        self.assertEqual(ax.get_ylabel(), 'Frequency')\n        self.assertEqual(ax.get_title(), 'Distribution')\n\n        # Check histogram properties\n        patches = ax.patches\n        # Check color and alpha of bars\n        for patch in patches:\n            self.assertEqual(patch.get_facecolor()[0:3], (0.0, 0.5019607843137255, 0.0))  # green in RGBA\n            self.assertAlmostEqual(patch.get_alpha(), 0.6, places=2)\n\n    def test_empty_df(self):\n        df = pd.DataFrame({'value': []})\n        expected_counter = Counter()\n        result_counter, ax = task_func(df)\n        self.assertEqual(result_counter, expected_counter)\n        self.assertEqual(ax.get_xlabel(), 'Value')\n        self.assertEqual(ax.get_ylabel(), 'Frequency')\n        self.assertEqual(ax.get_title(), 'Distribution')\n\n    def test_no_duplicates(self):\n        df = pd.DataFrame({'value': [1, 2, 3, 4, 5]})\n        expected_counter = Counter()\n        result_counter, ax = task_func(df)\n        self.assertEqual(result_counter, expected_counter)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(df, bins=4):\n    value_counts = df['value'].value_counts()\n    duplicates = value_counts[value_counts > 1]\n    counter_result = Counter(duplicates.to_dict())\n\n    fig, ax = plt.subplots()\n    ax.hist(df['value'], bins=bins, color='green', alpha=0.6)\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution')\n\n    return counter_result, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/532_4",
        "turn": "4",
        "instruct_prompt": "Enhance the plot by overlaying a normal distribution curve fitted to the 'value' data on top of the histogram. The normal curve should be black with a linewidth of 2. If the data is empty or constant, do not overlay the curve. Return the Counter and the Axes object.",
        "test": "import unittest\nimport pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_overlay_normal_curve(self):\n        df = pd.DataFrame({'value': [1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10]})\n        counter, ax = task_func(df, bins=5)\n        self.assertIsInstance(counter, Counter)\n        self.assertEqual(counter[2], 2)\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 1)\n        line = lines[0]\n        self.assertEqual(line.get_color(), 'k')\n        self.assertEqual(line.get_linewidth(), 2)\n\n    def test_no_overlay_on_empty(self):\n        df = pd.DataFrame({'value': []})\n        counter, ax = task_func(df, bins=3)\n        self.assertIsInstance(counter, Counter)\n        self.assertEqual(len(counter), 0)\n        self.assertEqual(len(ax.get_lines()), 0)\n\n    def test_no_overlay_on_constant(self):\n        df = pd.DataFrame({'value': [5, 5, 5, 5]})\n        counter, ax = task_func(df, bins=2)\n        self.assertIsInstance(counter, Counter)\n        self.assertEqual(counter[5], 4)\n        self.assertEqual(len(ax.get_lines()), 0)\n\n    def test_counter_counts_duplicates(self):\n        df = pd.DataFrame({'value': [1, 1, 2, 3, 3, 3, 4]})\n        counter, ax = task_func(df, bins=4)\n        self.assertEqual(counter[1], 2)\n        self.assertEqual(counter[3], 3)\n        self.assertNotIn(2, counter)\n        self.assertNotIn(4, counter)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import norm\n\ndef task_func(df, bins=4):\n    value_counts = df['value'].value_counts()\n    duplicates = value_counts[value_counts > 1]\n    counter_result = Counter(duplicates.to_dict())\n\n    fig, ax = plt.subplots()\n    ax.hist(df['value'], bins=bins, color='green', alpha=0.6)\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Distribution')\n\n    data = df['value'].dropna()\n    if len(data) > 0 and data.nunique() > 1:\n        mu, std = norm.fit(data)\n        x = np.linspace(data.min(), data.max(), 100)\n        p = norm.pdf(x, mu, std)\n        counts, bin_edges = np.histogram(data, bins=bins)\n        bin_width = bin_edges[1] - bin_edges[0]\n        p_scaled = p * len(data) * bin_width\n        ax.plot(x, p_scaled, 'k-', linewidth=2)\n\n    return counter_result, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 73,
    "task_id": "BigCodeBench/553",
    "mt_data": [
      {
        "task_id": "BigCodeBench/553_1",
        "turn": "1",
        "instruct_prompt": "Generate a pandas DataFrame with random values using the input lists 'a' and 'b'. The DataFrame should use 'a' as its row indices and have as many columns as the length of 'b'. You should write self-contained code starting with:```import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(a, b):```",
        "test": "import unittest\nimport pandas as pd\nclass TestCases(unittest.TestCase):\n    def test_dataframe_shape_and_index(self):\n        a = ['row1', 'row2', 'row3']\n        b = [10, 20, 30, 40]\n        df = task_func(a, b)\n        # Check DataFrame shape\n        self.assertEqual(df.shape, (len(a), len(b)))\n        # Check index\n        self.assertTrue(all(idx in df.index for idx in a))\n        # Check columns count\n        self.assertEqual(len(df.columns), len(b))\n        # Check columns are named correctly\n        expected_columns = [f'Col{i}' for i in range(len(b))]\n        self.assertListEqual(list(df.columns), expected_columns)\n        # Check if all values are between 0 and 1\n        self.assertTrue(((df.values >= 0) & (df.values <= 1)).all())\n",
        "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\ndef task_func(a, b):\n    # Generate a DataFrame with index from a, columns count from length of b\n    n_rows = len(a)\n    n_cols = len(b)\n    data = np.random.rand(n_rows, n_cols)\n    df = pd.DataFrame(data, index=a, columns=[f'Col{i}' for i in range(n_cols)])\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/553_2",
        "turn": "2",
        "instruct_prompt": "Use only the first len(b) elements of the predefined COLUMNS list as the DataFrame's column names.",
        "test": "import unittest\nimport pandas as pd\nfrom pandas.api.types import is_float_dtype\n\nclass TestCases(unittest.TestCase):\n    def test_columns_names_and_shape(self):\n        a = ['row1', 'row2', 'row3']\n        b = ['x', 'y']\n        df = task_func(a, b)\n        # Check shape\n        self.assertEqual(df.shape, (len(a), len(b)))\n        # Check index\n        self.assertListEqual(list(df.index), a)\n        # Check columns are first len(b) elements of COLUMNS\n        self.assertListEqual(list(df.columns), COLUMNS[:len(b)])\n        # Check data type is float\n        self.assertTrue(all(is_float_dtype(df[col]) for col in df.columns))\n\n    def test_empty_b(self):\n        a = ['row1', 'row2']\n        b = []\n        df = task_func(a, b)\n        self.assertEqual(df.shape, (len(a), 0))\n        self.assertListEqual(list(df.columns), [])\n\n    def test_single_column(self):\n        a = ['r1']\n        b = ['only']\n        df = task_func(a, b)\n        self.assertEqual(df.shape, (1,1))\n        self.assertListEqual(list(df.columns), COLUMNS[:1])\n\n    def test_b_longer_than_COLUMNS(self):\n        a = ['r1', 'r2']\n        b = ['x', 'y', 'z', 'w', 'v', 'u']  # length 6 > len(COLUMNS)=5\n        with self.assertRaises(ValueError):\n            task_func(a, b)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(a, b):\n    # Generate a DataFrame with index from a, columns from first len(b) elements of COLUMNS\n    n_rows = len(a)\n    n_cols = len(b)\n    # Slicing columns list\n    cols = COLUMNS[:n_cols]\n    if n_cols > len(COLUMNS):\n        # According to pandas, columns length must match data shape, so raise error here\n        raise ValueError('Length of b exceeds available columns in COLUMNS list')\n    data = np.random.rand(n_rows, n_cols)\n    df = pd.DataFrame(data, index=a, columns=cols)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/553_3",
        "turn": "3",
        "instruct_prompt": "Plot the generated DataFrame as a bar chart using pandas plotting and return the matplotlib Axes object of the plot.",
        "test": "import unittest\nimport matplotlib.pyplot as plt\nfrom matplotlib.container import BarContainer\n\nclass TestCases(unittest.TestCase):\n    def test_plot_axes_returned(self):\n        a = ['x', 'y', 'z']\n        b = [1, 2, 3]\n        ax = task_func(a, b)\n        # Check that the returned object is a matplotlib Axes\n        self.assertIsInstance(ax, plt.Axes)\n\n    def test_plot_bar_chart_structure(self):\n        a = ['row1', 'row2']\n        b = [1, 2]\n        ax = task_func(a, b)\n        # The plot should have bars corresponding to DataFrame values\n        # Check that the Axes contains bar containers\n        bars = [c for c in ax.containers if isinstance(c, BarContainer)]\n        self.assertTrue(len(bars) > 0)\n\n    def test_invalid_b_length_raises(self):\n        a = ['x']\n        b = [1, 2, 3, 4, 5, 6]  # More than COLUMNS length\n        with self.assertRaises(ValueError):\n            task_func(a, b)\n",
        "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(a, b):\n    # Generate a DataFrame with index from a, columns from first len(b) elements of COLUMNS\n    n_rows = len(a)\n    n_cols = len(b)\n    # Slicing columns list\n    cols = COLUMNS[:n_cols]\n    if n_cols > len(COLUMNS):\n        # According to pandas, columns length must match data shape, so raise error here\n        raise ValueError('Length of b exceeds available columns in COLUMNS list')\n    data = np.random.rand(n_rows, n_cols)\n    df = pd.DataFrame(data, index=a, columns=cols)\n    # Plot the DataFrame as a bar chart and return the Axes object\n    ax = df.plot(kind='bar')\n    return ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/553_4",
        "turn": "4",
        "instruct_prompt": "If either 'a' or 'b' is empty, return an empty matplotlib Axes object without raising errors or displaying any plot.",
        "test": "import unittest\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_empty_a(self):\n        ax = task_func([], ['x'])\n        self.assertIsInstance(ax, Axes)\n        self.assertEqual(len(ax.containers), 0)  # No bars plotted\n\n    def test_empty_b(self):\n        ax = task_func(['x'], [])\n        self.assertIsInstance(ax, Axes)\n        self.assertEqual(len(ax.containers), 0)  # No bars plotted\n\n    def test_non_empty(self):\n        a = ['row1', 'row2']\n        b = ['col1', 'col2']\n        ax = task_func(a, b)\n        self.assertIsInstance(ax, Axes)\n        self.assertGreater(len(ax.containers), 0)  # Bars should be plotted\n",
        "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\ndef task_func(a, b):\n    if not a or not b:\n        fig, ax = plt.subplots()\n        return ax\n\n    n_rows = len(a)\n    n_cols = len(b)\n    cols = COLUMNS[:n_cols]\n    if n_cols > len(COLUMNS):\n        raise ValueError('Length of b exceeds available columns in COLUMNS list')\n    data = np.random.rand(n_rows, n_cols)\n    df = pd.DataFrame(data, index=a, columns=cols)\n    ax = df.plot(kind='bar')\n    return ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 74,
    "task_id": "BigCodeBench/560",
    "mt_data": [
      {
        "task_id": "BigCodeBench/560_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a string input representing monthly data values for a single year and returns a matplotlib Axes object containing a bar chart with months on the x-axis and values on the y-axis. You should write self-contained code starting with:\n```\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(data):\n```",
        "test": "import unittest\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_basic_bar_chart(self):\n        data = '1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12'\n        ax = task_func(data)\n        # Check type\n        self.assertIsInstance(ax, plt.Axes)\n        # Check x-axis labels\n        expected_months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n        actual_months = [tick.get_text() for tick in ax.get_xticklabels() if tick.get_text() != '']\n        self.assertEqual(actual_months, expected_months)\n        # Check y values\n        bars = ax.patches\n        self.assertEqual(len(bars), 12)\n        heights = [bar.get_height() for bar in bars]\n        expected_values = [1,2,3,4,5,6,7,8,9,10,11,12]\n        self.assertEqual(heights, expected_values)\n",
        "code": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(data):\n    # data is a string of monthly values separated by commas or spaces\n    # Parse the values\n    if ',' in data:\n        values = [float(x.strip()) for x in data.split(',')]\n    else:\n        values = [float(x.strip()) for x in data.split()]\n\n    # Define months\n    months = [datetime(2000, m, 1).strftime('%b') for m in range(1, 13)]\n\n    # Create dataframe\n    df = pd.DataFrame({'Month': months, 'Value': values})\n\n    # Plot bar chart\n    fig, ax = plt.subplots()\n    ax.bar(df['Month'], df['Value'])\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n    ax.set_title('Monthly Data')\n\n    return ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/560_2",
        "turn": "2",
        "instruct_prompt": "The input data string contains comma-separated entries in the format 'yyyy-mm-value' (e.g., '2023-01-100'). Ensure the data contains entries from only one year; if multiple years are present, raise a ValueError.",
        "test": "import unittest\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_single_year_data(self):\n        data = '2023-01-100,2023-02-150,2023-03-200'\n        ax = task_func(data)\n        self.assertIsInstance(ax, Axes)\n        self.assertEqual(len(ax.patches), 3)  # 3 bars\n\n    def test_multiple_years_data_raises(self):\n        data = '2023-01-100,2024-02-150'\n        with self.assertRaises(ValueError) as cm:\n            task_func(data)\n        self.assertIn('multiple years', str(cm.exception))\n\n    def test_invalid_format_raises(self):\n        data = '2023-01-100,2023-02'\n        with self.assertRaises(ValueError):\n            task_func(data)\n\n    def test_invalid_value_raises(self):\n        data = '2023-01-abc,2023-02-150'\n        with self.assertRaises(ValueError):\n            task_func(data)\n",
        "code": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(data):\n    # data is a string of entries in format 'yyyy-mm-value' separated by commas\n    entries = [x.strip() for x in data.split(',')]\n\n    years = set()\n    values = []\n    months = []\n\n    for entry in entries:\n        parts = entry.split('-')\n        if len(parts) != 3:\n            raise ValueError(f\"Entry '{entry}' is not in 'yyyy-mm-value' format.\")\n        year_str, month_str, value_str = parts\n        years.add(year_str)\n        months.append(datetime(int(year_str), int(month_str), 1).strftime('%b'))\n        try:\n            values.append(float(value_str))\n        except ValueError:\n            raise ValueError(f\"Value part '{value_str}' is not a valid float.\")\n\n    if len(years) != 1:\n        raise ValueError(\"Data contains entries from multiple years.\")\n\n    df = pd.DataFrame({'Month': months, 'Value': values})\n\n    fig, ax = plt.subplots()\n    ax.bar(df['Month'], df['Value'])\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n    ax.set_title('Monthly Data')\n\n    return ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/560_3",
        "turn": "3",
        "instruct_prompt": "Parse the data string into month names and integer values, convert the month numbers to full month names (e.g., '01' to 'January'), and create a pandas DataFrame indexed by month names with their corresponding values.",
        "test": "import unittest\nimport pandas as pd\nfrom pandas.testing import assert_frame_equal\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        data = '2023-01-10, 2023-02-20, 2023-03-30'\n        expected_index = ['January', 'February', 'March']\n        expected_values = [10, 20, 30]\n        df = task_func(data)\n        expected_df = pd.DataFrame({'Value': expected_values}, index=expected_index)\n        assert_frame_equal(df, expected_df)\n\n    def test_single_entry(self):\n        data = '2023-12-100'\n        expected_df = pd.DataFrame({'Value': [100]}, index=['December'])\n        df = task_func(data)\n        assert_frame_equal(df, expected_df)\n\n    def test_invalid_format(self):\n        data = '2023-01-10, 2023-02'\n        with self.assertRaises(ValueError):\n            task_func(data)\n\n    def test_invalid_month(self):\n        data = '2023-13-10'\n        with self.assertRaises(ValueError):\n            task_func(data)\n\n    def test_invalid_value(self):\n        data = '2023-01-ten'\n        with self.assertRaises(ValueError):\n            task_func(data)\n\n    def test_multiple_years(self):\n        data = '2023-01-10, 2024-02-20'\n        with self.assertRaises(ValueError):\n            task_func(data)\n",
        "code": "from datetime import datetime\nimport pandas as pd\n\ndef task_func(data):\n    # data is a string of entries in format 'yyyy-mm-value' separated by commas\n    entries = [x.strip() for x in data.split(',')]\n\n    years = set()\n    values = []\n    months = []\n\n    for entry in entries:\n        parts = entry.split('-')\n        if len(parts) != 3:\n            raise ValueError(f\"Entry '{entry}' is not in 'yyyy-mm-value' format.\")\n        year_str, month_str, value_str = parts\n        years.add(year_str)\n        # Convert month number to full month name\n        try:\n            month_num = int(month_str)\n            month_name = datetime(int(year_str), month_num, 1).strftime('%B')\n        except ValueError:\n            raise ValueError(f\"Month part '{month_str}' is not a valid month number.\")\n        months.append(month_name)\n        try:\n            values.append(int(value_str))\n        except ValueError:\n            raise ValueError(f\"Value part '{value_str}' is not a valid integer.\")\n\n    if len(years) != 1:\n        raise ValueError(\"Data contains entries from multiple years.\")\n\n    df = pd.DataFrame({'Value': values}, index=months)\n\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/560_4",
        "turn": "4",
        "instruct_prompt": "Plot a bar chart on the Axes object with month names on the x-axis and values on the y-axis, set the x-axis label to 'Month', y-axis label to 'Value', and the plot title to 'Monthly Data for yyyy' where yyyy is the year from the data; rotate x-axis labels vertically and ensure the figure is closed to avoid display before returning the Axes.",
        "test": "import unittest\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_bar_chart_properties(self):\n        data = '2023-01-10, 2023-02-15, 2023-03-7'\n        ax = task_func(data)\n        self.assertIsInstance(ax, Axes)\n\n        # Check x-axis label\n        self.assertEqual(ax.get_xlabel(), 'Month')\n\n        # Check y-axis label\n        self.assertEqual(ax.get_ylabel(), 'Value')\n\n        # Check title\n        self.assertEqual(ax.get_title(), 'Monthly Data for 2023')\n\n        # Check that x-axis ticks are month names\n        xticklabels = [tick.get_text() for tick in ax.get_xticklabels()]\n        expected_months = ['January', 'February', 'March']\n        # Filter out empty labels\n        xticklabels = [label for label in xticklabels if label]\n        self.assertEqual(xticklabels, expected_months)\n\n        # Check rotation of x-axis labels is vertical (90 degrees)\n        rotations = [tick.get_rotation() for tick in ax.get_xticklabels() if tick.get_text()]\n        for rot in rotations:\n            self.assertAlmostEqual(rot % 360, 90, delta=1)  # allow small float differences\n\n    def test_figure_closed(self):\n        data = '2023-05-20'\n        ax = task_func(data)\n        fig = ax.figure\n        # After function returns, the figure should be closed and not exist anymore\n        self.assertFalse(plt.fignum_exists(fig.number))\n",
        "code": "from datetime import datetime\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    # data is a string of entries in format 'yyyy-mm-value' separated by commas\n    entries = [x.strip() for x in data.split(',')]\n\n    years = set()\n    values = []\n    months = []\n\n    for entry in entries:\n        parts = entry.split('-')\n        if len(parts) != 3:\n            raise ValueError(f\"Entry '{entry}' is not in 'yyyy-mm-value' format.\")\n        year_str, month_str, value_str = parts\n        years.add(year_str)\n        # Convert month number to full month name\n        try:\n            month_num = int(month_str)\n            month_name = datetime(int(year_str), month_num, 1).strftime('%B')\n        except ValueError:\n            raise ValueError(f\"Month part '{month_str}' is not a valid month number.\")\n        months.append(month_name)\n        try:\n            values.append(int(value_str))\n        except ValueError:\n            raise ValueError(f\"Value part '{value_str}' is not a valid integer.\")\n\n    if len(years) != 1:\n        raise ValueError(\"Data contains entries from multiple years.\")\n\n    year = years.pop()\n\n    df = pd.DataFrame({'Value': values}, index=months)\n\n    fig, ax = plt.subplots()\n    ax.bar(df.index, df['Value'])\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Value')\n    ax.set_title(f'Monthly Data for {year}')\n    plt.setp(ax.get_xticklabels(), rotation='vertical')\n    plt.close(fig)  # Close the figure to avoid display\n\n    return ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 75,
    "task_id": "BigCodeBench/567",
    "mt_data": [
      {
        "task_id": "BigCodeBench/567_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a string of numeric values separated by hyphens, converts it into a list of integers, and returns a pandas DataFrame containing these integers under the column name 'Values'. You should write self-contained code starting with:\n```python\nimport pandas as pd\n\ndef task_func(data):\n```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        input_str = \"1-2-3-4-5\"\n        expected_df = pd.DataFrame({'Values': [1, 2, 3, 4, 5]})\n        result_df = task_func(input_str)\n        pd.testing.assert_frame_equal(result_df, expected_df)\n\n    def test_single_value(self):\n        input_str = \"42\"\n        expected_df = pd.DataFrame({'Values': [42]})\n        result_df = task_func(input_str)\n        pd.testing.assert_frame_equal(result_df, expected_df)\n\n    def test_multiple_digits(self):\n        input_str = \"10-20-30\"\n        expected_df = pd.DataFrame({'Values': [10, 20, 30]})\n        result_df = task_func(input_str)\n        pd.testing.assert_frame_equal(result_df, expected_df)\n",
        "code": "import pandas as pd\n\ndef task_func(data):\n    # Split the input string by hyphens\n    str_values = data.split('-')\n    # Convert the split strings to integers\n    int_values = [int(val) for val in str_values]\n    # Create and return a DataFrame with column name 'Values'\n    return pd.DataFrame({'Values': int_values})",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/567_2",
        "turn": "2",
        "instruct_prompt": "Add code to plot a histogram of the 'Values' column from the DataFrame using matplotlib. The histogram should have bins defined by numpy as bins=np.arange(data_min, data_max+2) - 0.5, where data_min and data_max are the minimum and maximum values in the data respectively.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    def test_dataframe_creation(self):\n        data = '1-2-3-4-5'\n        df = task_func(data)\n        expected = pd.DataFrame({'Values': [1, 2, 3, 4, 5]})\n        pd.testing.assert_frame_equal(df, expected)\n\n    @patch('matplotlib.pyplot.hist')\n    def test_histogram_called_with_correct_bins(self, mock_hist):\n        data = '2-3-3-4-5-6'\n        df = task_func(data)\n        data_min = df['Values'].min()\n        data_max = df['Values'].max()\n        expected_bins = np.arange(data_min, data_max + 2) - 0.5\n        # Check that plt.hist was called once\n        self.assertTrue(mock_hist.called)\n        # Extract the bins argument from the call\n        args, kwargs = mock_hist.call_args\n        bins_passed = kwargs.get('bins') if 'bins' in kwargs else (args[1] if len(args) > 1 else None)\n        self.assertIsNotNone(bins_passed, \"Histogram bins argument is missing\")\n        # Check bins array equality\n        np.testing.assert_array_equal(bins_passed, expected_bins)\n",
        "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(data):\n    # Split the input string by hyphens\n    str_values = data.split('-')\n    # Convert the split strings to integers\n    int_values = [int(val) for val in str_values]\n    # Create a DataFrame with column name 'Values'\n    df = pd.DataFrame({'Values': int_values})\n    \n    # Calculate min and max values for bins\n    data_min = df['Values'].min()\n    data_max = df['Values'].max()\n    bins = np.arange(data_min, data_max + 2) - 0.5\n    \n    # Plot histogram\n    plt.hist(df['Values'], bins=bins)\n    plt.xlabel('Values')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Values')\n    plt.close()  # Close the plot to prevent display during tests\n    \n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/567_3",
        "turn": "3",
        "instruct_prompt": "Label the x-axis as 'Value', the y-axis as 'Frequency', and set the title of the plot to 'Histogram of Values'. Also, set the x-axis ticks to the unique sorted values present in the data.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_labels_and_ticks(self):\n        data = '3-1-2-2-3-4'\n        df, ax = task_func(data)\n        \n        # Check the returned DataFrame\n        expected_values = [3, 1, 2, 2, 3, 4]\n        self.assertTrue(isinstance(df, pd.DataFrame))\n        self.assertListEqual(df['Values'].tolist(), expected_values)\n        \n        # Check x-axis label\n        self.assertEqual(ax.get_xlabel(), 'Value')\n        # Check y-axis label\n        self.assertEqual(ax.get_ylabel(), 'Frequency')\n        # Check title\n        self.assertEqual(ax.get_title(), 'Histogram of Values')\n        \n        # Check x-axis ticks\n        x_ticks = ax.get_xticks()\n        # We expect ticks to be exactly the unique sorted integer values from the data\n        expected_ticks = sorted(set(expected_values))\n        # Matplotlib may return ticks as floats, so convert to int for comparison\n        x_ticks_int = list(map(int, x_ticks))\n        self.assertListEqual(x_ticks_int, expected_ticks)\n\n    def test_previous_round_code_should_fail(self):\n        # The previous round's code would have x-axis label 'Values' (plural) and no ticks set explicitly\n        # We simulate the previous round's plotting (without setting x-axis ticks and with 'Values' label)\n        import matplotlib.pyplot as plt\n        import numpy as np\n\n        data = '3-1-2-2-3-4'\n        str_values = data.split('-')\n        int_values = [int(val) for val in str_values]\n        import pandas as pd\n        df_prev = pd.DataFrame({'Values': int_values})\n\n        data_min = df_prev['Values'].min()\n        data_max = df_prev['Values'].max()\n        bins = np.arange(data_min, data_max + 2) - 0.5\n\n        fig, ax = plt.subplots()\n        ax.hist(df_prev['Values'], bins=bins)\n        ax.set_xlabel('Values')  # plural\n        ax.set_ylabel('Frequency')\n        ax.set_title('Histogram of Values')\n        # No x-axis ticks set\n\n        # Test should fail because x-axis label is not 'Value'\n        self.assertNotEqual(ax.get_xlabel(), 'Value')\n\n        # Test should fail because ticks are not set to unique sorted values\n        expected_ticks = sorted(set(int_values))\n        x_ticks = list(map(int, ax.get_xticks()))\n        self.assertNotEqual(x_ticks, expected_ticks)\n\n        plt.close(fig)\n",
        "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(data):\n    # Split the input string by hyphens\n    str_values = data.split('-')\n    # Convert the split strings to integers\n    int_values = [int(val) for val in str_values]\n    # Create a DataFrame with column name 'Values'\n    df = pd.DataFrame({'Values': int_values})\n    \n    # Calculate min and max values for bins\n    data_min = df['Values'].min()\n    data_max = df['Values'].max()\n    bins = np.arange(data_min, data_max + 2) - 0.5\n    \n    fig, ax = plt.subplots()\n    ax.hist(df['Values'], bins=bins)\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Values')\n    # Set x-axis ticks to unique sorted values\n    unique_sorted_values = sorted(df['Values'].unique())\n    ax.set_xticks(unique_sorted_values)\n    plt.close(fig)  # Close the plot to prevent display during tests\n    return df, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/567_4",
        "turn": "4",
        "instruct_prompt": "Ensure the function returns the matplotlib Axes object of the created histogram and displays the plot.",
        "test": "import unittest\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_returns_axes_and_displays_plot(self):\n        data = '1-2-2-3-4-4-4-5'\n        ax = task_func(data)\n        self.assertIsInstance(ax, Axes)\n        self.assertTrue(len(ax.patches) > 0)  # histogram bars exist\n        expected_ticks = sorted(set(int(x) for x in data.split('-')))\n        actual_ticks = list(map(int, ax.get_xticks()))\n        self.assertEqual(actual_ticks, expected_ticks)\n\n    def test_task_func_with_single_value(self):\n        data = '7'\n        ax = task_func(data)\n        self.assertIsInstance(ax, Axes)\n        expected_ticks = [7]\n        actual_ticks = list(map(int, ax.get_xticks()))\n        self.assertEqual(actual_ticks, expected_ticks)\n\n    def test_task_func_with_unsorted_input(self):\n        data = '5-3-1-4-2-5-3-1'\n        ax = task_func(data)\n        self.assertIsInstance(ax, Axes)\n        expected_ticks = sorted(set(int(x) for x in data.split('-')))\n        actual_ticks = list(map(int, ax.get_xticks()))\n        self.assertEqual(actual_ticks, expected_ticks)\n",
        "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(data):\n    # Split the input string by hyphens\n    str_values = data.split('-')\n    # Convert the split strings to integers\n    int_values = [int(val) for val in str_values]\n    # Create a DataFrame with column name 'Values'\n    df = pd.DataFrame({'Values': int_values})\n    \n    # Calculate min and max values for bins\n    data_min = df['Values'].min()\n    data_max = df['Values'].max()\n    bins = np.arange(data_min, data_max + 2) - 0.5\n    \n    fig, ax = plt.subplots()\n    ax.hist(df['Values'], bins=bins)\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Values')\n    # Set x-axis ticks to unique sorted values\n    unique_sorted_values = sorted(df['Values'].unique())\n    ax.set_xticks(unique_sorted_values)\n    plt.show()  # Display the plot\n    return ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 76,
    "task_id": "BigCodeBench/574",
    "mt_data": [
      {
        "task_id": "BigCodeBench/574_1",
        "turn": "1",
        "instruct_prompt": "Create a sine wave of a specified length with added noise. You should write self-contained code starting with:\n```python\nfrom scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array_length=100, noise_level=0.2):\n```",
        "test": "import unittest\nimport numpy as np\nclass TestCases(unittest.TestCase):\n    def test_signal_length(self):\n        x, y = task_func(array_length=50, noise_level=0.1)\n        self.assertEqual(len(x), 50)\n        self.assertEqual(len(y), 50)\n    \n    def test_signal_noise(self):\n        np.random.seed(0)  # fix seed for reproducibility\n        x, y = task_func(array_length=100, noise_level=0.5)\n        clean_signal = np.sin(x)\n        noise = y - clean_signal\n        self.assertAlmostEqual(np.std(noise), 0.5, delta=0.1)\n    \n    def test_default_parameters(self):\n        x, y = task_func()\n        self.assertEqual(len(x), 100)\n        self.assertEqual(len(y), 100)\n",
        "code": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef task_func(array_length=100, noise_level=0.2):\n    x = np.linspace(0, 2 * np.pi, array_length)\n    clean_signal = np.sin(x)\n    noise = np.random.normal(0, noise_level, array_length)\n    noisy_signal = clean_signal + noise\n    return x, noisy_signal",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/574_2",
        "turn": "2",
        "instruct_prompt": "Define a fitting function of the form a * sin(b * x) and use curve_fit from scipy.optimize to fit this function to the noisy sine wave data.",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_fit_parameters(self):\n        x, y, a, b = task_func(array_length=100, noise_level=0.2)\n        # Check types\n        self.assertIsInstance(x, np.ndarray)\n        self.assertIsInstance(y, np.ndarray)\n        self.assertIsInstance(a, float)\n        self.assertIsInstance(b, float)\n        # Check x and y lengths\n        self.assertEqual(len(x), 100)\n        self.assertEqual(len(y), 100)\n        # The amplitude a should be close to 1 within a reasonable delta\n        self.assertAlmostEqual(a, 1, delta=0.5)\n        # The frequency factor b should be close to 1 within a reasonable delta\n        self.assertAlmostEqual(b, 1, delta=0.5)",
        "code": "import numpy as np\nfrom scipy.optimize import curve_fit\n\ndef task_func(array_length=100, noise_level=0.2):\n    x = np.linspace(0, 2 * np.pi, array_length)\n    clean_signal = np.sin(x)\n    noise = np.random.normal(0, noise_level, array_length)\n    noisy_signal = clean_signal + noise\n\n    def fitting_function(x, a, b):\n        return a * np.sin(b * x)\n\n    popt, _ = curve_fit(fitting_function, x, noisy_signal, p0=[1, 1])\n    return x, noisy_signal, popt[0], popt[1]",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/574_3",
        "turn": "3",
        "instruct_prompt": "Plot both the noisy sine wave data and the fitted curve on the same axes with appropriate labels and legends, and return the matplotlib Axes object.",
        "test": "import unittest\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nfrom io import BytesIO\n\nclass TestCases(unittest.TestCase):\n    def test_plot_content_and_return_type(self):\n        ax = task_func(array_length=50, noise_level=0.1)\n        # Check return type\n        self.assertIsInstance(ax, plt.Axes)\n        # Check that there are exactly two lines plotted\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 2)\n\n        # Check labels\n        self.assertEqual(ax.get_xlabel(), 'x')\n        self.assertEqual(ax.get_ylabel(), 'y')\n\n        # Check legend exists and has two entries with correct labels\n        legend = ax.get_legend()\n        self.assertIsNotNone(legend)\n        labels = [text.get_text() for text in legend.get_texts()]\n        self.assertIn('Noisy sine wave', labels)\n        self.assertIn('Fitted curve', labels)\n\n        # Check that the data plotted for noisy sine wave is noisy (not exactly sine)\n        noisy_y = lines[0].get_ydata()\n        clean_y = np.sin(lines[0].get_xdata())\n        self.assertTrue(np.any(np.abs(noisy_y - clean_y) > 0.05))\n\n        # Check that the fitted curve is close to a*sin(b*x) shape\n        # We just check that the fitted line is smooth and roughly sine-like by comparing with noisy data\n        fitted_y = lines[1].get_ydata()\n        self.assertEqual(len(fitted_y), len(noisy_y))\n\n        # Check that the figure can be saved without error (optional check)\n        fig = ax.figure\n        buf = BytesIO()\n        fig.savefig(buf, format='png')\n        buf.close()\n",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n\ndef task_func(array_length=100, noise_level=0.2):\n    x = np.linspace(0, 2 * np.pi, array_length)\n    clean_signal = np.sin(x)\n    noise = np.random.normal(0, noise_level, array_length)\n    noisy_signal = clean_signal + noise\n\n    def fitting_function(x, a, b):\n        return a * np.sin(b * x)\n\n    popt, _ = curve_fit(fitting_function, x, noisy_signal, p0=[1, 1])\n\n    fitted_curve = fitting_function(x, *popt)\n\n    fig, ax = plt.subplots()\n    ax.plot(x, noisy_signal, label='Noisy sine wave')\n    ax.plot(x, fitted_curve, label='Fitted curve')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.legend()\n\n    return ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 77,
    "task_id": "BigCodeBench/579",
    "mt_data": [
      {
        "task_id": "BigCodeBench/579_1",
        "turn": "1",
        "instruct_prompt": "Reads a CSV file and extracts all text data into a list of words.\nYou should write self-contained code starting with:```import csv\ndef task_func(csv_file):```",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic(self):\n        content = \"name,age,city\\nAlice,30,New York\\nBob,25,Los Angeles\"\n        with tempfile.NamedTemporaryFile('w+', delete=False) as tmp:\n            tmp.write(content)\n            tmp_path = tmp.name\n        try:\n            result = task_func(tmp_path)\n            expected = ['name', 'age', 'city', 'Alice', '30', 'New', 'York', 'Bob', '25', 'Los', 'Angeles']\n            self.assertEqual(result, expected)\n        finally:\n            os.remove(tmp_path)\n\n    def test_task_func_empty_file(self):\n        with tempfile.NamedTemporaryFile('w+', delete=False) as tmp:\n            tmp_path = tmp.name\n        try:\n            result = task_func(tmp_path)\n            self.assertEqual(result, [])\n        finally:\n            os.remove(tmp_path)\n\n    def test_task_func_multiple_words_in_cell(self):\n        content = 'id,description\\n1,\"big red apple\"\\n2,\"small green pear\"'\n        with tempfile.NamedTemporaryFile('w+', delete=False) as tmp:\n            tmp.write(content)\n            tmp_path = tmp.name\n        try:\n            result = task_func(tmp_path)\n            expected = ['id', 'description', '1', 'big', 'red', 'apple', '2', 'small', 'green', 'pear']\n            self.assertEqual(result, expected)\n        finally:\n            os.remove(tmp_path)\n",
        "code": "import csv\n\ndef task_func(csv_file):\n    words = []\n    with open(csv_file, newline='', encoding='utf-8') as f:\n        reader = csv.reader(f)\n        for row in reader:\n            for cell in row:\n                # Split cell text by whitespace to extract words\n                words.extend(cell.split())\n    return words\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/579_2",
        "turn": "2",
        "instruct_prompt": "Normalize all extracted words to ASCII using Unicode normalization (NFKD) and remove non-ASCII characters.",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_ascii_normalization(self):\n        # Prepare CSV content with unicode accented and non-ASCII characters\n        csv_content = 'caf,nave\\njalapeo,faade\\nber,fianc'\n        with tempfile.NamedTemporaryFile('w+', delete=False, newline='', encoding='utf-8') as tmpfile:\n            tmpfile.write(csv_content)\n            tmpfile_name = tmpfile.name\n\n        try:\n            expected_words = ['cafe', 'naive', 'jalapeno', 'facade', 'uber', 'fiance']\n            result = task_func(tmpfile_name)\n            self.assertEqual(result, expected_words)\n        finally:\n            os.remove(tmpfile_name)\n\n    def test_mixed_ascii_and_unicode(self):\n        csv_content = 'hello,world\\nrsum,coperate\\nsmrgsbord'\n        with tempfile.NamedTemporaryFile('w+', delete=False, newline='', encoding='utf-8') as tmpfile:\n            tmpfile.write(csv_content)\n            tmpfile_name = tmpfile.name\n\n        try:\n            expected_words = ['hello', 'world', 'resume', 'cooperate', 'smorgasbord']\n            result = task_func(tmpfile_name)\n            self.assertEqual(result, expected_words)\n        finally:\n            os.remove(tmpfile_name)\n",
        "code": "import csv\nimport unicodedata\n\ndef task_func(csv_file):\n    words = []\n    with open(csv_file, newline='', encoding='utf-8') as f:\n        reader = csv.reader(f)\n        for row in reader:\n            for cell in row:\n                for word in cell.split():\n                    # Normalize word to NFKD and remove non-ASCII characters\n                    nfkd_form = unicodedata.normalize('NFKD', word)\n                    ascii_word = ''.join([c for c in nfkd_form if ord(c) < 128])\n                    words.append(ascii_word)\n    return words\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/579_3",
        "turn": "3",
        "instruct_prompt": "Count the frequency of each normalized word and identify the 10 most common words along with their counts.",
        "test": "import unittest\nimport os\nimport csv\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_csv = 'test.csv'\n\n    def tearDown(self):\n        if os.path.exists(self.test_csv):\n            os.remove(self.test_csv)\n\n    def write_csv(self, rows):\n        with open(self.test_csv, 'w', newline='', encoding='utf-8') as f:\n            writer = csv.writer(f)\n            writer.writerows(rows)\n\n    def test_most_common_words(self):\n        rows = [\n            ['Hello', 'world!'],\n            ['Hello', 'again', 'world'],\n            ['world', 'hello', 'HELLO'],\n            ['test', 'case', 'test', 'case', 'case'],\n            ['unique']\n        ]\n        self.write_csv(rows)\n        result = task_func(self.test_csv)\n        # Expected counts (case insensitive, punctuation removed, ASCII normalized):\n        # hello:4, case:3, world:3, test:2, again:1, unique:1\n        expected = [\n            ('hello', 4),\n            ('case', 3),\n            ('world', 3),\n            ('test', 2),\n            ('again', 1),\n            ('unique', 1)\n        ]\n        self.assertEqual(result, expected)\n\n    def test_empty_file(self):\n        self.write_csv([])\n        result = task_func(self.test_csv)\n        self.assertEqual(result, [])\n\n    def test_non_ascii_words(self):\n        rows = [\n            ['caf', 'nave', 'rsum', 'cafe', 'resume', 'naive'],\n            ['caf', 'nave', 'rsum']\n        ]\n        self.write_csv(rows)\n        result = task_func(self.test_csv)\n        # After normalization, lowercasing and punctuation removal:\n        # cafe:3, naive:3, resume:3\n        expected = [\n            ('cafe', 3),\n            ('naive', 3),\n            ('resume', 3)\n        ]\n        self.assertEqual(result, expected)\n",
        "code": "import csv\nimport unicodedata\nfrom collections import Counter\nimport string\n\ndef task_func(csv_file):\n    words = []\n    with open(csv_file, newline='', encoding='utf-8') as f:\n        reader = csv.reader(f)\n        for row in reader:\n            for cell in row:\n                for word in cell.split():\n                    # Normalize word to NFKD and remove non-ASCII characters\n                    nfkd_form = unicodedata.normalize('NFKD', word)\n                    ascii_word = ''.join([c for c in nfkd_form if ord(c) < 128])\n                    # Remove punctuation\n                    ascii_word = ascii_word.strip(string.punctuation)\n                    if ascii_word:\n                        words.append(ascii_word.lower())\n    counter = Counter(words)\n    # Sort by frequency descending, then alphabetically ascending\n    sorted_common = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n    return sorted_common[:10]\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/579_4",
        "turn": "4",
        "instruct_prompt": "Create a matplotlib bar plot showing the 10 most common words on the x-axis and their frequencies on the y-axis, and return a tuple containing the matplotlib.axes.Axes object and the list of the 10 most common word-frequency tuples.",
        "test": "import unittest\nimport os\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_csv = 'test.csv'\n        with open(self.test_csv, 'w', encoding='utf-8') as f:\n            f.write('hello world hello\\n')\n            f.write('test world test test\\n')\n            f.write('foo bar foo foo foo\\n')\n\n    def tearDown(self):\n        if os.path.exists(self.test_csv):\n            os.remove(self.test_csv)\n\n    def test_task_func_returns_axes_and_top10(self):\n        ax, top10 = task_func(self.test_csv)\n        # Check returned ax is matplotlib Axes\n        self.assertIsInstance(ax, Axes)\n        # Check top10 is a list of tuples\n        self.assertIsInstance(top10, list)\n        # Length of top10 should be min(10, unique words), here 5\n        self.assertEqual(len(top10), 5)\n        for item in top10:\n            self.assertIsInstance(item, tuple)\n            self.assertEqual(len(item), 2)\n            self.assertIsInstance(item[0], str)\n            self.assertIsInstance(item[1], int)\n\n    def test_top10_content_and_order(self):\n        _, top10 = task_func(self.test_csv)\n        # Expected words and counts:\n        # foo:4, test:3, hello:2, world:2, bar:1\n        expected = [('foo', 4), ('test', 3), ('hello', 2), ('world', 2), ('bar', 1)]\n        self.assertEqual(top10, expected)\n\n    def test_bar_plot_x_and_y_labels(self):\n        ax, _ = task_func(self.test_csv)\n        self.assertEqual(ax.get_xlabel(), 'Words')\n        self.assertEqual(ax.get_ylabel(), 'Frequencies')\n        self.assertEqual(ax.get_title(), 'Top 10 Most Common Words')\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import csv\nimport unicodedata\nfrom collections import Counter\nimport string\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file):\n    words = []\n    with open(csv_file, newline='', encoding='utf-8') as f:\n        reader = csv.reader(f)\n        for row in reader:\n            for cell in row:\n                for word in cell.split():\n                    # Normalize word to NFKD and remove non-ASCII characters\n                    nfkd_form = unicodedata.normalize('NFKD', word)\n                    ascii_word = ''.join([c for c in nfkd_form if ord(c) < 128])\n                    # Remove punctuation\n                    ascii_word = ascii_word.strip(string.punctuation)\n                    if ascii_word:\n                        words.append(ascii_word.lower())\n    counter = Counter(words)\n    # Sort by frequency descending, then alphabetically ascending\n    sorted_common = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n    top10 = sorted_common[:10]\n\n    # Create bar plot\n    fig, ax = plt.subplots()\n    words_list = [w for w, _ in top10]\n    freqs_list = [freq for _, freq in top10]\n    ax.bar(words_list, freqs_list)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('Top 10 Most Common Words')\n\n    return ax, top10\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/579_5",
        "turn": "5",
        "instruct_prompt": "Add exception handling to raise FileNotFoundError if the CSV file does not exist at the specified path, and IOError if there is an error reading the file.",
        "test": "import unittest\nimport os\nimport tempfile\nfrom unittest import mock\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_file_not_found(self):\n        # Check that the raised FileNotFoundError has the custom message\n        with self.assertRaises(FileNotFoundError) as cm:\n            task_func('non_existent_file.csv')\n        self.assertIn('File not found:', str(cm.exception))\n\n    def test_io_error_reading(self):\n        # Create a temporary file with valid content\n        with tempfile.NamedTemporaryFile(delete=False, mode='w', encoding='utf-8', suffix='.csv') as tmp:\n            tmp.write('word1,word2\\nword3')\n            tmp_path = tmp.name\n\n        # Patch csv.reader to raise an exception when called to simulate read error\n        original_csv_reader = csv.reader\n        def faulty_csv_reader(*args, **kwargs):\n            raise Exception('Simulated read error')\n\n        try:\n            with mock.patch('csv.reader', side_effect=faulty_csv_reader):\n                with self.assertRaises(IOError) as cm:\n                    task_func(tmp_path)\n                self.assertIn('Error reading the file:', str(cm.exception))\n        finally:\n            os.remove(tmp_path)\n\n    def test_successful_processing(self):\n        # Create a temporary CSV file with some words\n        content = 'Hello, world!\\nPython, python, PYTHON.\\nTest test test test.'\n        with tempfile.NamedTemporaryFile(delete=False, mode='w', encoding='utf-8', suffix='.csv') as tmp:\n            tmp.write(content)\n            tmp_path = tmp.name\n\n        try:\n            ax, top10 = task_func(tmp_path)\n            self.assertIsInstance(ax, Axes)\n            self.assertIsInstance(top10, list)\n            self.assertTrue(all(isinstance(item, tuple) and len(item) == 2 for item in top10))\n            # Check the most common word is 'test' with frequency 4\n            self.assertEqual(top10[0][0], 'test')\n            self.assertEqual(top10[0][1], 4)\n        finally:\n            os.remove(tmp_path)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import csv\nimport unicodedata\nfrom collections import Counter\nimport string\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file):\n    try:\n        with open(csv_file, newline='', encoding='utf-8') as f:\n            try:\n                reader = csv.reader(f)\n                words = []\n                for row in reader:\n                    for cell in row:\n                        for word in cell.split():\n                            # Normalize word to NFKD and remove non-ASCII characters\n                            nfkd_form = unicodedata.normalize('NFKD', word)\n                            ascii_word = ''.join([c for c in nfkd_form if ord(c) < 128])\n                            # Remove punctuation\n                            ascii_word = ascii_word.strip(string.punctuation)\n                            if ascii_word:\n                                words.append(ascii_word.lower())\n            except Exception as e:\n                raise IOError(f\"Error reading the file: {e}\")\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File not found: {csv_file}\")\n\n    counter = Counter(words)\n    # Sort by frequency descending, then alphabetically ascending\n    sorted_common = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n    top10 = sorted_common[:10]\n\n    # Create bar plot\n    fig, ax = plt.subplots()\n    words_list = [w for w, _ in top10]\n    freqs_list = [freq for _, freq in top10]\n    ax.bar(words_list, freqs_list)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('Top 10 Most Common Words')\n\n    return ax, top10\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 78,
    "task_id": "BigCodeBench/582",
    "mt_data": [
      {
        "task_id": "BigCodeBench/582_1",
        "turn": "1",
        "instruct_prompt": "Create a list of normally distributed random numbers. You should write self-contained code starting with:\n```python\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef task_func(size=1000):\n```",
        "test": "import unittest\nimport numpy as np\nfrom scipy import stats\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_output_length(self):\n        data = task_func(500)\n        self.assertEqual(len(data), 500)\n\n    def test_task_func_distribution(self):\n        data = task_func(10000)\n        # Test if data roughly follows a normal distribution using Shapiro-Wilk test\n        # The test returns a p-value, if p > 0.05, data is consistent with normality\n        stat, p = stats.shapiro(data)\n        self.assertGreater(p, 0.05)\n\n    def test_task_func_default_size(self):\n        data = task_func()\n        self.assertEqual(len(data), 1000)\n",
        "code": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(size=1000):\n    # Generate a list of normally distributed random numbers with mean 0 and std 1\n    data = np.random.normal(loc=0, scale=1, size=size)\n    return data\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/582_2",
        "turn": "2",
        "instruct_prompt": "Plot the histogram of the generated normally distributed random numbers with density normalization.",
        "test": "import unittest\nfrom unittest.mock import patch\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    @patch('matplotlib.pyplot.hist')\n    def test_task_func_hist_density(self, mock_hist):\n        data = task_func(1000)\n        # Check data is numpy array\n        self.assertIsInstance(data, np.ndarray)\n        # Check data size\n        self.assertEqual(data.size, 1000)\n        # Check data mean roughly around 0\n        self.assertTrue(abs(np.mean(data)) < 0.2)\n        # Check data std roughly around 1\n        self.assertTrue(abs(np.std(data) - 1) < 0.2)\n        # Check that plt.hist was called once\n        self.assertTrue(mock_hist.called)\n        # Check that plt.hist was called with density=True\n        args, kwargs = mock_hist.call_args\n        self.assertIn('density', kwargs)\n        self.assertTrue(kwargs['density'])\n",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(size=1000):\n    # Generate a list of normally distributed random numbers with mean 0 and std 1\n    data = np.random.normal(loc=0, scale=1, size=size)\n    # Plot the histogram with density normalization\n    plt.hist(data, bins=30, density=True)\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    plt.title('Histogram of Normally Distributed Data with Density Normalization')\n    plt.show()\n    return data\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/582_3",
        "turn": "3",
        "instruct_prompt": "Fit a normal distribution to the generated data and plot its probability density function (PDF) on the same figure.",
        "test": "import unittest\nimport numpy as np\nfrom scipy.stats import norm\nfrom matplotlib.testing.decorators import check_figures_equal\n\nclass TestCases(unittest.TestCase):\n    def test_data_distribution_and_fit(self):\n        data, mu, std = task_func(size=1000)\n        # Check data length\n        self.assertEqual(len(data), 1000)\n        # Check mu and std are floats\n        self.assertIsInstance(mu, float)\n        self.assertIsInstance(std, float)\n        # Check that the mean and std are close to 0 and 1 respectively (within reasonable tolerance)\n        self.assertAlmostEqual(mu, 0, delta=0.2)\n        self.assertAlmostEqual(std, 1, delta=0.2)\n",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(size=1000):\n    # Generate a list of normally distributed random numbers with mean 0 and std 1\n    data = np.random.normal(loc=0, scale=1, size=size)\n    \n    # Plot the histogram with density normalization\n    plt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n    \n    # Fit a normal distribution to the data\n    mu, std = norm.fit(data)\n    \n    # Plot the PDF of the fitted normal distribution\n    xmin, xmax = plt.xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, std)\n    plt.plot(x, p, 'k', linewidth=2)\n    \n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    plt.title('Histogram and Fitted Normal Distribution PDF')\n    plt.show()\n    \n    return data, mu, std\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/582_4",
        "turn": "4",
        "instruct_prompt": "Return the matplotlib.figure.Figure object containing both the histogram and the PDF plot.",
        "test": "import unittest\nimport matplotlib.figure\n\nclass TestCases(unittest.TestCase):\n    def test_return_type(self):\n        fig = task_func(size=500)\n        self.assertIsInstance(fig, matplotlib.figure.Figure)\n    \n    def test_figure_contains_axes(self):\n        fig = task_func(size=500)\n        self.assertTrue(len(fig.axes) > 0)\n        ax = fig.axes[0]\n        # Check that histogram patches exist\n        self.assertTrue(len(ax.patches) > 0)\n        # Check that line plots exist (for PDF)\n        self.assertTrue(len(ax.lines) > 0)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\ndef task_func(size=1000):\n    # Generate a list of normally distributed random numbers with mean 0 and std 1\n    data = np.random.normal(loc=0, scale=1, size=size)\n    \n    # Create a figure and axis\n    fig, ax = plt.subplots()\n    \n    # Plot the histogram with density normalization\n    ax.hist(data, bins=30, density=True, alpha=0.6, color='g')\n    \n    # Fit a normal distribution to the data\n    mu, std = norm.fit(data)\n    \n    # Plot the PDF of the fitted normal distribution\n    xmin, xmax = ax.get_xlim()\n    x = np.linspace(xmin, xmax, 100)\n    p = norm.pdf(x, mu, std)\n    ax.plot(x, p, 'k', linewidth=2)\n    \n    ax.set_xlabel('Value')\n    ax.set_ylabel('Density')\n    ax.set_title('Histogram and Fitted Normal Distribution PDF')\n    \n    return fig\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 79,
    "task_id": "BigCodeBench/583",
    "mt_data": [
      {
        "task_id": "BigCodeBench/583_1",
        "turn": "1",
        "instruct_prompt": "Generate an RSA public and private key pair and return the public key. You should write self-contained code starting with:```import rsa\ndef task_func():```",
        "test": "import unittest\nimport rsa\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_returns_public_key(self):\n        pubkey = task_func()\n        # Check the returned object is an instance of rsa.PublicKey\n        self.assertIsInstance(pubkey, rsa.PublicKey)\n        # Check that the key length is 2048 bits\n        self.assertEqual(pubkey.n.bit_length(), 2048)\n",
        "code": "import rsa\n\ndef task_func():\n    (pubkey, privkey) = rsa.newkeys(2048)\n    return pubkey",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/583_2",
        "turn": "2",
        "instruct_prompt": "Generate a random filename in the format \"private_key_<hex8>.txt\", where <hex8> is the hex representation of 8 random bytes, and return it along with the public key.",
        "test": "import unittest\nimport re\nfrom rsa import PublicKey\n\nclass TestCases(unittest.TestCase):\n    def test_task_func(self):\n        filename, pubkey = task_func()\n        # Check filename format\n        self.assertTrue(filename.startswith(\"private_key_\") and filename.endswith(\".txt\"))\n        hex_part = filename[len(\"private_key_\"):-4]\n        self.assertEqual(len(hex_part), 16)  # 8 bytes * 2 hex chars each\n        # Check hex_part is valid hex\n        int(hex_part, 16)  # should not raise\n        # Check pubkey type\n        self.assertIsInstance(pubkey, PublicKey)\n",
        "code": "import rsa\nimport os\n\ndef task_func():\n    (pubkey, privkey) = rsa.newkeys(2048)\n    random_bytes = os.urandom(8)\n    hex8 = random_bytes.hex()\n    filename = f\"private_key_{hex8}.txt\"\n    return filename, pubkey\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/583_3",
        "turn": "3",
        "instruct_prompt": "Encrypt the private key using AES encryption with a randomly generated 16-byte password in EAX mode, save the encrypted private key (base64-encoded) to the generated filename, and return the public key, filename, password, and AES nonce.",
        "test": "import unittest\nimport os\nimport base64\nfrom Crypto.Cipher import AES\nimport rsa\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_encryption_and_outputs(self):\n        pubkey, filename, password, nonce = task_func()\n\n        # Check types\n        self.assertIsInstance(pubkey, rsa.PublicKey)\n        self.assertIsInstance(filename, str)\n        self.assertIsInstance(password, bytes)\n        self.assertIsInstance(nonce, bytes)\n\n        # Check password length\n        self.assertEqual(len(password), 16)\n\n        # Check nonce length\n        self.assertEqual(len(nonce), 16)\n\n        # Check file exists\n        self.assertTrue(os.path.exists(filename))\n\n        # Read encrypted private key from file\n        with open(filename, 'r') as f:\n            encrypted_b64 = f.read()\n\n        # Check base64 decode\n        try:\n            encrypted_bytes = base64.b64decode(encrypted_b64)\n        except Exception as e:\n            self.fail(f\"File content is not valid base64: {e}\")\n\n        # Decrypt to verify correctness\n        cipher = AES.new(password, AES.MODE_EAX, nonce=nonce)\n        decrypted = cipher.decrypt(encrypted_bytes)\n\n        # Load private key from decrypted bytes\n        try:\n            privkey = rsa.PrivateKey.load_pkcs1(decrypted)\n        except Exception as e:\n            self.fail(f\"Decrypted data is not a valid RSA private key: {e}\")\n\n        # Check that public key corresponds to private key\n        self.assertEqual(pubkey.n, privkey.n)\n        self.assertEqual(pubkey.e, privkey.e)\n\n        # Cleanup test file\n        os.remove(filename)\n",
        "code": "import rsa\nimport os\nimport base64\nfrom Crypto.Cipher import AES\n\n\ndef task_func():\n    (pubkey, privkey) = rsa.newkeys(2048)\n    password = os.urandom(16)  # 16-byte random password\n    nonce = os.urandom(16)     # AES EAX nonce is usually 16 bytes\n\n    # Export private key in PEM format as bytes\n    privkey_pem = privkey.save_pkcs1(format='PEM')\n\n    # Encrypt private key using AES in EAX mode\n    cipher = AES.new(password, AES.MODE_EAX, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(privkey_pem)\n\n    # Encode ciphertext as base64\n    encrypted_privkey_b64 = base64.b64encode(ciphertext).decode('utf-8')\n\n    # Generate filename with 8 hex chars\n    hex8 = os.urandom(8).hex()\n    filename = f\"private_key_{hex8}.txt\"\n\n    # Save encrypted private key to file\n    with open(filename, 'w') as f:\n        f.write(encrypted_privkey_b64)\n\n    return pubkey, filename, password, nonce\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 80,
    "task_id": "BigCodeBench/587",
    "mt_data": [
      {
        "task_id": "BigCodeBench/587_1",
        "turn": "1",
        "instruct_prompt": "Write a function that reads a file given by file_path, generates a random 32-byte AES key and 16-byte IV, then encrypts the file content using AES encryption in CBC mode with PKCS7 padding. Save the encrypted data to a new file with the original filename appended by '.encrypted'. The function should return the filename of the encrypted file. You should write self-contained code starting with:```python\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\ndef task_func(file_path):\n```",
        "test": "import unittest\nimport os\nimport tempfile\n\nclass TestCases(unittest.TestCase):\n    def test_encrypt_file_creates_encrypted_file(self):\n        # Create a temporary file with some data\n        with tempfile.NamedTemporaryFile(delete=False) as tmp:\n            tmp.write(b'This is a test file content.')\n            tmp_filepath = tmp.name\n\n        # Run the task_func\n        encrypted_filepath = task_func(tmp_filepath)\n\n        # Check that the encrypted file exists\n        self.assertTrue(os.path.exists(encrypted_filepath))\n\n        # Check that encrypted file content is different from original\n        with open(tmp_filepath, 'rb') as original_file:\n            original_data = original_file.read()\n        with open(encrypted_filepath, 'rb') as encrypted_file:\n            encrypted_data = encrypted_file.read()\n\n        self.assertNotEqual(original_data, encrypted_data)\n\n        # Clean up temporary files\n        os.remove(tmp_filepath)\n        os.remove(encrypted_filepath)\n",
        "code": "import os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\n\ndef task_func(file_path):\n    # Read the file content\n    with open(file_path, 'rb') as f:\n        data = f.read()\n\n    # Generate random 32-byte AES key and 16-byte IV\n    key = os.urandom(32)\n    iv = os.urandom(16)\n\n    # Pad data using PKCS7\n    padder = padding.PKCS7(128).padder()\n    padded_data = padder.update(data) + padder.finalize()\n\n    # Create AES CBC cipher\n    cipher = Cipher(algorithms.AES(key), modes.CBC(iv), backend=default_backend())\n    encryptor = cipher.encryptor()\n\n    # Encrypt the padded data\n    encrypted_data = encryptor.update(padded_data) + encryptor.finalize()\n\n    # Save encrypted data to new file\n    encrypted_filename = file_path + '.encrypted'\n    with open(encrypted_filename, 'wb') as f:\n        f.write(encrypted_data)\n\n    return encrypted_filename\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/587_2",
        "turn": "2",
        "instruct_prompt": "Extend the function to generate an RSA public/private key pair with 512 bits using the rsa library. Then encrypt the AES key using the RSA public key with rsa.encrypt. Save the encrypted AES key (base64-encoded) to a separate file named 'aes_key.encrypted'. The function should now return the RSA public key object, the encrypted file's filename, and the encrypted AES key filename.",
        "test": "import unittest\nimport os\nimport base64\nimport rsa\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a test file\n        self.test_filename = 'testfile.txt'\n        with open(self.test_filename, 'wb') as f:\n            f.write(b'This is a test file for encryption.')\n\n    def tearDown(self):\n        # Remove created files after test\n        encrypted_file = self.test_filename + '.encrypted'\n        if os.path.exists(self.test_filename):\n            os.remove(self.test_filename)\n        if os.path.exists(encrypted_file):\n            os.remove(encrypted_file)\n        if os.path.exists('aes_key.encrypted'):\n            os.remove('aes_key.encrypted')\n\n    def test_task_func_rsa_encryption(self):\n        # Directly call task_func since it is defined in the same file\n        pubkey, encrypted_file, encrypted_aes_key_file = task_func(self.test_filename)\n\n        # Check returned types\n        self.assertIsInstance(pubkey, rsa.PublicKey)\n        self.assertIsInstance(encrypted_file, str)\n        self.assertIsInstance(encrypted_aes_key_file, str)\n\n        # Check files exist\n        self.assertTrue(os.path.exists(encrypted_file))\n        self.assertTrue(os.path.exists(encrypted_aes_key_file))\n\n        # Check encrypted AES key file content is base64\n        with open(encrypted_aes_key_file, 'rb') as f:\n            content = f.read()\n        # Should decode base64 without error\n        decoded = base64.b64decode(content)\n\n        # The decoded encrypted AES key length should match RSA key size (512 bits = 64 bytes)\n        self.assertEqual(len(decoded), 512 // 8)\n\n        # Check encrypted data file is not empty\n        with open(encrypted_file, 'rb') as f:\n            encrypted_data = f.read()\n        self.assertGreater(len(encrypted_data), 0)\n",
        "code": "import os\nimport base64\nimport rsa\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\n\ndef task_func(file_path):\n    # Read the file content\n    with open(file_path, 'rb') as f:\n        data = f.read()\n\n    # Generate random 32-byte AES key and 16-byte IV\n    key = os.urandom(32)\n    iv = os.urandom(16)\n\n    # Pad data using PKCS7\n    padder = padding.PKCS7(128).padder()\n    padded_data = padder.update(data) + padder.finalize()\n\n    # Create AES CBC cipher\n    cipher = Cipher(algorithms.AES(key), modes.CBC(iv), backend=default_backend())\n    encryptor = cipher.encryptor()\n\n    # Encrypt the padded data\n    encrypted_data = encryptor.update(padded_data) + encryptor.finalize()\n\n    # Save encrypted data to new file\n    encrypted_filename = file_path + '.encrypted'\n    with open(encrypted_filename, 'wb') as f:\n        f.write(encrypted_data)\n\n    # Generate RSA public/private key pair with 512 bits\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Encrypt the AES key using RSA public key\n    encrypted_aes_key = rsa.encrypt(key, pubkey)\n\n    # Base64 encode encrypted AES key and save to file\n    encrypted_aes_key_b64 = base64.b64encode(encrypted_aes_key)\n    encrypted_aes_key_filename = 'aes_key.encrypted'\n    with open(encrypted_aes_key_filename, 'wb') as f:\n        f.write(encrypted_aes_key_b64)\n\n    return pubkey, encrypted_filename, encrypted_aes_key_filename\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/587_3",
        "turn": "3",
        "instruct_prompt": "Ensure that the RSA public key returned is of type rsa.PublicKey and that the encrypted AES key file is saved in base64 encoding. The encrypted file and encrypted key file must be saved in binary mode. The function signature and all imports should remain as initially defined.",
        "test": "import unittest\nimport os\nimport base64\nimport rsa\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary test file\n        self.test_filename = 'testfile.txt'\n        with open(self.test_filename, 'wb') as f:\n            f.write(b'This is a test file content for encryption.')\n\n    def tearDown(self):\n        # Remove files created during tests\n        if os.path.exists(self.test_filename):\n            os.remove(self.test_filename)\n        encrypted_file = self.test_filename + '.encrypted'\n        if os.path.exists(encrypted_file):\n            os.remove(encrypted_file)\n        encrypted_key_file = self.test_filename + '.aes_key.encrypted'\n        if os.path.exists(encrypted_key_file):\n            os.remove(encrypted_key_file)\n\n    def test_pubkey_type_and_encrypted_key_file(self):\n        pubkey, encrypted_filename, encrypted_aes_key_filename = task_func(self.test_filename)\n\n        # Check that pubkey is exactly instance of rsa.PublicKey (not subclass)\n        self.assertIs(type(pubkey), rsa.PublicKey, 'Public key is not exactly rsa.PublicKey type')\n\n        # Check encrypted file exists and is readable in binary mode\n        with open(encrypted_filename, 'rb') as f:\n            encrypted_data = f.read()\n        self.assertIsInstance(encrypted_data, bytes)\n        self.assertTrue(len(encrypted_data) > 0)\n\n        # Check encrypted AES key file exists\n        with open(encrypted_aes_key_filename, 'rb') as f:\n            encrypted_key_b64 = f.read()\n\n        # Confirm content is bytes\n        self.assertIsInstance(encrypted_key_b64, bytes)\n\n        # Confirm content is valid base64 bytes (only base64 chars)\n        valid_b64_chars = b'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/='\n        for byte in encrypted_key_b64:\n            self.assertIn(byte, valid_b64_chars, 'Encrypted AES key file contains non-base64 bytes')\n\n        # Try to decode base64 content and check it is bytes\n        try:\n            decoded = base64.b64decode(encrypted_key_b64, validate=True)\n        except Exception as e:\n            self.fail(f'Encrypted AES key file content is not valid base64: {e}')\n\n        self.assertIsInstance(decoded, bytes)\n        self.assertTrue(len(decoded) > 0)\n\n        # Check decoded length matches RSA key size in bytes (512 bits / 8 = 64 bytes)\n        self.assertEqual(len(decoded), 64)\n\n    def test_encrypted_key_file_naming_and_mode(self):\n        # This test ensures that the encrypted AES key file is saved with filename based on input file path + '.aes_key.encrypted'\n        _, _, encrypted_aes_key_filename = task_func(self.test_filename)\n\n        expected_filename = self.test_filename + '.aes_key.encrypted'\n        self.assertEqual(encrypted_aes_key_filename, expected_filename, 'Encrypted AES key filename not as expected')\n\n        # Check file can be opened in binary mode without error\n        with open(encrypted_aes_key_filename, 'rb') as f:\n            content = f.read()\n        self.assertIsInstance(content, bytes)\n\n    def test_previous_solution_should_fail_due_to_filename(self):\n        # This test simulates that the previous solution would fail because it uses fixed filename 'aes_key.encrypted'\n        # We check that the encrypted AES key file named with input file path + '.aes_key.encrypted' exists,\n        # and that 'aes_key.encrypted' does NOT exist to simulate previous solution failure.\n\n        # Run task_func once\n        _, _, encrypted_aes_key_filename = task_func(self.test_filename)\n\n        # encrypted_aes_key_filename must be test_filename + '.aes_key.encrypted'\n        self.assertTrue(encrypted_aes_key_filename.endswith('.aes_key.encrypted'))\n\n        # Check that the fixed name 'aes_key.encrypted' does NOT exist\n        self.assertFalse(os.path.exists('aes_key.encrypted'), \"Previous solution's fixed filename 'aes_key.encrypted' should not exist\")\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import os\nimport base64\nimport rsa\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\n\ndef task_func(file_path):\n    # Read the file content\n    with open(file_path, 'rb') as f:\n        data = f.read()\n\n    # Generate random 32-byte AES key and 16-byte IV\n    key = os.urandom(32)\n    iv = os.urandom(16)\n\n    # Pad data using PKCS7\n    padder = padding.PKCS7(128).padder()\n    padded_data = padder.update(data) + padder.finalize()\n\n    # Create AES CBC cipher\n    cipher = Cipher(algorithms.AES(key), modes.CBC(iv), backend=default_backend())\n    encryptor = cipher.encryptor()\n\n    # Encrypt the padded data\n    encrypted_data = encryptor.update(padded_data) + encryptor.finalize()\n\n    # Save encrypted data to new file in binary mode\n    encrypted_filename = file_path + '.encrypted'\n    with open(encrypted_filename, 'wb') as f:\n        f.write(encrypted_data)\n\n    # Generate RSA public/private key pair with 512 bits\n    (pubkey, privkey) = rsa.newkeys(512)\n\n    # Ensure pubkey is exactly rsa.PublicKey type\n    if type(pubkey) is not rsa.PublicKey:\n        raise TypeError('Returned public key is not exactly of type rsa.PublicKey')\n\n    # Encrypt the AES key using RSA public key\n    encrypted_aes_key = rsa.encrypt(key, pubkey)\n\n    # Base64 encode encrypted AES key\n    encrypted_aes_key_b64 = base64.b64encode(encrypted_aes_key)\n\n    # Save base64 encoded encrypted AES key to file in binary mode\n    encrypted_aes_key_filename = file_path + '.aes_key.encrypted'\n    with open(encrypted_aes_key_filename, 'wb') as f:\n        f.write(encrypted_aes_key_b64)\n\n    return pubkey, encrypted_filename, encrypted_aes_key_filename\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 81,
    "task_id": "BigCodeBench/590",
    "mt_data": [
      {
        "task_id": "BigCodeBench/590_1",
        "turn": "1",
        "instruct_prompt": "Extract all anchor tag texts and href attributes from the HTML content of a given URL, and return them as a pandas DataFrame with columns 'text' and 'href'. You should write self-contained code starting with:```python\nimport urllib.request\nfrom pyquery import PyQuery as pq\nimport pandas as pd\ndef task_func(url):\n```",
        "test": "import unittest\nimport pandas as pd\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('urllib.request.urlopen')\n    def test_task_func(self, mock_urlopen):\n        html_content = b'''\n        <html>\n            <body>\n                <a href=\"http://example.com/page1\">Page 1</a>\n                <a href=\"http://example.com/page2\">Page 2</a>\n                <a href=\"http://example.com/page3\">Page 3</a>\n                <a>No href link</a>\n            </body>\n        </html>\n        '''\n        mock_response = MagicMock()\n        mock_response.read.return_value = html_content\n        mock_urlopen.return_value = mock_response\n\n        # Call task_func directly without import\n        df = task_func('http://fakeurl.com')\n\n        expected_data = [\n            {'text': 'Page 1', 'href': 'http://example.com/page1'},\n            {'text': 'Page 2', 'href': 'http://example.com/page2'},\n            {'text': 'Page 3', 'href': 'http://example.com/page3'},\n            {'text': 'No href link', 'href': None}\n        ]\n        expected_df = pd.DataFrame(expected_data, columns=['text', 'href'])\n\n        pd.testing.assert_frame_equal(df, expected_df)\n",
        "code": "import urllib.request\nfrom pyquery import PyQuery as pq\nimport pandas as pd\n\ndef task_func(url):\n    response = urllib.request.urlopen(url)\n    html = response.read().decode('utf-8')\n    doc = pq(html)\n    data = []\n    for a in doc('a').items():\n        text = a.text()\n        href = a.attr('href')\n        data.append({'text': text, 'href': href})\n    return pd.DataFrame(data, columns=['text', 'href'])",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/590_2",
        "turn": "2",
        "instruct_prompt": "Add error handling to raise a ValueError if the URL is empty or invalid, and raise URLError if there are network connectivity or server issues when fetching the HTML content.",
        "test": "import unittest\nfrom urllib.error import URLError\nfrom unittest.mock import patch, MagicMock\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_empty_url(self):\n        with self.assertRaises(ValueError):\n            task_func('')\n\n    def test_none_url(self):\n        with self.assertRaises(ValueError):\n            task_func(None)\n\n    def test_invalid_url(self):\n        with self.assertRaises(URLError):\n            task_func('http://invalid.url.test')\n\n    @patch('urllib.request.urlopen')\n    def test_valid_url(self, mock_urlopen):\n        html_content = '<html><body><a href=\"http://example.com\">Example</a></body></html>'\n        mock_response = MagicMock()\n        mock_response.read.return_value = html_content.encode('utf-8')\n        mock_urlopen.return_value = mock_response\n\n        df = task_func('http://valid.url')\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertEqual(df.shape[0], 1)\n        self.assertEqual(df.iloc[0]['text'], 'Example')\n        self.assertEqual(df.iloc[0]['href'], 'http://example.com')",
        "code": "import urllib.request\nfrom urllib.error import URLError\nfrom pyquery import PyQuery as pq\nimport pandas as pd\n\ndef task_func(url):\n    if not url or not isinstance(url, str):\n        raise ValueError('URL must be a non-empty string')\n    try:\n        response = urllib.request.urlopen(url)\n        html = response.read().decode('utf-8')\n    except URLError as e:\n        raise\n    doc = pq(html)\n    data = []\n    for a in doc('a').items():\n        text = a.text()\n        href = a.attr('href')\n        data.append({'text': text, 'href': href})\n    return pd.DataFrame(data, columns=['text', 'href'])",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/590_3",
        "turn": "3",
        "instruct_prompt": "Include the time of data extraction as a new column 'fetch_time' in the DataFrame, with the timestamp formatted as 'YYYY-MM-DD HH:MM:SS'. Import any necessary modules to get the current time.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.html_content = b'''\n        <html>\n            <body>\n                <a href=\"http://example.com/1\">Link1</a>\n                <a href=\"http://example.com/2\">Link2</a>\n            </body>\n        </html>\n        '''\n\n    @patch('urllib.request.urlopen')\n    def test_task_func_returns_dataframe_with_fetch_time(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = self.html_content\n        mock_urlopen.return_value = mock_response\n\n        df = task_func('http://dummyurl.com')\n\n        # Check columns\n        self.assertIn('text', df.columns)\n        self.assertIn('href', df.columns)\n        self.assertIn('fetch_time', df.columns)\n\n        # Check data correctness\n        self.assertEqual(len(df), 2)\n        self.assertEqual(df.loc[0, 'text'], 'Link1')\n        self.assertEqual(df.loc[0, 'href'], 'http://example.com/1')\n\n        # Check fetch_time format\n        fetch_time = df.loc[0, 'fetch_time']\n        self.assertIsInstance(fetch_time, str)\n        import re\n        pattern = r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}'\n        self.assertRegex(fetch_time, pattern)\n\n    def test_task_func_invalid_url(self):\n        with self.assertRaises(ValueError):\n            task_func('')\n        with self.assertRaises(ValueError):\n            task_func(None)\n\n    @patch('urllib.request.urlopen')\n    def test_task_func_urlerror(self, mock_urlopen):\n        from urllib.error import URLError\n        mock_urlopen.side_effect = URLError('Failed to reach server')\n        with self.assertRaises(URLError):\n            task_func('http://dummyurl.com')\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import urllib.request\nfrom urllib.error import URLError\nfrom pyquery import PyQuery as pq\nimport pandas as pd\nfrom datetime import datetime\n\ndef task_func(url):\n    if not url or not isinstance(url, str):\n        raise ValueError('URL must be a non-empty string')\n    try:\n        response = urllib.request.urlopen(url)\n        html = response.read().decode('utf-8')\n    except URLError as e:\n        raise\n    doc = pq(html)\n    data = []\n    for a in doc('a').items():\n        text = a.text()\n        href = a.attr('href')\n        data.append({'text': text, 'href': href})\n    df = pd.DataFrame(data, columns=['text', 'href'])\n    fetch_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    df['fetch_time'] = fetch_time\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 82,
    "task_id": "BigCodeBench/592",
    "mt_data": [
      {
        "task_id": "BigCodeBench/592_1",
        "turn": "1",
        "instruct_prompt": "Generate sensor data for a given number of hours and save it as a CSV file with a header row. You should write self-contained code starting with:```python\nimport csv\nimport os\nfrom datetime import datetime\nfrom random import randint\n# Constants\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n```",
        "test": "import unittest\nimport os\nimport csv\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Clean up output directory before each test\n        if os.path.exists(OUTPUT_DIR):\n            for f in os.listdir(OUTPUT_DIR):\n                file_path = os.path.join(OUTPUT_DIR, f)\n                if os.path.isfile(file_path):\n                    os.remove(file_path)\n        else:\n            os.makedirs(OUTPUT_DIR)\n\n    def test_file_creation_and_header(self):\n        hours = 3\n        task_func(hours)\n        filepath = os.path.join(OUTPUT_DIR, 'sensor_data.csv')\n        self.assertTrue(os.path.exists(filepath), 'CSV file should be created')\n\n        with open(filepath, mode='r', newline='') as csvfile:\n            reader = csv.reader(csvfile)\n            rows = list(reader)\n\n        # Check header\n        expected_header = ['Timestamp'] + SENSORS\n        self.assertEqual(rows[0], expected_header, 'CSV header row is incorrect')\n\n        # Check number of data rows\n        self.assertEqual(len(rows) - 1, hours, 'Number of data rows should match hours')\n\n    def test_data_format(self):\n        hours = 2\n        task_func(hours)\n        filepath = os.path.join(OUTPUT_DIR, 'sensor_data.csv')\n\n        with open(filepath, mode='r', newline='') as csvfile:\n            reader = csv.DictReader(csvfile)\n            for row in reader:\n                # Check timestamp format\n                try:\n                    datetime.strptime(row['Timestamp'], '%Y-%m-%d %H:%M:%S')\n                except ValueError:\n                    self.fail('Timestamp format is incorrect')\n\n                # Check sensor values are integers\n                for sensor in SENSORS:\n                    value = row[sensor]\n                    self.assertTrue(value.isdigit() or (value.startswith('-') and value[1:].isdigit()),\n                                    f'Sensor value for {sensor} should be integer')\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\n\n# Constants\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    filename = os.path.join(output_dir, 'sensor_data.csv')\n\n    start_time = datetime.now()\n\n    with open(filename, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        # Write header\n        header = ['Timestamp'] + SENSORS\n        writer.writerow(header)\n\n        # Generate data for each hour\n        for hour in range(hours):\n            timestamp = (start_time + timedelta(hours=hour)).strftime('%Y-%m-%d %H:%M:%S')\n            # Generate random sensor values\n            temperature = randint(-20, 40)  # Example range for Temperature\n            humidity = randint(0, 100)      # Example range for Humidity\n            pressure = randint(950, 1050)   # Example range for Pressure\n            row = [timestamp, temperature, humidity, pressure]\n            writer.writerow(row)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/592_2",
        "turn": "2",
        "instruct_prompt": "Ensure the CSV file contains the columns 'Time', 'Temperature', 'Humidity', and 'Pressure' with 'Time' using the current timestamp formatted as '%Y-%m-%d %H:%M:%S.%f' for each hour.",
        "test": "import unittest\nimport os\nimport csv\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.output_dir = './test_output'\n        if not os.path.exists(self.output_dir):\n            os.makedirs(self.output_dir)\n\n    def tearDown(self):\n        # Clean up the test output directory\n        file_path = os.path.join(self.output_dir, 'sensor_data.csv')\n        if os.path.exists(file_path):\n            os.remove(file_path)\n        if os.path.exists(self.output_dir):\n            os.rmdir(self.output_dir)\n\n    def test_csv_columns_and_time_format(self):\n        hours = 3\n        task_func(hours, self.output_dir)\n\n        file_path = os.path.join(self.output_dir, 'sensor_data.csv')\n        self.assertTrue(os.path.exists(file_path), \"CSV file was not created.\")\n\n        with open(file_path, newline='') as csvfile:\n            reader = csv.reader(csvfile)\n            rows = list(reader)\n\n        # Check header\n        self.assertGreaterEqual(len(rows), 2, \"CSV should have at least header and one data row.\")\n        header = rows[0]\n        expected_header = ['Time', 'Temperature', 'Humidity', 'Pressure']\n        self.assertEqual(header, expected_header, \"CSV header does not match expected columns.\")\n\n        # Check each row's time format\n        for i, row in enumerate(rows[1:], start=1):\n            self.assertEqual(len(row), 4, f\"Row {i} does not have 4 columns.\")\n            time_str = row[0]\n            try:\n                # Confirm the time string matches the format including microseconds\n                datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S.%f')\n            except ValueError:\n                self.fail(f\"Row {i} Time column '{time_str}' does not match the required format.\")\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\n\n# Constants\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    filename = os.path.join(output_dir, 'sensor_data.csv')\n\n    start_time = datetime.now()\n\n    with open(filename, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        # Write header\n        header = ['Time'] + SENSORS\n        writer.writerow(header)\n\n        # Generate data for each hour\n        for hour in range(hours):\n            timestamp = (start_time + timedelta(hours=hour)).strftime('%Y-%m-%d %H:%M:%S.%f')\n            # Generate random sensor values\n            temperature = randint(-20, 40)  # Example range for Temperature\n            humidity = randint(0, 100)      # Example range for Humidity\n            pressure = randint(950, 1050)   # Example range for Pressure\n            row = [timestamp, temperature, humidity, pressure]\n            writer.writerow(row)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/592_3",
        "turn": "3",
        "instruct_prompt": "Generate random integer sensor values between 0 and 100 for each of 'Temperature', 'Humidity', and 'Pressure' for every hour.",
        "test": "import unittest\nimport os\nimport csv\nfrom datetime import datetime\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.output_dir = './test_output'\n        if not os.path.exists(self.output_dir):\n            os.makedirs(self.output_dir)\n\n    def tearDown(self):\n        filepath = os.path.join(self.output_dir, 'sensor_data.csv')\n        if os.path.exists(filepath):\n            os.remove(filepath)\n        if os.path.exists(self.output_dir):\n            try:\n                os.rmdir(self.output_dir)\n            except OSError:\n                pass\n\n    def test_sensor_values_range_and_count(self):\n        hours = 5\n        task_func(hours, self.output_dir)  # direct call\n\n        filepath = os.path.join(self.output_dir, 'sensor_data.csv')\n        self.assertTrue(os.path.exists(filepath))\n\n        with open(filepath, newline='') as csvfile:\n            reader = csv.reader(csvfile)\n            rows = list(reader)\n\n        # Check header\n        self.assertEqual(rows[0], ['Time', 'Temperature', 'Humidity', 'Pressure'])\n\n        # Check number of data rows\n        self.assertEqual(len(rows) - 1, hours)\n\n        for row in rows[1:]:\n            # Check timestamp format\n            try:\n                datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S.%f')\n            except ValueError:\n                self.fail(f\"Timestamp format incorrect: {row[0]}\")\n\n            # Check sensor values are integers and between 0 and 100\n            for value in row[1:]:\n                ivalue = int(value)\n                self.assertGreaterEqual(ivalue, 0)\n                self.assertLessEqual(ivalue, 100)\n\n    def test_previous_code_fails_this_requirement(self):\n        # This simulates previous code behavior by producing out-of-range values for Temperature and Pressure\n        def fake_randint(low, high):\n            fake_randint.call_count += 1\n            # For first call (Temperature), return -20 (out of range)\n            if fake_randint.call_count % 3 == 1:\n                return -20\n            # For second call (Humidity), return 50 (in range)\n            elif fake_randint.call_count % 3 == 2:\n                return 50\n            # For third call (Pressure), return 1050 (out of range)\n            else:\n                return 1050\n        fake_randint.call_count = 0\n\n        # Patch randint in the current module namespace\n        with patch(__name__ + '.randint', side_effect=fake_randint):\n            hours = 1\n            task_func(hours, self.output_dir)\n\n        filepath = os.path.join(self.output_dir, 'sensor_data.csv')\n        with open(filepath, newline='') as csvfile:\n            reader = csv.reader(csvfile)\n            rows = list(reader)\n\n        out_of_range_found = False\n        for row in rows[1:]:\n            for value in row[1:]:\n                ivalue = int(value)\n                if ivalue < 0 or ivalue > 100:\n                    out_of_range_found = True\n                    break\n            if out_of_range_found:\n                break\n\n        self.assertTrue(out_of_range_found, \"Previous code test failed: no out-of-range values found.\")\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\n\n# Constants\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    filename = os.path.join(output_dir, 'sensor_data.csv')\n\n    start_time = datetime.now()\n\n    with open(filename, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        # Write header\n        header = ['Time'] + SENSORS\n        writer.writerow(header)\n\n        # Generate data for each hour\n        for hour in range(hours):\n            timestamp = (start_time + timedelta(hours=hour)).strftime('%Y-%m-%d %H:%M:%S.%f')\n            # Generate random sensor values between 0 and 100\n            temperature = randint(0, 100)\n            humidity = randint(0, 100)\n            pressure = randint(0, 100)\n            row = [timestamp, temperature, humidity, pressure]\n            writer.writerow(row)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/592_4",
        "turn": "4",
        "instruct_prompt": "Save the CSV file to the specified output directory, creating the directory if it does not exist, and return the file path of the created CSV file.",
        "test": "import unittest\nimport os\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = './test_output'\n        if os.path.exists(self.test_dir):\n            shutil.rmtree(self.test_dir)\n\n    def tearDown(self):\n        if os.path.exists(self.test_dir):\n            shutil.rmtree(self.test_dir)\n\n    def test_csv_creation_and_path_return(self):\n        hours = 3\n        filepath = task_func(hours, self.test_dir)\n\n        # Check directory is created\n        self.assertTrue(os.path.exists(self.test_dir))\n        self.assertTrue(os.path.isdir(self.test_dir))\n\n        # Check file path returned is correct\n        expected_path = os.path.join(self.test_dir, 'sensor_data.csv')\n        self.assertEqual(filepath, expected_path)\n\n        # Check file exists\n        self.assertTrue(os.path.isfile(filepath))\n\n        # Check file content\n        with open(filepath, 'r') as f:\n            lines = f.readlines()\n\n        # Header + hours lines\n        self.assertEqual(len(lines), hours + 1)\n        self.assertEqual(lines[0].strip(), 'Time,Temperature,Humidity,Pressure')\n\n    def test_directory_creation_when_not_exists(self):\n        # Directory does not exist initially\n        self.assertFalse(os.path.exists(self.test_dir))\n\n        filepath = task_func(1, self.test_dir)\n\n        # Directory should now exist\n        self.assertTrue(os.path.exists(self.test_dir))\n        self.assertTrue(os.path.isdir(self.test_dir))\n\n        # File should be created inside directory\n        self.assertTrue(os.path.isfile(filepath))\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\n\n# Constants\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    filename = os.path.join(output_dir, 'sensor_data.csv')\n\n    start_time = datetime.now()\n\n    with open(filename, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        # Write header\n        header = ['Time'] + SENSORS\n        writer.writerow(header)\n\n        # Generate data for each hour\n        for hour in range(hours):\n            timestamp = (start_time + timedelta(hours=hour)).strftime('%Y-%m-%d %H:%M:%S.%f')\n            # Generate random sensor values between 0 and 100\n            temperature = randint(0, 100)\n            humidity = randint(0, 100)\n            pressure = randint(0, 100)\n            row = [timestamp, temperature, humidity, pressure]\n            writer.writerow(row)\n\n    return filename\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 83,
    "task_id": "BigCodeBench/593",
    "mt_data": [
      {
        "task_id": "BigCodeBench/593_1",
        "turn": "1",
        "instruct_prompt": "Generate traffic count data for the vehicle types ['Car', 'Bus', 'Truck', 'Bike'] over a specified number of hours and save it to a CSV file. You should write self-contained code starting with:```python\nimport csv\nimport os\nfrom datetime import datetime\nfrom random import randint\n# Constants\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n```",
        "test": "import unittest\nimport csv\nimport os\nfrom pathlib import Path\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_creates_file_with_correct_content(self):\n        hours = 5\n        output_dir = './test_output'\n\n        # Ensure clean test environment\n        if os.path.exists(output_dir):\n            for f in os.listdir(output_dir):\n                os.remove(os.path.join(output_dir, f))\n        else:\n            os.makedirs(output_dir)\n\n        filepath = task_func(hours, output_dir)\n\n        # Check file exists\n        self.assertTrue(os.path.isfile(filepath))\n\n        # Check CSV content\n        with open(filepath, newline='') as csvfile:\n            reader = csv.DictReader(csvfile)\n            rows = list(reader)\n\n            # Check header fields\n            self.assertEqual(reader.fieldnames, ['Hour'] + VEHICLE_TYPES)\n\n            # Check number of rows\n            self.assertEqual(len(rows), hours)\n\n            # Check each row's Hour and vehicle counts\n            for i, row in enumerate(rows, start=1):\n                self.assertEqual(int(row['Hour']), i)\n                for vehicle in VEHICLE_TYPES:\n                    count = int(row[vehicle])\n                    self.assertGreaterEqual(count, 0)\n                    self.assertLessEqual(count, 100)\n\n        # Clean up test output files\n        for f in os.listdir(output_dir):\n            os.remove(os.path.join(output_dir, f))\n        os.rmdir(output_dir)\n",
        "code": "import csv\nimport os\nfrom datetime import datetime\nfrom random import randint\n\n# Constants\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    filename = f\"traffic_count_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n    filepath = os.path.join(output_dir, filename)\n\n    with open(filepath, mode='w', newline='') as csvfile:\n        fieldnames = ['Hour'] + VEHICLE_TYPES\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n        writer.writeheader()\n\n        for hour in range(1, hours + 1):\n            row = {'Hour': hour}\n            for vehicle in VEHICLE_TYPES:\n                row[vehicle] = randint(0, 100)  # Random count between 0 and 100\n            writer.writerow(row)\n\n    return filepath\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/593_2",
        "turn": "2",
        "instruct_prompt": "Ensure the CSV file includes columns 'Time', 'Car', 'Bus', 'Truck', and 'Bike', where 'Time' records the timestamp for each hour's data.",
        "test": "import unittest\nimport csv\nimport os\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_csv_columns_and_time_format(self):\n        filepath = task_func(3, output_dir='./test_output')\n        self.assertTrue(os.path.exists(filepath))\n\n        with open(filepath, newline='') as csvfile:\n            reader = csv.DictReader(csvfile)\n            expected_fields = ['Time', 'Car', 'Bus', 'Truck', 'Bike']\n            self.assertEqual(reader.fieldnames, expected_fields)\n\n            rows = list(reader)\n            self.assertEqual(len(rows), 3)\n\n            for row in rows:\n                time_str = row['Time']\n                try:\n                    datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')\n                except ValueError:\n                    self.fail(f\"Time field '{time_str}' is not in the correct format.\")\n\n                for vehicle in expected_fields[1:]:\n                    count = int(row[vehicle])\n                    self.assertTrue(0 <= count <= 100)\n\n        # Clean up\n        os.remove(filepath)\n        os.rmdir('./test_output')\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\n\n# Constants\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    filename = f\"traffic_count_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n    filepath = os.path.join(output_dir, filename)\n\n    with open(filepath, mode='w', newline='') as csvfile:\n        fieldnames = ['Time'] + VEHICLE_TYPES\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n        writer.writeheader()\n\n        start_time = datetime.now().replace(minute=0, second=0, microsecond=0)\n        for hour in range(hours):\n            current_time = start_time + timedelta(hours=hour)\n            row = {'Time': current_time.strftime('%Y-%m-%d %H:%M:%S')}\n            for vehicle in VEHICLE_TYPES:\n                row[vehicle] = randint(0, 100)  # Random count between 0 and 100\n            writer.writerow(row)\n\n    return filepath\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/593_3",
        "turn": "3",
        "instruct_prompt": "Read the generated CSV file using pandas and plot the traffic data as a line chart with 'Time' on the x-axis and 'Vehicle Count' on the y-axis, displaying separate lines for each vehicle type.",
        "test": "import unittest\nimport os\nimport pandas as pd\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_creates_file_and_content(self):\n        # Directly call task_func defined in the same script\n        filepath = task_func(3, output_dir='./output')\n\n        self.assertTrue(os.path.exists(filepath))\n\n        df = pd.read_csv(filepath)\n        self.assertIn('Time', df.columns)\n        for vehicle in VEHICLE_TYPES:\n            self.assertIn(vehicle, df.columns)\n\n        self.assertEqual(len(df), 3)  # 3 rows for 3 hours\n\n    def test_plot_traffic_data_runs_without_error(self):\n        # Generate a CSV file\n        filepath = task_func(2, output_dir='./output')\n\n        # The plot function should run without error\n        try:\n            plot_traffic_data(filepath)\n        except Exception as e:\n            self.fail(f\"plot_traffic_data raised an exception: {e}\")\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    filename = f\"traffic_count_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n    filepath = os.path.join(output_dir, filename)\n\n    with open(filepath, mode='w', newline='') as csvfile:\n        fieldnames = ['Time'] + VEHICLE_TYPES\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n        writer.writeheader()\n\n        start_time = datetime.now().replace(minute=0, second=0, microsecond=0)\n        for hour in range(hours):\n            current_time = start_time + timedelta(hours=hour)\n            row = {'Time': current_time.strftime('%Y-%m-%d %H:%M:%S')}\n            for vehicle in VEHICLE_TYPES:\n                row[vehicle] = randint(0, 100)  # Random count between 0 and 100\n            writer.writerow(row)\n\n    return filepath\n\ndef plot_traffic_data(csv_filepath):\n    df = pd.read_csv(csv_filepath)\n    df['Time'] = pd.to_datetime(df['Time'])\n\n    plt.figure(figsize=(10, 6))\n    for vehicle in VEHICLE_TYPES:\n        plt.plot(df['Time'], df[vehicle], label=vehicle)\n\n    plt.xlabel('Time')\n    plt.ylabel('Vehicle Count')\n    plt.title('Traffic Data Over Time')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/593_4",
        "turn": "4",
        "instruct_prompt": "The function should return a tuple containing the path to the CSV file and the matplotlib axes object of the line plot.",
        "test": "import unittest\nimport os\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_and_plot_traffic_data(self):\n        # Use the functions and constants directly since they are in the same file\n        hours = 3\n        csv_path = task_func(hours, output_dir=OUTPUT_DIR)\n\n        # Check that the CSV file exists\n        self.assertTrue(os.path.exists(csv_path))\n\n        # Check filename pattern\n        self.assertTrue(csv_path.startswith(OUTPUT_DIR))\n        self.assertTrue(csv_path.endswith('.csv'))\n\n        # Run plot_traffic_data and get returned tuple\n        ret = plot_traffic_data(csv_path)\n\n        # Check returned value is a tuple of length 2\n        self.assertIsInstance(ret, tuple)\n        self.assertEqual(len(ret), 2)\n\n        # Check first element is the CSV path and matches\n        self.assertEqual(ret[0], csv_path)\n\n        # Check second element is a matplotlib Axes object\n        self.assertIsInstance(ret[1], Axes)\n\n        # Check Axes has lines plotted for each vehicle type\n        ax = ret[1]\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 4)  # Four vehicle types\n\n        # Clean up generated file\n        if os.path.exists(csv_path):\n            os.remove(csv_path)\n\n        # Clean up output directory if empty\n        if os.path.exists(OUTPUT_DIR) and not os.listdir(OUTPUT_DIR):\n            os.rmdir(OUTPUT_DIR)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import csv\nimport os\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    filename = f\"traffic_count_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n    filepath = os.path.join(output_dir, filename)\n\n    with open(filepath, mode='w', newline='') as csvfile:\n        fieldnames = ['Time'] + VEHICLE_TYPES\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n        writer.writeheader()\n\n        start_time = datetime.now().replace(minute=0, second=0, microsecond=0)\n        for hour in range(hours):\n            current_time = start_time + timedelta(hours=hour)\n            row = {'Time': current_time.strftime('%Y-%m-%d %H:%M:%S')}\n            for vehicle in VEHICLE_TYPES:\n                row[vehicle] = randint(0, 100)  # Random count between 0 and 100\n            writer.writerow(row)\n\n    return filepath\n\ndef plot_traffic_data(csv_filepath):\n    df = pd.read_csv(csv_filepath)\n    df['Time'] = pd.to_datetime(df['Time'])\n\n    fig, ax = plt.subplots(figsize=(10, 6))\n    for vehicle in VEHICLE_TYPES:\n        ax.plot(df['Time'], df[vehicle], label=vehicle)\n\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Vehicle Count')\n    ax.set_title('Traffic Data Over Time')\n    ax.legend()\n    plt.tight_layout()\n\n    return csv_filepath, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 84,
    "task_id": "BigCodeBench/594",
    "mt_data": [
      {
        "task_id": "BigCodeBench/594_1",
        "turn": "1",
        "instruct_prompt": "Generate weather data for the specified number of hours. You should write self-contained code starting with:```python\nimport csv\nfrom datetime import datetime\nfrom random import randint\n# Constants\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\ndef task_func(hours, output_dir=OUTPUT_DIR):\n```",
        "test": "import unittest\nimport os\nimport csv\nfrom datetime import datetime, timedelta\nfrom random import seed\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.output_dir = './output'\n\n    def test_task_func_generates_correct_rows(self):\n        # Set random seed for reproducibility\n        seed(0)\n        hours = 5\n        # Call task_func directly (no import needed because in same file)\n        task_func(hours, self.output_dir)\n\n        file_path = os.path.join(self.output_dir, 'weather_data.csv')\n        self.assertTrue(os.path.exists(file_path))\n\n        with open(file_path, newline='') as csvfile:\n            reader = csv.reader(csvfile)\n            rows = list(reader)\n\n        # Header + hours rows\n        self.assertEqual(len(rows), hours + 1)\n        self.assertEqual(rows[0], ['Timestamp', 'Weather'])\n\n        # Check timestamp format and weather validity\n        start_time = datetime.now().replace(minute=0, second=0, microsecond=0)\n        for i in range(1, len(rows)):\n            timestamp_str, weather = rows[i]\n            expected_time = start_time + timedelta(hours=i-1)\n            self.assertEqual(timestamp_str, expected_time.strftime('%Y-%m-%d %H:%M:%S'))\n            self.assertIn(weather, WEATHER_CONDITIONS)\n",
        "code": "import csv\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport os\n\n# Constants\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    \"\"\"\n    Generate weather data for the specified number of hours.\n    Each record contains timestamp (hour by hour) and a random weather condition.\n    The data is saved as a CSV file named 'weather_data.csv' in the output directory.\n    \"\"\"\n    # Prepare data\n    start_time = datetime.now().replace(minute=0, second=0, microsecond=0)\n    data = []\n    for i in range(hours):\n        current_time = start_time + timedelta(hours=i)\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS) - 1)]\n        data.append([current_time.strftime('%Y-%m-%d %H:%M:%S'), condition])\n\n    # Write to CSV\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(file_path, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Timestamp', 'Weather'])\n        writer.writerows(data)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/594_2",
        "turn": "2",
        "instruct_prompt": "Save the generated weather data in a CSV file named 'weather_data.csv' with columns 'Time' and 'Condition' in the specified output directory.",
        "test": "import unittest\nimport os\nimport csv\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Use a test directory to avoid conflicts\n        self.test_dir = './test_output'\n        if not os.path.exists(self.test_dir):\n            os.makedirs(self.test_dir)\n\n    def tearDown(self):\n        # Clean up test directory files\n        file_path = os.path.join(self.test_dir, 'weather_data.csv')\n        if os.path.exists(file_path):\n            os.remove(file_path)\n        if os.path.exists(self.test_dir):\n            os.rmdir(self.test_dir)\n\n    def test_csv_file_creation_and_content(self):\n        hours = 5\n        task_func(hours, output_dir=self.test_dir)\n        file_path = os.path.join(self.test_dir, 'weather_data.csv')\n        # Check file exists\n        self.assertTrue(os.path.exists(file_path))\n\n        # Check file content\n        with open(file_path, mode='r', newline='') as csvfile:\n            reader = csv.reader(csvfile)\n            rows = list(reader)\n\n        # Check header\n        self.assertEqual(rows[0], ['Time', 'Condition'])\n\n        # Check number of data rows\n        self.assertEqual(len(rows) - 1, hours)\n\n        # Check time format and condition validity\n        for row in rows[1:]:\n            self.assertEqual(len(row), 2)\n            # Check time format\n            try:\n                datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S')\n            except ValueError:\n                self.fail(f\"Time format incorrect: {row[0]}\")\n            # Check condition value\n            self.assertIn(row[1], WEATHER_CONDITIONS)\n",
        "code": "import csv\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport os\n\n# Constants\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\n\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    \"\"\"\n    Generate weather data for the specified number of hours.\n    Each record contains timestamp (hour by hour) and a random weather condition.\n    The data is saved as a CSV file named 'weather_data.csv' in the output directory.\n    Columns are 'Time' and 'Condition' as required.\n    \"\"\"\n    # Prepare data\n    start_time = datetime.now().replace(minute=0, second=0, microsecond=0)\n    data = []\n    for i in range(hours):\n        current_time = start_time + timedelta(hours=i)\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS) - 1)]\n        data.append([current_time.strftime('%Y-%m-%d %H:%M:%S'), condition])\n\n    # Write to CSV\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(file_path, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Time', 'Condition'])\n        writer.writerows(data)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/594_3",
        "turn": "3",
        "instruct_prompt": "Create a backup of the generated CSV file by copying it to a subdirectory named 'backup' inside the output directory. Create the backup directory if it does not exist.",
        "test": "import unittest\nimport os\nimport shutil\n\n# Use the task_func defined above\n\nclass TestCases(unittest.TestCase):\n\n    def setUp(self):\n        # Clean up output directory before each test\n        if os.path.exists('./output'):\n            shutil.rmtree('./output')\n\n    def test_backup_creation(self):\n        hours = 5\n        task_func(hours)\n\n        original_file = os.path.join('./output', 'weather_data.csv')\n        backup_dir = os.path.join('./output', 'backup')\n        backup_file = os.path.join(backup_dir, 'weather_data.csv')\n\n        # Original CSV file should exist\n        self.assertTrue(os.path.isfile(original_file), 'Original CSV file should exist')\n\n        # Backup directory should be created\n        self.assertTrue(os.path.isdir(backup_dir), 'Backup directory should be created')\n\n        # Backup CSV file should exist\n        self.assertTrue(os.path.isfile(backup_file), 'Backup CSV file should exist')\n\n        # Backup content should match original content\n        with open(original_file, 'r') as f_orig, open(backup_file, 'r') as f_backup:\n            self.assertEqual(f_orig.read(), f_backup.read(), 'Backup content should match original content')\n\n    def test_backup_directory_created_only_if_missing(self):\n        # Pre-create backup directory\n        backup_dir = os.path.join('./output', 'backup')\n        os.makedirs(backup_dir)\n\n        task_func(1)\n\n        # Backup directory should still exist\n        self.assertTrue(os.path.isdir(backup_dir), 'Backup directory should still exist')\n\n        # Backup file should be created inside\n        backup_file = os.path.join(backup_dir, 'weather_data.csv')\n        self.assertTrue(os.path.isfile(backup_file), 'Backup CSV file should exist')\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import csv\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport os\nimport shutil\n\n# Constants\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\n\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    \"\"\"\n    Generate weather data for the specified number of hours.\n    Each record contains timestamp (hour by hour) and a random weather condition.\n    The data is saved as a CSV file named 'weather_data.csv' in the output directory.\n    Also creates a backup of the CSV file inside a 'backup' subdirectory.\n    Columns are 'Time' and 'Condition' as required.\n    \"\"\"\n    # Prepare data\n    start_time = datetime.now().replace(minute=0, second=0, microsecond=0)\n    data = []\n    for i in range(hours):\n        current_time = start_time + timedelta(hours=i)\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS) - 1)]\n        data.append([current_time.strftime('%Y-%m-%d %H:%M:%S'), condition])\n\n    # Write to CSV\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(file_path, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Time', 'Condition'])\n        writer.writerows(data)\n\n    # Create backup directory if it does not exist\n    backup_dir = os.path.join(output_dir, 'backup')\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n\n    # Copy the CSV file to the backup directory\n    backup_file_path = os.path.join(backup_dir, 'weather_data.csv')\n    shutil.copy2(file_path, backup_file_path)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/594_4",
        "turn": "4",
        "instruct_prompt": "The function should return the full path of the generated CSV file as a string.",
        "test": "import unittest\nimport os\nimport csv\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_returns_correct_path_and_file_exists(self):\n        output_dir = './test_output'\n        hours = 3\n        # Clean up before test\n        if os.path.exists(output_dir):\n            import shutil\n            shutil.rmtree(output_dir)\n\n        file_path = task_func(hours, output_dir)\n\n        # Check that the returned path is a string\n        self.assertIsInstance(file_path, str)\n\n        # Check that the file exists at the returned path\n        self.assertTrue(os.path.isfile(file_path))\n\n        # Check that the CSV file contains the correct number of data rows (excluding header)\n        with open(file_path, mode='r', newline='') as csvfile:\n            reader = csv.reader(csvfile)\n            rows = list(reader)\n            self.assertEqual(rows[0], ['Time', 'Condition'])  # header\n            self.assertEqual(len(rows) - 1, hours)  # data rows\n\n        # Clean up after test\n        if os.path.exists(output_dir):\n            import shutil\n            shutil.rmtree(output_dir)\n",
        "code": "import csv\nfrom datetime import datetime, timedelta\nfrom random import randint\nimport os\nimport shutil\n\n# Constants\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\n\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    \"\"\"\n    Generate weather data for the specified number of hours.\n    Each record contains timestamp (hour by hour) and a random weather condition.\n    The data is saved as a CSV file named 'weather_data.csv' in the output directory.\n    Also creates a backup of the CSV file inside a 'backup' subdirectory.\n    Columns are 'Time' and 'Condition' as required.\n\n    Returns:\n        str: The full path of the generated CSV file.\n    \"\"\"\n    # Prepare data\n    start_time = datetime.now().replace(minute=0, second=0, microsecond=0)\n    data = []\n    for i in range(hours):\n        current_time = start_time + timedelta(hours=i)\n        condition = WEATHER_CONDITIONS[randint(0, len(WEATHER_CONDITIONS) - 1)]\n        data.append([current_time.strftime('%Y-%m-%d %H:%M:%S'), condition])\n\n    # Write to CSV\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    file_path = os.path.join(output_dir, 'weather_data.csv')\n    with open(file_path, mode='w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Time', 'Condition'])\n        writer.writerows(data)\n\n    # Create backup directory if it does not exist\n    backup_dir = os.path.join(output_dir, 'backup')\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n\n    # Copy the CSV file to the backup directory\n    backup_file_path = os.path.join(backup_dir, 'weather_data.csv')\n    shutil.copy2(file_path, backup_file_path)\n\n    return file_path\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 85,
    "task_id": "BigCodeBench/618",
    "mt_data": [
      {
        "task_id": "BigCodeBench/618_1",
        "turn": "1",
        "instruct_prompt": "Generate a Pandas DataFrame containing football match results for multiple teams. Each team should have a random number of goals and penalties. You should write self-contained code starting with:\n```\nfrom random import randint\nimport pandas as pd\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\ndef task_func(goals, penalties):\n```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_dataframe_structure(self):\n        df = task_func(5, 3)\n        # Check if the result is a DataFrame\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check the columns\n        self.assertListEqual(list(df.columns), ['Team', 'Goals', 'Penalties'])\n        # Check the number of rows\n        self.assertEqual(len(df), len(['Team A', 'Team B', 'Team C', 'Team D', 'Team E']))\n\n    def test_goals_and_penalties_range(self):\n        max_goals = 10\n        max_penalties = 4\n        df = task_func(max_goals, max_penalties)\n        # Check if goals and penalties are within the specified range\n        self.assertTrue((df['Goals'] >= 0).all())\n        self.assertTrue((df['Goals'] <= max_goals).all())\n        self.assertTrue((df['Penalties'] >= 0).all())\n        self.assertTrue((df['Penalties'] <= max_penalties).all())\n\n    def test_teams_names(self):\n        df = task_func(3, 3)\n        # Check that all teams are present\n        self.assertCountEqual(df['Team'].tolist(), ['Team A', 'Team B', 'Team C', 'Team D', 'Team E'])\n",
        "code": "from random import randint\nimport pandas as pd\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties):\n    data = []\n    for team in TEAMS:\n        team_goals = randint(0, goals)\n        team_penalties = randint(0, penalties)\n        data.append({'Team': team, 'Goals': team_goals, 'Penalties': team_penalties})\n    df = pd.DataFrame(data)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/618_2",
        "turn": "2",
        "instruct_prompt": "Calculate the penalty cost for each team by multiplying the number of penalties by the PENALTY_COST constant and include this as a column in the DataFrame.",
        "test": "import unittest\nimport pandas as pd\nfrom pandas.api.types import is_integer_dtype\n\nclass TestCases(unittest.TestCase):\n    def test_penalty_cost_calculation(self):\n        goals = 5\n        penalties = 3\n        df = task_func(goals, penalties)\n        # Check that all required columns exist\n        self.assertIn('Team', df.columns)\n        self.assertIn('Goals', df.columns)\n        self.assertIn('Penalties', df.columns)\n        self.assertIn('PenaltyCost', df.columns)\n\n        # Check that PenaltyCost equals Penalties * PENALTY_COST for each row\n        for _, row in df.iterrows():\n            self.assertEqual(row['PenaltyCost'], row['Penalties'] * 1000)\n\n        # Check that Penalties values are within the expected range\n        self.assertTrue(df['Penalties'].between(0, penalties).all())\n\n        # Check that Goals values are within the expected range\n        self.assertTrue(df['Goals'].between(0, goals).all())\n\n        # Check that PenaltyCost column is of integer dtype\n        self.assertTrue(is_integer_dtype(df['PenaltyCost']))\n",
        "code": "from random import randint\nimport pandas as pd\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties):\n    data = []\n    for team in TEAMS:\n        team_goals = randint(0, goals)\n        team_penalties = randint(0, penalties)\n        penalty_cost = team_penalties * PENALTY_COST\n        data.append({'Team': team, 'Goals': team_goals, 'Penalties': team_penalties, 'PenaltyCost': penalty_cost})\n    df = pd.DataFrame(data)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/618_3",
        "turn": "3",
        "instruct_prompt": "Create two seaborn bar plots: one showing the goals per team and another showing the penalty costs per team. Return these plots along with the DataFrame.",
        "test": "import unittest\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_output(self):\n        from matplotlib.figure import Figure\n        df, goals_plot, penalty_cost_plot = task_func(10, 5)\n        \n        # Check that df is a DataFrame\n        self.assertIsInstance(df, pd.DataFrame)\n        \n        # Check that df contains required columns\n        self.assertTrue({'Team', 'Goals', 'Penalties', 'PenaltyCost'}.issubset(df.columns))\n        \n        # Check that df has data for all teams\n        self.assertEqual(len(df), len(['Team A', 'Team B', 'Team C', 'Team D', 'Team E']))\n        \n        # Check that goals_plot and penalty_cost_plot are seaborn Axes\n        self.assertIsInstance(goals_plot, Axes)\n        self.assertIsInstance(penalty_cost_plot, Axes)\n        \n        # Check that goals_plot has correct data\n        goals_y = [bar.get_height() for bar in goals_plot.patches]\n        self.assertEqual(goals_y, list(df['Goals']))\n        \n        # Check that penalty_cost_plot has correct data\n        penalty_y = [bar.get_height() for bar in penalty_cost_plot.patches]\n        self.assertEqual(penalty_y, list(df['PenaltyCost']))\n",
        "code": "from random import randint\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties):\n    data = []\n    for team in TEAMS:\n        team_goals = randint(0, goals)\n        team_penalties = randint(0, penalties)\n        penalty_cost = team_penalties * PENALTY_COST\n        data.append({'Team': team, 'Goals': team_goals, 'Penalties': team_penalties, 'PenaltyCost': penalty_cost})\n    df = pd.DataFrame(data)\n    \n    # Create bar plot for goals per team\n    plt.figure(figsize=(8, 4))\n    goals_plot = sns.barplot(x='Team', y='Goals', data=df)\n    plt.close()  # Close the plot to prevent it from displaying during function call\n    \n    # Create bar plot for penalty costs per team\n    plt.figure(figsize=(8, 4))\n    penalty_cost_plot = sns.barplot(x='Team', y='PenaltyCost', data=df)\n    plt.close()  # Close the plot\n\n    return df, goals_plot, penalty_cost_plot\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 86,
    "task_id": "BigCodeBench/636",
    "mt_data": [
      {
        "task_id": "BigCodeBench/636_1",
        "turn": "1",
        "instruct_prompt": "Create a Pandas DataFrame with random integer values between 0 and 9 for a given number of rows. You should write self-contained code starting with:\n```python\nimport numpy as np\nimport pandas as pd\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(rows):\n```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_dataframe_shape(self):\n        rows = 10\n        df = task_func(rows)\n        self.assertEqual(df.shape, (rows, 5))\n\n    def test_columns_names(self):\n        df = task_func(5)\n        self.assertListEqual(list(df.columns), ['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])\n\n    def test_values_range(self):\n        df = task_func(20)\n        self.assertTrue(((df.values >= 0) & (df.values <= 9)).all())\n\n    def test_zero_rows(self):\n        df = task_func(0)\n        self.assertEqual(df.shape, (0, 5))\n        self.assertListEqual(list(df.columns), ['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])\n",
        "code": "import numpy as np\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(rows):\n    data = np.random.randint(0, 10, size=(rows, len(COLUMNS)))\n    df = pd.DataFrame(data, columns=COLUMNS)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/636_2",
        "turn": "2",
        "instruct_prompt": "Count the non-zero values in each column of the generated DataFrame.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_non_zero_counts(self):\n        rows = 10\n        df, non_zero_counts = task_func(rows)\n        # Check that df is a DataFrame\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check that non_zero_counts is a Series with correct index\n        self.assertIsInstance(non_zero_counts, pd.Series)\n        self.assertListEqual(list(non_zero_counts.index), ['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])\n        # Check that non_zero_counts values are between 0 and rows\n        for val in non_zero_counts:\n            self.assertTrue(0 <= val <= rows)\n        # Check that non_zero_counts matches manual count\n        manual_counts = (df != 0).sum(axis=0)\n        pd.testing.assert_series_equal(non_zero_counts, manual_counts)\n\n    def test_previous_code_should_fail(self):\n        # Previous round code returns only df\n        # Here we check that if only df returned, test should fail\n        try:\n            # Emulate previous round function\n            def previous_task_func(rows):\n                data = np.random.randint(0, 10, size=(rows, len(['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])))\n                df = pd.DataFrame(data, columns=['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])\n                return df\n            result = previous_task_func(10)\n            # Try to unpack two values (should raise error)\n            _ = result, None\n            # If no error, fail the test\n            self.fail(\"Previous code should not return non_zero_counts\")\n        except Exception:\n            pass",
        "code": "import numpy as np\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(rows):\n    data = np.random.randint(0, 10, size=(rows, len(COLUMNS)))\n    df = pd.DataFrame(data, columns=COLUMNS)\n    non_zero_counts = (df != 0).sum(axis=0)\n    return df, non_zero_counts",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/636_3",
        "turn": "3",
        "instruct_prompt": "Visualize the counts of non-zero values for each column using a bar plot with matplotlib and return the plot's Axes object along with the DataFrame.",
        "test": "import unittest\nimport matplotlib.pyplot as plt\nfrom matplotlib.container import BarContainer\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_output(self):\n        rows = 10\n        df, ax = task_func(rows)\n        # Check returned types\n        self.assertTrue(hasattr(df, 'shape'))\n        self.assertEqual(df.shape[0], rows)\n        self.assertEqual(list(df.columns), ['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])\n        self.assertIsInstance(ax, plt.Axes)\n\n    def test_bar_plot_has_bars(self):\n        rows = 15\n        _, ax = task_func(rows)\n        # Check that the Axes contains bar containers\n        bar_containers = [c for c in ax.containers if isinstance(c, BarContainer)]\n        self.assertTrue(len(bar_containers) > 0)\n        # The number of bars should be equal to number of columns\n        self.assertEqual(len(bar_containers[0]), 5)\n",
        "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(rows):\n    data = np.random.randint(0, 10, size=(rows, len(COLUMNS)))\n    df = pd.DataFrame(data, columns=COLUMNS)\n    non_zero_counts = (df != 0).sum(axis=0)\n\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Count of Non-Zero Values')\n    ax.set_title('Non-Zero Value Counts per Column')\n\n    return df, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/636_4",
        "turn": "4",
        "instruct_prompt": "Handle the edge case where the input number of rows is less than or equal to zero by returning an empty DataFrame with the specified columns and an empty plot with the title 'Non-Zero Value Counts'.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_rows_zero(self):\n        df, ax = task_func(0)\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertListEqual(list(df.columns), ['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])\n        self.assertTrue(df.empty)\n        self.assertIsInstance(ax, Axes)\n        self.assertEqual(ax.get_title(), 'Non-Zero Value Counts')\n\n    def test_rows_negative(self):\n        df, ax = task_func(-5)\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertListEqual(list(df.columns), ['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])\n        self.assertTrue(df.empty)\n        self.assertIsInstance(ax, Axes)\n        self.assertEqual(ax.get_title(), 'Non-Zero Value Counts')\n\n    def test_rows_positive(self):\n        df, ax = task_func(10)\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertListEqual(list(df.columns), ['Column1', 'Column2', 'Column3', 'Column4', 'Column5'])\n        self.assertEqual(len(df), 10)\n        self.assertIsInstance(ax, Axes)\n        self.assertEqual(ax.get_title(), 'Non-Zero Value Counts per Column')\n",
        "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\ndef task_func(rows):\n    if rows <= 0:\n        df = pd.DataFrame(columns=COLUMNS)\n        fig, ax = plt.subplots()\n        ax.set_title('Non-Zero Value Counts')\n        return df, ax\n\n    data = np.random.randint(0, 10, size=(rows, len(COLUMNS)))\n    df = pd.DataFrame(data, columns=COLUMNS)\n    non_zero_counts = (df != 0).sum(axis=0)\n\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Columns')\n    ax.set_ylabel('Count of Non-Zero Values')\n    ax.set_title('Non-Zero Value Counts per Column')\n\n    return df, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 87,
    "task_id": "BigCodeBench/637",
    "mt_data": [
      {
        "task_id": "BigCodeBench/637_1",
        "turn": "1",
        "instruct_prompt": "Generate a Pandas DataFrame for a given number of students with random grades in multiple courses. You should write self-contained code starting with:\n```\nfrom random import sample\nfrom typing import Tuple\nimport numpy as np\nimport pandas as pd\ndef task_func(num_students):\n```",
        "test": "import unittest\nimport pandas as pd\nfrom pandas.api.types import is_integer_dtype\n\nclass TestCases(unittest.TestCase):\n    def test_task_func(self):\n        num_students = 10\n        df = task_func(num_students)\n        # Check type\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check number of rows\n        self.assertEqual(len(df), num_students)\n        # Check columns\n        expected_columns = ['StudentID', 'Math', 'English', 'Science', 'History', 'Art']\n        self.assertListEqual(list(df.columns), expected_columns)\n        # Check StudentID values\n        self.assertTrue(all(df['StudentID'] == range(1, num_students + 1)))\n        # Check grades are integers and within 0-100\n        for course in expected_columns[1:]:\n            self.assertTrue(is_integer_dtype(df[course]))\n            self.assertTrue(df[course].between(0, 100).all())\n",
        "code": "from random import sample\nfrom typing import Tuple\nimport numpy as np\nimport pandas as pd\n\ndef task_func(num_students):\n    # Define the courses\n    courses = ['Math', 'English', 'Science', 'History', 'Art']\n    # Generate random grades between 0 and 100 for each student in each course\n    data = {course: np.random.randint(0, 101, size=num_students) for course in courses}\n    # Create DataFrame\n    df = pd.DataFrame(data)\n    # Add a student ID column\n    df.insert(0, 'StudentID', range(1, num_students + 1))\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/637_2",
        "turn": "2",
        "instruct_prompt": "Select the students randomly from a list of 100 students named 'Student1' to 'Student100'. Assign grades as random integers between 40 and 100 for 5 courses named 'Course1' to 'Course5'. The DataFrame should use student names as index and course names as columns.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_task_func(self):\n        df = task_func()\n        # Check type\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check index length\n        self.assertEqual(len(df.index), 100)\n        # Check index names format\n        for name in df.index:\n            self.assertTrue(name.startswith('Student'))\n            num = int(name.replace('Student', ''))\n            self.assertTrue(1 <= num <= 100)\n        # Check columns\n        expected_courses = [f'Course{i}' for i in range(1, 6)]\n        self.assertListEqual(list(df.columns), expected_courses)\n        # Check grades range\n        for col in df.columns:\n            self.assertTrue((df[col] >= 40).all())\n            self.assertTrue((df[col] <= 100).all())\n",
        "code": "import random\nimport numpy as np\nimport pandas as pd\n\ndef task_func():\n    # List of 100 students\n    students = [f'Student{i}' for i in range(1, 101)]\n    # Randomly select students (select all 100 as per requirement)\n    selected_students = random.sample(students, 100)\n\n    # Courses\n    courses = [f'Course{i}' for i in range(1, 6)]\n\n    # Generate random grades between 40 and 100 for each student in each course\n    data = {course: np.random.randint(40, 101, size=100) for course in courses}\n\n    # Create DataFrame with student names as index\n    df = pd.DataFrame(data, index=selected_students)\n\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/637_3",
        "turn": "3",
        "instruct_prompt": "Calculate the average grade for each course and the number of students with passing grades (grade >= 60) in each course.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_task_func(self):\n        df, average_grades, passing_counts = task_func()\n\n        # Check df shape\n        self.assertEqual(df.shape, (100, 5))\n\n        # Check average_grades is a Series with 5 elements\n        self.assertIsInstance(average_grades, pd.Series)\n        self.assertEqual(len(average_grades), 5)\n\n        # Check passing_counts is a Series with 5 elements\n        self.assertIsInstance(passing_counts, pd.Series)\n        self.assertEqual(len(passing_counts), 5)\n\n        # Check all average grades are between 40 and 100\n        self.assertTrue(((average_grades >= 40) & (average_grades <= 100)).all())\n\n        # Check all passing counts are between 0 and 100\n        self.assertTrue(((passing_counts >= 0) & (passing_counts <= 100)).all())\n\n        # Check that passing counts correspond to count of grades >= 60\n        for course in df.columns:\n            expected_count = (df[course] >= 60).sum()\n            self.assertEqual(passing_counts[course], expected_count)\n",
        "code": "import random\nimport numpy as np\nimport pandas as pd\n\ndef task_func():\n    # List of 100 students\n    students = [f'Student{i}' for i in range(1, 101)]\n    # Randomly select students (select all 100 as per requirement)\n    selected_students = random.sample(students, 100)\n\n    # Courses\n    courses = [f'Course{i}' for i in range(1, 6)]\n\n    # Generate random grades between 40 and 100 for each student in each course\n    data = {course: np.random.randint(40, 101, size=100) for course in courses}\n\n    # Create DataFrame with student names as index\n    df = pd.DataFrame(data, index=selected_students)\n\n    # Calculate average grade for each course\n    average_grades = df.mean()\n\n    # Calculate number of students with passing grades (grade >= 60) in each course\n    passing_counts = (df >= 60).sum()\n\n    return df, average_grades, passing_counts\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/637_4",
        "turn": "4",
        "instruct_prompt": "Visualize the course-wise average grades and passing grade counts using a bar plot with the title 'Course-wise Average and Passing Grade Counts'. The average grades and passing counts should be shown side-by-side with different colors and a legend.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')  # Use a non-interactive backend for testing\nfrom matplotlib import pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_output_and_plot(self):\n        # Patch plt.show to avoid opening a window during tests\n        called = {'show_called': False}\n        original_show = plt.show\n\n        def fake_show():\n            called['show_called'] = True\n\n        plt.show = fake_show\n\n        # Directly call task_func since it is defined in the same file\n        df, avg_grades, passing_counts = task_func()\n\n        # Test dataframe shape\n        self.assertEqual(df.shape, (100, 5))\n\n        # Test columns\n        expected_courses = [f'Course{i}' for i in range(1, 6)]\n        self.assertListEqual(list(df.columns), expected_courses)\n\n        # Test average grades series\n        self.assertIsInstance(avg_grades, pd.Series)\n        self.assertListEqual(list(avg_grades.index), expected_courses)\n\n        # Test passing counts series\n        self.assertIsInstance(passing_counts, pd.Series)\n        self.assertListEqual(list(passing_counts.index), expected_courses)\n\n        # Check that average grades are between 40 and 100\n        self.assertTrue(((avg_grades >= 40) & (avg_grades <= 100)).all())\n\n        # Check that passing counts are between 0 and 100\n        self.assertTrue(((passing_counts >= 0) & (passing_counts <= 100)).all())\n\n        # Check that plt.show was called\n        self.assertTrue(called['show_called'])\n\n        # Restore plt.show\n        plt.show = original_show\n",
        "code": "import random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    # List of 100 students\n    students = [f'Student{i}' for i in range(1, 101)]\n    # Randomly select students (select all 100 as per requirement)\n    selected_students = random.sample(students, 100)\n\n    # Courses\n    courses = [f'Course{i}' for i in range(1, 6)]\n\n    # Generate random grades between 40 and 100 for each student in each course\n    data = {course: np.random.randint(40, 101, size=100) for course in courses}\n\n    # Create DataFrame with student names as index\n    df = pd.DataFrame(data, index=selected_students)\n\n    # Calculate average grade for each course\n    average_grades = df.mean()\n\n    # Calculate number of students with passing grades (grade >= 60) in each course\n    passing_counts = (df >= 60).sum()\n\n    # Plotting\n    x = np.arange(len(courses))  # the label locations\n    width = 0.35  # the width of the bars\n\n    fig, ax = plt.subplots()\n    bars1 = ax.bar(x - width/2, average_grades, width, label='Average Grades', color='blue')\n    bars2 = ax.bar(x + width/2, passing_counts, width, label='Passing Counts', color='orange')\n\n    # Add some text for labels, title and custom x-axis tick labels, etc.\n    ax.set_xlabel('Courses')\n    ax.set_ylabel('Values')\n    ax.set_title('Course-wise Average and Passing Grade Counts')\n    ax.set_xticks(x)\n    ax.set_xticklabels(courses)\n    ax.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n    return df, average_grades, passing_counts\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/637_5",
        "turn": "5",
        "instruct_prompt": "The function should return a tuple containing the generated DataFrame and the matplotlib Axes object of the bar plot.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_returns_tuple(self):\n        result = task_func()\n        # Check return type is tuple\n        self.assertIsInstance(result, tuple)\n        # Check tuple has length 2\n        self.assertEqual(len(result), 2)\n\n    def test_task_func_returns_dataframe_and_axes(self):\n        df, ax = task_func()\n        # Check df is a pandas DataFrame\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check ax is a matplotlib Axes object\n        self.assertIsInstance(ax, plt.Axes)\n\n    def test_dataframe_content(self):\n        df, _ = task_func()\n        # Check DataFrame shape (100 students, 5 courses)\n        self.assertEqual(df.shape, (100, 5))\n        # Check index contains student names\n        self.assertTrue(all(name.startswith('Student') for name in df.index))\n        # Check columns are named Course1 to Course5\n        expected_cols = [f'Course{i}' for i in range(1, 6)]\n        self.assertListEqual(list(df.columns), expected_cols)\n        # Check all grades are between 40 and 100\n        self.assertTrue(((df.values >= 40) & (df.values <= 100)).all())\n",
        "code": "import random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    # List of 100 students\n    students = [f'Student{i}' for i in range(1, 101)]\n    # Randomly select students (select all 100 as per requirement)\n    selected_students = random.sample(students, 100)\n\n    # Courses\n    courses = [f'Course{i}' for i in range(1, 6)]\n\n    # Generate random grades between 40 and 100 for each student in each course\n    data = {course: np.random.randint(40, 101, size=100) for course in courses}\n\n    # Create DataFrame with student names as index\n    df = pd.DataFrame(data, index=selected_students)\n\n    # Calculate average grade for each course\n    average_grades = df.mean()\n\n    # Calculate number of students with passing grades (grade >= 60) in each course\n    passing_counts = (df >= 60).sum()\n\n    # Plotting\n    x = np.arange(len(courses))  # the label locations\n    width = 0.35  # the width of the bars\n\n    fig, ax = plt.subplots()\n    bars1 = ax.bar(x - width/2, average_grades, width, label='Average Grades', color='blue')\n    bars2 = ax.bar(x + width/2, passing_counts, width, label='Passing Counts', color='orange')\n\n    # Add some text for labels, title and custom x-axis tick labels, etc.\n    ax.set_xlabel('Courses')\n    ax.set_ylabel('Values')\n    ax.set_title('Course-wise Average and Passing Grade Counts')\n    ax.set_xticks(x)\n    ax.set_xticklabels(courses)\n    ax.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n    return df, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 88,
    "task_id": "BigCodeBench/654",
    "mt_data": [
      {
        "task_id": "BigCodeBench/654_1",
        "turn": "1",
        "instruct_prompt": "Write a function that finds the indices in the input array where the first column matches the target value. You should write self-contained code starting with:```python\nimport numpy as np\ndef task_func(array, target_value):\n```",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_single_match(self):\n        arr = np.array([[1, 2], [3, 4], [5, 6]])\n        self.assertEqual(task_func(arr, 3), [1])\n\n    def test_multiple_matches(self):\n        arr = np.array([[7, 8], [7, 9], [10, 11], [7, 12]])\n        self.assertEqual(task_func(arr, 7), [0, 1, 3])\n\n    def test_no_match(self):\n        arr = np.array([[1, 2], [3, 4], [5, 6]])\n        self.assertEqual(task_func(arr, 9), [])\n\n    def test_empty_array(self):\n        arr = np.empty((0, 2))\n        self.assertEqual(task_func(arr, 1), [])\n\n    def test_single_element_array(self):\n        arr = np.array([[4, 5]])\n        self.assertEqual(task_func(arr, 4), [0])\n        self.assertEqual(task_func(arr, 5), [])",
        "code": "import numpy as np\ndef task_func(array, target_value):\n    return np.where(array[:, 0] == target_value)[0].tolist()",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/654_2",
        "turn": "2",
        "instruct_prompt": "Fit an exponential decay function of the form a * exp(-b * x) + c to the indices found, using scipy.optimize.curve_fit.",
        "test": "import unittest\nimport numpy as np\nfrom math import isclose\n\nclass TestCases(unittest.TestCase):\n    def test_fit_exponential_decay(self):\n        target_value = 7\n        x_indices = np.array([2, 3, 4, 5])\n        a_true, b_true, c_true = 10, 0.5, 1\n        y_values = a_true * np.exp(-b_true * x_indices) + c_true\n\n        arr = np.zeros((8, 2))\n        for i, x in enumerate(x_indices):\n            arr[x, 0] = target_value\n            arr[x, 1] = y_values[i]\n\n        indices, params = task_func(arr, target_value)\n\n        self.assertEqual(indices, list(x_indices))\n        self.assertIsNotNone(params)\n\n        a_fit, b_fit, c_fit = params\n\n        def exp_decay(x):\n            return a_fit * np.exp(-b_fit * x) + c_fit\n\n        for x, y_true in zip(x_indices, y_values):\n            y_fit = exp_decay(x)\n            self.assertTrue(isclose(y_fit, y_true, rel_tol=0.2, abs_tol=0.2))\n\n    def test_no_indices(self):\n        arr = np.array([[1, 0], [2, 0], [3, 0]], dtype=float)\n        target_value = 7\n        indices, params = task_func(arr, target_value)\n        self.assertEqual(indices, [])\n        self.assertIsNone(params)\n",
        "code": "import numpy as np\nfrom scipy.optimize import curve_fit\n\ndef task_func(array, target_value):\n    indices = np.where(array[:, 0] == target_value)[0]\n\n    def exp_decay(x, a, b, c):\n        return a * np.exp(-b * x) + c\n\n    if len(indices) == 0:\n        return [], None  # No indices found, no fit\n\n    x_data = indices.astype(float)\n    if array.shape[1] > 1:\n        y_data = array[indices, 1].astype(float)\n    else:\n        y_data = x_data  # fallback if no second column\n\n    initial_guess = (max(y_data) - min(y_data), 0.1, min(y_data))\n\n    try:\n        popt, _ = curve_fit(exp_decay, x_data, y_data, p0=initial_guess, maxfev=2000)\n    except RuntimeError:\n        return indices.tolist(), None\n\n    return indices.tolist(), popt\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/654_3",
        "turn": "3",
        "instruct_prompt": "Plot the original indices as data points and the fitted exponential decay curve on a matplotlib figure, and return a tuple containing the optimized parameters and the matplotlib Axes object.",
        "test": "import unittest\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom matplotlib.collections import PathCollection\n\nclass TestCases(unittest.TestCase):\n    def test_plot_and_params(self):\n        array = np.array([\n            [1, 10],\n            [2, 7],\n            [3, 5],\n            [2, 6],\n            [2, 4],\n            [3, 3],\n            [2, 2],\n            [1, 1]\n        ])\n        target_value = 2\n\n        popt, ax = task_func(array, target_value)\n\n        # Check popt is iterable and length 3\n        self.assertTrue(hasattr(popt, '__iter__'))\n        self.assertEqual(len(popt), 3)\n\n        # Check ax is a matplotlib Axes instance\n        self.assertIsInstance(ax, Axes)\n\n        # Check scatter points exist (PathCollection) and line exists (Line2D)\n        scatter_found = False\n        line_found = False\n        for child in ax.get_children():\n            if isinstance(child, PathCollection):\n                scatter_found = True\n            if isinstance(child, plt.Line2D) and child.get_linestyle() == '-':\n                line_found = True\n\n        self.assertTrue(scatter_found, \"Scatter points not found on plot\")\n        self.assertTrue(line_found, \"Fitted curve line not found on plot\")\n\n    def test_no_indices(self):\n        array = np.array([[1, 5], [1, 6]])\n        target_value = 3\n\n        result = task_func(array, target_value)\n\n        self.assertEqual(result, ([], None))\n",
        "code": "import numpy as np\nfrom scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\n\ndef task_func(array, target_value):\n    indices = np.where(array[:, 0] == target_value)[0]\n\n    def exp_decay(x, a, b, c):\n        return a * np.exp(-b * x) + c\n\n    if len(indices) == 0:\n        return [], None\n\n    x_data = indices.astype(float)\n    if array.shape[1] > 1:\n        y_data = array[indices, 1].astype(float)\n    else:\n        y_data = x_data\n\n    initial_guess = (max(y_data) - min(y_data), 0.1, min(y_data))\n\n    try:\n        popt, _ = curve_fit(exp_decay, x_data, y_data, p0=initial_guess, maxfev=2000)\n    except RuntimeError:\n        return indices.tolist(), None\n\n    fig, ax = plt.subplots()\n    ax.scatter(x_data, y_data, label='Data points')\n    x_fit = np.linspace(x_data.min(), x_data.max(), 100)\n    y_fit = exp_decay(x_fit, *popt)\n    ax.plot(x_fit, y_fit, 'r-', label='Fitted curve')\n    ax.legend()\n\n    return popt, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/654_4",
        "turn": "4",
        "instruct_prompt": "Raise an error if there are fewer than 3 matching indices to ensure the fitting is valid.",
        "test": "import unittest\nimport numpy as np\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_valid_fit(self):\n        # 3 matching indices, fitting should succeed\n        arr = np.array([[1, 10], [2, 8], [1, 6], [1, 5], [3, 2]])\n        popt, ax = task_func(arr, 1)\n        self.assertIsInstance(popt, np.ndarray)\n        self.assertEqual(len(popt), 3)\n        self.assertIsInstance(ax, Axes)\n\n    def test_fewer_than_3_indices(self):\n        # Only 2 matching indices, should raise ValueError\n        arr = np.array([[1, 10], [2, 8], [1, 6], [3, 5]])\n        with self.assertRaises(ValueError):\n            task_func(arr, 1)\n\n    def test_no_matching_indices(self):\n        # No matching indices, should raise ValueError\n        arr = np.array([[2, 10], [3, 8], [4, 6]])\n        with self.assertRaises(ValueError):\n            task_func(arr, 1)\n\n    def test_single_column_array(self):\n        # Array with single column and 3 matching indices\n        arr = np.array([[1], [2], [1], [1], [3]])\n        result, ax = task_func(arr, 1)\n        # result can be either ndarray (successful fit) or list (fit failure)\n        self.assertTrue(isinstance(result, np.ndarray) or isinstance(result, list))\n        if isinstance(result, np.ndarray):\n            self.assertEqual(len(result), 3)\n            self.assertIsInstance(ax, Axes)\n        else:\n            # result is list of indices, ax is None\n            self.assertIsNone(ax)\n",
        "code": "import numpy as np\nfrom scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\n\ndef task_func(array, target_value):\n    indices = np.where(array[:, 0] == target_value)[0]\n\n    def exp_decay(x, a, b, c):\n        return a * np.exp(-b * x) + c\n\n    if len(indices) < 3:\n        raise ValueError(\"Fewer than 3 matching indices, cannot perform valid fitting.\")\n\n    x_data = indices.astype(float)\n    if array.shape[1] > 1:\n        y_data = array[indices, 1].astype(float)\n    else:\n        y_data = x_data\n\n    initial_guess = (max(y_data) - min(y_data), 0.1, min(y_data))\n\n    try:\n        popt, _ = curve_fit(exp_decay, x_data, y_data, p0=initial_guess, maxfev=2000)\n    except RuntimeError:\n        return indices.tolist(), None\n\n    fig, ax = plt.subplots()\n    ax.scatter(x_data, y_data, label='Data points')\n    x_fit = np.linspace(x_data.min(), x_data.max(), 100)\n    y_fit = exp_decay(x_fit, *popt)\n    ax.plot(x_fit, y_fit, 'r-', label='Fitted curve')\n    ax.legend()\n\n    return popt, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 89,
    "task_id": "BigCodeBench/655",
    "mt_data": [
      {
        "task_id": "BigCodeBench/655_1",
        "turn": "1",
        "instruct_prompt": "Perform basic text preprocessing on a list of text documents by removing all non-alphanumeric characters (excluding spaces) and converting all characters to lowercase. You should write self-contained code starting with:```import re\nimport nltk\n# Ensure nltk's stopwords are downloaded\nnltk.download('stopwords')\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\ndef task_func(texts, num_topics):\n    cleaned_texts = [ALPHANUMERIC.sub(' ', text).lower() for text in texts]\n    return cleaned_texts\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic_preprocessing(self):\n        texts = [\n            \"Hello, World!\",\n            \"Python3 is #1.\",\n            \"Test: remove_non-alphanumeric_chars!\",\n            \"Mixed CASE and Spaces\",\n            \"1234567890\",\n            \"Special_chars *&^%$#@!\",\n            \"\"\n        ]\n        expected = [\n            \"hello world \",\n            \"python3 is 1 \",\n            \"test remove non alphanumeric chars \",\n            \"mixed case and spaces\",\n            \"1234567890\",\n            \"special chars \",\n            \"\"\n        ]\n        result = task_func(texts, num_topics=2)\n        self.assertEqual(result, expected)\n\n    def test_empty_list(self):\n        self.assertEqual(task_func([], num_topics=1), [])\n",
        "code": "import re\n\ndef task_func(texts, num_topics):\n    ALPHANUMERIC = re.compile('[\\W_]+')\n    cleaned_texts = [ALPHANUMERIC.sub(' ', text).lower() for text in texts]\n    return cleaned_texts\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/655_2",
        "turn": "2",
        "instruct_prompt": "Extend the preprocessing by removing English stopwords from the cleaned texts and return the list of processed texts where each text is a string of words separated by spaces.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_stopword_removal(self):\n        texts = [\n            \"This is a test of the preprocessing function.\",\n            \"We will remove stopwords from these sentences!\",\n            \"An example with mixed CASE and punctuation...\",\n            \"No stopwords here\",\n            \"The quick brown fox jumps over the lazy dog\"\n        ]\n        expected = [\n            \"test preprocessing function\",\n            \"remove stopwords sentences\",\n            \"example mixed case punctuation\",\n            \"stopwords here\",\n            \"quick brown fox jumps over lazy dog\"\n        ]\n        result = task_func(texts, 0)\n        self.assertEqual(result, expected)\n\n    def test_empty_and_stopwords_only(self):\n        texts = [\"\", \"The and if but or\", \"a an the\"]\n        expected = [\"\", \"\", \"\"]\n        result = task_func(texts, 0)\n        self.assertEqual(result, expected)\n",
        "code": "import re\n\ndef task_func(texts, num_topics):\n    ALPHANUMERIC = re.compile('[\\W_]+')\n    stopwords = set([\n        'a', 'an', 'the', 'and', 'or', 'but', 'if', 'while', 'with', 'to', 'of', 'at', 'by', 'for', 'on', 'in', 'out', 'up', 'down', 'as', 'is', 'it', 'this', 'that', 'these', 'those', 'he', 'she', 'they', 'we', 'you', 'i', 'me', 'my', 'mine', 'your', 'yours', 'his', 'her', 'hers', 'its', 'our', 'ours', 'their', 'theirs', 'be', 'am', 'are', 'was', 'were', 'been', 'being', 'do', 'does', 'did', 'doing', 'have', 'has', 'had', 'having', 'not', 'no', 'nor', 'can', 'could', 'will', 'would', 'shall', 'should', 'may', 'might', 'must', 'from'\n    ])\n    cleaned_texts = []\n    for text in texts:\n        cleaned = ALPHANUMERIC.sub(' ', text).lower()\n        words = cleaned.split()\n        filtered_words = [word for word in words if word not in stopwords]\n        cleaned_texts.append(' '.join(filtered_words))\n    return cleaned_texts\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/655_3",
        "turn": "3",
        "instruct_prompt": "Vectorize the list of processed texts using TF-IDF vectorization with scikit-learn's TfidfVectorizer, using default parameters except for setting stop_words='english', and return the TF-IDF matrix.",
        "test": "import unittest\nfrom scipy.sparse import csr_matrix\n\nclass TestCases(unittest.TestCase):\n    def test_tfidf_output_type_and_shape(self):\n        texts = [\n            'The quick brown fox jumps over the lazy dog.',\n            'Never jump over the lazy dog quickly.',\n            'Bright sun shines over the mountains.'\n        ]\n        num_topics = 2  # unused parameter but required by signature\n        tfidf_matrix = task_func(texts, num_topics)\n        # Check that output is a sparse matrix\n        self.assertIsInstance(tfidf_matrix, csr_matrix)\n        # The number of rows should equal number of texts\n        self.assertEqual(tfidf_matrix.shape[0], len(texts))\n        # The number of columns should be > 0\n        self.assertGreater(tfidf_matrix.shape[1], 0)\n\n    def test_stop_words_effect(self):\n        texts = ['and the and the the']\n        num_topics = 1\n        tfidf_matrix = task_func(texts, num_topics)\n        # After preprocessing, original text is empty, replaced by 'emptydoc', so tfidf matrix should have 1 row and at least 1 column\n        self.assertEqual(tfidf_matrix.shape[0], 1)\n        self.assertGreaterEqual(tfidf_matrix.shape[1], 1)\n\n    def test_different_texts(self):\n        texts = ['cat sat on mat', 'dog barked loudly', 'cat and dog']\n        num_topics = 3\n        tfidf_matrix = task_func(texts, num_topics)\n        self.assertEqual(tfidf_matrix.shape[0], 3)\n        self.assertGreater(tfidf_matrix.shape[1], 0)\n        # Check that different rows are not identical\n        self.assertFalse((tfidf_matrix[0].toarray() == tfidf_matrix[1].toarray()).all())\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ndef task_func(texts, num_topics):\n    ALPHANUMERIC = re.compile('[\\W_]+')\n    stopwords = set([\n        'a', 'an', 'the', 'and', 'or', 'but', 'if', 'while', 'with', 'to', 'of', 'at', 'by', 'for', 'on', 'in', 'out', 'up', 'down', 'as', 'is', 'it', 'this', 'that', 'these', 'those', 'he', 'she', 'they', 'we', 'you', 'i', 'me', 'my', 'mine', 'your', 'yours', 'his', 'her', 'hers', 'its', 'our', 'ours', 'their', 'theirs', 'be', 'am', 'are', 'was', 'were', 'been', 'being', 'do', 'does', 'did', 'doing', 'have', 'has', 'had', 'having', 'not', 'no', 'nor', 'can', 'could', 'will', 'would', 'shall', 'should', 'may', 'might', 'must', 'from'\n    ])\n    cleaned_texts = []\n    for text in texts:\n        cleaned = ALPHANUMERIC.sub(' ', text).lower()\n        words = cleaned.split()\n        filtered_words = [word for word in words if word not in stopwords]\n        cleaned_text = ' '.join(filtered_words)\n        if not cleaned_text:\n            # Replace empty cleaned text with a placeholder token not in stopwords or English stop words\n            cleaned_text = 'emptydoc'\n        cleaned_texts.append(cleaned_text)\n\n    vectorizer = TfidfVectorizer(stop_words='english')\n    tfidf_matrix = vectorizer.fit_transform(cleaned_texts)\n    return tfidf_matrix\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/655_4",
        "turn": "4",
        "instruct_prompt": "Apply Non-Negative Matrix Factorization (NMF) to the TF-IDF matrix to extract the specified number of topics (num_topics). For each topic, return a list of the top words representing that topic based on the component weights. The final output should be a list of lists of strings, where each inner list contains the most significant words for one topic.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic_topics(self):\n        texts = [\n            \"Cats are great pets.\",\n            \"Dogs are loyal animals.\",\n            \"I love my cat and my dog.\",\n            \"Birds can fly high in the sky.\",\n            \"My pet bird sings beautifully.\"\n        ]\n        num_topics = 2\n        result = task_func(texts, num_topics)\n        self.assertEqual(len(result), num_topics)\n        # Each topic should have at least one word\n        for topic_words in result:\n            self.assertTrue(len(topic_words) > 0)\n            # Words should be strings\n            for word in topic_words:\n                self.assertIsInstance(word, str)\n\n    def test_empty_and_stopwords(self):\n        texts = [\"the and if but or\", \"\", \"     \", \"a an the\"]\n        num_topics = 1\n        result = task_func(texts, num_topics)\n        self.assertEqual(len(result), 1)\n        # The topic should not be empty\n        self.assertTrue(len(result[0]) > 0)\n\n    def test_num_topics_greater_than_features(self):\n        texts = [\"apple banana\", \"banana orange\", \"orange apple\"]\n        num_topics = 5  # more than unique words\n        result = task_func(texts, num_topics)\n        self.assertEqual(len(result), num_topics)\n        for topic_words in result:\n            self.assertTrue(len(topic_words) > 0)\n\n    def test_stopwords_removed(self):\n        texts = [\"This is a test of the stopwords removal.\"]\n        num_topics = 1\n        result = task_func(texts, num_topics)\n        # None of the stopwords should appear in the topic words\n        stopwords = set([\n            'a', 'an', 'the', 'and', 'or', 'but', 'if', 'while', 'with', 'to', 'of', 'at', 'by', 'for', 'on', 'in', 'out', 'up', 'down', 'as', 'is', 'it', 'this', 'that', 'these', 'those', 'he', 'she', 'they', 'we', 'you', 'i', 'me', 'my', 'mine', 'your', 'yours', 'his', 'her', 'hers', 'its', 'our', 'ours', 'their', 'theirs', 'be', 'am', 'are', 'was', 'were', 'been', 'being', 'do', 'does', 'did', 'doing', 'have', 'has', 'had', 'having', 'not', 'no', 'nor', 'can', 'could', 'will', 'would', 'shall', 'should', 'may', 'might', 'must', 'from'\n        ])\n        for word in result[0]:\n            self.assertNotIn(word, stopwords)\n",
        "code": "import re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import NMF\n\ndef task_func(texts, num_topics):\n    ALPHANUMERIC = re.compile('[\\W_]+')\n    stopwords = set([\n        'a', 'an', 'the', 'and', 'or', 'but', 'if', 'while', 'with', 'to', 'of', 'at', 'by', 'for', 'on', 'in', 'out', 'up', 'down', 'as', 'is', 'it', 'this', 'that', 'these', 'those', 'he', 'she', 'they', 'we', 'you', 'i', 'me', 'my', 'mine', 'your', 'yours', 'his', 'her', 'hers', 'its', 'our', 'ours', 'their', 'theirs', 'be', 'am', 'are', 'was', 'were', 'been', 'being', 'do', 'does', 'did', 'doing', 'have', 'has', 'had', 'having', 'not', 'no', 'nor', 'can', 'could', 'will', 'would', 'shall', 'should', 'may', 'might', 'must', 'from'\n    ])\n    cleaned_texts = []\n    for text in texts:\n        cleaned = ALPHANUMERIC.sub(' ', text).lower()\n        words = cleaned.split()\n        filtered_words = [word for word in words if word not in stopwords]\n        cleaned_text = ' '.join(filtered_words)\n        if not cleaned_text:\n            cleaned_text = 'emptydoc'\n        cleaned_texts.append(cleaned_text)\n\n    vectorizer = TfidfVectorizer(stop_words='english')\n    tfidf_matrix = vectorizer.fit_transform(cleaned_texts)\n\n    nmf_model = NMF(n_components=num_topics, random_state=42)\n    nmf_model.fit(tfidf_matrix)\n\n    feature_names = vectorizer.get_feature_names_out()\n    topics = []\n    for topic_idx, topic in enumerate(nmf_model.components_):\n        top_indices = topic.argsort()[::-1]\n        top_words = [feature_names[i] for i in top_indices if topic[i] > 0]\n        topics.append(top_words)\n\n    return topics\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 90,
    "task_id": "BigCodeBench/657",
    "mt_data": [
      {
        "task_id": "BigCodeBench/657_1",
        "turn": "1",
        "instruct_prompt": "Generate word vectors from a list of texts using the gensim Word2Vec model.\nYou should write self-contained code starting with:\n```\nimport re\nfrom gensim.models import Word2Vec\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(texts, stopwords=None):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_word_vectors_basic(self):\n        texts = [\"Hello world\", \"Hello gensim world\"]\n        vectors = task_func(texts)\n        self.assertIn('hello', vectors)\n        self.assertIn('world', vectors)\n        self.assertIn('gensim', vectors)\n        self.assertEqual(len(vectors['hello']), 100)\n        self.assertEqual(len(vectors['world']), 100)\n        self.assertEqual(len(vectors['gensim']), 100)\n\n    def test_word_vectors_with_stopwords(self):\n        texts = [\"Hello world this is a test\", \"Test gensim world\"]\n        stopwords = {'this', 'is', 'a'}\n        vectors = task_func(texts, stopwords=stopwords)\n        self.assertIn('hello', vectors)\n        self.assertIn('world', vectors)\n        self.assertIn('test', vectors)\n        self.assertIn('gensim', vectors)\n        self.assertNotIn('this', vectors)\n        self.assertNotIn('is', vectors)\n        self.assertNotIn('a', vectors)\n\n    def test_empty_texts(self):\n        texts = [\"\", \"   \"]\n        vectors = task_func(texts)\n        self.assertEqual(vectors, {})\n\n    def test_non_alphanumeric_removal(self):\n        texts = [\"Hello, world!\", \"Gensim's world.\"]\n        vectors = task_func(texts)\n        self.assertIn('hello', vectors)\n        self.assertIn('world', vectors)\n        self.assertIn('gensim', vectors)\n        # 's' may appear because of splitting \"Gensim's\" into \"Gensim\" and \"s\"\n        self.assertIn('s', vectors)\n\n    def test_case_insensitivity(self):\n        texts = [\"HELLO world\", \"hello WORLD\"]\n        vectors = task_func(texts)\n        self.assertIn('hello', vectors)\n        self.assertIn('world', vectors)\n        self.assertNotIn('HELLO', vectors)\n        self.assertNotIn('WORLD', vectors)\n",
        "code": "import re\nfrom gensim.models import Word2Vec\n\n# Constants\nALPHANUMERIC = re.compile('[^a-zA-Z0-9]+')\n\ndef task_func(texts, stopwords=None):\n    # Preprocess texts: remove non-alphanumeric by replacing with space, lowercase, split, remove stopwords\n    processed_texts = []\n    for text in texts:\n        # Replace non-alphanumeric chars with space\n        clean_text = ALPHANUMERIC.sub(' ', text)\n        tokens = [word.lower() for word in clean_text.split()]\n        if stopwords:\n            tokens = [token for token in tokens if token not in stopwords]\n        if tokens:\n            processed_texts.append(tokens)\n    \n    # If no valid sentences, return empty dict\n    if not processed_texts:\n        return {}\n    \n    # Train Word2Vec model\n    model = Word2Vec(sentences=processed_texts, vector_size=100, window=5, min_count=1, workers=1, seed=42)\n    \n    # Return dict of word to vector list\n    word_vectors = {word: model.wv[word].tolist() for word in model.wv.index_to_key}\n    return word_vectors\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/657_2",
        "turn": "2",
        "instruct_prompt": "Clean each text by removing all non-alphanumeric characters except spaces and convert all characters to lowercase.",
        "test": "import unittest\nimport re\nfrom gensim.models import Word2Vec\n\nclass TestCases(unittest.TestCase):\n    def test_cleaning_and_lowercase(self):\n        texts = [\"Hello, World!\", \"Python3.8 is great!!!\", \"Clean THIS text: now.\"]\n        result = task_func(texts)\n        # The keys of result should be all lowercase and alphanumeric\n        for word in result.keys():\n            self.assertTrue(word.isalnum(), f\"Word '{word}' contains non-alphanumeric characters\")\n            self.assertEqual(word, word.lower(), f\"Word '{word}' is not lowercase\")\n        # Check that 'python38' is a key, not 'python3' or '8'\n        self.assertIn('python38', result.keys())\n        self.assertNotIn('python3', result.keys())\n        self.assertNotIn('8', result.keys())\n\n    def test_stopwords_removal(self):\n        texts = [\"Hello, World! This is a test.\"]\n        stopwords = {'this', 'is', 'a'}\n        result = task_func(texts, stopwords=stopwords)\n        # Confirm stopwords are removed\n        for sw in stopwords:\n            self.assertNotIn(sw, result.keys())\n        # Confirm other words present\n        expected_words = {'hello', 'world', 'test'}\n        for word in expected_words:\n            self.assertIn(word, result.keys())\n\n    def test_empty_after_cleaning(self):\n        texts = [\"!!!@@@###\"]\n        result = task_func(texts)\n        self.assertEqual(result, {})\n\n    def test_word2vec_training(self):\n        texts = [\"Hello World\", \"World of Python\"]\n        result = task_func(texts)\n        # Check keys are lowercase and alphanumeric\n        for word in result.keys():\n            self.assertTrue(word.isalnum())\n            self.assertEqual(word, word.lower())\n        # Check vectors are list of floats\n        for vec in result.values():\n            self.assertIsInstance(vec, list)\n            self.assertTrue(all(isinstance(x, float) for x in vec))\n\n    def test_previous_round_fail(self):\n        # Previous round replaced non-alphanumeric with spaces, so 'python3.8' -> ['python3', '8']\n        # Current round removes non-alphanumeric except spaces, so 'python3.8' -> 'python38'\n        texts = [\"python3.8\"]\n\n        # Run current task_func\n        current_result = task_func(texts)\n        current_keys = set(current_result.keys())\n\n        # Simulate previous round's cleaning\n        ALPHANUMERIC_PREV = re.compile('[^a-zA-Z0-9]+')\n        processed_texts_prev = []\n        for text in texts:\n            clean_text_prev = ALPHANUMERIC_PREV.sub(' ', text).lower()\n            tokens_prev = clean_text_prev.split()\n            if tokens_prev:\n                processed_texts_prev.append(tokens_prev)\n        if not processed_texts_prev:\n            prev_result = {}\n        else:\n            model_prev = Word2Vec(sentences=processed_texts_prev, vector_size=100, window=5, min_count=1, workers=1, seed=42)\n            prev_result = {word: model_prev.wv[word].tolist() for word in model_prev.wv.index_to_key}\n\n        prev_keys = set(prev_result.keys())\n\n        # They should differ\n        self.assertNotEqual(current_keys, prev_keys)\n\n        # Current keys should be {'python38'}\n        self.assertEqual(current_keys, {'python38'})\n\n        # Previous keys should be {'python3', '8'}\n        self.assertEqual(prev_keys, {'python3', '8'})\n",
        "code": "import re\nfrom gensim.models import Word2Vec\n\n# Constants\nALPHANUMERIC_EXCEPT_SPACE = re.compile('[^a-zA-Z0-9 ]+')\n\ndef task_func(texts, stopwords=None):\n    # Preprocess texts: remove all non-alphanumeric except spaces, lowercase, split, remove stopwords\n    processed_texts = []\n    for text in texts:\n        # Remove all non-alphanumeric except spaces\n        clean_text = ALPHANUMERIC_EXCEPT_SPACE.sub('', text)\n        clean_text = clean_text.lower()\n        tokens = clean_text.split()\n        if stopwords:\n            tokens = [token for token in tokens if token not in stopwords]\n        if tokens:\n            processed_texts.append(tokens)\n    \n    # If no valid sentences, return empty dict\n    if not processed_texts:\n        return {}\n    \n    # Train Word2Vec model\n    model = Word2Vec(sentences=processed_texts, vector_size=100, window=5, min_count=1, workers=1, seed=42)\n    \n    # Return dict of word to vector list\n    word_vectors = {word: model.wv[word].tolist() for word in model.wv.index_to_key}\n    return word_vectors\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/657_3",
        "turn": "3",
        "instruct_prompt": "Remove stop words from the cleaned texts using nltk.corpus.stopwords with English stop words as default if no stopwords argument is provided.",
        "test": "import unittest\nimport re\n\n# Assuming task_func is defined in the same file above\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Ensure nltk stopwords are downloaded before tests\n        import nltk\n        try:\n            from nltk.corpus import stopwords\n            stopwords.words('english')\n        except LookupError:\n            nltk.download('stopwords')\n\n    def test_default_stopwords_removal(self):\n        texts = [\"This is a simple test.\", \"Another test sentence here!\"]\n        result = task_func(texts)\n\n        # Get the nltk English stopwords\n        from nltk.corpus import stopwords\n        stopwords_set = set(stopwords.words('english'))\n\n        # After cleaning and stopwords removal, words in result keys should not be stopwords\n        for word in result.keys():\n            self.assertNotIn(word, stopwords_set)\n\n        # Make sure some expected non-stopword words are present\n        expected_words = set()\n        for text in texts:\n            clean_text = re.sub('[^a-zA-Z0-9 ]+', '', text).lower()\n            tokens = clean_text.split()\n            filtered = [t for t in tokens if t not in stopwords_set]\n            expected_words.update(filtered)\n\n        for word in expected_words:\n            self.assertIn(word, result)\n\n    def test_custom_stopwords(self):\n        texts = [\"Keep and remove words.\"]\n        custom_stopwords = {'and', 'remove'}\n        result = task_func(texts, stopwords=custom_stopwords)\n\n        # Stopwords should be removed\n        self.assertNotIn('and', result)\n        self.assertNotIn('remove', result)\n\n        # Non-stopwords should remain\n        self.assertIn('keep', result)\n        self.assertIn('words', result)\n\n    def test_all_stopwords_removed(self):\n        texts = [\"and the if but or\"]\n        result = task_func(texts)\n        self.assertEqual(result, {})\n\n    def test_empty_input(self):\n        result = task_func([])\n        self.assertEqual(result, {})\n",
        "code": "import re\nfrom gensim.models import Word2Vec\n\n# Constants\nALPHANUMERIC_EXCEPT_SPACE = re.compile('[^a-zA-Z0-9 ]+')\n\ndef task_func(texts, stopwords=None):\n    # Import nltk and download stopwords only when needed\n    import nltk\n    try:\n        from nltk.corpus import stopwords as nltk_stopwords\n        nltk_stopwords.words('english')\n    except LookupError:\n        nltk.download('stopwords')\n        from nltk.corpus import stopwords as nltk_stopwords\n\n    if stopwords is None:\n        stopwords_set = set(nltk_stopwords.words('english'))\n    else:\n        stopwords_set = set(stopwords)\n\n    processed_texts = []\n    for text in texts:\n        clean_text = ALPHANUMERIC_EXCEPT_SPACE.sub('', text)\n        clean_text = clean_text.lower()\n        tokens = clean_text.split()\n        tokens = [token for token in tokens if token not in stopwords_set]\n        if tokens:\n            processed_texts.append(tokens)\n\n    if not processed_texts:\n        return {}\n\n    model = Word2Vec(sentences=processed_texts, vector_size=100, window=5, min_count=1, workers=1, seed=42)\n    word_vectors = {word: model.wv[word].tolist() for word in model.wv.index_to_key}\n    return word_vectors\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/657_4",
        "turn": "4",
        "instruct_prompt": "Train and return a Word2Vec model on the tokenized texts with parameters vector_size=100, window=5, min_count=1, and workers=4. If the input texts list is empty after processing, return an untrained Word2Vec model with vector_size=100.",
        "test": "import unittest\nfrom gensim.models import Word2Vec\n\nclass TestCases(unittest.TestCase):\n    def test_trained_model(self):\n        texts = [\n            \"This is a sample text.\",\n            \"Another example sentence for Word2Vec training!\"\n        ]\n        model = task_func(texts)\n        self.assertIsInstance(model, Word2Vec)\n        # Check some known words exist in the vocabulary\n        vocab = set(model.wv.index_to_key)\n        # Words after processing (stopwords removed, lowercased, alphanumeric only)\n        expected_words = {'sample', 'text', 'another', 'example', 'sentence', 'word2vec', 'training'}\n        self.assertTrue(expected_words.issubset(vocab))\n        # Check model parameters\n        self.assertEqual(model.vector_size, 100)\n        self.assertEqual(model.window, 5)\n        self.assertEqual(model.min_count, 1)\n        self.assertEqual(model.workers, 4)\n\n    def test_empty_after_processing_returns_untrained_model(self):\n        # Input with only stopwords or empty strings\n        texts = [\"the and if\", \"or but\"]  # all stopwords likely\n        model = task_func(texts)\n        self.assertIsInstance(model, Word2Vec)\n        # The model should have no vocabulary\n        self.assertEqual(len(model.wv), 0)\n        self.assertEqual(model.vector_size, 100)\n\n    def test_empty_input_returns_untrained_model(self):\n        model = task_func([])\n        self.assertIsInstance(model, Word2Vec)\n        self.assertEqual(len(model.wv), 0)\n        self.assertEqual(model.vector_size, 100)\n",
        "code": "import re\nfrom gensim.models import Word2Vec\n\n# Constants\nALPHANUMERIC_EXCEPT_SPACE = re.compile('[^a-zA-Z0-9 ]+')\n\ndef task_func(texts, stopwords=None):\n    # Import nltk and download stopwords only when needed\n    import nltk\n    try:\n        from nltk.corpus import stopwords as nltk_stopwords\n        nltk_stopwords.words('english')\n    except LookupError:\n        nltk.download('stopwords')\n        from nltk.corpus import stopwords as nltk_stopwords\n\n    if stopwords is None:\n        stopwords_set = set(nltk_stopwords.words('english'))\n    else:\n        stopwords_set = set(stopwords)\n\n    processed_texts = []\n    for text in texts:\n        clean_text = ALPHANUMERIC_EXCEPT_SPACE.sub('', text)\n        clean_text = clean_text.lower()\n        tokens = clean_text.split()\n        tokens = [token for token in tokens if token not in stopwords_set]\n        if tokens:\n            processed_texts.append(tokens)\n\n    if not processed_texts:\n        # Return an untrained Word2Vec model with vector_size=100\n        return Word2Vec(vector_size=100)\n\n    model = Word2Vec(sentences=processed_texts, vector_size=100, window=5, min_count=1, workers=4, seed=42)\n    return model\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 91,
    "task_id": "BigCodeBench/678",
    "mt_data": [
      {
        "task_id": "BigCodeBench/678_1",
        "turn": "1",
        "instruct_prompt": "Write a function that reads all JSON files from a given directory path into a single pandas DataFrame. You should write self-contained code starting with:\n```python\nimport pandas as pd\nimport json\nimport os\n\ndef task_func(path):\n```",
        "test": "import unittest\nimport tempfile\nimport os\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        # Cleanup the temporary directory\n        self.test_dir.cleanup()\n\n    def write_json_file(self, filename, content):\n        path = os.path.join(self.test_dir.name, filename)\n        with open(path, 'w', encoding='utf-8') as f:\n            f.write(content)\n\n    def test_multiple_json_files(self):\n        json1 = '[{\"a\": 1, \"b\": 2}, {\"a\": 3, \"b\": 4}]'\n        json2 = '{\"a\": 5, \"b\": 6}'\n        self.write_json_file('file1.json', json1)\n        self.write_json_file('file2.json', json2)\n\n        df = task_func(self.test_dir.name)\n        expected_df = pd.DataFrame([\n            {\"a\": 1, \"b\": 2},\n            {\"a\": 3, \"b\": 4},\n            {\"a\": 5, \"b\": 6}\n        ])\n        pd.testing.assert_frame_equal(df.reset_index(drop=True), expected_df.reset_index(drop=True))\n\n    def test_non_json_files_ignored(self):\n        json1 = '[{\"a\": 1}]'\n        self.write_json_file('file1.json', json1)\n        # Write a non-json file\n        with open(os.path.join(self.test_dir.name, 'file.txt'), 'w') as f:\n            f.write('not json content')\n\n        df = task_func(self.test_dir.name)\n        expected_df = pd.DataFrame([{\"a\": 1}])\n        pd.testing.assert_frame_equal(df.reset_index(drop=True), expected_df.reset_index(drop=True))\n\n    def test_empty_directory(self):\n        df = task_func(self.test_dir.name)\n        self.assertTrue(df.empty)\n\n    def test_json_with_non_dict_or_list(self):\n        # JSON is a string, should be skipped\n        self.write_json_file('file1.json', '\"just a string\"')\n        df = task_func(self.test_dir.name)\n        self.assertTrue(df.empty)\n",
        "code": "import pandas as pd\nimport json\nimport os\n\ndef task_func(path):\n    data_frames = []\n    for filename in os.listdir(path):\n        if filename.endswith('.json'):\n            file_path = os.path.join(path, filename)\n            with open(file_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                # If the JSON data is a list of dicts, convert directly to DataFrame\n                # else if it is a dict, convert to DataFrame with one row\n                if isinstance(data, list):\n                    df = pd.DataFrame(data)\n                elif isinstance(data, dict):\n                    df = pd.DataFrame([data])\n                else:\n                    # If data is neither dict nor list, skip\n                    continue\n                data_frames.append(df)\n    if data_frames:\n        return pd.concat(data_frames, ignore_index=True)\n    else:\n        return pd.DataFrame()",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/678_2",
        "turn": "2",
        "instruct_prompt": "Ensure the JSON files are read in alphabetical order by filename.",
        "test": "import unittest\nimport os\nimport tempfile\nimport json\nimport pandas as pd\nfrom pandas.testing import assert_frame_equal\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def test_files_read_in_alphabetical_order(self):\n        file_contents = {\n            'b.json': [{'id': 2, 'value': 'B'}],\n            'a.json': [{'id': 1, 'value': 'A'}],\n            'c.json': [{'id': 3, 'value': 'C'}]\n        }\n        for filename, content in file_contents.items():\n            with open(os.path.join(self.test_dir.name, filename), 'w', encoding='utf-8') as f:\n                json.dump(content, f)\n\n        result_df = task_func(self.test_dir.name)\n\n        expected_data = [\n            {'id': 1, 'value': 'A'},\n            {'id': 2, 'value': 'B'},\n            {'id': 3, 'value': 'C'}\n        ]\n        expected_df = pd.DataFrame(expected_data)\n\n        assert_frame_equal(result_df, expected_df)\n\n    def test_non_json_files_ignored(self):\n        file_contents = {\n            'b.json': [{'id': 2}],\n            'a.txt': [{'id': 1}],\n            'a.json': [{'id': 1}]\n        }\n        for filename, content in file_contents.items():\n            with open(os.path.join(self.test_dir.name, filename), 'w', encoding='utf-8') as f:\n                if filename.endswith('.json'):\n                    json.dump(content, f)\n                else:\n                    f.write('not json')\n\n        result_df = task_func(self.test_dir.name)\n\n        expected_data = [\n            {'id': 1},\n            {'id': 2}\n        ]\n        expected_df = pd.DataFrame(expected_data)\n\n        assert_frame_equal(result_df, expected_df)\n",
        "code": "import pandas as pd\nimport json\nimport os\n\ndef task_func(path):\n    data_frames = []\n    for filename in sorted(os.listdir(path)):\n        if filename.endswith('.json'):\n            file_path = os.path.join(path, filename)\n            with open(file_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                if isinstance(data, list):\n                    df = pd.DataFrame(data)\n                elif isinstance(data, dict):\n                    df = pd.DataFrame([data])\n                else:\n                    continue\n                data_frames.append(df)\n    if data_frames:\n        return pd.concat(data_frames, ignore_index=True)\n    else:\n        return pd.DataFrame()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/678_3",
        "turn": "3",
        "instruct_prompt": "Add a new column named 'source' to each DataFrame that contains the filename of the JSON file it was read from.",
        "test": "import unittest\nimport tempfile\nimport os\nimport json\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        # Cleanup the temporary directory\n        self.test_dir.cleanup()\n\n    def test_source_column_added(self):\n        # Prepare two JSON files\n        data1 = [{\"a\": 1, \"b\": 2}, {\"a\": 3, \"b\": 4}]\n        data2 = {\"a\": 5, \"b\": 6}\n\n        file1 = os.path.join(self.test_dir.name, \"file1.json\")\n        file2 = os.path.join(self.test_dir.name, \"file2.json\")\n\n        with open(file1, 'w', encoding='utf-8') as f:\n            json.dump(data1, f)\n        with open(file2, 'w', encoding='utf-8') as f:\n            json.dump(data2, f)\n\n        # Run task_func\n        df = task_func(self.test_dir.name)\n\n        # Check that the source column exists\n        self.assertIn('source', df.columns)\n\n        # Check that source column contains correct filenames\n        expected_sources = ['file1.json'] * 2 + ['file2.json']\n        self.assertEqual(list(df['source']), expected_sources)\n\n        # Check data correctness\n        expected_a = [1, 3, 5]\n        expected_b = [2, 4, 6]\n        self.assertEqual(list(df['a']), expected_a)\n        self.assertEqual(list(df['b']), expected_b)\n\n    def test_no_json_files(self):\n        # Empty directory or no json files\n        df = task_func(self.test_dir.name)\n        self.assertTrue(df.empty)\n\n    def test_non_list_dict_json(self):\n        # JSON file with neither list nor dict\n        file_path = os.path.join(self.test_dir.name, \"file.json\")\n        with open(file_path, 'w', encoding='utf-8') as f:\n            json.dump(\"string_instead_of_list_or_dict\", f)\n\n        df = task_func(self.test_dir.name)\n        self.assertTrue(df.empty)\n",
        "code": "import pandas as pd\nimport json\nimport os\n\ndef task_func(path):\n    data_frames = []\n    for filename in sorted(os.listdir(path)):\n        if filename.endswith('.json'):\n            file_path = os.path.join(path, filename)\n            with open(file_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                if isinstance(data, list):\n                    df = pd.DataFrame(data)\n                elif isinstance(data, dict):\n                    df = pd.DataFrame([data])\n                else:\n                    continue\n                df['source'] = filename\n                data_frames.append(df)\n    if data_frames:\n        return pd.concat(data_frames, ignore_index=True)\n    else:\n        return pd.DataFrame()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/678_4",
        "turn": "4",
        "instruct_prompt": "After processing each JSON file, move it to a subdirectory named 'processed' inside the given path. Create the subdirectory if it does not exist.",
        "test": "import unittest\nimport tempfile\nimport os\nimport json\nimport pandas as pd\nfrom shutil import rmtree\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        rmtree(self.test_dir)\n\n    def test_json_files_moved_to_processed(self):\n        # Create sample JSON files\n        data1 = [{'a': 1}, {'a': 2}]\n        data2 = {'b': 3}\n        filenames = ['file1.json', 'file2.json']\n        for i, data in enumerate([data1, data2]):\n            with open(os.path.join(self.test_dir, filenames[i]), 'w', encoding='utf-8') as f:\n                json.dump(data, f)\n\n        df = task_func(self.test_dir)\n\n        # Check dataframe content\n        self.assertIn('source', df.columns)\n        self.assertEqual(set(df['source']), set(filenames))\n\n        # Check that original files are moved\n        processed_path = os.path.join(self.test_dir, 'processed')\n        self.assertTrue(os.path.isdir(processed_path))\n        for filename in filenames:\n            orig_path = os.path.join(self.test_dir, filename)\n            processed_file_path = os.path.join(processed_path, filename)\n            self.assertFalse(os.path.exists(orig_path))\n            self.assertTrue(os.path.exists(processed_file_path))\n\n    def test_no_json_files(self):\n        # Create a non-json file\n        with open(os.path.join(self.test_dir, 'test.txt'), 'w') as f:\n            f.write('hello')\n\n        df = task_func(self.test_dir)\n        self.assertTrue(df.empty)\n        # processed folder should still be created but empty\n        processed_path = os.path.join(self.test_dir, 'processed')\n        self.assertTrue(os.path.isdir(processed_path))\n        self.assertEqual(len(os.listdir(processed_path)), 0)\n",
        "code": "import pandas as pd\nimport json\nimport os\n\ndef task_func(path):\n    data_frames = []\n    processed_dir = os.path.join(path, 'processed')\n    if not os.path.exists(processed_dir):\n        os.makedirs(processed_dir)\n    for filename in sorted(os.listdir(path)):\n        if filename.endswith('.json') and os.path.isfile(os.path.join(path, filename)):\n            file_path = os.path.join(path, filename)\n            with open(file_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                if isinstance(data, list):\n                    df = pd.DataFrame(data)\n                elif isinstance(data, dict):\n                    df = pd.DataFrame([data])\n                else:\n                    continue\n                df['source'] = filename\n                data_frames.append(df)\n            # Move file to processed directory\n            os.rename(file_path, os.path.join(processed_dir, filename))\n    if data_frames:\n        return pd.concat(data_frames, ignore_index=True)\n    else:\n        return pd.DataFrame()\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 92,
    "task_id": "BigCodeBench/720",
    "mt_data": [
      {
        "task_id": "BigCodeBench/720_1",
        "turn": "1",
        "instruct_prompt": "Create a function task_func that writes sensor data for temperature and humidity into a CSV file named \"task_func_data/Output.txt\". You should write self-contained code starting with:\n```python\nimport os\nimport csv\nimport random\nfrom datetime import datetime\ndef task_func():\n```",
        "test": "import unittest\nimport os\nimport csv\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_writes_file(self):\n        # Run the function\n        task_func()\n        \n        # Check if file exists\n        file_path = 'task_func_data/Output.txt'\n        self.assertTrue(os.path.exists(file_path))\n        \n        # Check file content\n        with open(file_path, newline='') as file:\n            reader = csv.reader(file)\n            rows = list(reader)\n            # There should be exactly two rows: header + data\n            self.assertEqual(len(rows), 2)\n            self.assertEqual(rows[0], ['Timestamp', 'Temperature', 'Humidity'])\n            \n            # Check timestamp format\n            timestamp = rows[1][0]\n            try:\n                datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n                valid_timestamp = True\n            except ValueError:\n                valid_timestamp = False\n            self.assertTrue(valid_timestamp)\n            \n            # Check temperature and humidity are floats and within expected range\n            temp = float(rows[1][1])\n            humid = float(rows[1][2])\n            self.assertTrue(-10 <= temp <= 40)\n            self.assertTrue(0 <= humid <= 100)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import os\nimport csv\nimport random\nfrom datetime import datetime\n\ndef task_func():\n    # Ensure the directory exists\n    os.makedirs('task_func_data', exist_ok=True)\n    \n    file_path = 'task_func_data/Output.txt'\n    \n    # Generate sample sensor data\n    temperature = round(random.uniform(-10, 40), 2)  # Temperature in Celsius\n    humidity = round(random.uniform(0, 100), 2)      # Humidity in percentage\n    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    \n    # Write data to CSV file\n    with open(file_path, mode='w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Timestamp', 'Temperature', 'Humidity'])\n        writer.writerow([timestamp, temperature, humidity])",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/720_2",
        "turn": "2",
        "instruct_prompt": "Generate the temperature as a random float between 20 and 30 and humidity as a random float between 50 and 60. Include a timestamp of the current datetime for each data entry.",
        "test": "import unittest\nimport os\nimport csv\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_data_generation(self):\n        # Run the function to generate data\n        task_func()\n        file_path = 'task_func_data/Output.txt'\n        \n        # Check if file is created\n        self.assertTrue(os.path.exists(file_path))\n        \n        # Read the file and check contents\n        with open(file_path, mode='r', newline='') as file:\n            reader = csv.reader(file)\n            rows = list(reader)\n        \n        # Check header\n        self.assertEqual(rows[0], ['Timestamp', 'Temperature', 'Humidity'])\n        \n        # Check data row length\n        self.assertEqual(len(rows[1]), 3)\n        \n        # Check timestamp format\n        timestamp_str = rows[1][0]\n        try:\n            datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')\n        except ValueError:\n            self.fail('Timestamp format is incorrect')\n        \n        # Check temperature range\n        temperature = float(rows[1][1])\n        self.assertGreaterEqual(temperature, 20)\n        self.assertLessEqual(temperature, 30)\n        \n        # Check humidity range\n        humidity = float(rows[1][2])\n        self.assertGreaterEqual(humidity, 50)\n        self.assertLessEqual(humidity, 60)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import os\nimport csv\nimport random\nfrom datetime import datetime\n\ndef task_func():\n    # Ensure the directory exists\n    os.makedirs('task_func_data', exist_ok=True)\n    \n    file_path = 'task_func_data/Output.txt'\n    \n    # Generate sample sensor data with updated ranges\n    temperature = round(random.uniform(20, 30), 2)  # Temperature between 20 and 30 Celsius\n    humidity = round(random.uniform(50, 60), 2)     # Humidity between 50 and 60 percent\n    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    \n    # Write data to CSV file\n    with open(file_path, mode='w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Timestamp', 'Temperature', 'Humidity'])\n        writer.writerow([timestamp, temperature, humidity])",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/720_3",
        "turn": "3",
        "instruct_prompt": "Write the data to the CSV file in append mode. If the file does not exist, write the header row first with the fields: 'Timestamp', 'Temperature', 'Humidity'.",
        "test": "import unittest\nimport os\nimport csv\nfrom datetime import datetime\nfrom io import StringIO\nfrom unittest import mock\n\n# Import the task_func from the solution context\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.dir_path = 'task_func_data'\n        self.file_path = os.path.join(self.dir_path, 'Output.txt')\n        # Remove directory if exists to start fresh\n        if os.path.exists(self.file_path):\n            os.remove(self.file_path)\n        if os.path.exists(self.dir_path):\n            os.rmdir(self.dir_path)\n\n    def tearDown(self):\n        # Clean up after tests\n        if os.path.exists(self.file_path):\n            os.remove(self.file_path)\n        if os.path.exists(self.dir_path):\n            os.rmdir(self.dir_path)\n\n    def test_file_creation_and_header_written(self):\n        # Run task_func to create file and write first row\n        task_func()\n        self.assertTrue(os.path.isfile(self.file_path))\n\n        with open(self.file_path, newline='') as f:\n            reader = csv.reader(f)\n            rows = list(reader)\n\n        # Check header\n        self.assertEqual(rows[0], ['Timestamp', 'Temperature', 'Humidity'])\n        # Check that at least one data row exists\n        self.assertEqual(len(rows), 2)\n        # Check timestamp format\n        try:\n            datetime.strptime(rows[1][0], '%Y-%m-%d %H:%M:%S')\n        except ValueError:\n            self.fail('Timestamp format is incorrect')\n\n    def test_append_mode_writes_additional_rows_without_duplicate_header(self):\n        # First call to create file and header\n        task_func()\n        # Read initial content\n        with open(self.file_path, newline='') as f:\n            reader = csv.reader(f)\n            initial_rows = list(reader)\n\n        # Second call to append data\n        task_func()\n\n        with open(self.file_path, newline='') as f:\n            reader = csv.reader(f)\n            rows = list(reader)\n\n        # Header should only appear once\n        headers = [row for row in rows if row == ['Timestamp', 'Temperature', 'Humidity']]\n        self.assertEqual(len(headers), 1)\n\n        # Number of data rows should be initial data rows + 1\n        self.assertEqual(len(rows), len(initial_rows) + 1)\n\n        # Check that timestamps in data rows are valid\n        for row in rows[1:]:\n            try:\n                datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S')\n            except ValueError:\n                self.fail('Timestamp format is incorrect in appended data')\n\n    def test_file_created_if_not_exist(self):\n        # Ensure file does not exist\n        if os.path.exists(self.file_path):\n            os.remove(self.file_path)\n        if os.path.exists(self.dir_path):\n            os.rmdir(self.dir_path)\n\n        # Run task_func\n        task_func()\n        self.assertTrue(os.path.isfile(self.file_path))\n\n        with open(self.file_path, newline='') as f:\n            reader = csv.reader(f)\n            rows = list(reader)\n\n        # Header must be present\n        self.assertEqual(rows[0], ['Timestamp', 'Temperature', 'Humidity'])\n\n    def test_data_values_within_expected_ranges(self):\n        task_func()\n        with open(self.file_path, newline='') as f:\n            reader = csv.reader(f)\n            rows = list(reader)\n\n        # Check temperature and humidity ranges\n        temp = float(rows[1][1])\n        hum = float(rows[1][2])\n        self.assertGreaterEqual(temp, 20)\n        self.assertLessEqual(temp, 30)\n        self.assertGreaterEqual(hum, 50)\n        self.assertLessEqual(hum, 60)\n",
        "code": "import os\nimport csv\nimport random\nfrom datetime import datetime\n\ndef task_func():\n    # Ensure the directory exists\n    os.makedirs('task_func_data', exist_ok=True)\n    \n    file_path = 'task_func_data/Output.txt'\n    \n    # Generate sample sensor data with updated ranges\n    temperature = round(random.uniform(20, 30), 2)  # Temperature between 20 and 30 Celsius\n    humidity = round(random.uniform(50, 60), 2)     # Humidity between 50 and 60 percent\n    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    \n    # Check if file exists to decide if header is needed\n    file_exists = os.path.isfile(file_path)\n    \n    # Write data to CSV file in append mode\n    with open(file_path, mode='a', newline='') as file:\n        writer = csv.writer(file)\n        if not file_exists:\n            writer.writerow(['Timestamp', 'Temperature', 'Humidity'])\n        writer.writerow([timestamp, temperature, humidity])",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/720_4",
        "turn": "4",
        "instruct_prompt": "Return the path to the CSV file \"task_func_data/Output.txt\" from the function before deleting the file. After returning, delete the file from the filesystem.",
        "test": "import unittest\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_return_and_delete_file(self):\n        # Call the function\n        path = task_func()\n        \n        # Check the returned path is correct\n        self.assertEqual(path, 'task_func_data/Output.txt')\n        \n        # Check file does not exist after function call\n        self.assertFalse(os.path.isfile(path))\n\n    def test_file_created_and_deleted(self):\n        # This test ensures the file is created and then deleted by task_func\n        # Since task_func deletes the file after writing, we check file does not exist after call\n        path = task_func()\n        self.assertEqual(path, 'task_func_data/Output.txt')\n        self.assertFalse(os.path.isfile(path))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import os\nimport csv\nimport random\nfrom datetime import datetime\n\ndef task_func():\n    # Ensure the directory exists\n    os.makedirs('task_func_data', exist_ok=True)\n    \n    file_path = 'task_func_data/Output.txt'\n    \n    # Generate sample sensor data with updated ranges\n    temperature = round(random.uniform(20, 30), 2)  # Temperature between 20 and 30 Celsius\n    humidity = round(random.uniform(50, 60), 2)     # Humidity between 50 and 60 percent\n    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    \n    # Check if file exists to decide if header is needed\n    file_exists = os.path.isfile(file_path)\n    \n    # Write data to CSV file in append mode\n    with open(file_path, mode='a', newline='') as file:\n        writer = csv.writer(file)\n        if not file_exists:\n            writer.writerow(['Timestamp', 'Temperature', 'Humidity'])\n        writer.writerow([timestamp, temperature, humidity])\n\n    # Return the file path before deleting\n    returned_path = file_path\n    if os.path.isfile(file_path):\n        os.remove(file_path)\n    return returned_path\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 93,
    "task_id": "BigCodeBench/723",
    "mt_data": [
      {
        "task_id": "BigCodeBench/723_1",
        "turn": "1",
        "instruct_prompt": "Write a function `task_func(url)` that downloads the HTML content from the given URL and parses it using BeautifulSoup. You should write self-contained code starting with:\n```\nimport urllib.request\nfrom bs4 import BeautifulSoup\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\ndef task_func(url):\n```",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport io\n\nimport urllib.request\nfrom bs4 import BeautifulSoup\n\n# Assuming task_func is defined in the same file for testing\n\nclass TestCases(unittest.TestCase):\n    @patch('urllib.request.urlopen')\n    def test_task_func_returns_soup(self, mock_urlopen):\n        # Mock HTML content\n        html = b'<html><head><title>Test</title></head><body><p>Hello</p></body></html>'\n        mock_response = MagicMock()\n        mock_response.read.return_value = html\n        mock_urlopen.return_value = mock_response\n\n        url = 'http://example.com'\n        soup = task_func(url)\n\n        self.assertIsInstance(soup, BeautifulSoup)\n        self.assertEqual(soup.title.string, 'Test')\n        self.assertEqual(soup.p.string, 'Hello')\n\n    @patch('urllib.request.urlopen')\n    def test_task_func_with_empty_html(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = b''\n        mock_urlopen.return_value = mock_response\n\n        url = 'http://empty.com'\n        soup = task_func(url)\n\n        self.assertIsInstance(soup, BeautifulSoup)\n        self.assertEqual(str(soup), '')\n",
        "code": "import urllib.request\nfrom bs4 import BeautifulSoup\n\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\n\ndef task_func(url):\n    response = urllib.request.urlopen(url)\n    html_content = response.read()\n    soup = BeautifulSoup(html_content, 'html.parser')\n    return soup\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/723_2",
        "turn": "2",
        "instruct_prompt": "Extract all rows from the first HTML table with class 'data-table' on the page, and collect the text content of each cell into a list of lists.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('urllib.request.urlopen')\n    def test_task_func_extracts_table_rows(self, mock_urlopen):\n        html = '''\n        <html>\n            <body>\n                <table class=\"data-table\">\n                    <tr><th>Header1</th><th>Header2</th></tr>\n                    <tr><td>Row1Col1</td><td>Row1Col2</td></tr>\n                    <tr><td>Row2Col1</td><td>Row2Col2</td></tr>\n                </table>\n                <table class=\"data-table\">\n                    <tr><td>OtherTable1</td></tr>\n                </table>\n            </body>\n        </html>\n        '''\n        mock_response = MagicMock()\n        mock_response.read.return_value = html.encode('utf-8')\n        mock_urlopen.return_value = mock_response\n\n        result = task_func('http://fakeurl.com')\n\n        expected = [\n            ['Header1', 'Header2'],\n            ['Row1Col1', 'Row1Col2'],\n            ['Row2Col1', 'Row2Col2']\n        ]\n\n        self.assertEqual(result, expected)\n\n    @patch('urllib.request.urlopen')\n    def test_task_func_no_data_table(self, mock_urlopen):\n        html = '''<html><body><table class=\"other-table\"><tr><td>Data</td></tr></table></body></html>'''\n        mock_response = MagicMock()\n        mock_response.read.return_value = html.encode('utf-8')\n        mock_urlopen.return_value = mock_response\n\n        result = task_func('http://fakeurl.com')\n\n        self.assertEqual(result, [])\n",
        "code": "import urllib.request\nfrom bs4 import BeautifulSoup\n\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\n\ndef task_func(url):\n    response = urllib.request.urlopen(url)\n    html_content = response.read()\n    soup = BeautifulSoup(html_content, 'html.parser')\n\n    table = soup.find('table', class_='data-table')\n    if not table:\n        return []\n\n    rows = table.find_all('tr')\n    result = []\n    for row in rows:\n        cells = row.find_all(['td', 'th'])\n        row_data = [cell.get_text(strip=True) for cell in cells]\n        result.append(row_data)\n\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/723_3",
        "turn": "3",
        "instruct_prompt": "Write the extracted table data into a CSV file located at the path specified by CSV_FILE_PATH, overwriting the file if it already exists.",
        "test": "import unittest\nimport os\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('urllib.request.urlopen')\n    def test_task_func_writes_csv_and_returns_data(self, mock_urlopen):\n        # Prepare a simple HTML with a table\n        html = '''\n        <html>\n            <body>\n                <table class=\"data-table\">\n                    <tr><th>Header1</th><th>Header2</th></tr>\n                    <tr><td>Row1Col1</td><td>Row1Col2</td></tr>\n                    <tr><td>Row2Col1</td><td>Row2Col2</td></tr>\n                </table>\n            </body>\n        </html>\n        '''\n        mock_response = MagicMock()\n        mock_response.read.return_value = html.encode('utf-8')\n        mock_urlopen.return_value = mock_response\n\n        # Directly use task_func and CSV_FILE_PATH without import\n        result = task_func('http://example.com')\n\n        expected = [\n            ['Header1', 'Header2'],\n            ['Row1Col1', 'Row1Col2'],\n            ['Row2Col1', 'Row2Col2']\n        ]\n\n        # Check returned data\n        self.assertEqual(result, expected)\n\n        # Check file exists\n        self.assertTrue(os.path.exists(CSV_FILE_PATH))\n\n        # Check file contents\n        with open(CSV_FILE_PATH, encoding='utf-8') as f:\n            lines = [line.strip() for line in f.readlines()]\n\n        self.assertEqual(lines, [\n            'Header1,Header2',\n            'Row1Col1,Row1Col2',\n            'Row2Col1,Row2Col2'\n        ])\n\n        # Cleanup\n        os.remove(CSV_FILE_PATH)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\n\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\n\ndef task_func(url):\n    response = urllib.request.urlopen(url)\n    html_content = response.read()\n    soup = BeautifulSoup(html_content, 'html.parser')\n\n    table = soup.find('table', class_='data-table')\n    if not table:\n        return []\n\n    rows = table.find_all('tr')\n    result = []\n    for row in rows:\n        cells = row.find_all(['td', 'th'])\n        row_data = [cell.get_text(strip=True) for cell in cells]\n        result.append(row_data)\n\n    # Write to CSV file, overwriting if it exists\n    with open(CSV_FILE_PATH, mode='w', newline='', encoding='utf-8') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerows(result)\n\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/723_4",
        "turn": "4",
        "instruct_prompt": "Ensure the function returns the string CSV_FILE_PATH representing the path of the saved CSV file.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('urllib.request.urlopen')\n    def test_task_func_returns_csv_file_path(self, mock_urlopen):\n        # Prepare a fake HTML content with a table\n        html = '''\n        <html><body>\n        <table class=\"data-table\">\n            <tr><th>Header1</th><th>Header2</th></tr>\n            <tr><td>Data1</td><td>Data2</td></tr>\n        </table>\n        </body></html>\n        '''\n        mock_response = MagicMock()\n        mock_response.read.return_value = html.encode('utf-8')\n        mock_urlopen.return_value = mock_response\n\n        result = task_func('http://fakeurl.com')\n\n        # The function should return the CSV_FILE_PATH string\n        self.assertEqual(result, CSV_FILE_PATH)\n\n    @patch('urllib.request.urlopen')\n    def test_task_func_no_table_returns_csv_file_path(self, mock_urlopen):\n        # Prepare a fake HTML content with no table\n        html = '<html><body><p>No table here</p></body></html>'\n        mock_response = MagicMock()\n        mock_response.read.return_value = html.encode('utf-8')\n        mock_urlopen.return_value = mock_response\n\n        result = task_func('http://fakeurl.com')\n\n        # The function should return the CSV_FILE_PATH string even if no table found\n        self.assertEqual(result, CSV_FILE_PATH)\n",
        "code": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\n\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\n\ndef task_func(url):\n    response = urllib.request.urlopen(url)\n    html_content = response.read()\n    soup = BeautifulSoup(html_content, 'html.parser')\n\n    table = soup.find('table', class_='data-table')\n    if not table:\n        return CSV_FILE_PATH\n\n    rows = table.find_all('tr')\n    result = []\n    for row in rows:\n        cells = row.find_all(['td', 'th'])\n        row_data = [cell.get_text(strip=True) for cell in cells]\n        result.append(row_data)\n\n    # Write to CSV file, overwriting if it exists\n    with open(CSV_FILE_PATH, mode='w', newline='', encoding='utf-8') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerows(result)\n\n    return CSV_FILE_PATH\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 94,
    "task_id": "BigCodeBench/752",
    "mt_data": [
      {
        "task_id": "BigCodeBench/752_1",
        "turn": "1",
        "instruct_prompt": "Train a linear regression model using the provided DataFrame and target_column. Split the data into training and test sets using test_size and random_state parameters, then return the model's score on the test set. You should write self-contained code starting with:\n```\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef task_func(data, target_column, test_size=0.2, random_state=0) -> float:\n```",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_linear_regression_score(self):\n        # Create a simple linear relationship dataset\n        np.random.seed(0)\n        size = 100\n        X1 = np.random.rand(size)\n        X2 = np.random.rand(size)\n        noise = np.random.normal(0, 0.1, size)\n        y = 3 * X1 + 5 * X2 + 2 + noise\n        data = pd.DataFrame({'X1': X1, 'X2': X2, 'target': y})\n\n        score = task_func(data, 'target', test_size=0.25, random_state=42)\n        # The R^2 score should be reasonably high for this linear data\n        self.assertGreater(score, 0.9)\n\n    def test_different_test_size_and_random_state(self):\n        np.random.seed(1)\n        size = 50\n        X = np.linspace(0, 10, size)\n        y = 2 * X + 1 + np.random.normal(0, 0.5, size)\n        data = pd.DataFrame({'feature': X, 'target': y})\n\n        score1 = task_func(data, 'target', test_size=0.3, random_state=1)\n        score2 = task_func(data, 'target', test_size=0.3, random_state=2)\n\n        # Scores should be floats and between 0 and 1\n        self.assertIsInstance(score1, float)\n        self.assertIsInstance(score2, float)\n        self.assertGreaterEqual(score1, 0)\n        self.assertLessEqual(score1, 1)\n        self.assertGreaterEqual(score2, 0)\n        self.assertLessEqual(score2, 1)\n\n    def test_single_feature(self):\n        # Test with single feature\n        np.random.seed(2)\n        X = np.arange(20)\n        y = 4 * X + 10 + np.random.normal(0, 1, 20)\n        data = pd.DataFrame({'feat': X, 'target': y})\n\n        score = task_func(data, 'target', test_size=0.3, random_state=0)\n        self.assertGreater(score, 0.9)\n",
        "code": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state=0) -> float:\n    X = data.drop(columns=[target_column])\n    y = data[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/752_2",
        "turn": "2",
        "instruct_prompt": "Raise a ValueError if data is not a pandas DataFrame or if data is empty.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_valid_dataframe(self):\n        df = pd.DataFrame({\n            'feature1': [1, 2, 3, 4, 5],\n            'target': [2, 4, 6, 8, 10]\n        })\n        score = task_func(df, 'target')\n        self.assertIsInstance(score, float)\n\n    def test_not_dataframe(self):\n        with self.assertRaises(ValueError) as context:\n            task_func([1, 2, 3], 'target')\n        self.assertEqual(str(context.exception), \"data must be a pandas DataFrame\")\n\n    def test_empty_dataframe(self):\n        empty_df = pd.DataFrame()\n        with self.assertRaises(ValueError) as context:\n            task_func(empty_df, 'target')\n        self.assertEqual(str(context.exception), \"data must not be empty\")\n",
        "code": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state=0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"data must be a pandas DataFrame\")\n    if data.empty:\n        raise ValueError(\"data must not be empty\")\n    X = data.drop(columns=[target_column])\n    y = data[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/752_3",
        "turn": "3",
        "instruct_prompt": "Raise a ValueError if target_column is not a column in data.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.data = pd.DataFrame({\n            'feature1': [1, 2, 3, 4, 5],\n            'feature2': [5, 4, 3, 2, 1],\n            'target': [2, 3, 4, 5, 6]\n        })\n\n    def test_valid_target_column(self):\n        # Should return a float score\n        score = task_func(self.data, 'target')\n        self.assertIsInstance(score, float)\n\n    def test_target_column_not_in_data(self):\n        # Should raise ValueError if target_column not in columns\n        with self.assertRaises(ValueError) as context:\n            task_func(self.data, 'nonexistent_column')\n        self.assertIn(\"target_column 'nonexistent_column' is not in data columns\", str(context.exception))\n",
        "code": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state=0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"data must be a pandas DataFrame\")\n    if data.empty:\n        raise ValueError(\"data must not be empty\")\n    if target_column not in data.columns:\n        raise ValueError(f\"target_column '{target_column}' is not in data columns\")\n    X = data.drop(columns=[target_column])\n    y = data[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/752_4",
        "turn": "4",
        "instruct_prompt": "Raise a ValueError if any values in data are not numeric.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_valid_numeric_data(self):\n        data = pd.DataFrame({\n            'feature1': [1, 2, 3, 4, 5],\n            'feature2': [5, 4, 3, 2, 1],\n            'target': [2, 3, 4, 5, 6]\n        })\n        score = task_func(data, 'target')\n        self.assertIsInstance(score, float)\n\n    def test_non_numeric_feature_value(self):\n        data = pd.DataFrame({\n            'feature1': [1, 2, 'a', 4, 5],\n            'feature2': [5, 4, 3, 2, 1],\n            'target': [2, 3, 4, 5, 6]\n        })\n        with self.assertRaises(ValueError) as cm:\n            task_func(data, 'target')\n        self.assertIn('all feature values must be numeric', str(cm.exception))\n\n    def test_non_numeric_target_value(self):\n        data = pd.DataFrame({\n            'feature1': [1, 2, 3, 4, 5],\n            'feature2': [5, 4, 3, 2, 1],\n            'target': [2, 'b', 4, 5, 6]\n        })\n        with self.assertRaises(ValueError) as cm:\n            task_func(data, 'target')\n        self.assertIn('target column values must be numeric', str(cm.exception))\n",
        "code": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state=0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"data must be a pandas DataFrame\")\n    if data.empty:\n        raise ValueError(\"data must not be empty\")\n    if target_column not in data.columns:\n        raise ValueError(f\"target_column '{target_column}' is not in data columns\")\n    X = data.drop(columns=[target_column])\n    # Check each feature column dtype individually\n    for col in X.columns:\n        if not np.issubdtype(X[col].dtype, np.number):\n            raise ValueError(\"all feature values must be numeric\")\n    if not np.issubdtype(data[target_column].dtype, np.number):\n        raise ValueError(\"target column values must be numeric\")\n    y = data[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/752_5",
        "turn": "5",
        "instruct_prompt": "Raise a ValueError if random_state is not an integer or if test_size is not strictly between 0 and 1.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nfrom sklearn.datasets import make_regression\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        X, y = make_regression(n_samples=100, n_features=3, noise=0.1, random_state=42)\n        self.data = pd.DataFrame(X, columns=['feat1', 'feat2', 'feat3'])\n        self.data['target'] = y\n\n    def test_valid_input(self):\n        score = task_func(self.data, 'target', test_size=0.25, random_state=42)\n        self.assertIsInstance(score, float)\n\n    def test_random_state_not_int(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(self.data, 'target', test_size=0.2, random_state='not_int')\n        self.assertIn('random_state must be an integer', str(cm.exception))\n\n    def test_test_size_zero(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(self.data, 'target', test_size=0, random_state=0)\n        self.assertIn('test_size must be strictly between 0 and 1', str(cm.exception))\n\n    def test_test_size_one(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(self.data, 'target', test_size=1, random_state=0)\n        self.assertIn('test_size must be strictly between 0 and 1', str(cm.exception))\n\n    def test_test_size_negative(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(self.data, 'target', test_size=-0.1, random_state=0)\n        self.assertIn('test_size must be strictly between 0 and 1', str(cm.exception))\n\n    def test_test_size_greater_than_one(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(self.data, 'target', test_size=1.5, random_state=0)\n        self.assertIn('test_size must be strictly between 0 and 1', str(cm.exception))\n",
        "code": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state=0) -> float:\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"data must be a pandas DataFrame\")\n    if data.empty:\n        raise ValueError(\"data must not be empty\")\n    if target_column not in data.columns:\n        raise ValueError(f\"target_column '{target_column}' is not in data columns\")\n    if not isinstance(random_state, int):\n        raise ValueError(\"random_state must be an integer\")\n    if not (0 < test_size < 1):\n        raise ValueError(\"test_size must be strictly between 0 and 1\")\n    X = data.drop(columns=[target_column])\n    # Check each feature column dtype individually\n    for col in X.columns:\n        if not np.issubdtype(X[col].dtype, np.number):\n            raise ValueError(\"all feature values must be numeric\")\n    if not np.issubdtype(data[target_column].dtype, np.number):\n        raise ValueError(\"target column values must be numeric\")\n    y = data[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 95,
    "task_id": "BigCodeBench/760",
    "mt_data": [
      {
        "task_id": "BigCodeBench/760_1",
        "turn": "1",
        "instruct_prompt": "Create a function that generates a pandas DataFrame with 100 records. Each record should have an ID from 1 to 100 and a Name randomly selected from two provided name lists (latin_names and other_names). You should write self-contained code starting with:```python\nimport pandas as pd\nimport numpy as np\nimport datetime\n\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopetn', 'Mndez', 'Gmez', 'Prez', 'Muoz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_output(self):\n        df = task_func(rng_seed=42)\n        \n        # Check type\n        self.assertIsInstance(df, pd.DataFrame)\n        \n        # Check shape\n        self.assertEqual(df.shape, (100, 2))\n        \n        # Check ID column\n        self.assertTrue('ID' in df.columns)\n        self.assertTrue(all(df['ID'] == range(1, 101)))\n        \n        # Check Name column\n        self.assertTrue('Name' in df.columns)\n        allowed_names = ['Sopetn', 'Mndez', 'Gmez', 'Prez', 'Muoz',\n                         'Smith', 'Johnson', 'Williams', 'Brown', 'Jones']\n        self.assertTrue(all(name in allowed_names for name in df['Name']))",
        "code": "import pandas as pd\nimport numpy as np\nimport datetime\n\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopetn', 'Mndez', 'Gmez', 'Prez', 'Muoz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    \n    if rng_seed is not None:\n        np.random.seed(rng_seed)\n    \n    ids = np.arange(1, 101)\n    \n    # Combine both name lists\n    combined_names = latin_names + other_names\n    \n    # Randomly choose 100 names from combined_names\n    chosen_names = np.random.choice(combined_names, size=100)\n    \n    df = pd.DataFrame({'ID': ids, 'Name': chosen_names})\n    return df",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/760_2",
        "turn": "2",
        "instruct_prompt": "Add to the function the generation of a Date of Birth for each record. The Date of Birth should be a random datetime between start_year and end_year (inclusive), with random months and days (assume all months have 28 days for simplicity).",
        "test": "import unittest\nimport datetime\n\nclass TestCases(unittest.TestCase):\n    def test_dob_generation(self):\n        df = task_func(start_year=1990, end_year=1995, rng_seed=42)\n        self.assertEqual(len(df), 100)\n        # Check that Date of Birth column exists\n        self.assertIn('Date of Birth', df.columns)\n        for dob in df['Date of Birth']:\n            self.assertIsInstance(dob, datetime.date)\n            self.assertGreaterEqual(dob.year, 1990)\n            self.assertLessEqual(dob.year, 1995)\n            self.assertGreaterEqual(dob.month, 1)\n            self.assertLessEqual(dob.month, 12)\n            self.assertGreaterEqual(dob.day, 1)\n            self.assertLessEqual(dob.day, 28)\n\n    def test_previous_round_fails(self):\n        # The previous round code does not produce 'Date of Birth' column\n        # So trying to run the previous code here should fail the test\n        import pandas as pd\n        import numpy as np\n\n        def previous_task_func(start_year=1980, end_year=2000, email_domain='example.com',\n                   latin_names=['Sopetn', 'Mndez', 'Gmez', 'Prez', 'Muoz'],\n                   other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n                   rng_seed=None):\n            if rng_seed is not None:\n                np.random.seed(rng_seed)\n            ids = np.arange(1, 101)\n            combined_names = latin_names + other_names\n            chosen_names = np.random.choice(combined_names, size=100)\n            df = pd.DataFrame({'ID': ids, 'Name': chosen_names})\n            return df\n\n        df_prev = previous_task_func(start_year=1990, end_year=1995, rng_seed=42)\n        # This should fail because 'Date of Birth' column is missing\n        with self.assertRaises(KeyError):\n            _ = df_prev['Date of Birth']\n",
        "code": "import pandas as pd\nimport numpy as np\nimport datetime\n\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopetn', 'Mndez', 'Gmez', 'Prez', 'Muoz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    \n    if rng_seed is not None:\n        np.random.seed(rng_seed)\n    \n    ids = np.arange(1, 101)\n    \n    # Combine both name lists\n    combined_names = latin_names + other_names\n    \n    # Randomly choose 100 names from combined_names\n    chosen_names = np.random.choice(combined_names, size=100)\n    \n    # Generate random years between start_year and end_year inclusive\n    years = np.random.randint(start_year, end_year + 1, size=100)\n    \n    # Generate random months between 1 and 12\n    months = np.random.randint(1, 13, size=100)\n    \n    # Generate random days between 1 and 28 (all months assumed 28 days)\n    days = np.random.randint(1, 29, size=100)\n    \n    # Combine to datetime.date\n    dob = [datetime.date(year, month, day) for year, month, day in zip(years, months, days)]\n    \n    df = pd.DataFrame({'ID': ids, 'Name': chosen_names, 'Date of Birth': dob})\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/760_3",
        "turn": "3",
        "instruct_prompt": "Ensure that any improperly encoded Latin characters in latin_names are corrected before selection.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_improperly_encoded_latin_names_corrected(self):\n        # latin_names with decomposed accents (improperly encoded but fixable by normalization)\n        latin_names_bad = [\n            'Sopeto\\u0301n',  # decomposed '' as 'o' + combining acute accent\n            'Me\\u0301ndez',  # decomposed ''\n            'Go\\u0301mez',   # decomposed ''\n            'Pe\\u0301rez',  # decomposed ''\n            'Mun\\u0303oz'   # decomposed '' as 'n' + combining tilde\n        ]\n        other_names = ['Smith', 'Johnson']\n\n        df = task_func(latin_names=latin_names_bad, other_names=other_names, rng_seed=1)\n\n        # Expected normalized latin names\n        expected_latin_names = ['Sopetn', 'Mndez', 'Gmez', 'Prez', 'Muoz']\n\n        names_in_df = set(df['Name'])\n        for name in expected_latin_names:\n            self.assertIn(name, names_in_df)\n\n        combined = expected_latin_names + other_names\n        for name in df['Name']:\n            self.assertIn(name, combined)\n",
        "code": "import pandas as pd\nimport numpy as np\nimport datetime\nimport unicodedata\n\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopetn', 'Mndez', 'Gmez', 'Prez', 'Muoz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    \n    if rng_seed is not None:\n        np.random.seed(rng_seed)\n    \n    # Normalize latin_names to fix improperly encoded Latin characters\n    def normalize_name(name):\n        # Normalize to NFC form to fix decomposed or combining characters\n        normalized = unicodedata.normalize('NFC', name)\n        return normalized\n\n    corrected_latin_names = [normalize_name(name) for name in latin_names]\n    \n    ids = np.arange(1, 101)\n    \n    # Combine both name lists\n    combined_names = corrected_latin_names + other_names\n    \n    # Randomly choose 100 names from combined_names\n    chosen_names = np.random.choice(combined_names, size=100)\n    \n    # Generate random years between start_year and end_year inclusive\n    years = np.random.randint(start_year, end_year + 1, size=100)\n    \n    # Generate random months between 1 and 12\n    months = np.random.randint(1, 13, size=100)\n    \n    # Generate random days between 1 and 28 (all months assumed 28 days)\n    days = np.random.randint(1, 29, size=100)\n    \n    # Combine to datetime.date\n    dob = [datetime.date(year, month, day) for year, month, day in zip(years, months, days)]\n    \n    df = pd.DataFrame({'ID': ids, 'Name': chosen_names, 'Date of Birth': dob})\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/760_4",
        "turn": "4",
        "instruct_prompt": "Construct the Email for each record by concatenating the lowercase version of the name (with spaces replaced by periods), the birth year, and the provided email domain, separated appropriately (e.g., name + birth year + '@' + email_domain).",
        "test": "import unittest\nimport pandas as pd\nimport datetime\n\nclass TestCases(unittest.TestCase):\n    def test_email_construction(self):\n        df = task_func(rng_seed=42)\n        # Check DataFrame has Email column\n        self.assertIn('Email', df.columns)\n        \n        # Check email format for first 10 rows\n        for i in range(10):\n            name = df.at[i, 'Name']\n            dob = df.at[i, 'Date of Birth']\n            email = df.at[i, 'Email']\n            # Expected email construction\n            expected_name = name.lower().replace(' ', '.')\n            expected_email = f\"{expected_name}{dob.year}@example.com\"\n            self.assertEqual(email, expected_email)\n\n    def test_email_lowercase_and_periods(self):\n        # Test with names containing spaces\n        test_df = pd.DataFrame({\n            'ID': [1, 2],\n            'Name': ['John Doe', 'Anna Marie'],\n            'Date of Birth': [datetime.date(1990, 1, 1), datetime.date(1985, 5, 15)]\n        })\n\n        # Manually construct emails using the same logic\n        def construct_email(name, birth_year, domain):\n            name_part = name.lower().replace(' ', '.')\n            return f\"{name_part}{birth_year}@{domain}\"\n\n        test_df['Email'] = [construct_email(n, d.year, 'example.com') for n, d in zip(test_df['Name'], test_df['Date of Birth'])]\n\n        expected_emails = ['john.doe1990@example.com', 'anna.marie1985@example.com']\n        for i, expected_email in enumerate(expected_emails):\n            self.assertEqual(test_df.at[i, 'Email'], expected_email)\n",
        "code": "import pandas as pd\nimport numpy as np\nimport datetime\nimport unicodedata\n\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopetn', 'Mndez', 'Gmez', 'Prez', 'Muoz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    \n    if rng_seed is not None:\n        np.random.seed(rng_seed)\n    \n    # Normalize latin_names to fix improperly encoded Latin characters\n    def normalize_name(name):\n        # Normalize to NFC form to fix decomposed or combining characters\n        normalized = unicodedata.normalize('NFC', name)\n        return normalized\n\n    corrected_latin_names = [normalize_name(name) for name in latin_names]\n    \n    ids = np.arange(1, 101)\n    \n    # Combine both name lists\n    combined_names = corrected_latin_names + other_names\n    \n    # Randomly choose 100 names from combined_names\n    chosen_names = np.random.choice(combined_names, size=100)\n    \n    # Generate random years between start_year and end_year inclusive\n    years = np.random.randint(start_year, end_year + 1, size=100)\n    \n    # Generate random months between 1 and 12\n    months = np.random.randint(1, 13, size=100)\n    \n    # Generate random days between 1 and 28 (all months assumed 28 days)\n    days = np.random.randint(1, 29, size=100)\n    \n    # Combine to datetime.date\n    dob = [datetime.date(year, month, day) for year, month, day in zip(years, months, days)]\n    \n    df = pd.DataFrame({'ID': ids, 'Name': chosen_names, 'Date of Birth': dob})\n\n    # Construct Email column according to requirement\n    def construct_email(name, birth_year, domain):\n        # lowercase name, replace spaces with periods\n        name_part = name.lower().replace(' ', '.')\n        return f\"{name_part}{birth_year}@{domain}\"\n\n    df['Email'] = [construct_email(name, dob.year, email_domain) for name, dob in zip(df['Name'], df['Date of Birth'])]\n\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 96,
    "task_id": "BigCodeBench/763",
    "mt_data": [
      {
        "task_id": "BigCodeBench/763_1",
        "turn": "1",
        "instruct_prompt": "Write a function that reads a list of dictionaries from a JSON file and collects all values for each key into lists. You should write self-contained code starting with:\n```python\nimport json\nfrom collections import defaultdict\n# Constants\ndef task_func(input_file, output_file):\n```",
        "test": "import unittest\nimport json\nimport os\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def test_collect_values(self):\n        input_data = [\n            {\"a\": 1, \"b\": 2},\n            {\"a\": 3, \"b\": 4},\n            {\"a\": 5, \"c\": 6}\n        ]\n\n        expected_output = {\n            \"a\": [1, 3, 5],\n            \"b\": [2, 4],\n            \"c\": [6]\n        }\n\n        with NamedTemporaryFile('w+', delete=False) as input_file, \\\n             NamedTemporaryFile('r+', delete=False) as output_file:\n\n            json.dump(input_data, input_file)\n            input_file.flush()\n\n            task_func(input_file.name, output_file.name)\n\n            output_file.seek(0)\n            result = json.load(output_file)\n\n            self.assertEqual(result, expected_output)\n\n        os.remove(input_file.name)\n        os.remove(output_file.name)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import json\nfrom collections import defaultdict\n\ndef task_func(input_file, output_file):\n    with open(input_file, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n\n    result = defaultdict(list)\n    for entry in data:\n        for key, value in entry.items():\n            result[key].append(value)\n\n    with open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/763_2",
        "turn": "2",
        "instruct_prompt": "Calculate the mean and median of the collected values for each key using numpy, and store the results in a dictionary where each key maps to another dictionary with keys 'mean' and 'median'.",
        "test": "import unittest\nimport json\nimport os\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def test_mean_median_calculation(self):\n        input_data = [\n            {\"a\": 1, \"b\": 3},\n            {\"a\": 2, \"b\": 4},\n            {\"a\": 3, \"b\": 5}\n        ]\n\n        with NamedTemporaryFile(mode='w+', delete=False, suffix='.json') as input_file, \\\n             NamedTemporaryFile(mode='r', delete=False, suffix='.json') as output_file:\n            json.dump(input_data, input_file)\n            input_file.flush()\n\n            # Directly call task_func (no import)\n            task_func(input_file.name, output_file.name)\n\n            output_file.seek(0)\n            result = json.load(output_file)\n\n        os.unlink(input_file.name)\n        os.unlink(output_file.name)\n\n        # Check keys\n        self.assertIn('a', result)\n        self.assertIn('b', result)\n\n        # Check mean and median for 'a'\n        self.assertAlmostEqual(result['a']['mean'], 2.0)\n        self.assertAlmostEqual(result['a']['median'], 2.0)\n\n        # Check mean and median for 'b'\n        self.assertAlmostEqual(result['b']['mean'], 4.0)\n        self.assertAlmostEqual(result['b']['median'], 4.0)\n",
        "code": "import json\nfrom collections import defaultdict\nimport numpy as np\n\ndef task_func(input_file, output_file):\n    with open(input_file, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n\n    collected_values = defaultdict(list)\n    for entry in data:\n        for key, value in entry.items():\n            collected_values[key].append(value)\n\n    result = {}\n    for key, values in collected_values.items():\n        arr = np.array(values)\n        result[key] = {\n            'mean': np.mean(arr).item(),\n            'median': np.median(arr).item()\n        }\n\n    with open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/763_3",
        "turn": "3",
        "instruct_prompt": "Write the calculated mean and median for each key to a CSV file with columns 'key', 'mean', and 'median'. Then return the dictionary containing the statistics.",
        "test": "import unittest\nimport json\nimport csv\nimport os\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_data = [\n            {\"a\": 1, \"b\": 2},\n            {\"a\": 3, \"b\": 4},\n            {\"a\": 5, \"b\": 6}\n        ]\n\n    def test_task_func_creates_csv_and_returns_correct_stats(self):\n        with NamedTemporaryFile('w+', encoding='utf-8', delete=False) as input_tmp:\n            json.dump(self.test_data, input_tmp)\n            input_tmp.flush()\n            input_name = input_tmp.name\n\n        with NamedTemporaryFile('r', encoding='utf-8', delete=False) as output_tmp:\n            output_name = output_tmp.name\n\n        # Directly call task_func without import\n        result = task_func(input_name, output_name)\n\n        # Check returned dictionary\n        expected = {\n            'a': {'mean': 3.0, 'median': 3.0},\n            'b': {'mean': 4.0, 'median': 4.0}\n        }\n        self.assertEqual(result, expected)\n\n        # Check CSV content\n        with open(output_name, 'r', encoding='utf-8') as f:\n            reader = csv.DictReader(f)\n            rows = list(reader)\n\n        self.assertEqual(len(rows), 2)\n        # Validate keys and values in CSV\n        for row in rows:\n            key = row['key']\n            self.assertIn(key, expected)\n            self.assertAlmostEqual(float(row['mean']), expected[key]['mean'])\n            self.assertAlmostEqual(float(row['median']), expected[key]['median'])\n\n        # Cleanup temp files\n        os.remove(input_name)\n        os.remove(output_name)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import json\nfrom collections import defaultdict\nimport numpy as np\nimport csv\n\ndef task_func(input_file, output_file):\n    with open(input_file, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n\n    collected_values = defaultdict(list)\n    for entry in data:\n        for key, value in entry.items():\n            collected_values[key].append(value)\n\n    result = {}\n    for key, values in collected_values.items():\n        arr = np.array(values)\n        mean_val = np.mean(arr).item()\n        median_val = np.median(arr).item()\n        result[key] = {\n            'mean': mean_val,\n            'median': median_val\n        }\n\n    with open(output_file, 'w', newline='', encoding='utf-8') as f:\n        writer = csv.DictWriter(f, fieldnames=['key', 'mean', 'median'])\n        writer.writeheader()\n        for key, stats in result.items():\n            writer.writerow({'key': key, 'mean': stats['mean'], 'median': stats['median']})\n\n    return result\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 97,
    "task_id": "BigCodeBench/765",
    "mt_data": [
      {
        "task_id": "BigCodeBench/765_1",
        "turn": "1",
        "instruct_prompt": "Write a function that accepts a dictionary and a target directory path, and returns a list of file paths from the dictionary keys. You should write self-contained code starting with:\n```\nimport os\nfrom pathlib import Path\nimport shutil\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        input_dict = {\"file1.txt\": 123, \"file2.txt\": None, \"file3.txt\": \"data\"}\n        target_dir = \"my_files\"\n        expected = [\"my_files/file1.txt\", \"my_files/file2.txt\", \"my_files/file3.txt\"]\n        result = task_func(input_dict, target_dir)\n        self.assertEqual(result, expected)\n\n    def test_empty_dict(self):\n        self.assertEqual(task_func({}, \"some_dir\"), [])\n\n    def test_default_target_dir(self):\n        input_dict = {\"a.txt\": 1}\n        expected = [\"non_none_files/a.txt\"]\n        self.assertEqual(task_func(input_dict), expected)\n",
        "code": "import os\nfrom pathlib import Path\nimport shutil\n\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    file_paths = []\n    for key in kwargs.keys():\n        file_path = os.path.join(target_dir, key)\n        file_paths.append(file_path)\n    return file_paths\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/765_2",
        "turn": "2",
        "instruct_prompt": "Only include files that actually exist on the filesystem.",
        "test": "import unittest\nimport os\nfrom pathlib import Path\nimport tempfile\n\nclass TestCases(unittest.TestCase):\n    def test_only_existing_files_included(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            # Create some files\n            existing_files = [\"file1.txt\", \"file2.txt\"]\n            for fname in existing_files:\n                Path(tmpdir, fname).write_text(\"content\")\n            # Prepare kwargs with both existing and non-existing files\n            kwargs = {\"file1.txt\": None, \"file2.txt\": None, \"file3.txt\": None}\n            # Call the function\n            result = task_func(kwargs, target_dir=tmpdir)\n            # Only existing files should be included\n            expected = [os.path.join(tmpdir, f) for f in existing_files]\n            self.assertCountEqual(result, expected)\n\n    def test_no_files_exist(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            kwargs = {\"file1.txt\": None, \"file2.txt\": None}\n            result = task_func(kwargs, target_dir=tmpdir)\n            self.assertEqual(result, [])\n\n    def test_all_files_exist(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            files = [\"a\", \"b\", \"c\"]\n            for f in files:\n                Path(tmpdir, f).write_text(\"\")\n            kwargs = {f: None for f in files}\n            result = task_func(kwargs, target_dir=tmpdir)\n            expected = [os.path.join(tmpdir, f) for f in files]\n            self.assertCountEqual(result, expected)\n",
        "code": "import os\nfrom pathlib import Path\n\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    file_paths = []\n    for key in kwargs.keys():\n        file_path = os.path.join(target_dir, key)\n        if os.path.exists(file_path):\n            file_paths.append(file_path)\n    return file_paths\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/765_3",
        "turn": "3",
        "instruct_prompt": "Only include files whose corresponding dictionary values are not None.",
        "test": "import unittest\nimport os\nimport tempfile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = tempfile.TemporaryDirectory()\n        self.target_dir = self.test_dir.name\n\n        # Create some files\n        self.files = ['file1.txt', 'file2.txt', 'file3.txt']\n        for f in self.files:\n            with open(os.path.join(self.target_dir, f), 'w') as file:\n                file.write('test')\n\n    def tearDown(self):\n        # Cleanup temporary directory\n        self.test_dir.cleanup()\n\n    def test_only_non_none_files_included(self):\n        kwargs = {\n            'file1.txt': 'some value',\n            'file2.txt': None,\n            'file3.txt': 123,\n            'file4.txt': 'exists but no file'\n        }\n\n        expected_files = [\n            os.path.join(self.target_dir, 'file1.txt'),\n            os.path.join(self.target_dir, 'file3.txt')\n        ]\n\n        result = task_func(kwargs, target_dir=self.target_dir)\n\n        self.assertCountEqual(result, expected_files)\n\n    def test_all_values_none(self):\n        kwargs = {\n            'file1.txt': None,\n            'file2.txt': None\n        }\n        result = task_func(kwargs, target_dir=self.target_dir)\n        self.assertEqual(result, [])\n\n    def test_no_files_exist(self):\n        kwargs = {\n            'nofile1.txt': 'value',\n            'nofile2.txt': 1\n        }\n        result = task_func(kwargs, target_dir=self.target_dir)\n        self.assertEqual(result, [])\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import os\n\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    file_paths = []\n    for key, value in kwargs.items():\n        if value is not None:\n            file_path = os.path.join(target_dir, key)\n            if os.path.exists(file_path):\n                file_paths.append(file_path)\n    return file_paths\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/765_4",
        "turn": "4",
        "instruct_prompt": "Copy the qualifying files into the target directory, creating it if it does not exist, and return the list of full copied file paths.",
        "test": "import unittest\nimport os\nimport tempfile\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory for source files\n        self.src_dir = tempfile.mkdtemp()\n        # Create some files\n        self.file1 = os.path.join(self.src_dir, \"file1.txt\")\n        self.file2 = os.path.join(self.src_dir, \"file2.txt\")\n        with open(self.file1, \"w\") as f:\n            f.write(\"content1\")\n        with open(self.file2, \"w\") as f:\n            f.write(\"content2\")\n        # Create a temporary directory for target\n        self.target_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.src_dir)\n        shutil.rmtree(self.target_dir)\n\n    def test_copy_files_creates_target_and_returns_paths(self):\n        kwargs = {\n            \"f1\": self.file1,\n            \"f2\": self.file2,\n            \"f3\": None\n        }\n        # Remove target_dir to test creation\n        shutil.rmtree(self.target_dir)\n\n        copied = task_func(kwargs, target_dir=self.target_dir)\n\n        # Check target_dir is created\n        self.assertTrue(os.path.exists(self.target_dir))\n\n        # Check copied files list\n        expected_files = [os.path.join(self.target_dir, os.path.basename(self.file1)),\n                          os.path.join(self.target_dir, os.path.basename(self.file2))]\n        self.assertCountEqual(copied, expected_files)\n\n        # Check files actually copied\n        for f in expected_files:\n            self.assertTrue(os.path.isfile(f))\n\n    def test_nonexistent_file_not_copied(self):\n        kwargs = {\n            \"f1\": self.file1,\n            \"f2\": \"nonexistent_file.txt\"\n        }\n        copied = task_func(kwargs, target_dir=self.target_dir)\n        expected_files = [os.path.join(self.target_dir, os.path.basename(self.file1))]\n        self.assertCountEqual(copied, expected_files)\n        self.assertTrue(os.path.isfile(expected_files[0]))\n\n    def test_none_values_not_copied(self):\n        kwargs = {\n            \"f1\": None,\n            \"f2\": None\n        }\n        copied = task_func(kwargs, target_dir=self.target_dir)\n        self.assertEqual(copied, [])\n\n    def test_empty_kwargs(self):\n        copied = task_func({}, target_dir=self.target_dir)\n        self.assertEqual(copied, [])\n\nif __name__ == \"__main__\":\n    unittest.main()\n",
        "code": "import os\nimport shutil\n\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n    copied_files = []\n    for key, value in kwargs.items():\n        if value is not None and os.path.isfile(value):\n            dest_path = os.path.join(target_dir, os.path.basename(value))\n            shutil.copy2(value, dest_path)\n            copied_files.append(dest_path)\n    return copied_files\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 98,
    "task_id": "BigCodeBench/771",
    "mt_data": [
      {
        "task_id": "BigCodeBench/771_1",
        "turn": "1",
        "instruct_prompt": "Write a function that lists all files in a given directory whose names match a specified regex pattern and returns a list of these filenames. You should write self-contained code starting with:\n```python\nimport re\nimport os\nfrom pathlib import Path\n\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n```",
        "test": "import unittest\nimport tempfile\nimport os\nfrom pathlib import Path\n\nclass TestCases(unittest.TestCase):\n    def test_basic_matching(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            filenames = [\"data-1.csv\", \"data-2.csv\", \"info-3.csv\", \"notmatch.txt\", \"data-abc.csv\"]\n            for fn in filenames:\n                Path(tmpdir, fn).write_text(\"test\")\n\n            expected = [\"data-1.csv\", \"data-2.csv\", \"info-3.csv\"]\n            result = task_func(tmpdir)\n            self.assertCountEqual(result, expected)\n\n    def test_no_matches(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            filenames = [\"file.txt\", \"another.doc\", \"image.png\"]\n            for fn in filenames:\n                Path(tmpdir, fn).write_text(\"test\")\n\n            result = task_func(tmpdir)\n            self.assertEqual(result, [])\n\n    def test_custom_pattern(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            filenames = [\"test_123.log\", \"test_456.log\", \"test_abc.log\", \"random.log\"]\n            for fn in filenames:\n                Path(tmpdir, fn).write_text(\"test\")\n\n            pattern = r'^test_\\d+\\.log$'\n            expected = [\"test_123.log\", \"test_456.log\"]\n            result = task_func(tmpdir, pattern)\n            self.assertCountEqual(result, expected)\n\n    def test_directory_ignored(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            # Create a file and a directory with matching names\n            file_name = \"data-1.csv\"\n            dir_name = \"info-2.csv\"\n            Path(tmpdir, file_name).write_text(\"test\")\n            os.mkdir(Path(tmpdir, dir_name))\n\n            expected = [file_name]  # Only the file should be returned\n            result = task_func(tmpdir)\n            self.assertCountEqual(result, expected)\n",
        "code": "import re\nimport os\nfrom pathlib import Path\n\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n    regex = re.compile(pattern)\n    matched_files = []\n    for entry in os.listdir(directory):\n        if regex.match(entry) and Path(directory, entry).is_file():\n            matched_files.append(entry)\n    return matched_files\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/771_2",
        "turn": "2",
        "instruct_prompt": "For each file matching the pattern, read its content as CSV and create a new CSV file in the same directory with a new name derived from the pattern's first captured group plus the '.csv' extension.",
        "test": "import unittest\nimport tempfile\nimport os\nimport csv\nfrom pathlib import Path\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        # Cleanup the temporary directory\n        self.test_dir.cleanup()\n\n    def test_task_func_creates_new_csv_files(self):\n        # Prepare files\n        filenames = [\"test-123.csv\", \"example-456.csv\", \"ignore.txt\"]\n        contents = [\n            [[\"a\", \"b\"], [\"1\", \"2\"]],\n            [[\"x\", \"y\"], [\"9\", \"8\"]],\n            None\n        ]\n\n        for fname, content in zip(filenames, contents):\n            path = Path(self.test_dir.name) / fname\n            if content is not None:\n                with open(path, 'w', newline='', encoding='utf-8') as f:\n                    writer = csv.writer(f)\n                    writer.writerows(content)\n            else:\n                with open(path, 'w', encoding='utf-8') as f:\n                    f.write(\"This is a text file and should be ignored.\")\n\n        # Run the function directly since it's in the same file\n        result = task_func(self.test_dir.name)\n\n        # Expected new files\n        expected_files = [\"test.csv\", \"example.csv\"]\n\n        self.assertCountEqual(result, expected_files)\n\n        # Check if new files exist and contents match original\n        for original, newfile in zip(filenames[:-1], expected_files):\n            orig_path = Path(self.test_dir.name) / original\n            new_path = Path(self.test_dir.name) / newfile\n            self.assertTrue(new_path.exists())\n\n            # Read original\n            with open(orig_path, newline='', encoding='utf-8') as f:\n                original_rows = list(csv.reader(f))\n            # Read new\n            with open(new_path, newline='', encoding='utf-8') as f:\n                new_rows = list(csv.reader(f))\n            self.assertEqual(original_rows, new_rows)\n\n    def test_task_func_no_matching_files(self):\n        # Create a file that does not match pattern\n        path = Path(self.test_dir.name) / \"no-match-file.txt\"\n        with open(path, 'w', encoding='utf-8') as f:\n            f.write(\"No CSV here\")\n\n        result = task_func(self.test_dir.name)\n        self.assertEqual(result, [])\n",
        "code": "import re\nimport os\nimport csv\nfrom pathlib import Path\n\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n    regex = re.compile(pattern)\n    processed_files = []\n    for entry in os.listdir(directory):\n        full_path = Path(directory) / entry\n        match = regex.match(entry)\n        if match and full_path.is_file():\n            # Read the CSV content\n            with open(full_path, newline='', encoding='utf-8') as f:\n                reader = csv.reader(f)\n                rows = list(reader)\n            # New file name based on first captured group plus '.csv'\n            new_name = f\"{match.group(1)}.csv\"\n            new_path = Path(directory) / new_name\n            # Write the content to the new CSV file\n            with open(new_path, 'w', newline='', encoding='utf-8') as f:\n                writer = csv.writer(f)\n                writer.writerows(rows)\n            processed_files.append(new_name)\n    return processed_files\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/771_3",
        "turn": "3",
        "instruct_prompt": "Ensure that the function returns a list of the new filenames created.",
        "test": "import unittest\nimport tempfile\nimport os\nimport csv\nfrom pathlib import Path\nimport re\n\nclass TestCases(unittest.TestCase):\n    def test_returned_filenames(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            # Create files that match pattern\n            filenames = ['data-1.csv', 'data-2.csv', 'info-3.csv']\n            contents = [[['a', 'b'], ['1', '2']], [['c', 'd']], [['x', 'y', 'z']]]\n            for fname, rows in zip(filenames, contents):\n                with open(Path(tmpdir) / fname, 'w', newline='', encoding='utf-8') as f:\n                    writer = csv.writer(f)\n                    writer.writerows(rows)\n            # Create a non-matching file\n            with open(Path(tmpdir) / 'otherfile.csv', 'w', newline='', encoding='utf-8') as f:\n                writer = csv.writer(f)\n                writer.writerow(['not', 'matching'])\n\n            # Call the function\n            result = task_func(tmpdir)\n\n            # Expected new filenames (unique)\n            expected = ['data.csv', 'info.csv']\n\n            # Check returned list contains exactly the expected unique filenames\n            self.assertCountEqual(result, expected)\n\n            # Check that new files exist with correct content\n            for new_file in expected:\n                new_path = Path(tmpdir) / new_file\n                self.assertTrue(new_path.exists())\n",
        "code": "import re\nimport os\nimport csv\nfrom pathlib import Path\n\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n    regex = re.compile(pattern)\n    processed_files = []\n    for entry in os.listdir(directory):\n        full_path = Path(directory) / entry\n        match = regex.match(entry)\n        if match and full_path.is_file():\n            # Read the CSV content\n            with open(full_path, newline='', encoding='utf-8') as f:\n                reader = csv.reader(f)\n                rows = list(reader)\n            # New file name based on first captured group plus '.csv'\n            new_name = f\"{match.group(1)}.csv\"\n            new_path = Path(directory) / new_name\n            # Write the content to the new CSV file\n            with open(new_path, 'w', newline='', encoding='utf-8') as f:\n                writer = csv.writer(f)\n                writer.writerows(rows)\n            processed_files.append(new_name)\n    # Return unique new filenames created\n    return list(set(processed_files))\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 99,
    "task_id": "BigCodeBench/777",
    "mt_data": [
      {
        "task_id": "BigCodeBench/777_1",
        "turn": "1",
        "instruct_prompt": "Write a function that lists all zip files in a given directory whose filename matches a specified regex pattern. You should write self-contained code starting with:\n```python\nimport re\nimport os\nimport zipfile\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n```",
        "test": "import unittest\nimport tempfile\nimport os\nimport zipfile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = tempfile.TemporaryDirectory()\n\n        # Create some zip files and other files\n        self.files = [\n            'data-001.zip',\n            'data-002.zip',\n            'report-123.zip',\n            'summary.zip',\n            'invalid-abc.zip',\n            'image-01.png',\n            'data-003.zip'\n        ]\n\n        for f in self.files:\n            path = os.path.join(self.test_dir.name, f)\n            if f.endswith('.zip'):\n                # Create an empty zip file\n                with zipfile.ZipFile(path, 'w') as zf:\n                    pass\n            else:\n                # Create an empty normal file\n                with open(path, 'w') as fp:\n                    fp.write('')\n\n    def tearDown(self):\n        # Cleanup temporary directory\n        self.test_dir.cleanup()\n\n    def test_matching_zip_files_default_pattern(self):\n        # Default pattern matches filenames like <name>-<digits>.zip\n        expected = ['data-001.zip', 'data-002.zip', 'report-123.zip', 'data-003.zip']\n        result = task_func(self.test_dir.name)\n        self.assertCountEqual(result, expected)\n\n    def test_matching_zip_files_custom_pattern(self):\n        # Custom pattern to match files starting with 'report'\n        pattern = r'^report-\\d+\\.zip$'\n        expected = ['report-123.zip']\n        result = task_func(self.test_dir.name, pattern=pattern)\n        self.assertCountEqual(result, expected)\n\n    def test_no_matching_files(self):\n        pattern = r'^no-match-\\d+\\.zip$'\n        result = task_func(self.test_dir.name, pattern=pattern)\n        self.assertEqual(result, [])\n\n    def test_directory_not_exist(self):\n        result = task_func('/non/existent/directory')\n        self.assertEqual(result, [])\n",
        "code": "import re\nimport os\nimport zipfile\n\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    matched_files = []\n    regex = re.compile(pattern)\n    try:\n        for filename in os.listdir(directory):\n            if regex.match(filename) and filename.endswith('.zip'):\n                full_path = os.path.join(directory, filename)\n                if os.path.isfile(full_path):\n                    matched_files.append(filename)\n    except FileNotFoundError:\n        # Directory does not exist, return empty list\n        pass\n    return matched_files\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/777_2",
        "turn": "2",
        "instruct_prompt": "For each matching zip file, determine the directory name to extract into by splitting the filename at the last '-' and using the prefix part (before the last '-') as the directory name.",
        "test": "import unittest\nimport tempfile\nimport os\nimport zipfile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        # Cleanup the temporary directory\n        self.test_dir.cleanup()\n\n    def create_zip_file(self, dir_path, filename):\n        # Create an empty zip file\n        path = os.path.join(dir_path, filename)\n        with zipfile.ZipFile(path, 'w') as zf:\n            # add a dummy file inside\n            zf.writestr('dummy.txt', 'content')\n        return path\n\n    def test_task_func_and_get_extract_dir(self):\n        # No import needed, functions are in the same file\n\n        # Create files\n        valid_files = [\n            'example-123.zip',\n            'testfile-999.zip',\n            'data-1.zip'\n        ]\n        invalid_files = [\n            'example123.zip',\n            'testfile.zip',\n            'data-abc.zip',\n            'anotherfile-123.txt'\n        ]\n\n        for f in valid_files + invalid_files:\n            if f.endswith('.zip'):\n                self.create_zip_file(self.test_dir.name, f)\n            else:\n                # create dummy non-zip file\n                with open(os.path.join(self.test_dir.name, f), 'w') as fp:\n                    fp.write('not a zip')\n\n        matched = task_func(self.test_dir.name)\n\n        # matched must contain only valid_files\n        self.assertCountEqual(matched, valid_files)\n\n        # Test get_extract_dir\n        for filename in matched:\n            dir_name = get_extract_dir(filename)\n            # The directory name is prefix before last '-'\n            expected = filename.rsplit('-', 1)[0]\n            self.assertEqual(dir_name, expected)\n\n        # Check that get_extract_dir returns None if no '-'\n        self.assertIsNone(get_extract_dir('nohyphen.zip'))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import re\nimport os\nimport zipfile\n\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    matched_files = []\n    regex = re.compile(pattern)\n    try:\n        for filename in os.listdir(directory):\n            if regex.match(filename) and filename.endswith('.zip'):\n                full_path = os.path.join(directory, filename)\n                if os.path.isfile(full_path):\n                    matched_files.append(filename)\n    except FileNotFoundError:\n        # Directory does not exist, return empty list\n        pass\n    return matched_files\n\ndef get_extract_dir(filename):\n    # Split at the last '-' and take the prefix part\n    if '-' not in filename:\n        return None\n    prefix = filename.rsplit('-', 1)[0]\n    return prefix\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/777_3",
        "turn": "3",
        "instruct_prompt": "Extract each matching zip file into its corresponding directory (inside the given directory), creating the extraction directory if it does not exist.",
        "test": "import unittest\nimport tempfile\nimport os\nimport zipfile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        # Cleanup temporary directory\n        self.test_dir.cleanup()\n\n    def create_zip_file(self, dir_path, zip_name, files_content):\n        zip_path = os.path.join(dir_path, zip_name)\n        with zipfile.ZipFile(zip_path, 'w') as zf:\n            for filename, content in files_content.items():\n                zf.writestr(filename, content)\n        return zip_path\n\n    def test_extract_zips_to_dirs_creates_dirs_and_extracts(self):\n        # Create zip files matching pattern\n        zip1_name = 'project-1.zip'\n        zip2_name = 'sample-2.zip'\n        non_match_zip = 'other.zip'\n\n        # Create zip files content\n        files1 = {'file1.txt': 'hello1', 'file2.txt': 'world1'}\n        files2 = {'a.txt': 'hello2'}\n\n        self.create_zip_file(self.test_dir.name, zip1_name, files1)\n        self.create_zip_file(self.test_dir.name, zip2_name, files2)\n        self.create_zip_file(self.test_dir.name, non_match_zip, {'ignore.txt': 'ignore'})\n\n        # Call extraction function\n        extract_zips_to_dirs(self.test_dir.name)\n\n        # Check directories created\n        dir1 = os.path.join(self.test_dir.name, 'project')\n        dir2 = os.path.join(self.test_dir.name, 'sample')\n        dir_non = os.path.join(self.test_dir.name, 'other')\n\n        self.assertTrue(os.path.isdir(dir1))\n        self.assertTrue(os.path.isdir(dir2))\n        self.assertFalse(os.path.isdir(dir_non))  # non_match_zip should not create dir\n\n        # Check files extracted in dir1\n        extracted_files1 = os.listdir(dir1)\n        self.assertIn('file1.txt', extracted_files1)\n        self.assertIn('file2.txt', extracted_files1)\n\n        # Check files extracted in dir2\n        extracted_files2 = os.listdir(dir2)\n        self.assertIn('a.txt', extracted_files2)\n\n    def test_no_matching_zip_files(self):\n        # Create a zip file that does not match pattern\n        zip_name = 'nomatch.zip'\n        self.create_zip_file(self.test_dir.name, zip_name, {'file.txt': 'content'})\n\n        extract_zips_to_dirs(self.test_dir.name)\n\n        # No new directories should be created except the zip file itself\n        contents = os.listdir(self.test_dir.name)\n        # Only the zip file should be present, no extraction dirs\n        self.assertEqual(contents, [zip_name])\n\n    def test_extract_dir_creation_if_not_exists(self):\n        zip_name = 'test-123.zip'\n        files = {'testfile.txt': 'data'}\n        self.create_zip_file(self.test_dir.name, zip_name, files)\n\n        extract_dir = os.path.join(self.test_dir.name, 'test')\n        # Ensure directory does not exist before extraction\n        self.assertFalse(os.path.exists(extract_dir))\n\n        extract_zips_to_dirs(self.test_dir.name)\n\n        # Directory should be created\n        self.assertTrue(os.path.isdir(extract_dir))\n\n        # File should be extracted\n        extracted_files = os.listdir(extract_dir)\n        self.assertIn('testfile.txt', extracted_files)\n",
        "code": "import re\nimport os\nimport zipfile\n\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    matched_files = []\n    regex = re.compile(pattern)\n    try:\n        for filename in os.listdir(directory):\n            if regex.match(filename) and filename.endswith('.zip'):\n                full_path = os.path.join(directory, filename)\n                if os.path.isfile(full_path):\n                    matched_files.append(filename)\n    except FileNotFoundError:\n        # Directory does not exist, return empty list\n        pass\n    return matched_files\n\ndef get_extract_dir(filename):\n    # Split at the last '-' and take the prefix part\n    if '-' not in filename:\n        return None\n    prefix = filename.rsplit('-', 1)[0]\n    return prefix\n\ndef extract_zips_to_dirs(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    matched_files = task_func(directory, pattern)\n    for filename in matched_files:\n        extract_dir_name = get_extract_dir(filename)\n        if extract_dir_name is None:\n            continue\n        extract_dir_path = os.path.join(directory, extract_dir_name)\n        if not os.path.exists(extract_dir_path):\n            os.makedirs(extract_dir_path)\n        zip_path = os.path.join(directory, filename)\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall(extract_dir_path)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/777_4",
        "turn": "4",
        "instruct_prompt": "Return a list of all directories where files were extracted, without duplicates.",
        "test": "import unittest\nimport tempfile\nimport os\nimport zipfile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        for root, dirs, files in os.walk(self.test_dir, topdown=False):\n            for name in files:\n                os.remove(os.path.join(root, name))\n            for name in dirs:\n                os.rmdir(os.path.join(root, name))\n        os.rmdir(self.test_dir)\n\n    def create_zip(self, zip_path, file_contents=None):\n        with zipfile.ZipFile(zip_path, 'w') as zf:\n            if file_contents:\n                for filename, content in file_contents.items():\n                    zf.writestr(filename, content)\n            else:\n                zf.writestr('dummy.txt', 'dummy')\n\n    def test_extract_returns_all_unique_dirs(self):\n        filenames = ['project-1.zip', 'project-2.zip', 'data-1.zip', 'other-99.zip']\n        for fn in filenames:\n            self.create_zip(os.path.join(self.test_dir, fn))\n\n        self.create_zip(os.path.join(self.test_dir, 'nomatch.zip'))\n\n        extracted_dirs = task_func(self.test_dir)\n\n        expected_dirs = [os.path.join(self.test_dir, 'project'),\n                         os.path.join(self.test_dir, 'data'),\n                         os.path.join(self.test_dir, 'other')]\n\n        self.assertCountEqual(extracted_dirs, expected_dirs)\n\n        for d in expected_dirs:\n            self.assertTrue(os.path.isdir(d))\n\n    def test_extract_skips_files_without_dash(self):\n        fn = 'nodash.zip'\n        self.create_zip(os.path.join(self.test_dir, fn))\n\n        extracted_dirs = task_func(self.test_dir)\n        self.assertEqual(extracted_dirs, [])\n\n    def test_extract_handles_no_zip_files(self):\n        extracted_dirs = task_func(self.test_dir)\n        self.assertEqual(extracted_dirs, [])\n\n    def test_extract_handles_duplicate_directories(self):\n        fnames = ['dup-1.zip', 'dup-2.zip', 'dup-3.zip']\n        for fn in fnames:\n            self.create_zip(os.path.join(self.test_dir, fn))\n\n        extracted_dirs = task_func(self.test_dir)\n\n        expected_dirs = [os.path.join(self.test_dir, 'dup')]\n\n        self.assertEqual(extracted_dirs, expected_dirs)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import re\nimport os\nimport zipfile\n\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    regex = re.compile(pattern)\n    matched_files = []\n    try:\n        for filename in os.listdir(directory):\n            if regex.match(filename) and filename.endswith('.zip'):\n                full_path = os.path.join(directory, filename)\n                if os.path.isfile(full_path):\n                    matched_files.append(filename)\n    except FileNotFoundError:\n        return []\n\n    extracted_dirs = []\n    for filename in matched_files:\n        if '-' not in filename:\n            continue\n        extract_dir_name = filename.rsplit('-', 1)[0]\n        extract_dir_path = os.path.join(directory, extract_dir_name)\n        if not os.path.exists(extract_dir_path):\n            os.makedirs(extract_dir_path)\n        zip_path = os.path.join(directory, filename)\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall(extract_dir_path)\n        if extract_dir_path not in extracted_dirs:\n            extracted_dirs.append(extract_dir_path)\n\n    return extracted_dirs\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 100,
    "task_id": "BigCodeBench/785",
    "mt_data": [
      {
        "task_id": "BigCodeBench/785_1",
        "turn": "1",
        "instruct_prompt": "Write a function that finds all files matching a given pattern. You should write self-contained code starting with:\n```\nimport os\nimport glob\n# Constants\nARCHIVE_DIR = '/tmp/archive'\ndef task_func(pattern):\n```",
        "test": "import unittest\nimport os\nimport tempfile\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory to simulate ARCHIVE_DIR\n        self.test_dir = tempfile.mkdtemp()\n        global ARCHIVE_DIR\n        ARCHIVE_DIR = self.test_dir\n        # Create some test files\n        self.files = [\n            'file1.txt',\n            'file2.log',\n            'data1.txt',\n            'image.png',\n            'file3.txt'\n        ]\n        for f in self.files:\n            with open(os.path.join(self.test_dir, f), 'w') as fp:\n                fp.write('test')\n\n    def tearDown(self):\n        shutil.rmtree(self.test_dir)\n\n    def test_match_txt_files(self):\n        result = task_func('*.txt')\n        expected = {os.path.join(self.test_dir, f) for f in self.files if f.endswith('.txt')}\n        self.assertEqual(set(result), expected)\n\n    def test_match_log_files(self):\n        result = task_func('*.log')\n        expected = {os.path.join(self.test_dir, f) for f in self.files if f.endswith('.log')}\n        self.assertEqual(set(result), expected)\n\n    def test_match_no_files(self):\n        result = task_func('*.csv')\n        self.assertEqual(result, [])\n\n    def test_match_all_files(self):\n        result = task_func('*')\n        expected = {os.path.join(self.test_dir, f) for f in self.files}\n        self.assertEqual(set(result), expected)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import os\nimport glob\n\n# Constants\nARCHIVE_DIR = '/tmp/archive'\n\ndef task_func(pattern):\n    \"\"\"Find all files in ARCHIVE_DIR matching the given pattern.\"\"\"\n    search_path = os.path.join(ARCHIVE_DIR, pattern)\n    return glob.glob(search_path)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/785_2",
        "turn": "2",
        "instruct_prompt": "The function should create the archive directory if it does not already exist.",
        "test": "import unittest\nimport os\nimport shutil\nfrom tempfile import mkdtemp\n\n# Import the solution code (assuming it is in the same module for this example)\n# from solution_module import task_func, ARCHIVE_DIR\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Setup a temporary directory to simulate ARCHIVE_DIR\n        self.test_dir = mkdtemp()\n        global ARCHIVE_DIR\n        ARCHIVE_DIR = self.test_dir\n\n    def tearDown(self):\n        # Remove the temporary directory after tests\n        shutil.rmtree(self.test_dir, ignore_errors=True)\n\n    def test_create_archive_dir_if_not_exists(self):\n        # Remove the directory first to ensure it does not exist\n        shutil.rmtree(self.test_dir)\n        self.assertFalse(os.path.exists(self.test_dir))\n        # Call task_func, which should create the directory\n        result = task_func('*.txt')\n        self.assertTrue(os.path.exists(self.test_dir))\n        self.assertEqual(result, [])  # No files yet\n\n    def test_find_files_matching_pattern(self):\n        # Create some files\n        filenames = ['file1.txt', 'file2.log', 'file3.txt']\n        for fname in filenames:\n            with open(os.path.join(self.test_dir, fname), 'w') as f:\n                f.write('test')\n\n        # Should find only .txt files\n        result = task_func('*.txt')\n        expected = [os.path.join(self.test_dir, f) for f in ['file1.txt', 'file3.txt']]\n        self.assertCountEqual(result, expected)\n",
        "code": "import os\nimport glob\n\n# Constants\nARCHIVE_DIR = '/tmp/archive'\n\ndef task_func(pattern):\n    \"\"\"Find all files in ARCHIVE_DIR matching the given pattern. Create ARCHIVE_DIR if it does not exist.\"\"\"\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n    search_path = os.path.join(ARCHIVE_DIR, pattern)\n    return glob.glob(search_path)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/785_3",
        "turn": "3",
        "instruct_prompt": "The function should create a unique archive file path inside ARCHIVE_DIR for storing the archive, ensuring it does not overwrite existing archives.",
        "test": "import unittest\nimport os\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Ensure ARCHIVE_DIR is clean before each test\n        if os.path.exists(ARCHIVE_DIR):\n            shutil.rmtree(ARCHIVE_DIR)\n        os.makedirs(ARCHIVE_DIR)\n\n    def tearDown(self):\n        # Clean up after tests\n        if os.path.exists(ARCHIVE_DIR):\n            shutil.rmtree(ARCHIVE_DIR)\n\n    def test_create_unique_archive_path_creates_dir(self):\n        # Remove archive dir to test creation\n        shutil.rmtree(ARCHIVE_DIR)\n        path = create_unique_archive_path('archive.zip')\n        self.assertTrue(os.path.exists(ARCHIVE_DIR))\n        self.assertTrue(path.startswith(ARCHIVE_DIR))\n\n    def test_create_unique_archive_path_no_existing(self):\n        path = create_unique_archive_path('archive.zip')\n        expected = os.path.join(ARCHIVE_DIR, 'archive.zip')\n        self.assertEqual(path, expected)\n\n    def test_create_unique_archive_path_with_existing(self):\n        # Create a file named archive.zip\n        existing_path = os.path.join(ARCHIVE_DIR, 'archive.zip')\n        with open(existing_path, 'w') as f:\n            f.write('dummy')\n\n        path = create_unique_archive_path('archive.zip')\n        expected = os.path.join(ARCHIVE_DIR, 'archive_1.zip')\n        self.assertEqual(path, expected)\n\n        # Create archive_1.zip as well\n        with open(path, 'w') as f:\n            f.write('dummy')\n\n        path2 = create_unique_archive_path('archive.zip')\n        expected2 = os.path.join(ARCHIVE_DIR, 'archive_2.zip')\n        self.assertEqual(path2, expected2)\n\n    def test_create_unique_archive_path_with_no_extension(self):\n        existing_path = os.path.join(ARCHIVE_DIR, 'archive')\n        with open(existing_path, 'w') as f:\n            f.write('dummy')\n\n        path = create_unique_archive_path('archive')\n        expected = os.path.join(ARCHIVE_DIR, 'archive_1')\n        self.assertEqual(path, expected)\n",
        "code": "import os\nimport glob\n\n# Constants\nARCHIVE_DIR = '/tmp/archive'\n\ndef task_func(pattern):\n    \"\"\"Find all files in ARCHIVE_DIR matching the given pattern. Create ARCHIVE_DIR if it does not exist.\"\"\"\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n    search_path = os.path.join(ARCHIVE_DIR, pattern)\n    return glob.glob(search_path)\n\n\ndef create_unique_archive_path(filename):\n    \"\"\"Create a unique archive file path inside ARCHIVE_DIR without overwriting existing files.\"\"\"\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n\n    base, ext = os.path.splitext(filename)\n    candidate = filename\n    counter = 1\n    while os.path.exists(os.path.join(ARCHIVE_DIR, candidate)):\n        candidate = f\"{base}_{counter}{ext}\"\n        counter += 1\n    return os.path.join(ARCHIVE_DIR, candidate)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/785_4",
        "turn": "4",
        "instruct_prompt": "The function should archive all files matching the pattern into the archive file and then delete the original files.",
        "test": "import unittest\nimport os\nimport shutil\nimport zipfile\n\nARCHIVE_DIR = '/tmp/archive'\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        if os.path.exists(ARCHIVE_DIR):\n            shutil.rmtree(ARCHIVE_DIR)\n        os.makedirs(ARCHIVE_DIR)\n\n        # Create some test files matching pattern\n        self.test_files = [os.path.join(ARCHIVE_DIR, f'testfile{i}.txt') for i in range(3)]\n        for f in self.test_files:\n            with open(f, 'w') as fp:\n                fp.write(f'content of {os.path.basename(f)}')\n\n        # Create a file that does not match pattern\n        self.other_file = os.path.join(ARCHIVE_DIR, 'otherfile.log')\n        with open(self.other_file, 'w') as fp:\n            fp.write('other content')\n\n    def tearDown(self):\n        if os.path.exists(ARCHIVE_DIR):\n            shutil.rmtree(ARCHIVE_DIR)\n\n    def test_archive_and_delete_files(self):\n        # Call task_func to archive *.txt files\n        result = task_func('*.txt')\n        self.assertTrue(result)\n\n        # Check that the matched files are deleted\n        for f in self.test_files:\n            self.assertFalse(os.path.exists(f), f\"File {f} should be deleted after archiving\")\n\n        # Check that the non-matching file remains\n        self.assertTrue(os.path.exists(self.other_file), \"Non-matching file should not be deleted\")\n\n        # Check that an archive file exists\n        archives = [f for f in os.listdir(ARCHIVE_DIR) if f.endswith('.zip')]\n        self.assertEqual(len(archives), 1, \"There should be exactly one archive file\")\n\n        archive_path = os.path.join(ARCHIVE_DIR, archives[0])\n        self.assertTrue(os.path.isfile(archive_path), \"Archive file should exist\")\n\n        # Check the contents of the archive\n        with zipfile.ZipFile(archive_path, 'r') as archive:\n            archived_names = archive.namelist()\n            expected_names = [os.path.basename(f) for f in self.test_files]\n            self.assertCountEqual(archived_names, expected_names)\n\n    def test_no_matching_files(self):\n        # Call task_func with a pattern that matches no files\n        result = task_func('*.nomatch')\n        self.assertFalse(result, \"Should return False if no files matched\")\n\n        # No archive file should be created\n        archives = [f for f in os.listdir(ARCHIVE_DIR) if f.endswith('.zip')]\n        self.assertEqual(len(archives), 0, \"No archive file should be created if no files matched\")\n\n    def test_unique_archive_name_creation(self):\n        # Create an archive file manually\n        existing_archive = os.path.join(ARCHIVE_DIR, 'archive.zip')\n        with open(existing_archive, 'w') as f:\n            f.write('dummy')\n\n        # Call task_func to archive *.txt files\n        result = task_func('*.txt')\n        self.assertTrue(result)\n\n        # There should be two archive files: archive.zip (existing) and archive_1.zip (new)\n        archives = [f for f in os.listdir(ARCHIVE_DIR) if f.endswith('.zip')]\n        self.assertIn('archive.zip', archives)\n        self.assertIn('archive_1.zip', archives)\n\n        # The new archive should contain the txt files\n        archive_path = os.path.join(ARCHIVE_DIR, 'archive_1.zip')\n        with zipfile.ZipFile(archive_path, 'r') as archive:\n            archived_names = archive.namelist()\n            expected_names = [os.path.basename(f) for f in self.test_files]\n            self.assertCountEqual(archived_names, expected_names)\n\n        # The original txt files should be deleted\n        for f in self.test_files:\n            self.assertFalse(os.path.exists(f))\n",
        "code": "import os\nimport glob\nimport zipfile\n\nARCHIVE_DIR = '/tmp/archive'\n\ndef task_func(pattern):\n    \"\"\"Archive all files matching pattern into a uniquely named archive in ARCHIVE_DIR and delete the original files.\n    Return True if any files archived, False otherwise.\"\"\"\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n\n    search_path = os.path.join(ARCHIVE_DIR, pattern)\n    files_to_archive = glob.glob(search_path)\n    if not files_to_archive:\n        return False\n\n    def create_unique_archive_path(filename):\n        base, ext = os.path.splitext(filename)\n        candidate = filename\n        counter = 1\n        while os.path.exists(os.path.join(ARCHIVE_DIR, candidate)):\n            candidate = f\"{base}_{counter}{ext}\"\n            counter += 1\n        return os.path.join(ARCHIVE_DIR, candidate)\n\n    archive_name = 'archive.zip'\n    archive_path = create_unique_archive_path(archive_name)\n\n    with zipfile.ZipFile(archive_path, 'w') as archive:\n        for file_path in files_to_archive:\n            archive.write(file_path, os.path.basename(file_path))\n\n    for file_path in files_to_archive:\n        os.remove(file_path)\n\n    return True\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/785_5",
        "turn": "5",
        "instruct_prompt": "The function should return the archive file path as a string. If no files match the pattern, it should return a message indicating no files were found.",
        "test": "import os\nimport unittest\nimport zipfile\nfrom tempfile import TemporaryDirectory\n\nimport shutil\n\n# Assume the solution function is in the same file or imported\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Override ARCHIVE_DIR to a temporary directory for testing\n        global ARCHIVE_DIR\n        self.test_dir = TemporaryDirectory()\n        ARCHIVE_DIR = self.test_dir.name\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def test_no_files_found(self):\n        # No files exist\n        result = task_func('*.txt')\n        self.assertEqual(result, 'No files found matching the pattern.')\n\n    def test_files_archived_and_deleted(self):\n        # Create some files matching pattern\n        filenames = ['file1.txt', 'file2.txt']\n        for fn in filenames:\n            with open(os.path.join(ARCHIVE_DIR, fn), 'w') as f:\n                f.write('test content')\n\n        result = task_func('*.txt')\n\n        # Result should be a path string\n        self.assertTrue(isinstance(result, str))\n        self.assertTrue(os.path.isabs(result))\n\n        # Archive file should exist\n        self.assertTrue(os.path.exists(result))\n\n        # Original files should be deleted\n        for fn in filenames:\n            self.assertFalse(os.path.exists(os.path.join(ARCHIVE_DIR, fn)))\n\n        # The archive should contain the files\n        with zipfile.ZipFile(result, 'r') as archive:\n            archived_files = archive.namelist()\n            self.assertCountEqual(archived_files, filenames)\n\n    def test_existing_archive_name_creates_unique_name(self):\n        # Create a dummy archive file with the default name\n        existing_archive = os.path.join(ARCHIVE_DIR, 'archive.zip')\n        with open(existing_archive, 'w') as f:\n            f.write('dummy')\n\n        # Create files to archive\n        filenames = ['file1.txt']\n        for fn in filenames:\n            with open(os.path.join(ARCHIVE_DIR, fn), 'w') as f:\n                f.write('content')\n\n        result = task_func('*.txt')\n\n        # The new archive path should not be the same as existing_archive\n        self.assertNotEqual(result, existing_archive)\n        self.assertTrue(os.path.exists(result))\n\n        # Check that the new archive has the expected suffix\n        self.assertTrue(result.endswith('_1.zip'))\n\n        # Original file removed\n        self.assertFalse(os.path.exists(os.path.join(ARCHIVE_DIR, 'file1.txt')))\n\n    def test_pattern_with_no_match(self):\n        # Create files that don't match pattern\n        with open(os.path.join(ARCHIVE_DIR, 'file1.log'), 'w') as f:\n            f.write('content')\n\n        result = task_func('*.txt')\n        self.assertEqual(result, 'No files found matching the pattern.')\n\n",
        "code": "import os\nimport glob\nimport zipfile\n\nARCHIVE_DIR = '/tmp/archive'\n\ndef task_func(pattern):\n    \"\"\"Archive all files matching pattern into a uniquely named archive in ARCHIVE_DIR and delete the original files.\n    Return the archive file path as a string if any files archived, else a message indicating no files found.\"\"\"\n    if not os.path.exists(ARCHIVE_DIR):\n        os.makedirs(ARCHIVE_DIR)\n\n    search_path = os.path.join(ARCHIVE_DIR, pattern)\n    files_to_archive = glob.glob(search_path)\n    if not files_to_archive:\n        return 'No files found matching the pattern.'\n\n    def create_unique_archive_path(filename):\n        base, ext = os.path.splitext(filename)\n        candidate = filename\n        counter = 1\n        while os.path.exists(os.path.join(ARCHIVE_DIR, candidate)):\n            candidate = f\"{base}_{counter}{ext}\"\n            counter += 1\n        return os.path.join(ARCHIVE_DIR, candidate)\n\n    archive_name = 'archive.zip'\n    archive_path = create_unique_archive_path(archive_name)\n\n    with zipfile.ZipFile(archive_path, 'w') as archive:\n        for file_path in files_to_archive:\n            archive.write(file_path, os.path.basename(file_path))\n\n    for file_path in files_to_archive:\n        os.remove(file_path)\n\n    return archive_path\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 101,
    "task_id": "BigCodeBench/800",
    "mt_data": [
      {
        "task_id": "BigCodeBench/800_1",
        "turn": "1",
        "instruct_prompt": "Write a function named task_func that reads a CSV file containing match data with columns 'goals' and 'penalties', and returns a Counter object with the total counts of goals and penalties from the file. You should write self-contained code starting with:\n```\nimport csv\nimport os\nfrom collections import Counter\n# Constants\nCSV_FILE_PATH = 'match_data.csv'\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n```",
        "test": "import unittest\nimport os\nimport csv\nfrom collections import Counter\n\nclass TestCases(unittest.TestCase):\n    TEST_CSV = 'test_match_data.csv'\n\n    def setUp(self):\n        # Prepare a CSV file for testing\n        with open(self.TEST_CSV, mode='w', newline='') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=['goals', 'penalties'])\n            writer.writeheader()\n            writer.writerow({'goals': '2', 'penalties': '1'})\n            writer.writerow({'goals': '3', 'penalties': '0'})\n            writer.writerow({'goals': '1', 'penalties': '2'})\n\n    def tearDown(self):\n        # Remove the test CSV file\n        if os.path.exists(self.TEST_CSV):\n            os.remove(self.TEST_CSV)\n\n    def test_task_func(self):\n        expected = Counter({'goals': 6, 'penalties': 3})\n        result = task_func(0, 0, csv_file_path=self.TEST_CSV)\n        self.assertEqual(result, expected)\n\n    def test_empty_file(self):\n        # Create an empty CSV file with headers only\n        with open(self.TEST_CSV, mode='w', newline='') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=['goals', 'penalties'])\n            writer.writeheader()\n\n        expected = Counter()\n        result = task_func(0, 0, csv_file_path=self.TEST_CSV)\n        self.assertEqual(result, expected)\n\n    def test_missing_file(self):\n        # Remove file before test\n        if os.path.exists(self.TEST_CSV):\n            os.remove(self.TEST_CSV)\n        expected = Counter()\n        result = task_func(0, 0, csv_file_path=self.TEST_CSV)\n        self.assertEqual(result, expected)\n\n    def test_invalid_values(self):\n        # Write invalid integers\n        with open(self.TEST_CSV, mode='w', newline='') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=['goals', 'penalties'])\n            writer.writeheader()\n            writer.writerow({'goals': 'a', 'penalties': '2'})\n            writer.writerow({'goals': '3', 'penalties': 'b'})\n\n        expected = Counter({'goals': 3, 'penalties': 2})\n        result = task_func(0, 0, csv_file_path=self.TEST_CSV)\n        self.assertEqual(result, expected)\n",
        "code": "import csv\nimport os\nfrom collections import Counter\n\n# Constants\nCSV_FILE_PATH = 'match_data.csv'\n\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    total_counts = Counter()\n    if not os.path.exists(csv_file_path):\n        return total_counts\n    with open(csv_file_path, mode='r', newline='') as csvfile:\n        reader = csv.DictReader(csvfile)\n        for row in reader:\n            try:\n                g = int(row.get('goals', 0))\n            except (ValueError, TypeError):\n                g = 0\n            try:\n                p = int(row.get('penalties', 0))\n            except (ValueError, TypeError):\n                p = 0\n            total_counts['goals'] += g\n            total_counts['penalties'] += p\n    return total_counts\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/800_2",
        "turn": "2",
        "instruct_prompt": "Modify the function so that if the CSV file does not exist, it returns a Counter with 'goals' and 'penalties' counts both set to 0.",
        "test": "import unittest\nimport os\nimport tempfile\nfrom collections import Counter\n\nclass TestCases(unittest.TestCase):\n    def test_file_not_exist(self):\n        # Provide a path that does not exist\n        non_exist_path = 'non_existent_file.csv'\n        result = task_func(0, 0, csv_file_path=non_exist_path)\n        expected = Counter({'goals': 0, 'penalties': 0})\n        # Assert exact equality including keys\n        self.assertEqual(result, expected)\n        # Also assert keys present\n        self.assertIn('goals', result)\n        self.assertIn('penalties', result)\n\n    def test_existing_file(self):\n        # Create a temporary CSV file with valid data\n        with tempfile.NamedTemporaryFile(mode='w+', delete=False, newline='', suffix='.csv') as tmpfile:\n            tmpfile.write('goals,penalties\\n3,1\\n2,0\\n')\n            tmpfile_path = tmpfile.name\n\n        try:\n            result = task_func(0, 0, csv_file_path=tmpfile_path)\n            expected = Counter({'goals': 5, 'penalties': 1})\n            self.assertEqual(result, expected)\n        finally:\n            os.remove(tmpfile_path)\n",
        "code": "import csv\nimport os\nfrom collections import Counter\n\n# Constants\nCSV_FILE_PATH = 'match_data.csv'\n\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    if not os.path.exists(csv_file_path):\n        return Counter({'goals': 0, 'penalties': 0})\n    total_counts = Counter()\n    with open(csv_file_path, mode='r', newline='') as csvfile:\n        reader = csv.DictReader(csvfile)\n        for row in reader:\n            try:\n                g = int(row.get('goals', 0))\n            except (ValueError, TypeError):\n                g = 0\n            try:\n                p = int(row.get('penalties', 0))\n            except (ValueError, TypeError):\n                p = 0\n            total_counts['goals'] += g\n            total_counts['penalties'] += p\n    return total_counts\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/800_3",
        "turn": "3",
        "instruct_prompt": "Update the function to add the counts from the given 'goals' and 'penalties' dictionaries (mapping team names to integers) to the totals read from the CSV file before returning the Counter.",
        "test": "import unittest\nimport os\nimport csv\nfrom collections import Counter\n\n# Assuming the solution code is in the same file or imported\n\nclass TestCases(unittest.TestCase):\n    CSV_FILE = 'test_match_data.csv'\n\n    def setUp(self):\n        # Prepare a CSV file with known data\n        with open(self.CSV_FILE, mode='w', newline='') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=['goals', 'penalties'])\n            writer.writeheader()\n            writer.writerow({'goals': '3', 'penalties': '1'})\n            writer.writerow({'goals': '2', 'penalties': '0'})\n            writer.writerow({'goals': 'invalid', 'penalties': '2'})  # invalid goals should be treated as 0\n            writer.writerow({'goals': '', 'penalties': ''})  # empty strings treated as 0\n\n    def tearDown(self):\n        if os.path.exists(self.CSV_FILE):\n            os.remove(self.CSV_FILE)\n\n    def test_add_counts_from_goals_and_penalties(self):\n        goals = {'TeamA': 4, 'TeamB': 3}\n        penalties = {'TeamA': 1, 'TeamC': 2}\n        # CSV totals: goals=3+2+0+0=5, penalties=1+0+2+0=3\n        # Added totals: goals=4+3=7, penalties=1+2=3\n        # Expected totals: goals=12, penalties=6\n        result = task_func(goals, penalties, csv_file_path=self.CSV_FILE)\n        expected = Counter({'goals': 12, 'penalties': 6})\n        self.assertEqual(result, expected)\n\n    def test_empty_goals_penalties(self):\n        goals = {}\n        penalties = {}\n        # CSV totals: goals=5, penalties=3 as above\n        result = task_func(goals, penalties, csv_file_path=self.CSV_FILE)\n        expected = Counter({'goals': 5, 'penalties': 3})\n        self.assertEqual(result, expected)\n\n    def test_missing_csv_file(self):\n        goals = {'TeamX': 1}\n        penalties = {'TeamY': 2}\n        result = task_func(goals, penalties, csv_file_path='non_existent_file.csv')\n        # Since file is missing, should return zeros only (not add goals/penalties)\n        self.assertEqual(result, Counter({'goals': 0, 'penalties': 0}))\n\n    def test_non_integer_values_in_dicts(self):\n        # Although the requirement doesn't specify validation for dictionary values,\n        # the function expects integers, so passing non-integers may raise exceptions.\n        # This test is to confirm no code changes were made to handle non-integers in dicts.\n        goals = {'TeamA': '4'}  # string instead of int\n        penalties = {'TeamB': None}\n        # This should raise TypeError when sum() is called\n        with self.assertRaises(TypeError):\n            task_func(goals, penalties, csv_file_path=self.CSV_FILE)\n",
        "code": "import csv\nimport os\nfrom collections import Counter\n\n# Constants\nCSV_FILE_PATH = 'match_data.csv'\n\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    if not os.path.exists(csv_file_path):\n        return Counter({'goals': 0, 'penalties': 0})\n    total_counts = Counter()\n    with open(csv_file_path, mode='r', newline='') as csvfile:\n        reader = csv.DictReader(csvfile)\n        for row in reader:\n            try:\n                g = int(row.get('goals', 0))\n            except (ValueError, TypeError):\n                g = 0\n            try:\n                p = int(row.get('penalties', 0))\n            except (ValueError, TypeError):\n                p = 0\n            total_counts['goals'] += g\n            total_counts['penalties'] += p\n    total_counts['goals'] += sum(goals.values())\n    total_counts['penalties'] += sum(penalties.values())\n    return total_counts\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 102,
    "task_id": "BigCodeBench/826",
    "mt_data": [
      {
        "task_id": "BigCodeBench/826_1",
        "turn": "1",
        "instruct_prompt": "Write a function that lists all files in the source directory. You should write self-contained code starting with:```import os\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n```",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_list_files_with_pattern(self):\n        with tempfile.TemporaryDirectory() as source_dir:\n            # Create files\n            filenames = ['file1.txt', 'file2.doc', 'file3.docx', 'file4.pdf', 'file_5.txt', '123.doc']\n            for f in filenames:\n                with open(os.path.join(source_dir, f), 'w') as fp:\n                    fp.write('test')\n            # target_dir is not used in current implementation\n            result = task_func(source_dir, '')\n            expected = ['file1.txt', 'file2.doc', 'file3.docx', '123.doc']\n            self.assertCountEqual(result, expected)\n\n    def test_empty_directory(self):\n        with tempfile.TemporaryDirectory() as source_dir:\n            result = task_func(source_dir, '')\n            self.assertEqual(result, [])\n\n    def test_nonexistent_directory(self):\n        result = task_func('nonexistent_dir', '')\n        self.assertEqual(result, [])\n\n    def test_custom_pattern(self):\n        with tempfile.TemporaryDirectory() as source_dir:\n            filenames = ['abc123.txt', 'abc_123.txt', 'xyz.doc', 'test.docx']\n            for f in filenames:\n                with open(os.path.join(source_dir, f), 'w') as fp:\n                    fp.write('data')\n            # Pattern to match files with underscore in name\n            pattern = r'\\b[A-Za-z0-9_]+\\.(txt|doc|docx)\\b'\n            result = task_func(source_dir, '', file_pattern=pattern)\n            expected = ['abc123.txt', 'abc_123.txt', 'xyz.doc', 'test.docx']\n            self.assertCountEqual(result, expected)\n",
        "code": "import os\nimport re\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    matched_files = []\n    pattern = re.compile(file_pattern)\n    try:\n        for filename in os.listdir(source_dir):\n            if pattern.fullmatch(filename):\n                matched_files.append(filename)\n    except FileNotFoundError:\n        # If source_dir does not exist, return empty list\n        return []\n    return matched_files\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/826_2",
        "turn": "2",
        "instruct_prompt": "Add functionality to the function so that it moves files from the source directory to the target directory only if the file name matches the given regex pattern.",
        "test": "import os\nimport re\nimport shutil\nimport tempfile\nimport unittest\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create temporary source and target directories\n        self.source_dir = tempfile.mkdtemp()\n        self.target_dir = tempfile.mkdtemp()\n\n        # Create files in source_dir\n        self.files = [\n            'file1.txt',\n            'file2.doc',\n            'file3.docx',\n            'file4.pdf',\n            'file5.TXT',\n            '123file.doc'\n        ]\n        for filename in self.files:\n            with open(os.path.join(self.source_dir, filename), 'w') as f:\n                f.write('test content')\n\n    def tearDown(self):\n        # Clean up temporary directories\n        shutil.rmtree(self.source_dir, ignore_errors=True)\n        shutil.rmtree(self.target_dir, ignore_errors=True)\n\n    def test_move_matching_files_default_pattern(self):\n        # Default pattern: \\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b\n        moved_files = task_func(self.source_dir, self.target_dir)\n\n        expected_files = ['file1.txt', 'file2.doc', 'file3.docx', '123file.doc']\n\n        # Check moved files list\n        self.assertCountEqual(moved_files, expected_files)\n\n        # Check files moved to target_dir\n        target_files = os.listdir(self.target_dir)\n        self.assertCountEqual(target_files, expected_files)\n\n        # Check these files no longer exist in source_dir\n        source_files = os.listdir(self.source_dir)\n        for f in expected_files:\n            self.assertNotIn(f, source_files)\n\n        # Files that should remain in source_dir\n        remaining_files = ['file4.pdf', 'file5.TXT']\n        for f in remaining_files:\n            self.assertIn(f, source_files)\n\n    def test_move_matching_files_custom_pattern(self):\n        # Custom pattern: only files ending with .pdf\n        pattern = r'\\b[A-Za-z0-9]+\\.pdf\\b'\n        moved_files = task_func(self.source_dir, self.target_dir, file_pattern=pattern)\n\n        expected_files = ['file4.pdf']\n\n        self.assertCountEqual(moved_files, expected_files)\n\n        target_files = os.listdir(self.target_dir)\n        self.assertCountEqual(target_files, expected_files)\n\n        source_files = os.listdir(self.source_dir)\n        for f in expected_files:\n            self.assertNotIn(f, source_files)\n\n    def test_source_dir_not_exist(self):\n        moved_files = task_func('non_existent_dir', self.target_dir)\n        self.assertEqual(moved_files, [])\n",
        "code": "import os\nimport re\nimport shutil\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    matched_files = []\n    pattern = re.compile(file_pattern)\n    try:\n        for filename in os.listdir(source_dir):\n            if pattern.fullmatch(filename):\n                src_path = os.path.join(source_dir, filename)\n                dst_path = os.path.join(target_dir, filename)\n                shutil.move(src_path, dst_path)\n                matched_files.append(filename)\n    except FileNotFoundError:\n        # If source_dir does not exist, return empty list\n        return []\n    return matched_files\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/826_3",
        "turn": "3",
        "instruct_prompt": "Ensure the function creates the target directory if it does not exist and raises a FileNotFoundError if the source directory does not exist.",
        "test": "import unittest\nimport tempfile\nimport os\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create temporary directories for each test\n        self.temp_source = tempfile.mkdtemp()\n        self.temp_target = tempfile.mkdtemp()\n\n    def tearDown(self):\n        # Remove temporary directories after test\n        shutil.rmtree(self.temp_source, ignore_errors=True)\n        shutil.rmtree(self.temp_target, ignore_errors=True)\n\n    def test_create_target_dir_if_not_exists(self):\n        # Remove the target directory to test creation\n        shutil.rmtree(self.temp_target)\n        # Create some files matching the pattern in source\n        filenames = ['file1.txt', 'file2.doc', 'file3.docx', 'file4.pdf']\n        for f in filenames:\n            with open(os.path.join(self.temp_source, f), 'w') as fp:\n                fp.write('test')\n\n        moved_files = task_func(self.temp_source, self.temp_target)\n\n        # Check if target directory was created\n        self.assertTrue(os.path.exists(self.temp_target))\n\n        # Check that only matching files were moved\n        self.assertCountEqual(moved_files, ['file1.txt', 'file2.doc', 'file3.docx'])\n\n        # Check files in target\n        target_files = os.listdir(self.temp_target)\n        self.assertCountEqual(target_files, ['file1.txt', 'file2.doc', 'file3.docx'])\n\n        # Check files left in source\n        source_files = os.listdir(self.temp_source)\n        self.assertCountEqual(source_files, ['file4.pdf'])\n\n    def test_source_dir_not_exist_raises(self):\n        # Remove source directory to simulate non-existence\n        shutil.rmtree(self.temp_source)\n\n        with self.assertRaises(FileNotFoundError):\n            task_func(self.temp_source, self.temp_target)\n",
        "code": "import os\nimport re\nimport shutil\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory '{source_dir}' does not exist.\")\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    matched_files = []\n    pattern = re.compile(file_pattern)\n    for filename in os.listdir(source_dir):\n        if pattern.fullmatch(filename):\n            src_path = os.path.join(source_dir, filename)\n            dst_path = os.path.join(target_dir, filename)\n            shutil.move(src_path, dst_path)\n            matched_files.append(filename)\n    return matched_files\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/826_4",
        "turn": "4",
        "instruct_prompt": "Modify the function to return the count of files that were successfully moved from the source directory to the target directory.",
        "test": "import unittest\nimport os\nimport tempfile\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.source_dir = tempfile.mkdtemp()\n        self.target_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.source_dir)\n        shutil.rmtree(self.target_dir)\n\n    def test_move_and_count(self):\n        filenames = ['file1.txt', 'file2.doc', 'file3.docx', 'file4.pdf', 'file5']\n        for name in filenames:\n            with open(os.path.join(self.source_dir, name), 'w') as f:\n                f.write('test')\n\n        count = task_func(self.source_dir, self.target_dir)\n        self.assertEqual(count, 3)\n\n        # Check files moved\n        for name in ['file1.txt', 'file2.doc', 'file3.docx']:\n            self.assertFalse(os.path.exists(os.path.join(self.source_dir, name)))\n            self.assertTrue(os.path.exists(os.path.join(self.target_dir, name)))\n\n        # Check files not moved\n        for name in ['file4.pdf', 'file5']:\n            self.assertTrue(os.path.exists(os.path.join(self.source_dir, name)))\n            self.assertFalse(os.path.exists(os.path.join(self.target_dir, name)))\n\n    def test_source_dir_not_exist(self):\n        non_existing_dir = os.path.join(self.source_dir, 'nonexistent')\n        with self.assertRaises(FileNotFoundError):\n            task_func(non_existing_dir, self.target_dir)\n\n    def test_target_dir_created(self):\n        non_existing_target = os.path.join(self.target_dir, 'new_target')\n        filename = 'file1.txt'\n        with open(os.path.join(self.source_dir, filename), 'w') as f:\n            f.write('test')\n\n        count = task_func(self.source_dir, non_existing_target)\n        self.assertEqual(count, 1)\n        self.assertTrue(os.path.exists(non_existing_target))\n        self.assertTrue(os.path.exists(os.path.join(non_existing_target, filename)))\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import os\nimport re\nimport shutil\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory '{source_dir}' does not exist.\")\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    count = 0\n    pattern = re.compile(file_pattern)\n    for filename in os.listdir(source_dir):\n        if pattern.fullmatch(filename):\n            src_path = os.path.join(source_dir, filename)\n            dst_path = os.path.join(target_dir, filename)\n            shutil.move(src_path, dst_path)\n            count += 1\n    return count\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 103,
    "task_id": "BigCodeBench/845",
    "mt_data": [
      {
        "task_id": "BigCodeBench/845_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes two text strings and cleans them by removing all non-alphanumeric characters except spaces, then converts them to lowercase. You should write self-contained code starting with:```import re\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\ndef task_func(text1, text2):```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        self.assertEqual(task_func('Hello, World!', 'Python3.8'), ('hello world', 'python38'))\n\n    def test_with_spaces(self):\n        self.assertEqual(task_func('Hello World', 'Good Morning'), ('hello world', 'good morning'))\n\n    def test_with_special_chars(self):\n        self.assertEqual(task_func('Test@123!', 'Check_this#1'), ('test123', 'checkthis1'))\n\n    def test_empty_strings(self):\n        self.assertEqual(task_func('', ''), ('', ''))\n\n    def test_only_special_chars(self):\n        self.assertEqual(task_func('!@#$%^&*()', '_+=-{}[]'), ('', ''))",
        "code": "import re\n# Constants\nALPHANUMERIC = re.compile('[^a-zA-Z0-9 ]+')\ndef task_func(text1, text2):\n    cleaned1 = ALPHANUMERIC.sub('', text1).lower()\n    cleaned2 = ALPHANUMERIC.sub('', text2).lower()\n    return cleaned1, cleaned2",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/845_2",
        "turn": "2",
        "instruct_prompt": "Calculate the term frequency of words in each cleaned text and compute the cosine similarity between the two term frequency vectors. The cosine similarity should be a float between 0 and 1, where 1 means identical term frequency vectors and 0 means no common terms.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_identical_texts(self):\n        text = \"Hello world! Hello.\"\n        self.assertAlmostEqual(task_func(text, text), 1.0)\n\n    def test_completely_different_texts(self):\n        text1 = \"apple orange banana\"\n        text2 = \"cat dog mouse\"\n        self.assertEqual(task_func(text1, text2), 0.0)\n\n    def test_partial_overlap(self):\n        text1 = \"apple orange banana\"\n        text2 = \"banana banana cat\"\n        result = task_func(text1, text2)\n        self.assertTrue(0 < result < 1)\n\n    def test_empty_texts(self):\n        self.assertEqual(task_func(\"\", \"\"), 0.0)\n\n    def test_one_empty_text(self):\n        self.assertEqual(task_func(\"apple banana\", \"\"), 0.0)\n\n    def test_case_insensitivity_and_cleaning(self):\n        text1 = \"Apple, orange! Banana?\"\n        text2 = \"banana apple orange\"\n        self.assertAlmostEqual(task_func(text1, text2), 1.0)\n",
        "code": "import re\nimport math\nfrom collections import Counter\n\nALPHANUMERIC = re.compile('[^a-zA-Z0-9 ]+')\n\ndef task_func(text1, text2):\n    cleaned1 = ALPHANUMERIC.sub('', text1).lower()\n    cleaned2 = ALPHANUMERIC.sub('', text2).lower()\n\n    words1 = cleaned1.split()\n    words2 = cleaned2.split()\n\n    tf1 = Counter(words1)\n    tf2 = Counter(words2)\n\n    # Get the set of all unique words\n    all_words = set(tf1.keys()).union(set(tf2.keys()))\n\n    # Create vectors\n    vec1 = [tf1[word] for word in all_words]\n    vec2 = [tf2[word] for word in all_words]\n\n    # Compute cosine similarity\n    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n    magnitude1 = math.sqrt(sum(a * a for a in vec1))\n    magnitude2 = math.sqrt(sum(b * b for b in vec2))\n\n    if magnitude1 == 0 or magnitude2 == 0:\n        cosine_similarity = 0.0\n    else:\n        cosine_similarity = dot_product / (magnitude1 * magnitude2)\n\n    return cosine_similarity\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/845_3",
        "turn": "3",
        "instruct_prompt": "Using the 'ratio' function from the 'python-Levenshtein' library, compute the Levenshtein ratio between the two cleaned texts as a float between 0 and 1, where 1 means the texts are identical and 0 means they are completely different.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_identical_texts(self):\n        self.assertEqual(task_func('Hello World!', 'Hello World!'), 1.0)\n\n    def test_completely_different_texts(self):\n        self.assertAlmostEqual(task_func('abc', 'xyz'), 0.0, places=2)\n\n    def test_partial_similarity(self):\n        self.assertGreater(task_func('Hello there!', 'Hello world!'), 0.5)\n\n    def test_cleaning_effect(self):\n        # Punctuation and case differences should be ignored\n        self.assertEqual(task_func('Hello, World!', 'hello world'), 1.0)\n\n    def test_empty_texts(self):\n        self.assertEqual(task_func('', ''), 1.0)\n        self.assertEqual(task_func('Non-empty', ''), 0.0)\n        self.assertEqual(task_func('', 'Non-empty'), 0.0)\n",
        "code": "import re\nfrom Levenshtein import ratio\n\nALPHANUMERIC = re.compile('[^a-zA-Z0-9 ]+')\n\ndef task_func(text1, text2):\n    cleaned1 = ALPHANUMERIC.sub('', text1).lower()\n    cleaned2 = ALPHANUMERIC.sub('', text2).lower()\n\n    return ratio(cleaned1, cleaned2)",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/845_4",
        "turn": "4",
        "instruct_prompt": "Return a tuple containing the cosine similarity and the Levenshtein ratio as floats.",
        "test": "import unittest\nfrom Levenshtein import ratio\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        text1 = \"Hello, world!\"\n        text2 = \"Hello world\"\n        result = task_func(text1, text2)\n        # cosine similarity should be 1.0 (same words)\n        self.assertAlmostEqual(result[0], 1.0)\n        # Levenshtein ratio should be close to 1.0\n        self.assertAlmostEqual(result[1], ratio('hello world', 'hello world'))\n\n    def test_different(self):\n        text1 = \"abc def ghi\"\n        text2 = \"xyz uvw\"\n        result = task_func(text1, text2)\n        # cosine similarity should be 0.0 (no shared words)\n        self.assertEqual(result[0], 0.0)\n        # Levenshtein ratio should be less than 1\n        self.assertLess(result[1], 1.0)\n\n    def test_empty(self):\n        text1 = \"\"\n        text2 = \"abc\"\n        result = task_func(text1, text2)\n        # cosine similarity should be 0.0\n        self.assertEqual(result[0], 0.0)\n        # Levenshtein ratio should be 0.0 since empty vs non-empty\n        self.assertEqual(result[1], 0.0)\n\n    def test_partial_overlap(self):\n        text1 = \"The quick brown fox\"\n        text2 = \"The quick fox jumps\"\n        result = task_func(text1, text2)\n        # Cosine similarity should be > 0 and < 1\n        self.assertGreater(result[0], 0.0)\n        self.assertLess(result[0], 1.0)\n        # Levenshtein ratio should be > 0 and < 1\n        self.assertGreater(result[1], 0.0)\n        self.assertLess(result[1], 1.0)\n",
        "code": "import re\nfrom Levenshtein import ratio\nimport math\n\ndef cosine_similarity(text1, text2):\n    # Tokenize by whitespace\n    words1 = text1.lower().split()\n    words2 = text2.lower().split()\n\n    # Frequency count\n    freq1 = {}\n    for w in words1:\n        freq1[w] = freq1.get(w, 0) + 1\n    freq2 = {}\n    for w in words2:\n        freq2[w] = freq2.get(w, 0) + 1\n\n    # Compute dot product and magnitudes\n    intersection = set(freq1.keys()) & set(freq2.keys())\n    dot_product = sum(freq1[w] * freq2[w] for w in intersection)\n    mag1 = math.sqrt(sum(v * v for v in freq1.values()))\n    mag2 = math.sqrt(sum(v * v for v in freq2.values()))\n\n    if mag1 == 0 or mag2 == 0:\n        return 0.0\n    return dot_product / (mag1 * mag2)\n\nALPHANUMERIC = re.compile('[^a-zA-Z0-9 ]+')\n\ndef task_func(text1, text2):\n    cleaned1 = ALPHANUMERIC.sub('', text1).lower()\n    cleaned2 = ALPHANUMERIC.sub('', text2).lower()\n\n    cos_sim = cosine_similarity(cleaned1, cleaned2)\n    lev_ratio = ratio(cleaned1, cleaned2)\n\n    return (cos_sim, lev_ratio)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 104,
    "task_id": "BigCodeBench/854",
    "mt_data": [
      {
        "task_id": "BigCodeBench/854_1",
        "turn": "1",
        "instruct_prompt": "Generate all permutations of a given list of numbers and return them as a list of tuples. If the input list is empty, return an empty list for permutations. You should write self-contained code starting with:\n```\nfrom itertools import permutations\n\ndef task_func(numbers):\n```",
        "test": "import unittest\n\nfrom itertools import permutations\n\nclass TestCases(unittest.TestCase):\n    def test_non_empty_list(self):\n        numbers = [1, 2, 3]\n        expected = list(permutations(numbers))\n        result = task_func(numbers)\n        self.assertEqual(result, expected)\n\n    def test_empty_list(self):\n        numbers = []\n        expected = []\n        result = task_func(numbers)\n        self.assertEqual(result, expected)\n\n    def test_single_element(self):\n        numbers = [5]\n        expected = [(5,)]\n        result = task_func(numbers)\n        self.assertEqual(result, expected)\n\n    def test_duplicates(self):\n        numbers = [1, 1]\n        expected = list(permutations(numbers))\n        result = task_func(numbers)\n        self.assertEqual(result, expected)\n",
        "code": "from itertools import permutations\n\ndef task_func(numbers):\n    if not numbers:\n        return []\n    return list(permutations(numbers))",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/854_2",
        "turn": "2",
        "instruct_prompt": "For each permutation generated, calculate the sum of the factorials of each number in that permutation and return a list of these sums alongside the list of permutations.",
        "test": "import unittest\nfrom itertools import permutations\nfrom math import factorial\n\nclass TestCases(unittest.TestCase):\n    def test_empty_list(self):\n        perms, sums = task_func([])\n        self.assertEqual(perms, [])\n        self.assertEqual(sums, [])\n\n    def test_single_element(self):\n        perms, sums = task_func([3])\n        self.assertEqual(perms, [(3,)])\n        self.assertEqual(sums, [factorial(3)])\n\n    def test_two_elements(self):\n        nums = [1, 2]\n        perms, sums = task_func(nums)\n        expected_perms = [(1, 2), (2, 1)]\n        expected_sums = [factorial(1) + factorial(2), factorial(2) + factorial(1)]\n        self.assertEqual(perms, expected_perms)\n        self.assertEqual(sums, expected_sums)\n\n    def test_three_elements(self):\n        nums = [1, 2, 3]\n        perms, sums = task_func(nums)\n        expected_perms = list(permutations(nums))\n        expected_sums = [sum(factorial(n) for n in perm) for perm in expected_perms]\n        self.assertEqual(perms, expected_perms)\n        self.assertEqual(sums, expected_sums)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "from itertools import permutations\nimport math\n\ndef task_func(numbers):\n    if not numbers:\n        return [], []\n    perms = list(permutations(numbers))\n    sums = [sum(math.factorial(num) for num in perm) for perm in perms]\n    return perms, sums\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/854_3",
        "turn": "3",
        "instruct_prompt": "If the input is not a list of integers, raise a TypeError with the message: \"numbers should be a list of integers.\"",
        "test": "import unittest\nfrom math import factorial\n\nclass TestCases(unittest.TestCase):\n    def test_valid_input(self):\n        numbers = [1, 2]\n        perms, sums = task_func(numbers)\n        expected_perms = [(1, 2), (2, 1)]\n        expected_sums = [factorial(1) + factorial(2), factorial(2) + factorial(1)]\n        self.assertEqual(perms, expected_perms)\n        self.assertEqual(sums, expected_sums)\n\n    def test_empty_list(self):\n        self.assertEqual(task_func([]), ([], []))\n\n    def test_not_list(self):\n        with self.assertRaises(TypeError) as cm:\n            task_func(\"123\")\n        self.assertEqual(str(cm.exception), \"numbers should be a list of integers.\")\n\n    def test_list_with_non_integers(self):\n        with self.assertRaises(TypeError) as cm:\n            task_func([1, \"2\", 3])\n        self.assertEqual(str(cm.exception), \"numbers should be a list of integers.\")\n\n    def test_list_with_floats(self):\n        with self.assertRaises(TypeError) as cm:\n            task_func([1, 2.0, 3])\n        self.assertEqual(str(cm.exception), \"numbers should be a list of integers.\")\n",
        "code": "from itertools import permutations\nimport math\n\ndef task_func(numbers):\n    if not isinstance(numbers, list) or not all(isinstance(num, int) for num in numbers):\n        raise TypeError(\"numbers should be a list of integers.\")\n    if not numbers:\n        return [], []\n    perms = list(permutations(numbers))\n    sums = [sum(math.factorial(num) for num in perm) for perm in perms]\n    return perms, sums\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/854_4",
        "turn": "4",
        "instruct_prompt": "If any number in the list is negative, raise a ValueError with the message: \"each number in numbers should be non negative.\"",
        "test": "import unittest\nfrom math import factorial\n\nclass TestCases(unittest.TestCase):\n    def test_negative_number(self):\n        with self.assertRaises(ValueError) as context:\n            task_func([1, -1, 2])\n        self.assertEqual(str(context.exception), \"each number in numbers should be non negative.\")\n\n    def test_no_negative_number(self):\n        numbers = [1, 2]\n        perms, sums = task_func(numbers)\n        expected_perms = [(1, 2), (2, 1)]\n        expected_sums = [factorial(1) + factorial(2), factorial(2) + factorial(1)]\n        self.assertEqual(perms, expected_perms)\n        self.assertEqual(sums, expected_sums)\n\n    def test_empty_list(self):\n        perms, sums = task_func([])\n        self.assertEqual(perms, [])\n        self.assertEqual(sums, [])\n",
        "code": "from itertools import permutations\nimport math\n\ndef task_func(numbers):\n    if not isinstance(numbers, list) or not all(isinstance(num, int) for num in numbers):\n        raise TypeError(\"numbers should be a list of integers.\")\n    if any(num < 0 for num in numbers):\n        raise ValueError(\"each number in numbers should be non negative.\")\n    if not numbers:\n        return [], []\n    perms = list(permutations(numbers))\n    sums = [sum(math.factorial(num) for num in perm) for perm in perms]\n    return perms, sums\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/854_5",
        "turn": "5",
        "instruct_prompt": "If the input list is empty, return two empty lists: one for sums and one for permutations.",
        "test": "import unittest\nimport math\nfrom itertools import permutations\n\nclass CustomList(list):\n    def __iter__(self):\n        raise RuntimeError(\"Iteration not allowed\")\n\nclass TestCases(unittest.TestCase):\n    def test_empty_list_returns_two_empty_lists(self):\n        perms, sums = task_func([])\n        self.assertEqual(perms, [])\n        self.assertEqual(sums, [])\n\n    def test_empty_list_returns_without_iterating(self):\n        # Using CustomList that raises on iteration\n        custom_empty = CustomList()\n        perms, sums = task_func(custom_empty)\n        self.assertEqual(perms, [])\n        self.assertEqual(sums, [])\n\n    def test_type_error_for_non_list(self):\n        with self.assertRaises(TypeError):\n            task_func(\"not a list\")\n\n    def test_type_error_for_non_int_elements(self):\n        with self.assertRaises(TypeError):\n            task_func([1, \"a\"])\n\n    def test_value_error_for_negative_elements(self):\n        with self.assertRaises(ValueError):\n            task_func([-1, 2])\n\n    def test_non_empty_list_returns_correct_perms_and_sums(self):\n        input_list = [1, 2]\n        perms, sums = task_func(input_list)\n        expected_perms = list(permutations(input_list))\n        self.assertEqual(perms, expected_perms)\n        expected_sums = [sum(math.factorial(num) for num in perm) for perm in expected_perms]\n        self.assertEqual(sums, expected_sums)\n",
        "code": "from itertools import permutations\nimport math\n\ndef task_func(numbers):\n    # Immediately return two empty lists if input is empty list\n    if numbers == []:\n        return [], []\n    # Validate type and values\n    if not isinstance(numbers, list) or not all(isinstance(num, int) for num in numbers):\n        raise TypeError(\"numbers should be a list of integers.\")\n    if any(num < 0 for num in numbers):\n        raise ValueError(\"each number in numbers should be non negative.\")\n    perms = list(permutations(numbers))\n    sums = [sum(math.factorial(num) for num in perm) for perm in perms]\n    return perms, sums\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 105,
    "task_id": "BigCodeBench/857",
    "mt_data": [
      {
        "task_id": "BigCodeBench/857_1",
        "turn": "1",
        "instruct_prompt": "Transfer all files from one directory (SOURCE_DIR) to another (DEST_DIR). You should write self-contained code starting with:\n```\nimport os\nimport shutil\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n```",
        "test": "import unittest\nimport os\nimport tempfile\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.source_dir = tempfile.mkdtemp()\n        self.dest_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        # Remove entire source_dir and dest_dir recursively\n        if os.path.exists(self.source_dir):\n            shutil.rmtree(self.source_dir)\n        if os.path.exists(self.dest_dir):\n            shutil.rmtree(self.dest_dir)\n\n    def test_move_all_files(self):\n        filenames = ['file1.txt', 'file2.jpg', 'file3.pdf']\n        for f in filenames:\n            with open(os.path.join(self.source_dir, f), 'w') as fp:\n                fp.write('test')\n\n        task_func(self.source_dir, self.dest_dir, [])\n\n        # Source dir should be empty\n        self.assertEqual(len(os.listdir(self.source_dir)), 0)\n        # Destination dir should contain all files\n        dest_files = os.listdir(self.dest_dir)\n        self.assertCountEqual(dest_files, filenames)\n\n    def test_move_filtered_files(self):\n        filenames = ['a.txt', 'b.jpg', 'c.pdf', 'd.txt']\n        for f in filenames:\n            with open(os.path.join(self.source_dir, f), 'w') as fp:\n                fp.write('data')\n\n        task_func(self.source_dir, self.dest_dir, ['.txt', '.pdf'])\n\n        # Only .txt and .pdf files moved\n        dest_files = os.listdir(self.dest_dir)\n        self.assertCountEqual(dest_files, ['a.txt', 'c.pdf', 'd.txt'])\n        # Remaining files in source\n        source_files = os.listdir(self.source_dir)\n        self.assertCountEqual(source_files, ['b.jpg'])\n\n    def test_dest_dir_created_if_not_exists(self):\n        non_existing_dest = os.path.join(self.dest_dir, 'subdir')\n        filenames = ['file.txt']\n        for f in filenames:\n            with open(os.path.join(self.source_dir, f), 'w') as fp:\n                fp.write('hello')\n\n        task_func(self.source_dir, non_existing_dest, [])\n\n        self.assertTrue(os.path.exists(non_existing_dest))\n        self.assertCountEqual(os.listdir(non_existing_dest), filenames)\n        self.assertEqual(len(os.listdir(self.source_dir)), 0)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import os\nimport shutil\n\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    if not os.path.exists(DEST_DIR):\n        os.makedirs(DEST_DIR)\n\n    for filename in os.listdir(SOURCE_DIR):\n        source_path = os.path.join(SOURCE_DIR, filename)\n        if os.path.isfile(source_path):\n            if not EXTENSIONS or any(filename.endswith(ext) for ext in EXTENSIONS):\n                dest_path = os.path.join(DEST_DIR, filename)\n                shutil.move(source_path, dest_path)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/857_2",
        "turn": "2",
        "instruct_prompt": "Only transfer files that match the specified file extensions (EXTENSIONS), which is a list of extensions like ['.txt', '.jpg'].",
        "test": "import unittest\nimport os\nimport tempfile\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.source_dir = tempfile.mkdtemp()\n        self.dest_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.source_dir)\n        shutil.rmtree(self.dest_dir)\n\n    def create_file(self, directory, filename, content=\"test\"):\n        path = os.path.join(directory, filename)\n        with open(path, 'w') as f:\n            f.write(content)\n        return path\n\n    def test_transfer_only_matching_extensions(self):\n        matched_files = ['file1.txt', 'file2.jpg']\n        unmatched_files = ['file3.pdf', 'file4.png', 'file5']\n\n        for f in matched_files + unmatched_files:\n            self.create_file(self.source_dir, f)\n\n        EXTENSIONS = ['.txt', '.jpg']\n\n        task_func(self.source_dir, self.dest_dir, EXTENSIONS)\n\n        for f in matched_files:\n            self.assertFalse(os.path.exists(os.path.join(self.source_dir, f)))\n            self.assertTrue(os.path.exists(os.path.join(self.dest_dir, f)))\n\n        for f in unmatched_files:\n            self.assertTrue(os.path.exists(os.path.join(self.source_dir, f)))\n            self.assertFalse(os.path.exists(os.path.join(self.dest_dir, f)))\n\n    def test_no_files_moved_if_no_match(self):\n        files = ['file1.pdf', 'file2.png']\n        for f in files:\n            self.create_file(self.source_dir, f)\n\n        EXTENSIONS = ['.txt', '.jpg']\n\n        task_func(self.source_dir, self.dest_dir, EXTENSIONS)\n\n        for f in files:\n            self.assertTrue(os.path.exists(os.path.join(self.source_dir, f)))\n            self.assertFalse(os.path.exists(os.path.join(self.dest_dir, f)))\n\n    def test_all_files_moved_if_all_match(self):\n        files = ['a.txt', 'b.txt']\n        for f in files:\n            self.create_file(self.source_dir, f)\n\n        EXTENSIONS = ['.txt']\n\n        task_func(self.source_dir, self.dest_dir, EXTENSIONS)\n\n        for f in files:\n            self.assertFalse(os.path.exists(os.path.join(self.source_dir, f)))\n            self.assertTrue(os.path.exists(os.path.join(self.dest_dir, f)))\n\n    def test_no_files_moved_if_extensions_empty(self):\n        files = ['file1.txt', 'file2.jpg', 'file3.pdf']\n        for f in files:\n            self.create_file(self.source_dir, f)\n\n        EXTENSIONS = []  # Empty means move nothing according to new requirement\n\n        task_func(self.source_dir, self.dest_dir, EXTENSIONS)\n\n        # All files should remain in source_dir\n        for f in files:\n            self.assertTrue(os.path.exists(os.path.join(self.source_dir, f)))\n            self.assertFalse(os.path.exists(os.path.join(self.dest_dir, f)))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import os\nimport shutil\n\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    if not os.path.exists(DEST_DIR):\n        os.makedirs(DEST_DIR)\n\n    for filename in os.listdir(SOURCE_DIR):\n        source_path = os.path.join(SOURCE_DIR, filename)\n        if os.path.isfile(source_path):\n            # Only move files if EXTENSIONS is non-empty and filename ends with one of the extensions\n            if EXTENSIONS and any(filename.endswith(ext) for ext in EXTENSIONS):\n                dest_path = os.path.join(DEST_DIR, filename)\n                shutil.move(source_path, dest_path)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/857_3",
        "turn": "3",
        "instruct_prompt": "Collect and return a list of the names of files that were successfully transferred.",
        "test": "import unittest\nimport os\nimport tempfile\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create temporary source and destination directories\n        self.source_dir = tempfile.mkdtemp()\n        self.dest_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        # Remove temporary directories\n        shutil.rmtree(self.source_dir)\n        shutil.rmtree(self.dest_dir)\n\n    def create_file(self, dir_path: str, filename: str, content: str = \"test\") -> None:\n        with open(os.path.join(dir_path, filename), 'w') as f:\n            f.write(content)\n\n    def test_transferred_files_list(self):\n        # Create files in source_dir\n        files = [\"a.txt\", \"b.jpg\", \"c.txt\", \"d.pdf\"]\n        for f in files:\n            self.create_file(self.source_dir, f)\n\n        # Only transfer .txt files\n        extensions = [\".txt\"]\n        transferred = task_func(self.source_dir, self.dest_dir, extensions)\n\n        # Check transferred files list\n        expected = [\"a.txt\", \"c.txt\"]\n        self.assertCountEqual(transferred, expected)\n\n        # Check files have been moved\n        for f in expected:\n            self.assertTrue(os.path.exists(os.path.join(self.dest_dir, f)))\n            self.assertFalse(os.path.exists(os.path.join(self.source_dir, f)))\n\n        # Files not matching extension remain in source_dir\n        self.assertTrue(os.path.exists(os.path.join(self.source_dir, \"b.jpg\")))\n        self.assertTrue(os.path.exists(os.path.join(self.source_dir, \"d.pdf\")))\n\n    def test_no_extensions(self):\n        # Create files\n        self.create_file(self.source_dir, \"file1.txt\")\n        # EXTENSIONS is empty list, no files should be moved\n        transferred = task_func(self.source_dir, self.dest_dir, [])\n        self.assertEqual(transferred, [])\n        self.assertTrue(os.path.exists(os.path.join(self.source_dir, \"file1.txt\")))\n\n    def test_all_files_transferred(self):\n        # Create files\n        files = [\"file1.txt\", \"file2.log\"]\n        for f in files:\n            self.create_file(self.source_dir, f)\n\n        # Use extensions that match all files\n        transferred = task_func(self.source_dir, self.dest_dir, [\".txt\", \".log\"])\n        self.assertCountEqual(transferred, files)\n        for f in files:\n            self.assertTrue(os.path.exists(os.path.join(self.dest_dir, f)))\n            self.assertFalse(os.path.exists(os.path.join(self.source_dir, f)))\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import os\nimport shutil\n\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    if not os.path.exists(DEST_DIR):\n        os.makedirs(DEST_DIR)\n\n    transferred_files = []\n    for filename in os.listdir(SOURCE_DIR):\n        source_path = os.path.join(SOURCE_DIR, filename)\n        if os.path.isfile(source_path):\n            if EXTENSIONS and any(filename.endswith(ext) for ext in EXTENSIONS):\n                dest_path = os.path.join(DEST_DIR, filename)\n                shutil.move(source_path, dest_path)\n                transferred_files.append(filename)\n    return transferred_files\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/857_4",
        "turn": "4",
        "instruct_prompt": "Issue warnings for any files that could not be transferred due to errors during the move operation.",
        "test": "import unittest\nimport tempfile\nimport os\nimport shutil\nimport warnings\nfrom unittest import mock\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.source_dir = tempfile.mkdtemp()\n        self.dest_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.source_dir)\n        shutil.rmtree(self.dest_dir)\n\n    def test_warning_on_move_error(self):\n        filename = 'testfile.txt'\n        filepath = os.path.join(self.source_dir, filename)\n        with open(filepath, 'w') as f:\n            f.write('content')\n\n        # Mock shutil.move to raise an exception to simulate move failure\n        with mock.patch('shutil.move', side_effect=Exception('mocked move error')):\n            with warnings.catch_warnings(record=True) as w:\n                warnings.simplefilter('always')\n                moved_files = task_func(self.source_dir, self.dest_dir, ['.txt'])\n\n                # Check that a warning was issued\n                self.assertTrue(any(f'Could not transfer file {filename}' in str(warn.message) for warn in w))\n\n                # The file should not be in moved_files\n                self.assertNotIn(filename, moved_files)\n\n    def test_successful_transfer(self):\n        filename = 'file1.txt'\n        filepath = os.path.join(self.source_dir, filename)\n        with open(filepath, 'w') as f:\n            f.write('data')\n\n        moved_files = task_func(self.source_dir, self.dest_dir, ['.txt'])\n\n        self.assertIn(filename, moved_files)\n        self.assertFalse(os.path.exists(filepath))\n        self.assertTrue(os.path.exists(os.path.join(self.dest_dir, filename)))\n\n    def test_no_warning_for_non_matching_extension(self):\n        filename = 'file2.doc'\n        filepath = os.path.join(self.source_dir, filename)\n        with open(filepath, 'w') as f:\n            f.write('data')\n\n        with warnings.catch_warnings(record=True) as w:\n            warnings.simplefilter('always')\n            moved_files = task_func(self.source_dir, self.dest_dir, ['.txt'])\n            self.assertEqual(len(w), 0)\n            self.assertNotIn(filename, moved_files)\n            self.assertTrue(os.path.exists(filepath))\n",
        "code": "import os\nimport shutil\nimport warnings\n\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    if not os.path.exists(DEST_DIR):\n        os.makedirs(DEST_DIR)\n\n    transferred_files = []\n    for filename in os.listdir(SOURCE_DIR):\n        source_path = os.path.join(SOURCE_DIR, filename)\n        if os.path.isfile(source_path):\n            if EXTENSIONS and any(filename.endswith(ext) for ext in EXTENSIONS):\n                dest_path = os.path.join(DEST_DIR, filename)\n                try:\n                    shutil.move(source_path, dest_path)\n                    transferred_files.append(filename)\n                except Exception as e:\n                    warnings.warn(f'Could not transfer file {filename}: {e}')\n    return transferred_files\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 106,
    "task_id": "BigCodeBench/865",
    "mt_data": [
      {
        "task_id": "BigCodeBench/865_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a list of tuples, each containing an item and its count, and returns a pandas DataFrame with two columns: 'Item' and 'Count'. You should write self-contained code starting with:\n```python\nimport pandas as pd\ndef task_func(data):\n```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        data = [('apple', 10), ('banana', 5), ('orange', 8)]\n        expected = pd.DataFrame({'Item': ['apple', 'banana', 'orange'], 'Count': [10, 5, 8]})\n        result = task_func(data)\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_empty(self):\n        data = []\n        expected = pd.DataFrame(columns=['Item', 'Count'])\n        result = task_func(data)\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_single(self):\n        data = [('pear', 3)]\n        expected = pd.DataFrame({'Item': ['pear'], 'Count': [3]})\n        result = task_func(data)\n        pd.testing.assert_frame_equal(result, expected)",
        "code": "import pandas as pd\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=['Item', 'Count'])\n    return df",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/865_2",
        "turn": "2",
        "instruct_prompt": "Modify the function so that it normalizes the 'Count' values using z-score normalization before adding them to the DataFrame as a column named 'Normalized Count'.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_normalized_count(self):\n        data = [['A', 10], ['B', 20], ['C', 30]]\n        df = task_func(data)\n        self.assertIn('Normalized Count', df.columns)\n        mean = df['Count'].mean()\n        std = df['Count'].std()\n        expected = [(x - mean) / std for x in df['Count']]\n        for actual, exp in zip(df['Normalized Count'], expected):\n            self.assertAlmostEqual(actual, exp)\n\n    def test_output_type(self):\n        data = [['X', 5], ['Y', 15]]\n        result = task_func(data)\n        self.assertIsInstance(result, pd.DataFrame)\n\n    def test_empty_data(self):\n        data = []\n        df = task_func(data)\n        self.assertIn('Normalized Count', df.columns)\n        self.assertEqual(len(df), 0)\n",
        "code": "import pandas as pd\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=['Item', 'Count'])\n    mean_count = df['Count'].mean()\n    std_count = df['Count'].std()\n    df['Normalized Count'] = (df['Count'] - mean_count) / std_count\n    return df",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/865_3",
        "turn": "3",
        "instruct_prompt": "Extend the input tuples to include weights as a third element. Normalize the weights using min-max scaling and add them to the DataFrame as a column named 'Normalized Weight'.",
        "test": "import unittest\nimport pandas as pd\nfrom pandas.testing import assert_frame_equal\n\nclass TestCases(unittest.TestCase):\n    def test_normalized_weight_and_count(self):\n        data = [\n            ('A', 10, 1),\n            ('B', 20, 2),\n            ('C', 30, 3),\n            ('D', 40, 4),\n            ('E', 50, 5),\n        ]\n        result = task_func(data)\n        expected_weight_norm = [(w - 1) / (5 - 1) for _, _, w in data]\n        expected_count = [row[1] for row in data]\n        expected_count_mean = sum(expected_count) / len(expected_count)\n        expected_count_std = (sum((x - expected_count_mean)**2 for x in expected_count) / (len(expected_count) - 1)) ** 0.5\n        expected_count_norm = [(x - expected_count_mean) / expected_count_std for x in expected_count]\n        self.assertListEqual(result['Item'].tolist(), [row[0] for row in data])\n        self.assertListEqual(result['Count'].tolist(), expected_count)\n        for a, b in zip(result['Normalized Weight'], expected_weight_norm):\n            self.assertAlmostEqual(a, b)\n        for a, b in zip(result['Normalized Count'], expected_count_norm):\n            self.assertAlmostEqual(a, b)\n\n    def test_single_weight(self):\n        data = [\n            ('A', 10, 2),\n            ('B', 20, 2),\n            ('C', 30, 2),\n        ]\n        result = task_func(data)\n        self.assertTrue(all(result['Normalized Weight'] == 0.0))\n\n    def test_previous_round_fail(self):\n        # This test ensures that the previous round's code (without weights) fails this test\n        # by passing tuples without weights, which should raise an error\n        data = [\n            ('A', 10),\n            ('B', 20),\n        ]\n        with self.assertRaises(ValueError):\n            task_func(data)\n",
        "code": "import pandas as pd\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=['Item', 'Count', 'Weight'])\n    min_weight = df['Weight'].min()\n    max_weight = df['Weight'].max()\n    df['Normalized Count'] = (df['Count'] - df['Count'].mean()) / df['Count'].std()\n    df['Normalized Weight'] = (df['Weight'] - min_weight) / (max_weight - min_weight) if max_weight != min_weight else 0.0\n    return df",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/865_4",
        "turn": "4",
        "instruct_prompt": "Ensure the returned DataFrame has exactly three columns named 'Item', 'Normalized Count', and 'Normalized Weight', with each row corresponding to an input tuple.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_columns_and_rows(self):\n        data = [('A', 10, 5), ('B', 20, 15), ('C', 30, 10)]\n        result = task_func(data)\n        # Check columns exactly as required\n        self.assertEqual(list(result.columns), ['Item', 'Normalized Count', 'Normalized Weight'])\n        # Check number of rows equals number of input tuples\n        self.assertEqual(len(result), len(data))\n        # Check that 'Item' column matches input\n        self.assertTrue(all(result['Item'] == [x[0] for x in data]))\n\n    def test_single_row(self):\n        data = [('X', 100, 50)]\n        result = task_func(data)\n        self.assertEqual(list(result.columns), ['Item', 'Normalized Count', 'Normalized Weight'])\n        self.assertEqual(len(result), 1)\n        self.assertEqual(result.iloc[0]['Item'], 'X')\n\n    def test_same_weight_values(self):\n        data = [('A', 1, 10), ('B', 2, 10), ('C', 3, 10)]\n        result = task_func(data)\n        self.assertEqual(list(result.columns), ['Item', 'Normalized Count', 'Normalized Weight'])\n        self.assertTrue(all(result['Normalized Weight'] == 0.0))\n\n    def test_output_type(self):\n        data = [('A', 5, 3), ('B', 10, 7)]\n        result = task_func(data)\n        self.assertIsInstance(result, pd.DataFrame)\n",
        "code": "import pandas as pd\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=['Item', 'Count', 'Weight'])\n    min_weight = df['Weight'].min()\n    max_weight = df['Weight'].max()\n    df['Normalized Count'] = (df['Count'] - df['Count'].mean()) / df['Count'].std()\n    if max_weight != min_weight:\n        df['Normalized Weight'] = (df['Weight'] - min_weight) / (max_weight - min_weight)\n    else:\n        df['Normalized Weight'] = 0.0\n    return df[['Item', 'Normalized Count', 'Normalized Weight']]",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 107,
    "task_id": "BigCodeBench/870",
    "mt_data": [
      {
        "task_id": "BigCodeBench/870_1",
        "turn": "1",
        "instruct_prompt": "Calculate the mean of numerical values in each position across tuples in a list. You should write self-contained code starting with:```import pandas as pd\nimport numpy as np\nimport itertools\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic(self):\n        data = [('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]\n        result = task_func(data)\n        expected = ((1+2+3+4+5)/5, (2.1+3.2+4.3+5.4+6.5)/5)\n        self.assertEqual(result, expected)\n\n    def test_task_func_single_tuple(self):\n        data = [('x', 10, 20.5)]\n        result = task_func(data)\n        expected = (10, 20.5)\n        self.assertEqual(result, expected)\n\n    def test_task_func_empty_list(self):\n        with self.assertRaises(ValueError):\n            task_func([])\n\n    def test_task_func_negative_numbers(self):\n        data = [('a', -1, -2.0), ('b', -3, -4.0)]\n        result = task_func(data)\n        expected = ((-1 + -3)/2, (-2.0 + -4.0)/2)\n        self.assertEqual(result, expected)\n",
        "code": "import pandas as pd\nimport numpy as np\nimport itertools\n\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    if not data_list:\n        raise ValueError('Input data_list is empty')\n    # Extract only the numerical values from each tuple (skip the first element)\n    numeric_data = [t[1:] for t in data_list]\n    if not numeric_data or not all(len(t) == len(numeric_data[0]) for t in numeric_data):\n        raise ValueError('Input tuples have inconsistent length or no numeric data')\n    arr = np.array(numeric_data, dtype=float)\n    means = np.mean(arr, axis=0)\n    return tuple(means)",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/870_2",
        "turn": "2",
        "instruct_prompt": "Ignore non-numeric values when calculating the mean for each position.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_all_numeric(self):\n        data = [('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3)]\n        result = task_func(data)\n        expected = (2.0, 3.2)\n        self.assertAlmostEqual(result[0], expected[0])\n        self.assertAlmostEqual(result[1], expected[1])\n\n    def test_ignore_non_numeric(self):\n        data = [('a', 1, 2.1), ('b', 'x', 3.2), ('c', 3, 'y')]\n        result = task_func(data)\n        # Means should be computed ignoring 'x' and 'y'\n        expected_first = (1 + 3) / 2  # ignore 'x'\n        expected_second = (2.1 + 3.2) / 2  # ignore 'y'\n        self.assertAlmostEqual(result[0], expected_first)\n        self.assertAlmostEqual(result[1], expected_second)\n\n    def test_all_non_numeric_in_column(self):\n        data = [('a', 'x', 2.1), ('b', 'y', 3.2), ('c', 'z', 4.3)]\n        result = task_func(data)\n        # First position has no numeric values, expect nan\n        self.assertTrue(np.isnan(result[0]))\n        # Second position mean\n        expected_second = (2.1 + 3.2 + 4.3) / 3\n        self.assertAlmostEqual(result[1], expected_second)\n\n    def test_empty_input(self):\n        with self.assertRaises(ValueError):\n            task_func([])\n\n    def test_inconsistent_length(self):\n        data = [('a', 1, 2), ('b', 2, 3, 4)]\n        with self.assertRaises(ValueError):\n            task_func(data)\n",
        "code": "import numpy as np\n\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    if not data_list:\n        raise ValueError('Input data_list is empty')\n    # Extract the values after the first element for each tuple\n    numeric_data = [t[1:] for t in data_list]\n    if not numeric_data or not all(len(t) == len(numeric_data[0]) for t in numeric_data):\n        raise ValueError('Input tuples have inconsistent length or no numeric data')\n    # Convert to numpy array with object dtype to handle non-numeric values\n    arr = np.array(numeric_data, dtype=object)\n    means = []\n    for col in range(arr.shape[1]):\n        # Filter out non-numeric values in the column\n        numeric_col = [x for x in arr[:, col] if isinstance(x, (int, float, np.integer, np.floating))]\n        if not numeric_col:\n            means.append(np.nan)  # or raise error if no numeric values\n        else:\n            means.append(np.mean(numeric_col))\n    return tuple(means)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/870_3",
        "turn": "3",
        "instruct_prompt": "If some tuples are shorter and missing values at certain positions, ignore those missing values and compute means only from available numerical data.",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        data = [('a', 1, 2), ('b', 2, 4), ('c', 3, 6)]\n        self.assertEqual(task_func(data), (2.0, 4.0))\n\n    def test_with_missing_values(self):\n        data = [('a', 1, 2), ('b', 2), ('c', 3, 6)]  # second tuple missing second value\n        result = task_func(data)\n        expected = (2.0, 4.0)  # mean of first col: (1+2+3)/3=2.0, second col: (2+6)/2=4.0\n        self.assertEqual(result, expected)\n\n    def test_all_missing_in_column(self):\n        data = [('a',), ('b',), ('c',)]  # all tuples missing numeric values\n        result = task_func(data)\n        self.assertTrue(all(np.isnan(x) for x in result))\n\n    def test_empty_input(self):\n        with self.assertRaises(ValueError):\n            task_func([])\n\n    def test_mixed_lengths(self):\n        data = [('a', 1, 2.1, 3), ('b', 2), ('c', 3, 4.3)]\n        result = task_func(data)\n        expected_first = (1+2+3)/3\n        expected_second = (2.1+4.3)/2\n        expected_third = 3  # only one value\n        self.assertEqual(result, (expected_first, expected_second, expected_third))\n",
        "code": "import numpy as np\n\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    if not data_list:\n        raise ValueError('Input data_list is empty')\n\n    # Extract the values after the first element for each tuple\n    numeric_data = [t[1:] for t in data_list]\n\n    # Determine the maximum length of tuples in numeric_data\n    max_len = max(len(t) for t in numeric_data)\n\n    means = []\n    for col in range(max_len):\n        col_values = []\n        for t in numeric_data:\n            if col < len(t):\n                val = t[col]\n                if isinstance(val, (int, float, np.integer, np.floating)):\n                    col_values.append(val)\n        if not col_values:\n            means.append(np.nan)\n        else:\n            means.append(np.mean(col_values))\n    return tuple(means)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/870_4",
        "turn": "4",
        "instruct_prompt": "Return the results as a pandas DataFrame with one column named 'Mean Value' and the index labeled as 'Position i' where i is the position index. If the input list is empty, return an empty DataFrame.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_normal_case(self):\n        data = [('a', 1, 2.0), ('b', 3, 4.0), ('c', 5, 6.0)]\n        result = task_func(data)\n        expected_index = ['Position 0', 'Position 1']\n        expected_values = [3.0, 4.0]  # mean of [1,3,5] and mean of [2.0,4.0,6.0]\n        self.assertIsInstance(result, pd.DataFrame)\n        self.assertListEqual(list(result.index), expected_index)\n        self.assertListEqual(list(result.columns), ['Mean Value'])\n        np.testing.assert_almost_equal(result['Mean Value'].values, expected_values)\n\n    def test_empty_input(self):\n        result = task_func([])\n        self.assertIsInstance(result, pd.DataFrame)\n        self.assertEqual(result.shape[0], 0)\n        self.assertListEqual(list(result.columns), ['Mean Value'])\n\n    def test_single_element_tuples(self):\n        data = [('a', 10), ('b', 20), ('c', 30)]\n        result = task_func(data)\n        expected_index = ['Position 0']\n        expected_values = [20.0]  # mean of [10, 20, 30]\n        self.assertListEqual(list(result.index), expected_index)\n        np.testing.assert_almost_equal(result['Mean Value'].values, expected_values)\n\n    def test_tuples_with_different_lengths(self):\n        data = [('a', 1), ('b', 2, 3), ('c', 4, 5, 6)]\n        result = task_func(data)\n        expected_index = ['Position 0', 'Position 1', 'Position 2']\n        expected_values = [ (1+2+4)/3, (3+5)/2, 6 ]\n        self.assertListEqual(list(result.index), expected_index)\n        np.testing.assert_almost_equal(result['Mean Value'].values, expected_values)\n",
        "code": "import numpy as np\nimport pandas as pd\n\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    if not data_list:\n        return pd.DataFrame(columns=['Mean Value'])\n\n    # Extract the values after the first element for each tuple\n    numeric_data = [t[1:] for t in data_list]\n\n    # Determine the maximum length of tuples in numeric_data\n    max_len = max(len(t) for t in numeric_data)\n\n    means = []\n    for col in range(max_len):\n        col_values = []\n        for t in numeric_data:\n            if col < len(t):\n                val = t[col]\n                if isinstance(val, (int, float, np.integer, np.floating)):\n                    col_values.append(val)\n        if not col_values:\n            means.append(np.nan)\n        else:\n            means.append(np.mean(col_values))\n\n    index = [f'Position {i}' for i in range(len(means))]\n    df = pd.DataFrame({'Mean Value': means}, index=index)\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 108,
    "task_id": "BigCodeBench/879",
    "mt_data": [
      {
        "task_id": "BigCodeBench/879_1",
        "turn": "1",
        "instruct_prompt": "Perform a chi-square test of independence for two categorical variables in a DataFrame. The function takes a DataFrame and two column names, constructs a contingency table from these columns, and returns the p-value of the chi-square test.\nYou should write self-contained code starting with:\n```\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\ndef task_func(data, col1, col2):\n```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_independence(self):\n        data = pd.DataFrame({\n            'A': ['x', 'x', 'y', 'y', 'x', 'y', 'x', 'y'],\n            'B': ['u', 'v', 'u', 'v', 'u', 'v', 'v', 'u']\n        })\n        p_value = task_func(data, 'A', 'B')\n        self.assertTrue(0 <= p_value <= 1)\n\n    def test_same_category(self):\n        data = pd.DataFrame({\n            'A': ['x', 'x', 'x', 'x'],\n            'B': ['u', 'u', 'u', 'u']\n        })\n        p_value = task_func(data, 'A', 'B')\n        self.assertTrue(0 <= p_value <= 1)\n\n    def test_different_sizes(self):\n        data = pd.DataFrame({\n            'A': ['x', 'x', 'y', 'y', 'z'],\n            'B': ['u', 'v', 'u', 'v', 'u']\n        })\n        p_value = task_func(data, 'A', 'B')\n        self.assertTrue(0 <= p_value <= 1)\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\n\ndef task_func(data, col1, col2):\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    _, p_value, _, _ = chi2_contingency(contingency_table)\n    return p_value\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/879_2",
        "turn": "2",
        "instruct_prompt": "Raise a ValueError if the input DataFrame is empty or if either of the specified columns does not exist in the DataFrame.",
        "test": "import unittest\nimport pandas as pd\nfrom scipy.stats import chi2_contingency\n\nclass TestCases(unittest.TestCase):\n    def test_valid_input(self):\n        data = pd.DataFrame({\n            'A': ['x', 'y', 'x', 'y', 'x'],\n            'B': ['one', 'one', 'two', 'two', 'one']\n        })\n        p_value = task_func(data, 'A', 'B')\n        self.assertIsInstance(p_value, float)\n\n    def test_empty_dataframe(self):\n        data = pd.DataFrame(columns=['A', 'B'])\n        with self.assertRaises(ValueError) as context:\n            task_func(data, 'A', 'B')\n        self.assertEqual(str(context.exception), 'Input DataFrame is empty')\n\n    def test_missing_col1(self):\n        data = pd.DataFrame({\n            'A': ['x', 'y', 'x'],\n            'B': ['one', 'one', 'two']\n        })\n        with self.assertRaises(ValueError) as context:\n            task_func(data, 'C', 'B')\n        self.assertEqual(str(context.exception), 'Specified columns do not exist in the DataFrame')\n\n    def test_missing_col2(self):\n        data = pd.DataFrame({\n            'A': ['x', 'y', 'x'],\n            'B': ['one', 'one', 'two']\n        })\n        with self.assertRaises(ValueError) as context:\n            task_func(data, 'A', 'D')\n        self.assertEqual(str(context.exception), 'Specified columns do not exist in the DataFrame')\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\n\ndef task_func(data, col1, col2):\n    if data.empty:\n        raise ValueError('Input DataFrame is empty')\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError('Specified columns do not exist in the DataFrame')\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    _, p_value, _, _ = chi2_contingency(contingency_table)\n    return p_value\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/879_3",
        "turn": "3",
        "instruct_prompt": "Raise a TypeError if either specified column contains non-categorical data (e.g., numerical data types).",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_valid_categorical_columns(self):\n        df = pd.DataFrame({\n            'A': pd.Categorical(['a', 'b', 'a', 'b']),\n            'B': pd.Categorical(['x', 'x', 'y', 'y'])\n        })\n        p_value = task_func(df, 'A', 'B')\n        self.assertTrue(isinstance(p_value, float))\n\n    def test_non_categorical_col1(self):\n        df = pd.DataFrame({\n            'A': [1, 2, 1, 2],  # numerical\n            'B': pd.Categorical(['x', 'x', 'y', 'y'])\n        })\n        with self.assertRaises(TypeError):\n            task_func(df, 'A', 'B')\n\n    def test_non_categorical_col2(self):\n        df = pd.DataFrame({\n            'A': pd.Categorical(['a', 'b', 'a', 'b']),\n            'B': [1, 2, 1, 2]  # numerical\n        })\n        with self.assertRaises(TypeError):\n            task_func(df, 'A', 'B')\n\n    def test_both_non_categorical(self):\n        df = pd.DataFrame({\n            'A': [1, 2, 1, 2],\n            'B': [3, 4, 3, 4]\n        })\n        with self.assertRaises(TypeError):\n            task_func(df, 'A', 'B')\n\n    def test_empty_dataframe(self):\n        df = pd.DataFrame(columns=['A', 'B'])\n        with self.assertRaises(ValueError):\n            task_func(df, 'A', 'B')\n\n    def test_missing_columns(self):\n        df = pd.DataFrame({\n            'A': pd.Categorical(['a', 'b']),\n            'C': pd.Categorical(['x', 'y'])\n        })\n        with self.assertRaises(ValueError):\n            task_func(df, 'A', 'B')\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\n\ndef task_func(data, col1, col2):\n    if data.empty:\n        raise ValueError('Input DataFrame is empty')\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError('Specified columns do not exist in the DataFrame')\n    \n    # Check if both columns have categorical dtype\n    if not (pd.api.types.is_categorical_dtype(data[col1]) and pd.api.types.is_categorical_dtype(data[col2])):\n        raise TypeError('Both columns must be categorical data types')\n\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    _, p_value, _, _ = chi2_contingency(contingency_table)\n    return p_value\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/879_4",
        "turn": "4",
        "instruct_prompt": "Raise a ValueError if either of the specified columns has fewer than two unique categories or if any category in the contingency table has less than 5 observations, as these violate the assumptions of the chi-square test.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_valid_case(self):\n        # Construct data so that each cell in the contingency table has at least 5 observations\n        data = pd.DataFrame({\n            'A': pd.Categorical(['x']*10 + ['y']*10),\n            'B': pd.Categorical(['m']*6 + ['n']*4 + ['m']*5 + ['n']*5)\n        })\n        # Contingency table:\n        # A\\B  m   n\n        # x    6   4\n        # y    5   5\n        # After construction, some cells have 4 which is less than 5, so adjust to make all >=5\n\n        # Adjust data to ensure all cells >=5\n        data = pd.DataFrame({\n            'A': pd.Categorical(['x']*11 + ['y']*11),\n            'B': pd.Categorical(['m']*6 + ['n']*5 + ['m']*6 + ['n']*5)\n        })\n        # Contingency table:\n        # x: m=6, n=5\n        # y: m=6, n=5\n\n        p_value = task_func(data, 'A', 'B')\n        self.assertTrue(isinstance(p_value, float))\n\n    def test_fewer_than_two_unique_categories_col1(self):\n        data = pd.DataFrame({\n            'A': pd.Categorical(['x', 'x', 'x', 'x']),\n            'B': pd.Categorical(['m', 'n', 'm', 'n'])\n        })\n        with self.assertRaises(ValueError) as cm:\n            task_func(data, 'A', 'B')\n        self.assertIn('at least two unique categories', str(cm.exception))\n\n    def test_fewer_than_two_unique_categories_col2(self):\n        data = pd.DataFrame({\n            'A': pd.Categorical(['x', 'y', 'x', 'y']),\n            'B': pd.Categorical(['m', 'm', 'm', 'm'])\n        })\n        with self.assertRaises(ValueError) as cm:\n            task_func(data, 'A', 'B')\n        self.assertIn('at least two unique categories', str(cm.exception))\n\n    def test_cell_with_less_than_five_observations(self):\n        data = pd.DataFrame({\n            'A': pd.Categorical(['x']*5 + ['y']*5 + ['z']*1),\n            'B': pd.Categorical(['m']*5 + ['n']*5 + ['m'])\n        })\n        # The category 'z' in A has only 1 observation\n        with self.assertRaises(ValueError) as cm:\n            task_func(data, 'A', 'B')\n        self.assertIn('at least 5 observations', str(cm.exception))\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\n\ndef task_func(data, col1, col2):\n    if data.empty:\n        raise ValueError('Input DataFrame is empty')\n    if col1 not in data.columns or col2 not in data.columns:\n        raise ValueError('Specified columns do not exist in the DataFrame')\n    \n    # Check if both columns have categorical dtype\n    if not (pd.api.types.is_categorical_dtype(data[col1]) and pd.api.types.is_categorical_dtype(data[col2])):\n        raise TypeError('Both columns must be categorical data types')\n\n    # Check if each column has at least two unique categories\n    if data[col1].nunique() < 2 or data[col2].nunique() < 2:\n        raise ValueError('Each specified column must have at least two unique categories')\n\n    contingency_table = pd.crosstab(data[col1], data[col2])\n\n    # Check if any cell in the contingency table has less than 5 observations\n    if (contingency_table < 5).any().any():\n        raise ValueError('All categories in the contingency table must have at least 5 observations')\n\n    _, p_value, _, _ = chi2_contingency(contingency_table)\n    return p_value\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 109,
    "task_id": "BigCodeBench/897",
    "mt_data": [
      {
        "task_id": "BigCodeBench/897_1",
        "turn": "1",
        "instruct_prompt": "Simulate rolling a dice multiple times and return the results as a list. You should write self-contained code starting with:\n```\nimport random\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\ndef task_func(rolls, seed=None):\n```",
        "test": "import unittest\nfrom collections import Counter\n\nclass TestCases(unittest.TestCase):\n    def test_length(self):\n        res = task_func(5, seed=42)\n        self.assertEqual(len(res), 5)\n\n    def test_range(self):\n        res = task_func(100, seed=1)\n        for value in res:\n            self.assertIn(value, NUMBERS)\n\n    def test_seed_reproducibility(self):\n        res1 = task_func(10, seed=123)\n        res2 = task_func(10, seed=123)\n        self.assertEqual(res1, res2)\n\n    def test_zero_rolls(self):\n        res = task_func(0, seed=10)\n        self.assertEqual(res, [])\n\n    def test_single_roll(self):\n        res = task_func(1, seed=99)\n        self.assertEqual(len(res), 1)\n        self.assertIn(res[0], NUMBERS)\n",
        "code": "import random\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    results = []\n    for _ in range(rolls):\n        result = random.choice(NUMBERS)\n        results.append(result)\n    return results\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/897_2",
        "turn": "2",
        "instruct_prompt": "Count the frequency of each dice outcome (1-6) from the simulated rolls and return the frequencies as a numpy array.",
        "test": "import unittest\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_frequency_counts(self):\n        # Test with a fixed seed and 12 rolls\n        # With seed=0, the sequence is deterministic\n        freq = task_func(12, seed=0)\n        # We know what sequence should be generated\n        # Let's reconstruct it to get expected frequencies\n        random.seed(0)\n        rolls = [random.choice(list(range(1, 7))) for _ in range(12)]\n        expected = [rolls.count(i) for i in range(1, 7)]\n        np.testing.assert_array_equal(freq, np.array(expected))\n        \n    def test_zero_rolls(self):\n        # No rolls, all frequencies should be 0\n        freq = task_func(0)\n        np.testing.assert_array_equal(freq, np.zeros(6, dtype=int))\n        \n    def test_all_possible_outcomes(self):\n        # If we force 6 rolls and patch random.choice to cycle through 1-6\n        # we'll get one of each outcome\n        original_choice = random.choice\n        try:\n            sequence = iter(range(1, 7))\n            random.choice = lambda x: next(sequence)\n            freq = task_func(6)\n            np.testing.assert_array_equal(freq, np.ones(6, dtype=int))\n        finally:\n            random.choice = original_choice\n",
        "code": "import random\nimport numpy as np\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    results = []\n    for _ in range(rolls):\n        result = random.choice(NUMBERS)\n        results.append(result)\n    # Count frequencies for 1-6\n    freq = [0] * 6\n    for r in results:\n        freq[r-1] += 1\n    return np.array(freq)",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/897_3",
        "turn": "3",
        "instruct_prompt": "Also create and return a histogram of the dice outcomes using matplotlib.",
        "test": "import unittest\nimport numpy as np\nfrom matplotlib.figure import Figure\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_histogram_return_types(self):\n        freq, fig, ax = task_func(20, seed=1)\n        self.assertIsInstance(freq, np.ndarray)\n        self.assertEqual(freq.shape, (6,))\n        # Check matplotlib figure and axes types\n        self.assertIsInstance(fig, Figure)\n        self.assertIsInstance(ax, Axes)\n\n    def test_histogram_content(self):\n        rolls = 30\n        freq, fig, ax = task_func(rolls, seed=42)\n        self.assertEqual(freq.sum(), rolls)\n        # The histogram bars should match the frequencies\n        bar_heights = [rect.get_height() for rect in ax.patches]\n        self.assertEqual(bar_heights, freq.tolist())\n        # Check x-axis labels\n        self.assertEqual(ax.get_xlabel(), 'Dice Face')\n        self.assertEqual(ax.get_ylabel(), 'Frequency')\n        self.assertEqual(ax.get_title(), 'Histogram of Dice Outcomes')\n\n    def test_histogram_zero_rolls(self):\n        freq, fig, ax = task_func(0, seed=123)\n        self.assertTrue(np.all(freq == 0))\n        # The histogram bars should all be zero\n        bar_heights = [rect.get_height() for rect in ax.patches]\n        self.assertTrue(all(h == 0 for h in bar_heights))\n",
        "code": "import random\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.pyplot as plt\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    results = []\n    for _ in range(rolls):\n        result = random.choice(NUMBERS)\n        results.append(result)\n    # Count frequencies for 1-6\n    freq = [0] * 6\n    for r in results:\n        freq[r-1] += 1\n    # Create and return histogram\n    fig, ax = plt.subplots()\n    ax.bar(range(1, 7), freq)\n    ax.set_xlabel('Dice Face')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Dice Outcomes')\n    plt.close(fig)  # Prevent automatic display in some environments\n    return np.array(freq), fig, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/897_4",
        "turn": "4",
        "instruct_prompt": "The histogram must have the title 'Histogram of Dice Rolls', x-axis labeled 'Dice Value', and y-axis labeled 'Frequency'.",
        "test": "import unittest\nimport matplotlib\nmatplotlib.use('Agg')\nimport numpy as np\n# Import the solution's task_func if in another file; here, assumed available in scope\n\nclass TestCases(unittest.TestCase):\n    def test_histogram_labels_and_title(self):\n        rolls = 20\n        freq, fig, ax = task_func(rolls, seed=123)\n        self.assertEqual(ax.get_xlabel(), 'Dice Value')\n        self.assertEqual(ax.get_ylabel(), 'Frequency')\n        self.assertEqual(ax.get_title(), 'Histogram of Dice Rolls')\n\n    def test_histogram_freq_sum(self):\n        rolls = 30\n        freq, fig, ax = task_func(rolls, seed=1)\n        self.assertEqual(freq.sum(), 30)\n        # Check that the labels are correct\n        self.assertEqual(ax.get_xlabel(), 'Dice Value')\n        self.assertEqual(ax.get_ylabel(), 'Frequency')\n        self.assertEqual(ax.get_title(), 'Histogram of Dice Rolls')\n",
        "code": "import random\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.pyplot as plt\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    results = []\n    for _ in range(rolls):\n        result = random.choice(NUMBERS)\n        results.append(result)\n    # Count frequencies for 1-6\n    freq = [0] * 6\n    for r in results:\n        freq[r-1] += 1\n    # Create and return histogram\n    fig, ax = plt.subplots()\n    ax.bar(range(1, 7), freq)\n    ax.set_xlabel('Dice Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Dice Rolls')\n    plt.close(fig)  # Prevent automatic display in some environments\n    return np.array(freq), fig, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/897_5",
        "turn": "5",
        "instruct_prompt": "Return a tuple containing the numpy frequency array and the matplotlib Axes object representing the histogram.",
        "test": "import unittest\nimport numpy as np\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_output_types(self):\n        freq, ax = task_func(10, seed=42)\n        self.assertIsInstance(freq, np.ndarray)\n        self.assertIsInstance(ax, Axes)\n    def test_frequency_shape(self):\n        freq, _ = task_func(100, seed=1)\n        self.assertEqual(freq.shape, (6,))\n    def test_frequency_values(self):\n        freq, _ = task_func(12, seed=0)\n        self.assertEqual(freq.sum(), 12)\n    def test_axes_content(self):\n        freq, ax = task_func(15, seed=3)\n        bars = [rect.get_height() for rect in ax.patches]\n        self.assertEqual(list(freq), bars)\n",
        "code": "import random\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.pyplot as plt\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\ndef task_func(rolls, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    results = []\n    for _ in range(rolls):\n        result = random.choice(NUMBERS)\n        results.append(result)\n    # Count frequencies for 1-6\n    freq = [0] * 6\n    for r in results:\n        freq[r-1] += 1\n    # Create and return histogram\n    fig, ax = plt.subplots()\n    ax.bar(range(1, 7), freq)\n    ax.set_xlabel('Dice Value')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Histogram of Dice Rolls')\n    plt.close(fig)  # Prevent automatic display in some environments\n    return np.array(freq), ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 110,
    "task_id": "BigCodeBench/906",
    "mt_data": [
      {
        "task_id": "BigCodeBench/906_1",
        "turn": "1",
        "instruct_prompt": "Write a function that creates the target directory if it doesn't exist and returns its path. You should write self-contained code starting with:\n```python\nimport os\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n```",
        "test": "import unittest\nimport os\nimport shutil\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = 'test_target_dir'\n        if os.path.exists(self.test_dir):\n            shutil.rmtree(self.test_dir)\n\n    def tearDown(self):\n        if os.path.exists(self.test_dir):\n            shutil.rmtree(self.test_dir)\n\n    def test_directory_creation(self):\n        # Directory does not exist initially\n        self.assertFalse(os.path.exists(self.test_dir))\n        result = task_func('some_source', self.test_dir)\n        self.assertTrue(os.path.exists(self.test_dir))\n        self.assertEqual(result, self.test_dir)\n\n    def test_directory_already_exists(self):\n        os.makedirs(self.test_dir)\n        self.assertTrue(os.path.exists(self.test_dir))\n        result = task_func('some_source', self.test_dir)\n        self.assertTrue(os.path.exists(self.test_dir))\n        self.assertEqual(result, self.test_dir)\n",
        "code": "import os\n\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n    return target_dir\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/906_2",
        "turn": "2",
        "instruct_prompt": "Modify the function to create a zip archive with the given archive_name inside the target directory and return the archive path.",
        "test": "import unittest\nimport tempfile\nimport os\nimport zipfile\n\nclass TestCases(unittest.TestCase):\n    def test_create_zip_archive(self):\n        with tempfile.TemporaryDirectory() as source_dir, tempfile.TemporaryDirectory() as target_dir:\n            # Create some files in source_dir\n            file1 = os.path.join(source_dir, 'file1.txt')\n            file2 = os.path.join(source_dir, 'subdir', 'file2.txt')\n            os.makedirs(os.path.dirname(file2))\n            with open(file1, 'w') as f:\n                f.write('hello')\n            with open(file2, 'w') as f:\n                f.write('world')\n\n            archive_name = 'test_archive.zip'\n            archive_path = task_func(source_dir, target_dir, archive_name)\n\n            # Check archive path\n            self.assertTrue(archive_path.startswith(target_dir))\n            self.assertTrue(archive_path.endswith(archive_name))\n            self.assertTrue(os.path.isfile(archive_path))\n\n            # Check contents of the zip archive\n            with zipfile.ZipFile(archive_path, 'r') as zipf:\n                namelist = zipf.namelist()\n                self.assertIn('file1.txt', namelist)\n                self.assertIn(os.path.join('subdir', 'file2.txt'), namelist)\n\n                # Check file contents inside the zip\n                with zipf.open('file1.txt') as f:\n                    self.assertEqual(f.read().decode(), 'hello')\n                with zipf.open(os.path.join('subdir', 'file2.txt')) as f:\n                    self.assertEqual(f.read().decode(), 'world')\n",
        "code": "import os\nimport zipfile\n\n\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    archive_path = os.path.join(target_dir, archive_name)\n\n    with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, _, files in os.walk(source_dir):\n            for file in files:\n                file_path = os.path.join(root, file)\n                arcname = os.path.relpath(file_path, start=source_dir)\n                zipf.write(file_path, arcname)\n\n    return archive_path\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/906_3",
        "turn": "3",
        "instruct_prompt": "Update the function to add files from the source directory to the archive only if their filename (without extension) ends with '_processed'.",
        "test": "import os\nimport unittest\nimport tempfile\nimport zipfile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.source_dir = tempfile.mkdtemp()\n        self.target_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        for folder in [self.source_dir, self.target_dir]:\n            for root, dirs, files in os.walk(folder, topdown=False):\n                for name in files:\n                    os.remove(os.path.join(root, name))\n                for name in dirs:\n                    os.rmdir(os.path.join(root, name))\n            os.rmdir(folder)\n\n    def test_only_processed_files_added(self):\n        files_to_create = [\n            'file1_processed.txt',\n            'file2_processed.csv',\n            'file3.txt',\n            'file4_processed',\n            'file5.doc',\n            'file6_processed.pdf'\n        ]\n\n        for filename in files_to_create:\n            path = os.path.join(self.source_dir, filename)\n            with open(path, 'w') as f:\n                f.write('test content')\n\n        archive_path = task_func(self.source_dir, self.target_dir)\n\n        self.assertTrue(os.path.isfile(archive_path))\n\n        with zipfile.ZipFile(archive_path, 'r') as zipf:\n            archived_files = zipf.namelist()\n\n        expected_files = [f for f in files_to_create if os.path.splitext(f)[0].endswith('_processed')]\n\n        self.assertCountEqual(archived_files, expected_files)\n\n    def test_no_files_added_if_none_processed(self):\n        files_to_create = [\n            'file1.txt',\n            'file2.csv',\n            'file3.doc'\n        ]\n\n        for filename in files_to_create:\n            path = os.path.join(self.source_dir, filename)\n            with open(path, 'w') as f:\n                f.write('test content')\n\n        archive_path = task_func(self.source_dir, self.target_dir)\n\n        with zipfile.ZipFile(archive_path, 'r') as zipf:\n            archived_files = zipf.namelist()\n\n        self.assertEqual(len(archived_files), 0)\n\n    def test_subdirectories_included(self):\n        sub_dir = os.path.join(self.source_dir, 'subfolder')\n        os.makedirs(sub_dir)\n\n        files_to_create = [\n            'a_processed.txt',\n            'b.txt'\n        ]\n\n        for filename in files_to_create:\n            path = os.path.join(sub_dir, filename)\n            with open(path, 'w') as f:\n                f.write('content')\n\n        archive_path = task_func(self.source_dir, self.target_dir)\n\n        with zipfile.ZipFile(archive_path, 'r') as zipf:\n            archived_files = zipf.namelist()\n\n        self.assertIn(os.path.join('subfolder', 'a_processed.txt'), archived_files)\n        self.assertNotIn(os.path.join('subfolder', 'b.txt'), archived_files)\n",
        "code": "import os\nimport zipfile\n\n\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    archive_path = os.path.join(target_dir, archive_name)\n\n    with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, _, files in os.walk(source_dir):\n            for file in files:\n                filename_without_ext, _ = os.path.splitext(file)\n                if filename_without_ext.endswith('_processed'):\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.relpath(file_path, start=source_dir)\n                    zipf.write(file_path, arcname)\n\n    return archive_path\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/906_4",
        "turn": "4",
        "instruct_prompt": "After adding each processed file to the archive, move that file from the source directory to the target directory.",
        "test": "import os\nimport unittest\nimport tempfile\nimport zipfile\nfrom shutil import rmtree\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create temporary source and target directories\n        self.source_dir = tempfile.mkdtemp()\n        self.target_dir = tempfile.mkdtemp()\n\n        # Create some files in source_dir\n        self.files = [\n            'file1_processed.txt',\n            'file2_processed.log',\n            'file3.txt',\n            'file4_processed.csv'\n        ]\n\n        for filename in self.files:\n            with open(os.path.join(self.source_dir, filename), 'w') as f:\n                f.write('test content')\n\n    def tearDown(self):\n        rmtree(self.source_dir)\n        rmtree(self.target_dir)\n\n    def test_task_func_moves_and_archives_processed_files(self):\n        archive_path = task_func(self.source_dir, self.target_dir, 'test_archive.zip')\n\n        # Check archive exists in target_dir\n        self.assertTrue(os.path.isfile(archive_path))\n\n        # Check that all _processed files are in the archive\n        with zipfile.ZipFile(archive_path, 'r') as zipf:\n            archived_files = zipf.namelist()\n\n        expected_archived_files = [f for f in self.files if os.path.splitext(f)[0].endswith('_processed')]\n\n        self.assertCountEqual(archived_files, expected_archived_files)\n\n        # Check that processed files are moved from source_dir to target_dir\n        for f in expected_archived_files:\n            self.assertFalse(os.path.exists(os.path.join(self.source_dir, f)))\n            self.assertTrue(os.path.exists(os.path.join(self.target_dir, f)))\n\n        # Check that non-processed files remain in source_dir\n        non_processed_files = [f for f in self.files if not os.path.splitext(f)[0].endswith('_processed')]\n        for f in non_processed_files:\n            self.assertTrue(os.path.exists(os.path.join(self.source_dir, f)))\n            self.assertFalse(os.path.exists(os.path.join(self.target_dir, f)))\n",
        "code": "import os\nimport shutil\nimport zipfile\n\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    archive_path = os.path.join(target_dir, archive_name)\n\n    with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, _, files in os.walk(source_dir):\n            for file in files:\n                filename_without_ext, _ = os.path.splitext(file)\n                if filename_without_ext.endswith('_processed'):\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.relpath(file_path, start=source_dir)\n                    zipf.write(file_path, arcname)\n                    # Move file to target_dir\n                    shutil.move(file_path, os.path.join(target_dir, file))\n\n    return archive_path\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 111,
    "task_id": "BigCodeBench/914",
    "mt_data": [
      {
        "task_id": "BigCodeBench/914_1",
        "turn": "1",
        "instruct_prompt": "Predict the stock closing prices for the next 7 days using simple linear regression. You should write self-contained code starting with:\n```\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\ndef task_func(df):\n```",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_linear_increasing(self):\n        # Create a dataframe with a clear increasing trend\n        data = {'Close': [10, 12, 14, 16, 18, 20, 22]}\n        df = pd.DataFrame(data)\n        result = task_func(df)\n        # The model should predict a continuation of the trend\n        expected = [24, 26, 28, 30, 32, 34, 36]  # continuing +2 each day\n        for r, e in zip(result, expected):\n            self.assertAlmostEqual(r, e, places=5)\n\n    def test_constant_prices(self):\n        # Constant closing prices\n        data = {'Close': [5, 5, 5, 5, 5]}\n        df = pd.DataFrame(data)\n        result = task_func(df)\n        expected = [5]*7\n        for r, e in zip(result, expected):\n            self.assertAlmostEqual(r, e, places=5)\n\n    def test_decreasing_prices(self):\n        # Decreasing closing prices\n        data = {'Close': [20, 18, 16, 14, 12]}\n        df = pd.DataFrame(data)\n        result = task_func(df)\n        expected = [10, 8, 6, 4, 2, 0, -2]  # continuing -2 each day\n        for r, e in zip(result, expected):\n            self.assertAlmostEqual(r, e, places=5)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    # Assume df has a 'Close' column with closing prices indexed by date or integer\n    # Prepare the feature: day index\n    X = np.arange(len(df)).reshape(-1, 1)\n    y = df['Close'].values\n\n    # Fit linear regression model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Predict next 7 days\n    future_X = np.arange(len(df), len(df) + 7).reshape(-1, 1)\n    predictions = model.predict(future_X)\n\n    # Return as a list\n    return predictions.tolist()",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/914_2",
        "turn": "2",
        "instruct_prompt": "Use a constant time step of 24*60*60 seconds to generate future timestamps for the next 7 days based on the maximum date in the input dataframe.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_future_timestamps_and_predictions(self):\n        # Create dataframe with datetime index and Close prices\n        dates = pd.date_range(start='2024-01-01', periods=10, freq='D')\n        close_prices = np.arange(10) * 10 + 100  # 100, 110, ..., 190\n        df = pd.DataFrame({'Close': close_prices}, index=dates)\n\n        result = task_func(df)\n\n        # Check length\n        self.assertEqual(len(result), 7)\n\n        # Check that dates are 1 day apart and start from day after max date\n        for i in range(7):\n            expected_date = dates[-1] + pd.Timedelta(days=i+1)\n            self.assertEqual(result[i][0], expected_date)\n\n        # Check predictions roughly follow linear trend (close to 200, 210, ...)\n        # Since linear regression fit on 0..9 with y=100..190, slope ~10\n        expected_preds = [close_prices[-1] + 10 * (i+1) for i in range(7)]\n        for i in range(7):\n            self.assertAlmostEqual(result[i][1], expected_preds[i], delta=1.0)\n\n    def test_non_datetime_index_should_fail(self):\n        # Provide a dataframe with integer index (previous round style)\n        df = pd.DataFrame({'Close': [100, 110, 120]})\n        # This should raise an error when trying to get max_date\n        with self.assertRaises(Exception):\n            task_func(df)\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\nSECONDS_IN_DAY = 24 * 60 * 60\n\ndef task_func(df):\n    # Assume df index is datetime-like\n    # Prepare the feature: day index starting from 0\n    X = np.arange(len(df)).reshape(-1, 1)\n    y = df['Close'].values\n\n    # Fit linear regression model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Get the maximum date from the index\n    max_date = df.index.max()\n\n    # Generate future timestamps for the next 7 days with constant step of 1 day in seconds\n    future_dates = [max_date + pd.Timedelta(seconds=SECONDS_IN_DAY * (i + 1)) for i in range(7)]\n\n    # Predict next 7 days\n    future_X = np.arange(len(df), len(df) + 7).reshape(-1, 1)\n    predictions = model.predict(future_X)\n\n    # Return predictions and future_dates as tuples in a list\n    return list(zip(future_dates, predictions))",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/914_3",
        "turn": "3",
        "instruct_prompt": "Convert the 'date' column in the dataframe to timestamps (seconds since epoch) before fitting the regression model and use these timestamps as features.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_with_date_column(self):\n        base_date = datetime(2023, 1, 1)\n        dates = [base_date + timedelta(days=i) for i in range(10)]\n        close_values = np.arange(10) * 2 + 5  # y = 2x + 5\n        df = pd.DataFrame({'date': dates, 'Close': close_values})\n\n        results = task_func(df)\n\n        # Check length\n        self.assertEqual(len(results), 7)\n\n        # Check future dates increase by 1 day\n        expected_dates = [dates[-1] + timedelta(days=i + 1) for i in range(7)]\n        for (res_date, _), exp_date in zip(results, expected_dates):\n            self.assertEqual(res_date.date(), exp_date.date())\n\n        # Check predictions increase (since y=2x+5 is increasing)\n        preds = [pred for _, pred in results]\n        for i in range(1, len(preds)):\n            self.assertGreater(preds[i], preds[i - 1])\n\n    def test_previous_round_fails(self):\n        # Old code uses index as features (0..9)\n        # New code uses 'date' timestamps which we make irregular to differ from index\n\n        def old_task_func(df):\n            import numpy as np\n            from sklearn.linear_model import LinearRegression\n            X = np.arange(len(df)).reshape(-1, 1)\n            y = df['Close'].values\n            model = LinearRegression()\n            model.fit(X, y)\n            max_index = df.index.max()\n            future_indices = np.arange(max_index + 1, max_index + 8).reshape(-1, 1)\n            predictions = model.predict(future_indices)\n            future_dates = future_indices.flatten()\n            return list(zip(future_dates, predictions))\n\n        base_date = datetime(2023, 1, 1)\n\n        # Create non-linear spaced 'date' column to differ from index\n        # For example, dates skip some days irregularly\n        irregular_days = [0, 1, 3, 6, 10, 15, 21, 28, 36, 45]\n        dates = [base_date + timedelta(days=d) for d in irregular_days]\n        close_values = np.arange(10) * 2 + 5\n        df = pd.DataFrame({'date': dates, 'Close': close_values})\n\n        old_results = old_task_func(df)\n        new_results = task_func(df)\n\n        old_preds = np.array([pred for _, pred in old_results])\n        new_preds = np.array([pred for _, pred in new_results])\n\n        # Assert predictions differ significantly\n        diff = np.abs(old_preds - new_preds)\n        mean_diff = diff.mean()\n        self.assertGreater(mean_diff, 1.0, \"Old and new predictions should differ significantly.\")\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    # Convert 'date' column to timestamps (seconds since epoch)\n    timestamps = pd.to_datetime(df['date']).values.astype('int64') // 10**9\n    X = timestamps.reshape(-1, 1)\n    y = df['Close'].values\n\n    # Fit linear regression model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Generate future timestamps for next 7 days (86400 seconds per day)\n    max_timestamp = timestamps.max()\n    future_timestamps = np.array([max_timestamp + 86400 * (i + 1) for i in range(7)]).reshape(-1, 1)\n\n    # Predict next 7 days\n    predictions = model.predict(future_timestamps)\n\n    # Convert future timestamps back to pandas Timestamps\n    future_dates = [pd.to_datetime(ts, unit='s') for ts in future_timestamps.flatten()]\n\n    # Return list of tuples (future_date, prediction)\n    return list(zip(future_dates, predictions))",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/914_4",
        "turn": "4",
        "instruct_prompt": "Plot the original data points and the predicted future prices on a matplotlib Axes object and return a tuple containing the list of predicted prices and the Axes object.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_return_types_and_plot(self):\n        data = {\n            'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04'],\n            'Close': [100, 102, 104, 106]\n        }\n        df = pd.DataFrame(data)\n\n        result, ax = task_func(df)\n\n        # Check result is a list of length 7\n        self.assertIsInstance(result, list)\n        self.assertEqual(len(result), 7)\n\n        # Check each predicted price is a float or np.float64\n        for price in result:\n            self.assertTrue(isinstance(price, (float, np.floating)))\n\n        # Check ax is a matplotlib Axes object\n        import matplotlib.axes\n        self.assertIsInstance(ax, matplotlib.axes.Axes)\n\n        # Check that the original data points are plotted (blue color line)\n        lines = ax.get_lines()\n        self.assertGreaterEqual(len(lines), 2)\n\n        # The first line corresponds to original data (blue color 'b')\n        original_line = lines[0]\n        self.assertEqual(original_line.get_color(), 'b')\n\n        # The second line corresponds to predicted data (red color 'r')\n        predicted_line = lines[1]\n        self.assertEqual(predicted_line.get_color(), 'r')\n\n    def test_task_func_prediction_values(self):\n        # Test with known linear data\n        data = {\n            'date': ['2023-01-01', '2023-01-02', '2023-01-03'],\n            'Close': [10, 20, 30]\n        }\n        df = pd.DataFrame(data)\n\n        predictions, _ = task_func(df)\n\n        # Since data is perfectly linear with slope 10 per day,\n        # predictions should continue with increments of about 10\n        self.assertEqual(len(predictions), 7)\n        for i in range(7):\n            expected = 30 + 10 * (i + 1)\n            self.assertAlmostEqual(predictions[i], expected, delta=1)\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    # Convert 'date' column to timestamps (seconds since epoch)\n    timestamps = pd.to_datetime(df['date']).values.astype('int64') // 10**9\n    X = timestamps.reshape(-1, 1)\n    y = df['Close'].values\n\n    # Fit linear regression model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Generate future timestamps for next 7 days (86400 seconds per day)\n    max_timestamp = timestamps.max()\n    future_timestamps = np.array([max_timestamp + 86400 * (i + 1) for i in range(7)]).reshape(-1, 1)\n\n    # Predict next 7 days\n    predictions = model.predict(future_timestamps)\n\n    # Convert future timestamps back to pandas Timestamps\n    future_dates = [pd.to_datetime(ts, unit='s') for ts in future_timestamps.flatten()]\n\n    # Plot original data points and predicted future prices\n    fig, ax = plt.subplots()\n    ax.plot(pd.to_datetime(df['date']), y, 'bo-', label='Original Data')\n    ax.plot(future_dates, predictions, 'ro-', label='Predicted Prices')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Close Price')\n    ax.legend()\n\n    # Return list of predicted prices and the Axes object\n    return list(predictions), ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 112,
    "task_id": "BigCodeBench/915",
    "mt_data": [
      {
        "task_id": "BigCodeBench/915_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a DataFrame and returns a DataFrame containing the rows where the 'closing_price' column values are outliers based on the Z-Score method. You should write self-contained code starting with:\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\ndef task_func(df, z_threshold=2):\n```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_outliers_detection(self):\n        data = {\n            'closing_price': [10, 12, 12, 13, 12, 11, 300, 12, 11, 10]\n        }\n        df = pd.DataFrame(data)\n        result = task_func(df, z_threshold=2)\n        # The outlier is the value 300\n        self.assertEqual(len(result), 1)\n        self.assertEqual(result.iloc[0]['closing_price'], 300)\n\n    def test_no_outliers(self):\n        data = {\n            'closing_price': [10, 11, 12, 13, 12, 11, 12, 12, 11, 10]\n        }\n        df = pd.DataFrame(data)\n        result = task_func(df, z_threshold=2)\n        # No outliers expected\n        self.assertTrue(result.empty)\n\n    def test_multiple_outliers(self):\n        data = {\n            'closing_price': [10, 200, 12, 13, 300, 11, 12, 12, 11, 400]\n        }\n        df = pd.DataFrame(data)\n        result = task_func(df, z_threshold=2)\n        # Only the value 400 passes the z-score threshold of 2 in this dataset\n        expected_outliers = [400]\n        self.assertEqual(sorted(result['closing_price'].tolist()), sorted(expected_outliers))\n",
        "code": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\nimport pandas as pd\n\ndef task_func(df, z_threshold=2):\n    # Calculate z-scores for the 'closing_price' column\n    z_scores = zscore(df['closing_price'])\n    # Select rows where the absolute z-score is greater than the threshold\n    outliers = df[np.abs(z_scores) > z_threshold]\n    return outliers\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/915_2",
        "turn": "2",
        "instruct_prompt": "Add a parameter 'z_threshold' to customize the Z-Score threshold used to identify outliers instead of using a fixed threshold.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Data with clear outlier (100) and a less extreme value (50)\n        self.df = pd.DataFrame({\n            'closing_price': [10, 12, 12, 13, 12, 11, 100, 50, 11, 14]\n        })\n\n    def test_missing_z_threshold_raises(self):\n        # Calling task_func without z_threshold should raise TypeError\n        with self.assertRaises(TypeError):\n            task_func(self.df)\n\n    def test_outliers_threshold_behavior(self):\n        # Test multiple thresholds and their effect on outlier detection\n        thresholds = [0.5, 1, 1.5, 2, 3]\n        previous_count = None\n        for threshold in thresholds:\n            outliers = task_func(self.df, threshold)\n            z_scores = zscore(self.df['closing_price'])\n            # Verify all outliers have abs(z-score) > threshold\n            for val in outliers['closing_price']:\n                idx = self.df[self.df['closing_price'] == val].index[0]\n                self.assertGreater(abs(z_scores[idx]), threshold)\n            # Verify the count of outliers is non-increasing as threshold increases\n            if previous_count is not None:\n                self.assertLessEqual(len(outliers), previous_count)\n            previous_count = len(outliers)\n\n    def test_outliers_include_known_extreme(self):\n        # At low threshold (0.5), 100 should be detected as outlier\n        outliers = task_func(self.df, 0.5)\n        self.assertIn(100, outliers['closing_price'].values)\n\n    def test_outliers_empty_for_high_threshold(self):\n        # At very high threshold, no outliers should be detected\n        outliers = task_func(self.df, 10)\n        self.assertEqual(len(outliers), 0)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import numpy as np\nimport pandas as pd\nfrom scipy.stats import zscore\n\ndef task_func(df, z_threshold):\n    # Calculate z-scores for the 'closing_price' column\n    z_scores = zscore(df['closing_price'])\n    # Select rows where the absolute z-score is greater than the threshold\n    outliers = df[np.abs(z_scores) > z_threshold]\n    return outliers\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/915_3",
        "turn": "3",
        "instruct_prompt": "Create a plot displaying the 'closing_price' values from the DataFrame, marking the outliers with a distinct marker and color. The x-axis label should be 'Index', the y-axis label should be 'Closing Price', and the plot title should be 'Outliers in Closing Prices'.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    def test_outlier_detection_and_plot(self):\n        # Create a sample DataFrame\n        data = {'closing_price': [10, 12, 11, 10, 300, 12, 11, 13, 10, 9]}\n        df = pd.DataFrame(data)\n\n        with patch('matplotlib.pyplot.plot') as mock_plot, \\\n             patch('matplotlib.pyplot.scatter') as mock_scatter, \\\n             patch('matplotlib.pyplot.xlabel') as mock_xlabel, \\\n             patch('matplotlib.pyplot.ylabel') as mock_ylabel, \\\n             patch('matplotlib.pyplot.title') as mock_title, \\\n             patch('matplotlib.pyplot.legend') as mock_legend, \\\n             patch('matplotlib.pyplot.show') as mock_show:\n\n            outliers = task_func(df, z_threshold=2)\n\n            # Check that outliers detected correctly\n            self.assertEqual(len(outliers), 1)\n            self.assertEqual(outliers.iloc[0]['closing_price'], 300)\n            self.assertIn(4, outliers.index)\n\n            # Check plotting calls\n            mock_plot.assert_called_once()\n            mock_scatter.assert_called_once()\n            mock_xlabel.assert_called_once_with('Index')\n            mock_ylabel.assert_called_once_with('Closing Price')\n            mock_title.assert_called_once_with('Outliers in Closing Prices')\n            mock_legend.assert_called_once()\n            mock_show.assert_called_once()\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import numpy as np\nimport pandas as pd\nfrom scipy.stats import zscore\nimport matplotlib.pyplot as plt\n\ndef task_func(df, z_threshold):\n    # Calculate z-scores for the 'closing_price' column\n    z_scores = zscore(df['closing_price'])\n    # Select rows where the absolute z-score is greater than the threshold\n    outliers = df[np.abs(z_scores) > z_threshold]\n\n    # Plot all closing prices\n    plt.figure(figsize=(8, 5))\n    plt.plot(df.index, df['closing_price'], label='Closing Price', marker='o', linestyle='-', color='blue')\n\n    # Plot outliers with distinct marker and color\n    plt.scatter(outliers.index, outliers['closing_price'], color='red', marker='x', label='Outliers')\n\n    # Set labels and title\n    plt.xlabel('Index')\n    plt.ylabel('Closing Price')\n    plt.title('Outliers in Closing Prices')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n    return outliers\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/915_4",
        "turn": "4",
        "instruct_prompt": "Return a tuple where the first element is the DataFrame containing the outliers and the second element is the matplotlib Axes object of the generated plot.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_outliers_and_axes_returned(self):\n        data = {'closing_price': [10, 10, 10, 100, 10, 10, 10]}\n        df = pd.DataFrame(data)\n        z_threshold = 2\n        outliers, ax = task_func(df, z_threshold)\n\n        # Check outliers is a DataFrame\n        self.assertIsInstance(outliers, pd.DataFrame)\n\n        # Check that outliers contain the expected outlier\n        self.assertTrue((outliers['closing_price'] == 100).any())\n\n        # Check ax is a matplotlib Axes object\n        self.assertIsInstance(ax, Axes)\n\n        # Check that the plot contains correct labels\n        self.assertEqual(ax.get_xlabel(), 'Index')\n        self.assertEqual(ax.get_ylabel(), 'Closing Price')\n        self.assertEqual(ax.get_title(), 'Outliers in Closing Prices')\n\n    def test_no_outliers(self):\n        data = {'closing_price': [10, 11, 9, 10, 9, 11, 10]}\n        df = pd.DataFrame(data)\n        z_threshold = 3\n        outliers, ax = task_func(df, z_threshold)\n\n        # Outliers should be empty DataFrame\n        self.assertTrue(outliers.empty)\n\n        # ax should still be an Axes object\n        self.assertIsInstance(ax, Axes)\n",
        "code": "import numpy as np\nimport pandas as pd\nfrom scipy.stats import zscore\nimport matplotlib.pyplot as plt\n\ndef task_func(df, z_threshold):\n    # Calculate z-scores for the 'closing_price' column\n    z_scores = zscore(df['closing_price'])\n    # Select rows where the absolute z-score is greater than the threshold\n    outliers = df[np.abs(z_scores) > z_threshold]\n\n    # Plot all closing prices\n    fig, ax = plt.subplots(figsize=(8, 5))\n    ax.plot(df.index, df['closing_price'], label='Closing Price', marker='o', linestyle='-', color='blue')\n\n    # Plot outliers with distinct marker and color\n    ax.scatter(outliers.index, outliers['closing_price'], color='red', marker='x', label='Outliers')\n\n    # Set labels and title\n    ax.set_xlabel('Index')\n    ax.set_ylabel('Closing Price')\n    ax.set_title('Outliers in Closing Prices')\n    ax.legend()\n    plt.tight_layout()\n\n    return outliers, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 113,
    "task_id": "BigCodeBench/916",
    "mt_data": [
      {
        "task_id": "BigCodeBench/916_1",
        "turn": "1",
        "instruct_prompt": "Visualize the distribution of stock closing prices using a box plot. You should write self-contained code starting with:\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(df: pd.DataFrame) -> tuple:\n```",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import PathPatch\n\nclass TestCases(unittest.TestCase):\n    def test_boxplot_output(self):\n        data = {'Close': [100, 102, 98, 101, 99, 105, 97, 103]}\n        df = pd.DataFrame(data)\n        fig, ax = task_func(df)\n        self.assertIsInstance(fig, plt.Figure)\n        self.assertIsInstance(ax, plt.Axes)\n        self.assertEqual(ax.get_ylabel(), 'Closing Price')\n        self.assertEqual(ax.get_title(), 'Box plot of Stock Closing Prices')\n        # Check presence of PathPatch objects (boxes) in the plot\n        boxes = [child for child in ax.get_children() if isinstance(child, PathPatch)]\n        self.assertTrue(len(boxes) > 0)\n\n    def test_empty_close_column(self):\n        df = pd.DataFrame({'Close': []})\n        fig, ax = task_func(df)\n        self.assertIsInstance(fig, plt.Figure)\n        self.assertIsInstance(ax, plt.Axes)\n        self.assertEqual(ax.get_ylabel(), 'Closing Price')\n        self.assertEqual(ax.get_title(), 'Box plot of Stock Closing Prices')\n\n    def test_close_column_missing(self):\n        df = pd.DataFrame({'Open': [100, 101]})\n        with self.assertRaises(KeyError):\n            task_func(df)\n",
        "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df: pd.DataFrame) -> tuple:\n    plt.figure(figsize=(8,6))\n    sns.boxplot(y=df['Close'])\n    plt.title('Box plot of Stock Closing Prices')\n    plt.ylabel('Closing Price')\n    plt.tight_layout()\n    fig = plt.gcf()\n    ax = plt.gca()\n    return fig, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/916_2",
        "turn": "2",
        "instruct_prompt": "Add a histogram of the stock closing prices next to the box plot within the same figure, so that both plots appear side by side.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_outputs_and_plots(self):\n        # Create sample data\n        data = {'Close': np.random.normal(loc=100, scale=10, size=100)}\n        df = pd.DataFrame(data)\n\n        fig, axs = task_func(df)\n\n        # Check figure type\n        self.assertIsInstance(fig, plt.Figure)\n\n        # Check that axs is a tuple of length 2\n        self.assertIsInstance(axs, tuple)\n        self.assertEqual(len(axs), 2)\n\n        # Check each element is an Axes instance\n        self.assertTrue(all(isinstance(ax, Axes) for ax in axs))\n\n        # Check that first plot is boxplot by checking y-axis label\n        self.assertEqual(axs[0].get_ylabel(), 'Closing Price')\n\n        # Check that second plot is histogram by checking x-axis label\n        self.assertEqual(axs[1].get_xlabel(), 'Closing Price')\n        self.assertEqual(axs[1].get_ylabel(), 'Frequency')\n\n        plt.close(fig)\n",
        "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df: pd.DataFrame) -> tuple:\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n    sns.boxplot(y=df['Close'], ax=ax1)\n    ax1.set_title('Box plot of Stock Closing Prices')\n    ax1.set_ylabel('Closing Price')\n\n    sns.histplot(df['Close'], bins=30, kde=False, ax=ax2)\n    ax2.set_title('Histogram of Stock Closing Prices')\n    ax2.set_xlabel('Closing Price')\n    ax2.set_ylabel('Frequency')\n\n    plt.tight_layout()\n    return fig, (ax1, ax2)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/916_3",
        "turn": "3",
        "instruct_prompt": "Set the title of the box plot to 'Box Plot of Closing Prices' and the title of the histogram to 'Histogram of Closing Prices'.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.text import Text\n\nclass TestCases(unittest.TestCase):\n    def test_titles(self):\n        data = {'Close': [10, 20, 15, 30, 25, 40, 35]}\n        df = pd.DataFrame(data)\n        fig, (ax1, ax2) = task_func(df)\n        self.assertIsInstance(fig, plt.Figure)\n        # Check title of box plot\n        self.assertIsInstance(ax1.title, Text)\n        self.assertEqual(ax1.get_title(), 'Box Plot of Closing Prices')\n        # Check title of histogram\n        self.assertIsInstance(ax2.title, Text)\n        self.assertEqual(ax2.get_title(), 'Histogram of Closing Prices')\n        plt.close(fig)\n",
        "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df: pd.DataFrame) -> tuple:\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n    sns.boxplot(y=df['Close'], ax=ax1)\n    ax1.set_title('Box Plot of Closing Prices')\n    ax1.set_ylabel('Closing Price')\n\n    sns.histplot(df['Close'], bins=30, kde=False, ax=ax2)\n    ax2.set_title('Histogram of Closing Prices')\n    ax2.set_xlabel('Closing Price')\n    ax2.set_ylabel('Frequency')\n\n    plt.tight_layout()\n    return fig, (ax1, ax2)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/916_4",
        "turn": "4",
        "instruct_prompt": "Return a tuple containing the matplotlib axes objects for the box plot and the histogram respectively. Also, ensure the figure layout is tight and the figure does not display automatically in interactive environments.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_axes_returned_and_layout(self):\n        data = {'Close': [10, 20, 20, 30, 40, 50, 60, 70, 80, 90, 100]}\n        df = pd.DataFrame(data)\n        result = task_func(df)\n\n        # The result must be a tuple of two matplotlib axes\n        self.assertIsInstance(result, tuple)\n        self.assertEqual(len(result), 2)\n        self.assertTrue(all(isinstance(ax, Axes) for ax in result))\n\n        ax1, ax2 = result\n\n        # Check titles and labels to confirm correct plots\n        self.assertEqual(ax1.get_title(), 'Box Plot of Closing Prices')\n        self.assertEqual(ax1.get_ylabel(), 'Closing Price')\n\n        self.assertEqual(ax2.get_title(), 'Histogram of Closing Prices')\n        self.assertEqual(ax2.get_xlabel(), 'Closing Price')\n        self.assertEqual(ax2.get_ylabel(), 'Frequency')\n\n    def test_fig_not_displayed_automatically(self):\n        # This test ensures plt.show() is not called implicitly by checking plt._pylab_helpers\n        # After calling task_func, no figures should be open (closed by plt.close)\n        data = {'Close': [1, 2, 3, 4, 5]}\n        df = pd.DataFrame(data)\n        _ = task_func(df)\n        # plt.get_fignums() returns list of open figure numbers\n        self.assertEqual(len(plt.get_fignums()), 0)\n",
        "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df: pd.DataFrame) -> tuple:\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n    sns.boxplot(y=df['Close'], ax=ax1)\n    ax1.set_title('Box Plot of Closing Prices')\n    ax1.set_ylabel('Closing Price')\n\n    sns.histplot(df['Close'], bins=30, kde=False, ax=ax2)\n    ax2.set_title('Histogram of Closing Prices')\n    ax2.set_xlabel('Closing Price')\n    ax2.set_ylabel('Frequency')\n\n    plt.tight_layout()\n    plt.close(fig)  # Prevent automatic display in interactive environments\n    return (ax1, ax2)",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 114,
    "task_id": "BigCodeBench/917",
    "mt_data": [
      {
        "task_id": "BigCodeBench/917_1",
        "turn": "1",
        "instruct_prompt": "Write a function to forecast the next 7 days of closing prices from a given DataFrame containing historical closing prices. You should write self-contained code starting with:\n```\nimport pandas as pd\nfrom typing import List, Tuple\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], None]:\n```",
        "test": "import unittest\nimport pandas as pd\nfrom typing import List, Tuple\n\nclass TestCases(unittest.TestCase):\n    def test_forecast_basic(self):\n        data = {'Close': [100, 101, 102, 103, 104]}\n        df = pd.DataFrame(data)\n        forecast, _ = task_func(df)\n        self.assertEqual(len(forecast), 7)\n        self.assertTrue(all(isinstance(x, float) for x in forecast))\n        self.assertTrue(all(x == 104.0 for x in forecast))\n\n    def test_empty_df(self):\n        df = pd.DataFrame()\n        forecast, _ = task_func(df)\n        self.assertEqual(forecast, [])\n\n    def test_missing_close_column(self):\n        df = pd.DataFrame({'Open': [1, 2, 3]})\n        forecast, _ = task_func(df)\n        self.assertEqual(forecast, [])\n\n    def test_single_row(self):\n        df = pd.DataFrame({'Close': [150]})\n        forecast, _ = task_func(df)\n        self.assertEqual(forecast, [150.0]*7)\n",
        "code": "import pandas as pd\nfrom typing import List, Tuple\n\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], None]:\n    # Simple forecasting by repeating the last closing price for next 7 days\n    if df.empty or 'Close' not in df.columns:\n        return ([], None)\n    last_price = df['Close'].iloc[-1]\n    forecast = [float(last_price)] * 7\n    return (forecast, None)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/917_2",
        "turn": "2",
        "instruct_prompt": "Use the ARIMA model from statsmodels to perform the forecasting with order (5, 1, 0).",
        "test": "import unittest\nimport pandas as pd\nfrom math import isclose\n\nclass TestCases(unittest.TestCase):\n    def test_empty_dataframe(self):\n        df = pd.DataFrame()\n        forecast, _ = task_func(df)\n        self.assertEqual(forecast, [])\n\n    def test_missing_close_column(self):\n        df = pd.DataFrame({'Open': [1, 2, 3]})\n        forecast, _ = task_func(df)\n        self.assertEqual(forecast, [])\n\n    def test_too_short_series(self):\n        df = pd.DataFrame({'Close': [10, 11, 12, 13, 14]})  # length 5 < 6\n        forecast, _ = task_func(df)\n        self.assertEqual(forecast, [])\n\n    def test_forecast_length_and_type(self):\n        df = pd.DataFrame({'Close': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]})\n        forecast, _ = task_func(df)\n        self.assertEqual(len(forecast), 7)\n        for val in forecast:\n            self.assertIsInstance(val, float)\n\n    def test_forecast_values_consistency(self):\n        # Provide a simple upward trend to check if forecast roughly continues upward\n        data = [10 + i for i in range(20)]\n        df = pd.DataFrame({'Close': data})\n        forecast, _ = task_func(df)\n        # Forecast values should be floats and generally increasing\n        self.assertEqual(len(forecast), 7)\n        for i in range(6):\n            self.assertLessEqual(forecast[i], forecast[i+1])\n\n    def test_forecast_values_not_constant(self):\n        # The previous round's code returns constant forecast, so this should fail that test\n        data = [100, 101, 102, 103, 104, 105, 106]\n        df = pd.DataFrame({'Close': data})\n        forecast, _ = task_func(df)\n        # Check that forecast is not all the same value\n        self.assertFalse(all(isclose(forecast[0], f) for f in forecast))\n",
        "code": "import pandas as pd\nfrom typing import List, Tuple, Optional\nfrom statsmodels.tsa.arima.model import ARIMA\n\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Optional[None]]:\n    # Use ARIMA model with order (5, 1, 0) to forecast next 7 days\n    if df.empty or 'Close' not in df.columns or len(df['Close']) < 6:\n        # Need at least 6 points to fit ARIMA(5,1,0)\n        return ([], None)\n    series = df['Close'].astype(float)\n    model = ARIMA(series, order=(5, 1, 0))\n    model_fit = model.fit()\n    forecast_result = model_fit.forecast(steps=7)\n    forecast = forecast_result.tolist()\n    return (forecast, None)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/917_3",
        "turn": "3",
        "instruct_prompt": "Plot the historical closing prices and the 7-day forecast on a matplotlib Axes object and return it along with the forecasted prices.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')  # Use a non-interactive backend for testing\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_with_valid_data(self):\n        # Create a DataFrame with 10 days of closing prices\n        dates = pd.date_range(start='2024-01-01', periods=10, freq='D')\n        close_prices = np.linspace(100, 110, 10)  # Increasing linearly\n        df = pd.DataFrame({'Close': close_prices}, index=dates)\n\n        ax, forecast = task_func(df)\n\n        # Check returned types\n        self.assertIsInstance(ax, Axes)\n        self.assertIsInstance(forecast, list)\n\n        # Forecast should have length 7\n        self.assertEqual(len(forecast), 7)\n\n        # Axes should have two lines: historical and forecast\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 2)\n\n        # Historical line x-data length should be 10\n        self.assertEqual(len(lines[0].get_xdata()), 10)\n\n        # Forecast line x-data length should be 7\n        self.assertEqual(len(lines[1].get_xdata()), 7)\n\n    def test_with_insufficient_data(self):\n        # Only 5 data points, less than required 6\n        dates = pd.date_range(start='2024-01-01', periods=5, freq='D')\n        close_prices = [100, 101, 102, 103, 104]\n        df = pd.DataFrame({'Close': close_prices}, index=dates)\n\n        ax, forecast = task_func(df)\n\n        # Forecast should be empty list\n        self.assertEqual(forecast, [])\n\n        # Axes object should be returned\n        self.assertIsInstance(ax, Axes)\n\n        # Axes should have no lines plotted\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 0)\n\n    def test_with_empty_dataframe(self):\n        df = pd.DataFrame()\n        ax, forecast = task_func(df)\n        self.assertEqual(forecast, [])\n        self.assertIsInstance(ax, Axes)\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 0)\n\n    def test_with_missing_close_column(self):\n        dates = pd.date_range(start='2024-01-01', periods=10, freq='D')\n        df = pd.DataFrame({'Open': np.arange(10)}, index=dates)\n        ax, forecast = task_func(df)\n        self.assertEqual(forecast, [])\n        self.assertIsInstance(ax, Axes)\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 0)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nfrom typing import List, Tuple\nfrom statsmodels.tsa.arima.model import ARIMA\nimport matplotlib.pyplot as plt\n\ndef task_func(df: pd.DataFrame) -> Tuple[plt.Axes, List[float]]:\n    # Use ARIMA model with order (5, 1, 0) to forecast next 7 days\n    if df.empty or 'Close' not in df.columns or len(df['Close']) < 6:\n        # Need at least 6 points to fit ARIMA(5,1,0)\n        fig, ax = plt.subplots()\n        return ax, []\n\n    series = df['Close'].astype(float)\n    model = ARIMA(series, order=(5, 1, 0))\n    model_fit = model.fit()\n    forecast_result = model_fit.forecast(steps=7)\n    forecast = forecast_result.tolist()\n\n    fig, ax = plt.subplots()\n    ax.plot(df.index, series, label='Historical Close')\n\n    # Create forecast dates assuming daily frequency\n    last_date = df.index[-1]\n    freq = None\n    if hasattr(df.index, 'freq') and df.index.freq is not None:\n        freq = df.index.freq\n    if freq is None:\n        freq = pd.infer_freq(df.index)\n    if freq is None:\n        freq = 'D'\n\n    forecast_index = pd.date_range(start=last_date, periods=8, freq=freq)[1:]\n\n    ax.plot(forecast_index, forecast, label='7-day Forecast')\n    ax.legend()\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Close Price')\n    ax.set_title('Historical Close Prices and 7-day Forecast')\n\n    return ax, forecast\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/917_4",
        "turn": "4",
        "instruct_prompt": "Ensure the function returns a tuple with a list of forecasted floats and a matplotlib Axes object, and include all necessary imports for pandas, matplotlib.pyplot, matplotlib.axes.Axes, statsmodels.tsa.arima.model.ARIMA, and typing.List, Tuple.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom typing import List\n\n# The function task_func is assumed to be imported here\n\nclass TestCases(unittest.TestCase):\n    def test_valid_forecast(self):\n        dates = pd.date_range(start='2023-01-01', periods=20, freq='D')\n        close_prices = [float(i) for i in range(20)]\n        df = pd.DataFrame({'Close': close_prices}, index=dates)\n\n        result = task_func(df)\n        self.assertIsInstance(result, tuple)\n        self.assertEqual(len(result), 2)\n\n        forecast, ax = result\n\n        self.assertIsInstance(forecast, list)\n        self.assertEqual(len(forecast), 7)\n        self.assertTrue(all(isinstance(x, float) for x in forecast))\n\n        self.assertIsInstance(ax, Axes)\n\n    def test_empty_dataframe(self):\n        df = pd.DataFrame()\n        forecast, ax = task_func(df)\n        self.assertEqual(forecast, [])\n        self.assertIsInstance(ax, Axes)\n\n    def test_missing_close_column(self):\n        dates = pd.date_range(start='2023-01-01', periods=10, freq='D')\n        df = pd.DataFrame({'Open': range(10)}, index=dates)\n        forecast, ax = task_func(df)\n        self.assertEqual(forecast, [])\n        self.assertIsInstance(ax, Axes)\n\n    def test_insufficient_data(self):\n        dates = pd.date_range(start='2023-01-01', periods=5, freq='D')\n        close_prices = [1.0, 2.0, 3.0, 4.0, 5.0]\n        df = pd.DataFrame({'Close': close_prices}, index=dates)\n        forecast, ax = task_func(df)\n        self.assertEqual(forecast, [])\n        self.assertIsInstance(ax, Axes)\n",
        "code": "import pandas as pd\nfrom typing import List, Tuple\nfrom statsmodels.tsa.arima.model import ARIMA\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\n\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    # Use ARIMA model with order (5, 1, 0) to forecast next 7 days\n    if df.empty or 'Close' not in df.columns or len(df['Close']) < 6:\n        # Need at least 6 points to fit ARIMA(5,1,0)\n        fig, ax = plt.subplots()\n        return [], ax\n\n    series = df['Close'].astype(float)\n    model = ARIMA(series, order=(5, 1, 0))\n    model_fit = model.fit()\n    forecast_result = model_fit.forecast(steps=7)\n    forecast = forecast_result.tolist()\n\n    fig, ax = plt.subplots()\n    ax.plot(df.index, series, label='Historical Close')\n\n    # Create forecast dates assuming daily frequency\n    last_date = df.index[-1]\n    freq = None\n    if hasattr(df.index, 'freq') and df.index.freq is not None:\n        freq = df.index.freq\n    if freq is None:\n        freq = pd.infer_freq(df.index)\n    if freq is None:\n        freq = 'D'\n\n    forecast_index = pd.date_range(start=last_date, periods=8, freq=freq)[1:]\n\n    ax.plot(forecast_index, forecast, label='7-day Forecast')\n    ax.legend()\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Close Price')\n    ax.set_title('Historical Close Prices and 7-day Forecast')\n\n    return forecast, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 115,
    "task_id": "BigCodeBench/928",
    "mt_data": [
      {
        "task_id": "BigCodeBench/928_1",
        "turn": "1",
        "instruct_prompt": "Count the frequency of all two-letter combinations in a given word. You should write self-contained code starting with:\n```\nfrom collections import Counter\nimport itertools\nimport string\ndef task_func(word: str) -> dict:\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        self.assertEqual(task_func('hello'), {'he':1, 'el':1, 'll':1, 'lo':1})\n\n    def test_repeated_letters(self):\n        self.assertEqual(task_func('aabbcc'), {'aa':1, 'ab':1, 'bb':1, 'bc':1, 'cc':1})\n\n    def test_single_letter(self):\n        self.assertEqual(task_func('a'), {})\n\n    def test_empty(self):\n        self.assertEqual(task_func(''), {})\n\n    def test_overlap(self):\n        self.assertEqual(task_func('banana'), {'ba':1, 'an':2, 'na':2})\n\n    def test_all_same(self):\n        self.assertEqual(task_func('aaaa'), {'aa':3})\n",
        "code": "from collections import Counter\nimport itertools\nimport string\n\ndef task_func(word: str) -> dict:\n    pairs = [word[i:i+2] for i in range(len(word) - 1)]\n    return dict(Counter(pairs))\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/928_2",
        "turn": "2",
        "instruct_prompt": "Only consider combinations made from lowercase English alphabets.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic_lowercase(self):\n        self.assertEqual(task_func('hello'), {'he':1, 'el':1, 'll':1, 'lo':1})\n    \n    def test_with_uppercase(self):\n        # 'HeLlo' -> only 'lo' is valid ('l' and 'o' are both lowercase at positions 3,4)\n        self.assertEqual(task_func('HeLlo'), {'lo':1})\n    \n    def test_with_digits_and_symbols(self):\n        # 'ab1c*d' -> only 'ab' is valid\n        self.assertEqual(task_func('ab1c*d'), {'ab': 1})\n\n    def test_all_non_lowercase(self):\n        self.assertEqual(task_func('1234!@'), {})\n\n    def test_mixed_adjacent(self):\n        # 'abCde' -> 'ab', 'de' are valid\n        self.assertEqual(task_func('abCde'), {'ab':1, 'de':1})\n\n    def test_empty(self):\n        self.assertEqual(task_func(''), {})\n        self.assertEqual(task_func('a'), {})\n",
        "code": "from collections import Counter\nimport string\n\ndef task_func(word: str) -> dict:\n    valid_chars = set(string.ascii_lowercase)\n    pairs = []\n    for i in range(len(word) - 1):\n        if word[i] in valid_chars and word[i+1] in valid_chars:\n            pairs.append(word[i] + word[i+1])\n    return dict(Counter(pairs))\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/928_3",
        "turn": "3",
        "instruct_prompt": "Include all possible two-letter combinations as keys in the dictionary, with a value of 0 if the combination does not appear in the word.",
        "test": "import unittest\nimport string\n\nclass TestCases(unittest.TestCase):\n    def test_all_two_letter_combinations_present(self):\n        # Test that all possible two-letter combinations are present as keys.\n        word = 'abacabadabacaba'\n        result = task_func(word)\n        all_combinations = {a + b for a in string.ascii_lowercase for b in string.ascii_lowercase}\n        self.assertEqual(set(result.keys()), all_combinations)\n\n    def test_counts_and_zeros(self):\n        word = 'abcabc'\n        result = task_func(word)\n        # 'ab': appears at positions 0 and 3 => 2\n        self.assertEqual(result['ab'], 2)\n        # 'bc': appears at positions 1 and 4 => 2\n        self.assertEqual(result['bc'], 2)\n        # 'ca': appears at positions 2 => 1\n        self.assertEqual(result['ca'], 1)\n        # 'zz': never appears\n        self.assertEqual(result['zz'], 0)\n        # 'az': never appears\n        self.assertEqual(result['az'], 0)\n\n    def test_non_alpha_ignored(self):\n        word = 'a1b2c3d4'\n        result = task_func(word)\n        # Only pairs of lowercase letters are counted\n        for comb in result:\n            self.assertIn(len(comb), [2])\n        # No valid pairs\n        for k in result:\n            self.assertEqual(result[k], 0)\n\n    def test_empty_string(self):\n        word = ''\n        result = task_func(word)\n        for k in result:\n            self.assertEqual(result[k], 0)\n\n    def test_single_letter(self):\n        word = 'a'\n        result = task_func(word)\n        for k in result:\n            self.assertEqual(result[k], 0)\n",
        "code": "from collections import Counter\nimport string\n\ndef task_func(word: str) -> dict:\n    valid_chars = set(string.ascii_lowercase)\n    # Generate all possible two-letter combinations\n    all_combinations = [a + b for a in string.ascii_lowercase for b in string.ascii_lowercase]\n    pairs = []\n    for i in range(len(word) - 1):\n        if word[i] in valid_chars and word[i+1] in valid_chars:\n            pairs.append(word[i] + word[i+1])\n    counts = Counter(pairs)\n    result = {comb: counts.get(comb, 0) for comb in all_combinations}\n    return result\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 116,
    "task_id": "BigCodeBench/942",
    "mt_data": [
      {
        "task_id": "BigCodeBench/942_1",
        "turn": "1",
        "instruct_prompt": "Create a function that generates a DataFrame with sales data for multiple categories over a specified period of time. You should write self-contained code starting with:```import pandas as pd\nimport numpy as np\n\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'W'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_output(self):\n        df = task_func()\n        # Check type\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check index name\n        self.assertEqual(df.index.name, 'Date')\n        # Check index length\n        self.assertEqual(len(df.index), 13)\n        # Check index frequency\n        self.assertEqual(pd.infer_freq(df.index), 'W-SUN')\n        # Check columns\n        expected_cols = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n        self.assertListEqual(list(df.columns), expected_cols)\n        # Check values are integers and within expected range\n        for col in expected_cols:\n            self.assertTrue((df[col] >= 50).all() and (df[col] <= 500).all())\n            self.assertTrue(pd.api.types.is_integer_dtype(df[col]))\n",
        "code": "import pandas as pd\nimport numpy as np\n\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'W'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    data = {}\n    for category in categories:\n        # Generate random sales data for each category\n        data[category] = np.random.randint(50, 500, size=periods)\n    df = pd.DataFrame(data, index=dates)\n    df.index.name = 'Date'\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/942_2",
        "turn": "2",
        "instruct_prompt": "Generate the sales data by creating a date range with the given start_date, periods, and freq, and for each date and category, generate random sales values between 100 and 500. Store the data in a DataFrame with columns: 'Date', 'Category', 'Sales'.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_structure_and_values(self):\n        df = task_func()\n        # Check columns\n        self.assertListEqual(sorted(df.columns.tolist()), ['Category', 'Date', 'Sales'])\n        # Check types\n        self.assertTrue(pd.api.types.is_datetime64_any_dtype(df['Date']))\n        self.assertTrue(pd.api.types.is_integer_dtype(df['Sales']))\n        self.assertTrue(df['Category'].dtype == object)\n        # Check date range length\n        unique_dates = df['Date'].unique()\n        self.assertEqual(len(unique_dates), 13)\n        # Check categories\n        unique_categories = set(df['Category'].unique())\n        self.assertEqual(unique_categories, set(['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']))\n        # Check sales values are between 100 and 500 inclusive\n        self.assertTrue(((df['Sales'] >= 100) & (df['Sales'] <= 500)).all())\n        # Check total number of rows\n        self.assertEqual(len(df), 13 * 5)\n",
        "code": "import pandas as pd\nimport numpy as np\n\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'W'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    records = []\n    for date in dates:\n        for category in categories:\n            sales = np.random.randint(100, 501)  # inclusive of 100 and 500\n            records.append({'Date': date, 'Category': category, 'Sales': sales})\n    df = pd.DataFrame(records)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/942_3",
        "turn": "3",
        "instruct_prompt": "Use Matplotlib to plot the sales data as a line chart showing sales trends over time for each category. Return both the DataFrame and the Matplotlib Axes object from the function.",
        "test": "import unittest\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_output(self):\n        df, ax = task_func()\n        # Check that df is a DataFrame\n        self.assertIsInstance(df, pd.DataFrame)\n        # Check that ax is a Matplotlib Axes object\n        self.assertTrue(hasattr(ax, 'plot'))\n        self.assertTrue(hasattr(ax, 'set_title'))\n\n    def test_df_content(self):\n        df, _ = task_func()\n        # Check columns\n        self.assertTrue(all(col in df.columns for col in ['Date', 'Category', 'Sales']))\n        # Check data types\n        self.assertTrue(pd.api.types.is_datetime64_any_dtype(df['Date']))\n        self.assertTrue(pd.api.types.is_integer_dtype(df['Sales']))\n        self.assertTrue(df['Category'].dtype == object or pd.api.types.is_categorical_dtype(df['Category']))\n\n    def test_plot_has_lines_for_all_categories(self):\n        _, ax = task_func()\n        # The number of lines plotted should equal the number of categories\n        # Access lines on the Axes\n        lines = ax.get_lines()\n        self.assertEqual(len(lines), 5)  # 5 categories\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'W'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    records = []\n    for date in dates:\n        for category in categories:\n            sales = np.random.randint(100, 501)  # inclusive of 100 and 500\n            records.append({'Date': date, 'Category': category, 'Sales': sales})\n    df = pd.DataFrame(records)\n\n    # Pivot the data to have categories as columns for plotting\n    pivot_df = df.pivot(index='Date', columns='Category', values='Sales')\n\n    fig, ax = plt.subplots()\n    pivot_df.plot(ax=ax, marker='o')\n    ax.set_title('Sales Trends Over Time by Category')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    ax.legend(title='Category')\n    plt.tight_layout()\n\n    return df, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/942_4",
        "turn": "4",
        "instruct_prompt": "Use the frequency string 'WOM-2FRI' for the date range to represent the second Friday of each month, and set the plot figure size to (12, 8), add a title 'Category-wise Sales Trends' and enable grid on the plot. Also, set the numpy random seed to 0 for reproducibility.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_output_and_plot(self):\n        df, ax = task_func()\n\n        # Check if df is a DataFrame\n        self.assertIsInstance(df, pd.DataFrame)\n\n        # Check if 'Date', 'Category', 'Sales' columns exist\n        self.assertTrue(all(col in df.columns for col in ['Date', 'Category', 'Sales']))\n\n        # Check that dates correspond to second Friday of each month\n        dates = df['Date'].unique()\n        self.assertEqual(len(dates), 13)\n        for date in dates:\n            # Friday is weekday 4 (Monday=0)\n            self.assertEqual(date.weekday(), 4)\n            # Second Friday falls between 8th and 14th day inclusive\n            self.assertTrue(8 <= date.day <= 14)\n\n        # Check random seed reproducibility: sales for first date and first category\n        first_date = dates[0]\n        first_category = 'Electronics'\n        sales_value = df[(df['Date'] == first_date) & (df['Category'] == first_category)]['Sales'].values[0]\n        self.assertEqual(sales_value, 272)  # Confirmed expected value\n\n        # Check figure size\n        fig = ax.get_figure()\n        width, height = fig.get_size_inches()\n        self.assertAlmostEqual(width, 12)\n        self.assertAlmostEqual(height, 8)\n\n        # Check title\n        self.assertEqual(ax.get_title(), 'Category-wise Sales Trends')\n\n        # Check grid is enabled by verifying visibility of grid lines\n        x_gridlines = ax.xaxis.get_gridlines()\n        y_gridlines = ax.yaxis.get_gridlines()\n        # At least one gridline on each axis should be visible\n        self.assertTrue(any(line.get_visible() for line in x_gridlines))\n        self.assertTrue(any(line.get_visible() for line in y_gridlines))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n\n\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    np.random.seed(0)  # Set random seed for reproducibility\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    records = []\n    for date in dates:\n        for category in categories:\n            sales = np.random.randint(100, 501)  # inclusive of 100 and 500\n            records.append({'Date': date, 'Category': category, 'Sales': sales})\n    df = pd.DataFrame(records)\n\n    # Pivot the data to have categories as columns for plotting\n    pivot_df = df.pivot(index='Date', columns='Category', values='Sales')\n\n    fig, ax = plt.subplots(figsize=(12, 8))\n    pivot_df.plot(ax=ax, marker='o')\n    ax.set_title('Category-wise Sales Trends')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sales')\n    ax.legend(title='Category')\n    ax.grid(True)\n    plt.tight_layout()\n\n    return df, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 117,
    "task_id": "BigCodeBench/945",
    "mt_data": [
      {
        "task_id": "BigCodeBench/945_1",
        "turn": "1",
        "instruct_prompt": "Generate a time series of sales data starting from a specified date with given parameters. You should write self-contained code starting with:\n```python\nimport pandas as pd\nimport numpy as np\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n```",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_default_behavior(self):\n        df = task_func()\n        self.assertEqual(len(df), 13)\n        self.assertTrue(pd.api.types.is_datetime64_any_dtype(df['date']))\n        self.assertTrue(((df['sales'] >= 50) & (df['sales'] < 200)).all())\n\n    def test_custom_start_date(self):\n        df = task_func(start_date='2020-05-01')\n        # The first 2nd Friday in May 2020 is 2020-05-08\n        self.assertEqual(df.iloc[0]['date'].strftime('%Y-%m-%d'), '2020-05-08')\n\n    def test_custom_periods(self):\n        df = task_func(periods=5)\n        self.assertEqual(len(df), 5)\n\n    def test_custom_freq(self):\n        df = task_func(freq='W-MON', periods=4)\n        self.assertEqual(len(df), 4)\n        self.assertTrue(all(df['date'].dt.weekday == 0))  # All Mondays\n\n    def test_provided_sales_data(self):\n        sales = [10, 20, 30]\n        df = task_func(periods=3, sales_data=sales)\n        self.assertTrue((df['sales'] == sales).all())\n\n    def test_sales_data_length_mismatch(self):\n        with self.assertRaises(ValueError):\n            task_func(periods=5, sales_data=[1, 2, 3])\n",
        "code": "import pandas as pd\nimport numpy as np\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    # Generate the date range according to the given frequency and periods\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    \n    # If sales_data is not provided, generate random sales data\n    if sales_data is None:\n        sales_data = np.random.randint(50, 200, size=periods)\n    else:\n        # If sales_data is provided, ensure its length matches periods\n        if len(sales_data) != periods:\n            raise ValueError(\"Length of sales_data must match periods\")\n\n    # Create a DataFrame with the dates and sales data\n    df = pd.DataFrame({'date': dates, 'sales': sales_data})\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/945_2",
        "turn": "2",
        "instruct_prompt": "If sales_data is not provided, generate random integer sales data between 100 and 500 for the given number of periods.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\n\nclass TestCases(unittest.TestCase):\n    def test_random_sales_data_range(self):\n        periods = 10\n        df = task_func(periods=periods, sales_data=None)\n        self.assertEqual(len(df), periods)\n        self.assertTrue(is_datetime(df['date']))\n        # Check sales data is within [100, 500]\n        self.assertTrue(((df['sales'] >= 100) & (df['sales'] <= 500)).all())\n\n    def test_provided_sales_data_length_mismatch(self):\n        periods = 5\n        sales_data = [100, 200]  # length mismatch\n        with self.assertRaises(ValueError):\n            task_func(periods=periods, sales_data=sales_data)\n\n    def test_provided_sales_data_used(self):\n        periods = 4\n        sales_data = [150, 250, 350, 450]\n        df = task_func(periods=periods, sales_data=sales_data)\n        self.assertTrue((df['sales'] == sales_data).all())\n\n    def test_date_range_length(self):\n        periods = 7\n        df = task_func(periods=periods)\n        self.assertEqual(len(df), periods)\n        self.assertTrue(is_datetime(df['date']))\n",
        "code": "import pandas as pd\nimport numpy as np\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    # Generate the date range according to the given frequency and periods\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    \n    # If sales_data is not provided, generate random sales data between 100 and 500\n    if sales_data is None:\n        sales_data = np.random.randint(100, 501, size=periods)\n    else:\n        # If sales_data is provided, ensure its length matches periods\n        if len(sales_data) != periods:\n            raise ValueError(\"Length of sales_data must match periods\")\n\n    # Create a DataFrame with the dates and sales data\n    df = pd.DataFrame({'date': dates, 'sales': sales_data})\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/945_3",
        "turn": "3",
        "instruct_prompt": "Create a pandas DataFrame with a date range starting from start_date using the given frequency and periods, and associate the sales data with these dates.",
        "test": "import unittest\nimport pandas as pd\nfrom pandas._testing import assert_frame_equal\n\nclass TestCases(unittest.TestCase):\n    def test_valid_input(self):\n        start_date = '2020-01-01'\n        periods = 5\n        freq = 'D'\n        sales_data = [10, 20, 30, 40, 50]\n        expected_dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n        expected_df = pd.DataFrame({'date': expected_dates, 'sales': sales_data})\n\n        result_df = task_func(start_date=start_date, periods=periods, freq=freq, sales_data=sales_data)\n        assert_frame_equal(result_df, expected_df)\n\n    def test_sales_data_none_raises(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(sales_data=None)\n        self.assertEqual(str(cm.exception), \"sales_data must be provided\")\n\n    def test_sales_data_length_mismatch_raises(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(periods=3, sales_data=[1, 2])\n        self.assertEqual(str(cm.exception), \"Length of sales_data must match periods\")\n",
        "code": "import pandas as pd\n\ndef task_func(start_date='2016-01-01', periods=13, freq='W', sales_data=None):\n    # Generate the date range according to the given frequency and periods\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n\n    # If sales_data is not provided, raise an error since it is required to associate sales with dates\n    if sales_data is None:\n        raise ValueError(\"sales_data must be provided\")\n    else:\n        # If sales_data is provided, ensure its length matches periods\n        if len(sales_data) != periods:\n            raise ValueError(\"Length of sales_data must match periods\")\n\n    # Create a DataFrame with the dates and sales data\n    df = pd.DataFrame({'date': dates, 'sales': sales_data})\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/945_4",
        "turn": "4",
        "instruct_prompt": "Use sklearn's LinearRegression to fit a model on the generated or provided sales data indexed by time, then forecast future sales for the same number of periods and return the forecast as a numpy array.",
        "test": "import unittest\nimport numpy as np\nfrom numpy.testing import assert_array_almost_equal\n\nclass TestCases(unittest.TestCase):\n    def test_forecast_length_and_type(self):\n        sales_data = [100, 120, 130, 150, 170, 200, 210, 230, 250, 270, 300, 320, 350]\n        forecast = task_func(sales_data=sales_data)\n        self.assertIsInstance(forecast, np.ndarray)\n        self.assertEqual(len(forecast), len(sales_data))\n\n    def test_forecast_values_linear_trend(self):\n        # Sales data with an obvious linear trend: y = 10 * t + 5\n        sales_data = [10 * t + 5 for t in range(13)]\n        forecast = task_func(sales_data=sales_data)\n        expected = [10 * t + 5 for t in range(13, 26)]\n        assert_array_almost_equal(forecast, expected, decimal=5)\n\n    def test_error_on_missing_sales_data(self):\n        with self.assertRaises(ValueError):\n            task_func()\n\n    def test_error_on_length_mismatch(self):\n        sales_data = [100, 200]\n        with self.assertRaises(ValueError):\n            task_func(sales_data=sales_data)\n",
        "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(start_date='2016-01-01', periods=13, freq='W', sales_data=None):\n    # Generate the date range according to the given frequency and periods\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n\n    # If sales_data is not provided, raise an error since it is required to associate sales with dates\n    if sales_data is None:\n        raise ValueError(\"sales_data must be provided\")\n    else:\n        # If sales_data is provided, ensure its length matches periods\n        if len(sales_data) != periods:\n            raise ValueError(\"Length of sales_data must match periods\")\n\n    # Prepare features X as time indices and target y as sales\n    X = np.arange(periods).reshape(-1, 1)\n    y = np.array(sales_data)\n\n    # Fit LinearRegression model\n    model = LinearRegression()\n    model.fit(X, y)\n\n    # Forecast for the next 'periods' time points\n    X_forecast = np.arange(periods, periods * 2).reshape(-1, 1)\n    y_forecast = model.predict(X_forecast)\n\n    return y_forecast",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 118,
    "task_id": "BigCodeBench/952",
    "mt_data": [
      {
        "task_id": "BigCodeBench/952_1",
        "turn": "1",
        "instruct_prompt": "Assign a specified number of tasks to employees and return a DataFrame with these assignments. You should write self-contained code starting with:\n```\nimport pandas as pd\nimport random\nfrom datetime import datetime\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_basic_assignment(self):\n        task_list = ['Task A', 'Task B', 'Task C', 'Task D', 'Task E']\n        n_tasks = 3\n        df = task_func(task_list, n_tasks, employees=[\"Alice\", \"Bob\"], seed=42)\n        self.assertEqual(len(df), n_tasks)\n        self.assertIn('Task', df.columns)\n        self.assertIn('Employee', df.columns)\n        # Ensure employees are assigned in round-robin\n        self.assertEqual(list(df['Employee']), ['Alice', 'Bob', 'Alice'])\n\n    def test_employee_wraps_around(self):\n        task_list = ['T1', 'T2', 'T3', 'T4']\n        n_tasks = 4\n        employees = ['E1', 'E2']\n        df = task_func(task_list, n_tasks, employees=employees, seed=1)\n        expected_employees = ['E1', 'E2', 'E1', 'E2']\n        self.assertEqual(list(df['Employee']), expected_employees)\n\n    def test_error_on_too_many_tasks(self):\n        task_list = ['T1', 'T2']\n        n_tasks = 3\n        with self.assertRaises(ValueError):\n            task_func(task_list, n_tasks)\n\n    def test_no_seed_randomness(self):\n        task_list = ['A', 'B', 'C', 'D']\n        n_tasks = 2\n        df1 = task_func(task_list, n_tasks)\n        df2 = task_func(task_list, n_tasks)\n        # Without seed, likely not the same\n        self.assertFalse(df1.equals(df2))\n\n    def test_with_seed_determinism(self):\n        task_list = ['A', 'B', 'C', 'D']\n        n_tasks = 2\n        df1 = task_func(task_list, n_tasks, seed=123)\n        df2 = task_func(task_list, n_tasks, seed=123)\n        self.assertTrue(df1.equals(df2))\n",
        "code": "import pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if seed is not None:\n        random.seed(seed)\n    if n_tasks > len(task_list):\n        raise ValueError(\"n_tasks cannot be greater than the number of available tasks.\")\n    selected_tasks = random.sample(task_list, n_tasks)\n    assignments = []\n    for i, task in enumerate(selected_tasks):\n        employee = employees[i % len(employees)]\n        assignments.append({'Task': task, 'Employee': employee})\n    df = pd.DataFrame(assignments)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/952_2",
        "turn": "2",
        "instruct_prompt": "Task names must be sanitized by replacing spaces with underscores before assignment.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_sanitized_task_names(self):\n        tasks = ['Write report', 'Attend meeting', 'Fix bug', 'Code review']\n        df = task_func(tasks, 4, seed=42)\n        sanitized_tasks_expected = [t.replace(' ', '_') for t in tasks]\n        # The selected tasks may be in any order due to random.sample\n        for t in df['Task']:\n            self.assertIn(t, sanitized_tasks_expected)\n            self.assertNotIn(' ', t)\n    def test_assignment_count(self):\n        tasks = ['Task One', 'Task Two', 'Task Three']\n        df = task_func(tasks, 3, seed=1)\n        self.assertEqual(len(df), 3)\n        # All task names should be sanitized\n        for t in df['Task']:\n            self.assertNotIn(' ', t)\n    def test_error_on_too_many_tasks(self):\n        tasks = ['Alpha Beta', 'Gamma Delta']\n        with self.assertRaises(ValueError):\n            task_func(tasks, 3)\n",
        "code": "import pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if seed is not None:\n        random.seed(seed)\n    if n_tasks > len(task_list):\n        raise ValueError(\"n_tasks cannot be greater than the number of available tasks.\")\n    selected_tasks = random.sample(task_list, n_tasks)\n    assignments = []\n    for i, task in enumerate(selected_tasks):\n        sanitized_task = task.replace(' ', '_')\n        employee = employees[i % len(employees)]\n        assignments.append({'Task': sanitized_task, 'Employee': employee})\n    df = pd.DataFrame(assignments)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/952_3",
        "turn": "3",
        "instruct_prompt": "All assigned tasks must have a due date set to the current system date in 'YYYY-MM-DD' format.",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_due_date_column_and_format(self):\n        tasks = [\"Task A\", \"Task B\", \"Task C\"]\n        n = 2\n        df = task_func(tasks, n, seed=42)\n        self.assertIn('Due Date', df.columns)\n        current_date = datetime.now().strftime('%Y-%m-%d')\n        for due_date in df['Due Date']:\n            self.assertEqual(due_date, current_date)\n            # Check the format is 'YYYY-MM-DD'\n            try:\n                datetime.strptime(due_date, '%Y-%m-%d')\n            except ValueError:\n                self.fail(f\"Date {due_date} is not in YYYY-MM-DD format.\")\n\n    def test_due_date_with_multiple_tasks(self):\n        tasks = [f\"Task {i}\" for i in range(10)]\n        n = 7\n        df = task_func(tasks, n, seed=1)\n        self.assertEqual(len(df), n)\n        current_date = datetime.now().strftime('%Y-%m-%d')\n        self.assertTrue(all(d == current_date for d in df['Due Date']))\n",
        "code": "import pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if seed is not None:\n        random.seed(seed)\n    if n_tasks > len(task_list):\n        raise ValueError(\"n_tasks cannot be greater than the number of available tasks.\")\n    selected_tasks = random.sample(task_list, n_tasks)\n    assignments = []\n    current_date = datetime.now().strftime('%Y-%m-%d')\n    for i, task in enumerate(selected_tasks):\n        sanitized_task = task.replace(' ', '_')\n        employee = employees[i % len(employees)]\n        assignments.append({'Task': sanitized_task, 'Employee': employee, 'Due Date': current_date})\n    df = pd.DataFrame(assignments)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/952_4",
        "turn": "4",
        "instruct_prompt": "Raise a ValueError if n_tasks is negative.",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_n_tasks_negative(self):\n        task_list = ['Task A', 'Task B', 'Task C']\n        with self.assertRaises(ValueError) as cm:\n            task_func(task_list, -1)\n        self.assertIn('n_tasks cannot be negative', str(cm.exception))\n    \n    def test_n_tasks_zero(self):\n        task_list = ['Task A', 'Task B']\n        df = task_func(task_list, 0)\n        self.assertTrue(isinstance(df, pd.DataFrame))\n        self.assertEqual(len(df), 0)\n",
        "code": "import pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks cannot be negative.\")\n    if seed is not None:\n        random.seed(seed)\n    if n_tasks > len(task_list):\n        raise ValueError(\"n_tasks cannot be greater than the number of available tasks.\")\n    selected_tasks = random.sample(task_list, n_tasks)\n    assignments = []\n    current_date = datetime.now().strftime('%Y-%m-%d')\n    for i, task in enumerate(selected_tasks):\n        sanitized_task = task.replace(' ', '_')\n        employee = employees[i % len(employees)]\n        assignments.append({'Task': sanitized_task, 'Employee': employee, 'Due Date': current_date})\n    df = pd.DataFrame(assignments)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/952_5",
        "turn": "5",
        "instruct_prompt": "The output DataFrame must have columns 'Task Name', 'Assigned To', and 'Due Date', with each row representing an assigned task.",
        "test": "import unittest\nimport pandas as pd\nfrom datetime import datetime\n\nclass TestCases(unittest.TestCase):\n    def test_output_dataframe_columns(self):\n        tasks = ['Write report', 'Update database', 'Email client', 'Fix bug']\n        n_tasks = 3\n        df = task_func(tasks, n_tasks, seed=1)\n        expected_columns = ['Task Name', 'Assigned To', 'Due Date']\n        self.assertEqual(list(df.columns), expected_columns)\n        self.assertEqual(len(df), n_tasks)\n        # Check that each row has a task, employee, and due date\n        for _, row in df.iterrows():\n            self.assertIsInstance(row['Task Name'], str)\n            self.assertIsInstance(row['Assigned To'], str)\n            self.assertIsInstance(row['Due Date'], str)\n            # Check that date is in YYYY-MM-DD format\n            try:\n                datetime.strptime(row['Due Date'], '%Y-%m-%d')\n            except ValueError:\n                self.fail(\"Due Date is not in YYYY-MM-DD format\")\n\n    def test_column_names_exact(self):\n        tasks = ['A', 'B', 'C']\n        df = task_func(tasks, 2, seed=42)\n        self.assertEqual(list(df.columns), ['Task Name', 'Assigned To', 'Due Date'])\n\n    def test_row_count(self):\n        tasks = ['Task1', 'Task2', 'Task3', 'Task4']\n        df = task_func(tasks, 4, seed=5)\n        self.assertEqual(len(df), 4)\n",
        "code": "import pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    if n_tasks < 0:\n        raise ValueError(\"n_tasks cannot be negative.\")\n    if seed is not None:\n        random.seed(seed)\n    if n_tasks > len(task_list):\n        raise ValueError(\"n_tasks cannot be greater than the number of available tasks.\")\n    selected_tasks = random.sample(task_list, n_tasks)\n    assignments = []\n    current_date = datetime.now().strftime('%Y-%m-%d')\n    for i, task in enumerate(selected_tasks):\n        sanitized_task = task.replace(' ', '_')\n        employee = employees[i % len(employees)]\n        assignments.append({'Task Name': sanitized_task, 'Assigned To': employee, 'Due Date': current_date})\n    df = pd.DataFrame(assignments, columns=['Task Name', 'Assigned To', 'Due Date'])\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 119,
    "task_id": "BigCodeBench/955",
    "mt_data": [
      {
        "task_id": "BigCodeBench/955_1",
        "turn": "1",
        "instruct_prompt": "Write a function that counts the frequency of each unique word in a given text and returns the counts. You should write self-contained code starting with:```python\nimport collections\ndef task_func(mystrings, text):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        text = 'apple banana apple orange banana apple'\n        expected = {'apple': 3, 'banana': 2, 'orange': 1}\n        self.assertEqual(task_func(None, text), expected)\n\n    def test_empty(self):\n        self.assertEqual(task_func(None, ''), {})\n\n    def test_single_word(self):\n        self.assertEqual(task_func(None, 'hello'), {'hello': 1})\n\n    def test_multiple_spaces(self):\n        text = 'hello   world  hello'\n        expected = {'hello': 2, 'world': 1}\n        self.assertEqual(task_func(None, text), expected)\n\n    def test_punctuation(self):\n        text = 'hello, world! hello.'\n        # Since split on spaces, punctuation remains attached\n        expected = {'hello,': 1, 'world!': 1, 'hello.': 1}\n        self.assertEqual(task_func(None, text), expected)",
        "code": "import collections\ndef task_func(mystrings, text):\n    words = text.split()\n    return dict(collections.Counter(words))",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/955_2",
        "turn": "2",
        "instruct_prompt": "Make the word counting case-insensitive.",
        "test": "import unittest\nimport collections\n\nclass TestCases(unittest.TestCase):\n    def test_case_insensitive_count(self):\n        # Mixed case input\n        text = 'Hello hello HeLLo hELlo world'\n        expected = {'hello': 4, 'world': 1}\n        self.assertEqual(task_func([], text), expected)\n\n    def test_single_word(self):\n        text = 'Python'\n        expected = {'python': 1}\n        self.assertEqual(task_func([], text), expected)\n\n    def test_empty_string(self):\n        text = ''\n        expected = {}\n        self.assertEqual(task_func([], text), expected)\n\n    def test_multiple_words(self):\n        text = 'This is a Test. This test is simple.'\n        # Note: punctuation remains attached to words here, so 'Test.' and 'test' differ\n        expected = {'this': 2, 'is': 2, 'a': 1, 'test.': 1, 'test': 1, 'simple.': 1}\n        self.assertEqual(task_func([], text), expected)",
        "code": "import collections\ndef task_func(mystrings, text):\n    words = text.lower().split()\n    return dict(collections.Counter(words))",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/955_3",
        "turn": "3",
        "instruct_prompt": "Replace spaces in the given list of words (mystrings) with underscores within the text before counting frequencies.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_replace_spaces_and_split(self):\n        mystrings = ['irrelevant']\n        text = 'a b_c'\n        # After replacing spaces with underscores: 'a_b_c'\n        # Splitting by underscores: ['a', 'b', 'c']\n        expected = {'a': 1, 'b': 1, 'c': 1}\n        result = task_func(mystrings, text)\n        self.assertEqual(result, expected)\n\n    def test_previous_solution_fails_on_this(self):\n        # Previous solution splits on spaces, tokens would be ['a', 'b_c']\n        # Counts would be {'a': 1, 'b_c': 1} which is different\n        mystrings = ['irrelevant']\n        text = 'a b_c'\n        expected = {'a': 1, 'b': 1, 'c': 1}\n        result = task_func(mystrings, text)\n        self.assertEqual(result, expected)\n\n    def test_multiple_spaces(self):\n        mystrings = ['irrelevant']\n        text = 'hello  world'\n        # Replace spaces with underscores: 'hello__world'\n        # Split by underscores: ['hello', '', 'world'] => filter empty\n        expected = {'hello': 1, 'world': 1}\n        result = task_func(mystrings, text)\n        self.assertEqual(result, expected)\n\n    def test_text_with_only_spaces(self):\n        mystrings = ['irrelevant']\n        text = '   '\n        # After replacement: '___'\n        # Split by underscores: ['', '', '', ''] => all empty filtered\n        expected = {}\n        result = task_func(mystrings, text)\n        self.assertEqual(result, expected)\n\n    def test_text_without_spaces(self):\n        mystrings = ['irrelevant']\n        text = 'abc_def'\n        # No spaces replaced, so text stays 'abc_def'\n        # Split by underscores: ['abc', 'def']\n        expected = {'abc': 1, 'def': 1}\n        result = task_func(mystrings, text)\n        self.assertEqual(result, expected)",
        "code": "import collections\n\ndef task_func(mystrings, text):\n    # Replace spaces in the text with underscores\n    modified_text = text.replace(' ', '_').lower()\n    # Split the modified text by underscores\n    words = [w for w in modified_text.split('_') if w != '']\n    return dict(collections.Counter(words))",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/955_4",
        "turn": "4",
        "instruct_prompt": "Raise a ValueError if the input text is empty.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_normal_input(self):\n        result = task_func(None, 'Hello world hello')\n        expected = {'hello': 2, 'world': 1}\n        self.assertEqual(result, expected)\n\n    def test_empty_string_raises(self):\n        with self.assertRaises(ValueError):\n            task_func(None, '')\n\n    def test_only_spaces(self):\n        # Spaces replaced by underscores, split results in empty words, but not empty string\n        result = task_func(None, '   ')\n        self.assertEqual(result, {})\n\n    def test_multiple_spaces(self):\n        result = task_func(None, 'a  b   c')\n        expected = {'a': 1, 'b': 1, 'c': 1}\n        self.assertEqual(result, expected)",
        "code": "import collections\n\ndef task_func(mystrings, text):\n    if text == '':\n        raise ValueError('Input text is empty')\n    # Replace spaces in the text with underscores\n    modified_text = text.replace(' ', '_').lower()\n    # Split the modified text by underscores\n    words = [w for w in modified_text.split('_') if w != '']\n    return dict(collections.Counter(words))",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/955_5",
        "turn": "5",
        "instruct_prompt": "Plot the frequency of each unique word on a bar chart using matplotlib, with words on the x-axis in the order they appear after modifications and their frequencies on the y-axis, and return the Axes object.",
        "test": "import unittest\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_plot_and_return_axes(self):\n        text = 'Hello world hello world test'\n        ax = task_func(None, text)\n        # Check return type\n        self.assertIsInstance(ax, Axes)\n        # Check that bars correspond to correct words and counts\n        bars = ax.patches\n        # Words after modification: ['hello', 'world', 'hello', 'world', 'test']\n        # Frequencies: hello:2, world:2, test:1\n        expected_words = ['hello', 'world', 'test']\n        expected_counts = [2, 2, 1]\n\n        # The x-tick labels should be exactly expected_words in order\n        xticklabels = [tick.get_text() for tick in ax.get_xticklabels() if tick.get_text() != '']\n        self.assertEqual(xticklabels, expected_words)\n\n        # The heights of bars correspond to expected_counts\n        heights = [bar.get_height() for bar in bars]\n        self.assertEqual(heights, expected_counts)\n\n    def test_empty_text_raises(self):\n        with self.assertRaises(ValueError):\n            task_func(None, '')\n",
        "code": "import collections\nimport matplotlib.pyplot as plt\n\ndef task_func(mystrings, text):\n    if text == '':\n        raise ValueError('Input text is empty')\n    # Replace spaces in the text with underscores\n    modified_text = text.replace(' ', '_').lower()\n    # Split the modified text by underscores\n    words = [w for w in modified_text.split('_') if w != '']\n    # Count frequencies preserving order of first appearance\n    freq_dict = collections.OrderedDict()\n    for w in words:\n        freq_dict[w] = freq_dict.get(w, 0) + 1\n\n    # Plot bar chart\n    fig, ax = plt.subplots()\n    ax.bar(freq_dict.keys(), freq_dict.values())\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Word Frequency Bar Chart')\n\n    return ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 120,
    "task_id": "BigCodeBench/963",
    "mt_data": [
      {
        "task_id": "BigCodeBench/963_1",
        "turn": "1",
        "instruct_prompt": "Write a function task_func that takes three parameters: source_directory, target_directory, and zip_name. The function should create a zip file named zip_name.zip in the target_directory containing files from the source_directory. You should write self-contained code starting with:\n```\nimport os\nimport zipfile\ndef task_func(source_directory, target_directory, zip_name):\n```",
        "test": "import unittest\nimport os\nimport tempfile\nimport zipfile\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_creates_zip_with_files(self):\n        with tempfile.TemporaryDirectory() as source_dir, tempfile.TemporaryDirectory() as target_dir:\n            # Create some files in source_dir\n            file1_path = os.path.join(source_dir, 'file1.txt')\n            file2_path = os.path.join(source_dir, 'file2.txt')\n            with open(file1_path, 'w') as f:\n                f.write('Hello World')\n            with open(file2_path, 'w') as f:\n                f.write('Another file')\n            # Create a subdirectory with a file\n            sub_dir = os.path.join(source_dir, 'sub')\n            os.mkdir(sub_dir)\n            sub_file = os.path.join(sub_dir, 'subfile.txt')\n            with open(sub_file, 'w') as f:\n                f.write('Subdirectory file')\n\n            zip_name = 'testzip'\n            task_func(source_dir, target_dir, zip_name)\n\n            zip_path = os.path.join(target_dir, zip_name + '.zip')\n            self.assertTrue(os.path.isfile(zip_path))\n\n            with zipfile.ZipFile(zip_path, 'r') as zipf:\n                namelist = zipf.namelist()\n                self.assertIn('file1.txt', namelist)\n                self.assertIn('file2.txt', namelist)\n                self.assertIn(os.path.join('sub', 'subfile.txt'), namelist)\n                # Check contents\n                with zipf.open('file1.txt') as f:\n                    self.assertEqual(f.read().decode(), 'Hello World')\n                with zipf.open(os.path.join('sub', 'subfile.txt')) as f:\n                    self.assertEqual(f.read().decode(), 'Subdirectory file')\n",
        "code": "import os\nimport zipfile\n\ndef task_func(source_directory, target_directory, zip_name):\n    zip_path = os.path.join(target_directory, zip_name + '.zip')\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(source_directory):\n            for file in files:\n                file_path = os.path.join(root, file)\n                arcname = os.path.relpath(file_path, source_directory)\n                zipf.write(file_path, arcname)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/963_2",
        "turn": "2",
        "instruct_prompt": "The function should only include files with the following extensions: ['.txt', '.docx', '.xlsx', '.csv'] from source_directory and its subdirectories.",
        "test": "import unittest\nimport os\nimport tempfile\nimport zipfile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.source_dir = tempfile.mkdtemp()\n        self.target_dir = tempfile.mkdtemp()\n\n        self.allowed_files = ['file1.txt', 'file2.docx', 'file3.xlsx', 'file4.csv']\n        self.disallowed_files = ['file5.jpg', 'file6.pdf', 'file7.png']\n\n        for filename in self.allowed_files:\n            with open(os.path.join(self.source_dir, filename), 'w') as f:\n                f.write('allowed content')\n\n        for filename in self.disallowed_files:\n            with open(os.path.join(self.source_dir, filename), 'w') as f:\n                f.write('disallowed content')\n\n        self.sub_dir = os.path.join(self.source_dir, 'subdir')\n        os.makedirs(self.sub_dir)\n\n        with open(os.path.join(self.sub_dir, 'subfile.txt'), 'w') as f:\n            f.write('subdir allowed')\n\n        with open(os.path.join(self.sub_dir, 'subfile.exe'), 'w') as f:\n            f.write('subdir disallowed')\n\n    def tearDown(self):\n        for root, dirs, files in os.walk(self.source_dir, topdown=False):\n            for name in files:\n                os.remove(os.path.join(root, name))\n            for name in dirs:\n                os.rmdir(os.path.join(root, name))\n        os.rmdir(self.source_dir)\n\n        for root, dirs, files in os.walk(self.target_dir, topdown=False):\n            for name in files:\n                os.remove(os.path.join(root, name))\n            for name in dirs:\n                os.rmdir(os.path.join(root, name))\n        os.rmdir(self.target_dir)\n\n    def test_only_allowed_extensions_in_zip(self):\n        zip_name = 'testzip'\n\n        # Directly call task_func without import\n        task_func(self.source_dir, self.target_dir, zip_name)\n\n        zip_path = os.path.join(self.target_dir, zip_name + '.zip')\n        self.assertTrue(os.path.exists(zip_path))\n\n        with zipfile.ZipFile(zip_path, 'r') as zipf:\n            zipped_files = zipf.namelist()\n\n            expected_files = self.allowed_files + ['subdir/subfile.txt']\n            for expected_file in expected_files:\n                self.assertIn(expected_file, zipped_files)\n\n            disallowed_expected = self.disallowed_files + ['subdir/subfile.exe']\n            for disallowed_file in disallowed_expected:\n                self.assertNotIn(disallowed_file, zipped_files)\n",
        "code": "import os\nimport zipfile\n\ndef task_func(source_directory, target_directory, zip_name):\n    allowed_extensions = ['.txt', '.docx', '.xlsx', '.csv']\n    zip_path = os.path.join(target_directory, zip_name + '.zip')\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(source_directory):\n            for file in files:\n                if os.path.splitext(file)[1] in allowed_extensions:\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.relpath(file_path, source_directory)\n                    zipf.write(file_path, arcname)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/963_3",
        "turn": "3",
        "instruct_prompt": "If the source_directory does not exist, the function should raise an OSError.",
        "test": "import unittest\nimport os\nimport tempfile\nimport shutil\nfrom zipfile import ZipFile\n\nclass TestCases(unittest.TestCase):\n    def test_source_directory_not_exist(self):\n        with tempfile.TemporaryDirectory() as target_dir:\n            with self.assertRaises(OSError):\n                task_func('non_existent_dir', target_dir, 'archive')\n\n    def test_normal_zip_creation(self):\n        with tempfile.TemporaryDirectory() as source_dir, tempfile.TemporaryDirectory() as target_dir:\n            # Create files with allowed and disallowed extensions\n            allowed_files = ['file1.txt', 'file2.docx', 'file3.xlsx', 'file4.csv']\n            disallowed_files = ['file5.jpg', 'file6.pdf']\n            for filename in allowed_files + disallowed_files:\n                with open(os.path.join(source_dir, filename), 'w') as f:\n                    f.write('test content')\n\n            zip_name = 'testzip'\n            task_func(source_dir, target_dir, zip_name)\n\n            zip_path = os.path.join(target_dir, zip_name + '.zip')\n            self.assertTrue(os.path.exists(zip_path))\n\n            with ZipFile(zip_path, 'r') as zipf:\n                zipped_files = zipf.namelist()\n                # Only allowed files should be in the zip\n                self.assertCountEqual(zipped_files, allowed_files)\n",
        "code": "import os\nimport zipfile\n\ndef task_func(source_directory, target_directory, zip_name):\n    if not os.path.exists(source_directory):\n        raise OSError(f\"Source directory '{source_directory}' does not exist.\")\n    allowed_extensions = ['.txt', '.docx', '.xlsx', '.csv']\n    zip_path = os.path.join(target_directory, zip_name + '.zip')\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(source_directory):\n            for file in files:\n                if os.path.splitext(file)[1] in allowed_extensions:\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.relpath(file_path, source_directory)\n                    zipf.write(file_path, arcname)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/963_4",
        "turn": "4",
        "instruct_prompt": "If the target_directory does not exist, the function should create it. The function should return the absolute full path to the created zip file in the format '/path/to/target_directory/zip_name.zip'.",
        "test": "import os\nimport shutil\nimport tempfile\nimport unittest\nfrom zipfile import ZipFile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create temporary source and target directories\n        self.temp_dir = tempfile.mkdtemp()\n        self.source_dir = os.path.join(self.temp_dir, 'source')\n        self.target_dir = os.path.join(self.temp_dir, 'target')\n        os.mkdir(self.source_dir)\n        # Create some files with allowed and disallowed extensions\n        self.allowed_files = ['file1.txt', 'file2.docx', 'file3.xlsx', 'file4.csv']\n        self.disallowed_files = ['file5.pdf', 'file6.jpg']\n        for filename in self.allowed_files:\n            with open(os.path.join(self.source_dir, filename), 'w') as f:\n                f.write('test')\n        for filename in self.disallowed_files:\n            with open(os.path.join(self.source_dir, filename), 'w') as f:\n                f.write('test')\n\n    def tearDown(self):\n        shutil.rmtree(self.temp_dir)\n\n    def test_target_directory_creation_and_zip_path(self):\n        zip_name = 'archive'\n        # target_dir does not exist before calling task_func\n        self.assertFalse(os.path.exists(self.target_dir))\n        result_path = task_func(self.source_dir, self.target_dir, zip_name)\n        # Check target_dir is created\n        self.assertTrue(os.path.exists(self.target_dir))\n        # Check returned path is absolute\n        self.assertTrue(os.path.isabs(result_path))\n        # Check returned path ends with correct zip file name\n        self.assertTrue(result_path.endswith(zip_name + '.zip'))\n        # Check the zip file exists\n        self.assertTrue(os.path.exists(result_path))\n        # Check the zip file contains only allowed files\n        with ZipFile(result_path, 'r') as zipf:\n            zip_files = zipf.namelist()\n            self.assertCountEqual(zip_files, self.allowed_files)\n\n    def test_source_directory_not_exist(self):\n        with self.assertRaises(OSError):\n            task_func('non_existent_dir', self.target_dir, 'archive')\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import os\nimport zipfile\n\ndef task_func(source_directory, target_directory, zip_name):\n    if not os.path.exists(source_directory):\n        raise OSError(f\"Source directory '{source_directory}' does not exist.\")\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n    allowed_extensions = ['.txt', '.docx', '.xlsx', '.csv']\n    zip_path = os.path.join(target_directory, zip_name + '.zip')\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(source_directory):\n            for file in files:\n                if os.path.splitext(file)[1] in allowed_extensions:\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.relpath(file_path, source_directory)\n                    zipf.write(file_path, arcname)\n    return os.path.abspath(zip_path)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 121,
    "task_id": "BigCodeBench/964",
    "mt_data": [
      {
        "task_id": "BigCodeBench/964_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a source directory and a target directory, and converts all .txt files in the source directory to CSV files saved in the target directory. Each CSV should have a single column named 'Text' containing the lines of the text file. You should write self-contained code starting with:\n```\nimport os\nfrom pathlib import Path\nimport pandas as pd\ndef task_func(source_directory: str, target_directory: str) -> int:\n```",
        "test": "import unittest\nimport tempfile\nimport os\nfrom pathlib import Path\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_conversion(self):\n        with tempfile.TemporaryDirectory() as src_dir, tempfile.TemporaryDirectory() as tgt_dir:\n            # Create sample txt files\n            file1 = Path(src_dir) / 'file1.txt'\n            file1.write_text('line1\\nline2\\nline3', encoding='utf-8')\n            file2 = Path(src_dir) / 'file2.txt'\n            file2.write_text('hello\\nworld', encoding='utf-8')\n\n            # Run the function\n            count = task_func(src_dir, tgt_dir)\n\n            # Check the count\n            self.assertEqual(count, 2)\n\n            # Check files created in target directory\n            csv1 = Path(tgt_dir) / 'file1.csv'\n            csv2 = Path(tgt_dir) / 'file2.csv'\n            self.assertTrue(csv1.exists())\n            self.assertTrue(csv2.exists())\n\n            # Check content of first csv\n            df1 = pd.read_csv(csv1)\n            self.assertListEqual(df1.columns.tolist(), ['Text'])\n            self.assertListEqual(df1['Text'].tolist(), ['line1', 'line2', 'line3'])\n\n            # Check content of second csv\n            df2 = pd.read_csv(csv2)\n            self.assertListEqual(df2.columns.tolist(), ['Text'])\n            self.assertListEqual(df2['Text'].tolist(), ['hello', 'world'])\n\n    def test_empty_directory(self):\n        with tempfile.TemporaryDirectory() as src_dir, tempfile.TemporaryDirectory() as tgt_dir:\n            count = task_func(src_dir, tgt_dir)\n            self.assertEqual(count, 0)\n            self.assertEqual(len(list(Path(tgt_dir).iterdir())), 0)\n\n    def test_target_directory_creation(self):\n        with tempfile.TemporaryDirectory() as src_dir:\n            file1 = Path(src_dir) / 'file1.txt'\n            file1.write_text('abc', encoding='utf-8')\n\n            # Use a non-existent target directory\n            with tempfile.TemporaryDirectory() as base_dir:\n                target_dir = Path(base_dir) / 'nonexistent_subdir'\n                count = task_func(src_dir, str(target_dir))\n                self.assertEqual(count, 1)\n                self.assertTrue(target_dir.exists())\n                csv_file = target_dir / 'file1.csv'\n                self.assertTrue(csv_file.exists())\n\n    def test_non_txt_files_ignored(self):\n        with tempfile.TemporaryDirectory() as src_dir, tempfile.TemporaryDirectory() as tgt_dir:\n            # Create a txt file and a non-txt file\n            txt_file = Path(src_dir) / 'file1.txt'\n            txt_file.write_text('line1', encoding='utf-8')\n            other_file = Path(src_dir) / 'file2.doc'\n            other_file.write_text('should be ignored', encoding='utf-8')\n\n            count = task_func(src_dir, tgt_dir)\n            self.assertEqual(count, 1)\n            csv_file = Path(tgt_dir) / 'file1.csv'\n            self.assertTrue(csv_file.exists())\n            other_csv = Path(tgt_dir) / 'file2.csv'\n            self.assertFalse(other_csv.exists())\n",
        "code": "import os\nfrom pathlib import Path\nimport pandas as pd\n\ndef task_func(source_directory: str, target_directory: str) -> int:\n    source_path = Path(source_directory)\n    target_path = Path(target_directory)\n    if not target_path.exists():\n        target_path.mkdir(parents=True, exist_ok=True)\n\n    txt_files = list(source_path.glob('*.txt'))\n    count = 0\n    for txt_file in txt_files:\n        with open(txt_file, 'r', encoding='utf-8') as f:\n            lines = f.read().splitlines()\n        df = pd.DataFrame({'Text': lines})\n        csv_file = target_path / (txt_file.stem + '.csv')\n        df.to_csv(csv_file, index=False)\n        count += 1\n    return count\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/964_2",
        "turn": "2",
        "instruct_prompt": "Extend the function to also convert .docx files from the source directory to CSV files in the target directory. Extract the text from all paragraphs in the .docx file and store each paragraph as a row in the 'Text' column of the CSV.",
        "test": "import unittest\nimport tempfile\nimport shutil\nimport os\nfrom pathlib import Path\nimport pandas as pd\nfrom docx import Document\n\n# Import the function from the solution\n# from solution_module import task_func  # (Assuming saved as solution_module.py)\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.source_dir = tempfile.mkdtemp()\n        self.target_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.source_dir)\n        shutil.rmtree(self.target_dir)\n\n    def test_txt_and_docx_conversion(self):\n        # Create a .txt file\n        txt_path = Path(self.source_dir) / 'sample.txt'\n        txt_content = 'line1\\nline2\\nline3'\n        with open(txt_path, 'w', encoding='utf-8') as f:\n            f.write(txt_content)\n\n        # Create a .docx file\n        docx_path = Path(self.source_dir) / 'sample_doc.docx'\n        doc = Document()\n        doc.add_paragraph('Paragraph 1')\n        doc.add_paragraph('Paragraph 2')\n        doc.add_paragraph('Paragraph 3')\n        doc.save(docx_path)\n\n        # Run the function\n        count = task_func(self.source_dir, self.target_dir)\n\n        # Check count\n        self.assertEqual(count, 2)\n\n        # Verify TXT CSV\n        txt_csv_path = Path(self.target_dir) / 'sample.csv'\n        self.assertTrue(txt_csv_path.exists())\n        df_txt = pd.read_csv(txt_csv_path)\n        self.assertEqual(list(df_txt['Text']), ['line1', 'line2', 'line3'])\n\n        # Verify DOCX CSV\n        docx_csv_path = Path(self.target_dir) / 'sample_doc.csv'\n        self.assertTrue(docx_csv_path.exists())\n        df_docx = pd.read_csv(docx_csv_path)\n        self.assertEqual(list(df_docx['Text']), ['Paragraph 1', 'Paragraph 2', 'Paragraph 3'])\n\n    def test_no_files(self):\n        # Empty source directory\n        count = task_func(self.source_dir, self.target_dir)\n        self.assertEqual(count, 0)\n        self.assertEqual(len(os.listdir(self.target_dir)), 0)\n\n    def test_only_docx(self):\n        # Create only a .docx file\n        docx_path = Path(self.source_dir) / 'only_doc.docx'\n        doc = Document()\n        doc.add_paragraph('Only paragraph')\n        doc.save(docx_path)\n\n        count = task_func(self.source_dir, self.target_dir)\n        self.assertEqual(count, 1)\n\n        docx_csv_path = Path(self.target_dir) / 'only_doc.csv'\n        self.assertTrue(docx_csv_path.exists())\n        df_docx = pd.read_csv(docx_csv_path)\n        self.assertEqual(list(df_docx['Text']), ['Only paragraph'])\n\n    def test_only_txt(self):\n        # Create only a .txt file\n        txt_path = Path(self.source_dir) / 'only_txt.txt'\n        txt_content = 'single line'\n        with open(txt_path, 'w', encoding='utf-8') as f:\n            f.write(txt_content)\n\n        count = task_func(self.source_dir, self.target_dir)\n        self.assertEqual(count, 1)\n\n        txt_csv_path = Path(self.target_dir) / 'only_txt.csv'\n        self.assertTrue(txt_csv_path.exists())\n        df_txt = pd.read_csv(txt_csv_path)\n        self.assertEqual(list(df_txt['Text']), ['single line'])\n",
        "code": "import os\nfrom pathlib import Path\nimport pandas as pd\nfrom docx import Document\n\n\ndef task_func(source_directory: str, target_directory: str) -> int:\n    source_path = Path(source_directory)\n    target_path = Path(target_directory)\n    if not target_path.exists():\n        target_path.mkdir(parents=True, exist_ok=True)\n\n    count = 0\n\n    # Process .txt files\n    txt_files = list(source_path.glob('*.txt'))\n    for txt_file in txt_files:\n        with open(txt_file, 'r', encoding='utf-8') as f:\n            lines = f.read().splitlines()\n        df = pd.DataFrame({'Text': lines})\n        csv_file = target_path / (txt_file.stem + '.csv')\n        df.to_csv(csv_file, index=False)\n        count += 1\n\n    # Process .docx files\n    docx_files = list(source_path.glob('*.docx'))\n    for docx_file in docx_files:\n        document = Document(docx_file)\n        paragraphs = [para.text for para in document.paragraphs]\n        df = pd.DataFrame({'Text': paragraphs})\n        csv_file = target_path / (docx_file.stem + '.csv')\n        df.to_csv(csv_file, index=False)\n        count += 1\n\n    return count\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/964_3",
        "turn": "3",
        "instruct_prompt": "Further extend the function to convert .xlsx files in the source directory to CSV files in the target directory by reading the first sheet and saving all its data as-is in the CSV.",
        "test": "import unittest\nimport tempfile\nimport shutil\nfrom pathlib import Path\nimport pandas as pd\nfrom docx import Document\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.source_dir = tempfile.mkdtemp()\n        self.target_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.source_dir)\n        shutil.rmtree(self.target_dir)\n\n    def test_xlsx_conversion(self):\n        # create a sample .xlsx file with some data\n        xlsx_path = Path(self.source_dir) / 'sample.xlsx'\n        df = pd.DataFrame({\n            'A': [1, 2, 3],\n            'B': ['x', 'y', 'z']\n        })\n        df.to_excel(xlsx_path, index=False)\n\n        # call the task_func directly (no import needed)\n        count = task_func(self.source_dir, self.target_dir)\n\n        # Check count\n        self.assertEqual(count, 1)\n\n        # Check that CSV file is created\n        csv_path = Path(self.target_dir) / 'sample.csv'\n        self.assertTrue(csv_path.exists())\n\n        # Read the CSV file and verify contents\n        df_result = pd.read_csv(csv_path)\n        pd.testing.assert_frame_equal(df, df_result)\n",
        "code": "import os\nfrom pathlib import Path\nimport pandas as pd\nfrom docx import Document\n\ndef task_func(source_directory: str, target_directory: str) -> int:\n    source_path = Path(source_directory)\n    target_path = Path(target_directory)\n    if not target_path.exists():\n        target_path.mkdir(parents=True, exist_ok=True)\n\n    count = 0\n\n    # Process .txt files\n    txt_files = list(source_path.glob('*.txt'))\n    for txt_file in txt_files:\n        with open(txt_file, 'r', encoding='utf-8') as f:\n            lines = f.read().splitlines()\n        df = pd.DataFrame({'Text': lines})\n        csv_file = target_path / (txt_file.stem + '.csv')\n        df.to_csv(csv_file, index=False)\n        count += 1\n\n    # Process .docx files\n    docx_files = list(source_path.glob('*.docx'))\n    for docx_file in docx_files:\n        document = Document(docx_file)\n        paragraphs = [para.text for para in document.paragraphs]\n        df = pd.DataFrame({'Text': paragraphs})\n        csv_file = target_path / (docx_file.stem + '.csv')\n        df.to_csv(csv_file, index=False)\n        count += 1\n\n    # Process .xlsx files\n    xlsx_files = list(source_path.glob('*.xlsx'))\n    for xlsx_file in xlsx_files:\n        df = pd.read_excel(xlsx_file, sheet_name=0)\n        csv_file = target_path / (xlsx_file.stem + '.csv')\n        df.to_csv(csv_file, index=False)\n        count += 1\n\n    return count\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/964_4",
        "turn": "4",
        "instruct_prompt": "Modify the function to also convert existing .csv files from the source directory by reading and rewriting them into the target directory as CSV files with the same content. The function should overwrite existing files in the target directory with the same names. Raise FileNotFoundError if the source directory does not exist. The function should return the total number of files converted.",
        "test": "import unittest\nimport tempfile\nimport shutil\nfrom pathlib import Path\nimport pandas as pd\nfrom docx import Document\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.source_dir = tempfile.mkdtemp()\n        self.target_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        if Path(self.source_dir).exists():\n            shutil.rmtree(self.source_dir)\n        if Path(self.target_dir).exists():\n            shutil.rmtree(self.target_dir)\n\n    def test_file_conversion_including_csv(self):\n        # Create a .txt file\n        txt_path = Path(self.source_dir) / 'test.txt'\n        with open(txt_path, 'w', encoding='utf-8') as f:\n            f.write('line1\\nline2\\nline3')\n\n        # Create a .docx file\n        docx_path = Path(self.source_dir) / 'docfile.docx'\n        doc = Document()\n        doc.add_paragraph('para1')\n        doc.add_paragraph('para2')\n        doc.save(docx_path)\n\n        # Create a .xlsx file\n        xlsx_path = Path(self.source_dir) / 'excelfile.xlsx'\n        df_xlsx = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n        df_xlsx.to_excel(xlsx_path, index=False)\n\n        # Create a .csv file\n        csv_path = Path(self.source_dir) / 'csvfile.csv'\n        df_csv = pd.DataFrame({'X': ['a', 'b'], 'Y': ['c', 'd']})\n        df_csv.to_csv(csv_path, index=False)\n\n        # Call the function directly (no import needed)\n        count = task_func(self.source_dir, self.target_dir)\n\n        self.assertEqual(count, 4)\n\n        # Check .txt converted to .csv\n        txt_csv_path = Path(self.target_dir) / 'test.csv'\n        self.assertTrue(txt_csv_path.exists())\n        df_txt_csv = pd.read_csv(txt_csv_path)\n        self.assertListEqual(df_txt_csv['Text'].tolist(), ['line1', 'line2', 'line3'])\n\n        # Check .docx converted to .csv\n        docx_csv_path = Path(self.target_dir) / 'docfile.csv'\n        self.assertTrue(docx_csv_path.exists())\n        df_docx_csv = pd.read_csv(docx_csv_path)\n        self.assertListEqual(df_docx_csv['Text'].tolist(), ['para1', 'para2'])\n\n        # Check .xlsx converted to .csv\n        xlsx_csv_path = Path(self.target_dir) / 'excelfile.csv'\n        self.assertTrue(xlsx_csv_path.exists())\n        df_xlsx_csv = pd.read_csv(xlsx_csv_path)\n        pd.testing.assert_frame_equal(df_xlsx_csv, df_xlsx)\n\n        # Check .csv copied and rewritten\n        csv_csv_path = Path(self.target_dir) / 'csvfile.csv'\n        self.assertTrue(csv_csv_path.exists())\n        df_csv_csv = pd.read_csv(csv_csv_path)\n        pd.testing.assert_frame_equal(df_csv_csv, df_csv)\n\n    def test_source_directory_not_exist(self):\n        # Remove source directory to simulate not existing\n        shutil.rmtree(self.source_dir)\n        with self.assertRaises(FileNotFoundError):\n            task_func(self.source_dir, self.target_dir)\n",
        "code": "import os\nfrom pathlib import Path\nimport pandas as pd\nfrom docx import Document\n\ndef task_func(source_directory: str, target_directory: str) -> int:\n    source_path = Path(source_directory)\n    target_path = Path(target_directory)\n    if not source_path.exists():\n        raise FileNotFoundError(f\"Source directory '{source_directory}' does not exist.\")\n    if not target_path.exists():\n        target_path.mkdir(parents=True, exist_ok=True)\n\n    count = 0\n\n    # Process .txt files\n    txt_files = list(source_path.glob('*.txt'))\n    for txt_file in txt_files:\n        with open(txt_file, 'r', encoding='utf-8') as f:\n            lines = f.read().splitlines()\n        df = pd.DataFrame({'Text': lines})\n        csv_file = target_path / (txt_file.stem + '.csv')\n        df.to_csv(csv_file, index=False)\n        count += 1\n\n    # Process .docx files\n    docx_files = list(source_path.glob('*.docx'))\n    for docx_file in docx_files:\n        document = Document(docx_file)\n        paragraphs = [para.text for para in document.paragraphs]\n        df = pd.DataFrame({'Text': paragraphs})\n        csv_file = target_path / (docx_file.stem + '.csv')\n        df.to_csv(csv_file, index=False)\n        count += 1\n\n    # Process .xlsx files\n    xlsx_files = list(source_path.glob('*.xlsx'))\n    for xlsx_file in xlsx_files:\n        df = pd.read_excel(xlsx_file, sheet_name=0)\n        csv_file = target_path / (xlsx_file.stem + '.csv')\n        df.to_csv(csv_file, index=False)\n        count += 1\n\n    # Process .csv files\n    csv_files = list(source_path.glob('*.csv'))\n    for csv_file_src in csv_files:\n        df = pd.read_csv(csv_file_src)\n        csv_file_dst = target_path / csv_file_src.name\n        df.to_csv(csv_file_dst, index=False)\n        count += 1\n\n    return count\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 122,
    "task_id": "BigCodeBench/969",
    "mt_data": [
      {
        "task_id": "BigCodeBench/969_1",
        "turn": "1",
        "instruct_prompt": "Compute the cumulative sum for each numeric column in the given DataFrame and return the resulting DataFrame with the original column names. You should write self-contained code starting with:\n```\nimport numpy as np\nimport pandas as pd\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n```",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_cumsum_numeric(self):\n        df = pd.DataFrame({\n            'A': [1, 2, 3],\n            'B': [4, 5, 6],\n            'C': ['x', 'y', 'z']\n        })\n        result = task_func(df)\n        expected = pd.DataFrame({\n            'A': [1, 3, 6],\n            'B': [4, 9, 15],\n            'C': ['x', 'y', 'z']\n        })\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_empty_df(self):\n        df = pd.DataFrame()\n        result = task_func(df)\n        expected = pd.DataFrame()\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_all_numeric(self):\n        df = pd.DataFrame({\n            'X': [10, 20, 30],\n            'Y': [1.5, 2.5, 3.5]\n        })\n        result = task_func(df)\n        expected = pd.DataFrame({\n            'X': [10, 30, 60],\n            'Y': [1.5, 4.0, 7.5]\n        })\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_mixed_types(self):\n        df = pd.DataFrame({\n            'num': [1, 2, 3],\n            'bool': [True, False, True],\n            'text': ['a', 'b', 'c']\n        })\n        result = task_func(df)\n        expected = df.copy()\n        # Apply cumsum on numeric columns including bool, which will convert bool to int64\n        numeric_cols = df.select_dtypes(include=[np.number]).columns\n        expected[numeric_cols] = df[numeric_cols].cumsum()\n        pd.testing.assert_frame_equal(result, expected)\n",
        "code": "import numpy as np\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    result = df.copy()\n    result[numeric_cols] = df[numeric_cols].cumsum()\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/969_2",
        "turn": "2",
        "instruct_prompt": "Raise a TypeError if the DataFrame contains any non-numeric data types.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_all_numeric(self):\n        df = pd.DataFrame({\n            'a': [1, 2, 3],\n            'b': [4.0, 5.0, 6.0]\n        })\n        expected = pd.DataFrame({\n            'a': [1, 3, 6],\n            'b': [4.0, 9.0, 15.0]\n        })\n        pd.testing.assert_frame_equal(task_func(df), expected)\n\n    def test_non_numeric_raises(self):\n        df = pd.DataFrame({\n            'a': [1, 2, 3],\n            'b': ['x', 'y', 'z']\n        })\n        with self.assertRaises(TypeError):\n            task_func(df)\n\n    def test_mixed_numeric_and_non_numeric_raises(self):\n        df = pd.DataFrame({\n            'a': [1, 2, 3],\n            'b': [4, 5, 6],\n            'c': ['x', 'y', 'z']\n        })\n        with self.assertRaises(TypeError):\n            task_func(df)\n\n    def test_empty_dataframe(self):\n        df = pd.DataFrame()\n        result = task_func(df)\n        pd.testing.assert_frame_equal(result, df)\n\n    def test_all_integer(self):\n        df = pd.DataFrame({\n            'a': [1, 1, 1],\n            'b': [2, 2, 2]\n        })\n        expected = pd.DataFrame({\n            'a': [1, 2, 3],\n            'b': [2, 4, 6]\n        })\n        pd.testing.assert_frame_equal(task_func(df), expected)\n",
        "code": "import numpy as np\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if not all(dtype.kind in 'biufc' for dtype in df.dtypes):\n        raise TypeError('DataFrame contains non-numeric data types')\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    result = df.copy()\n    result[numeric_cols] = df[numeric_cols].cumsum()\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/969_3",
        "turn": "3",
        "instruct_prompt": "Raise a ValueError if the DataFrame is empty or contains any NaN values.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_valid_dataframe(self):\n        df = pd.DataFrame({'A': [1, 2, 3], 'B': [4.0, 5.0, 6.0]})\n        result = task_func(df)\n        expected = pd.DataFrame({'A': [1, 3, 6], 'B': [4.0, 9.0, 15.0]})\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_empty_dataframe(self):\n        df = pd.DataFrame()\n        with self.assertRaises(ValueError) as cm:\n            task_func(df)\n        self.assertEqual(str(cm.exception), 'DataFrame is empty')\n\n    def test_dataframe_with_nan(self):\n        df = pd.DataFrame({'A': [1, np.nan, 3], 'B': [4, 5, 6]})\n        with self.assertRaises(ValueError) as cm:\n            task_func(df)\n        self.assertEqual(str(cm.exception), 'DataFrame contains NaN values')\n",
        "code": "import numpy as np\nimport pandas as pd\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty:\n        raise ValueError('DataFrame is empty')\n    if df.isnull().values.any():\n        raise ValueError('DataFrame contains NaN values')\n    if not all(dtype.kind in 'biufc' for dtype in df.dtypes):\n        raise TypeError('DataFrame contains non-numeric data types')\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    result = df.copy()\n    result[numeric_cols] = df[numeric_cols].cumsum()\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/969_4",
        "turn": "4",
        "instruct_prompt": "Apply MinMax normalization to the cumulative sum values of each column and return the normalized DataFrame with the original column names. You should import and use MinMaxScaler from sklearn.preprocessing.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\nclass TestCases(unittest.TestCase):\n    def test_basic_functionality(self):\n        df = pd.DataFrame({\n            'A': [1, 2, 3],\n            'B': [4, 5, 6]\n        })\n        result = task_func(df)\n        # Calculate expected result manually\n        cumsum = df.cumsum()\n        scaler = MinMaxScaler()\n        expected_array = scaler.fit_transform(cumsum)\n        expected = pd.DataFrame(expected_array, columns=['A', 'B'])\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_empty_dataframe(self):\n        df = pd.DataFrame()\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_nan_values(self):\n        df = pd.DataFrame({'A': [1, np.nan, 3]})\n        with self.assertRaises(ValueError):\n            task_func(df)\n\n    def test_non_numeric(self):\n        df = pd.DataFrame({'A': [1, 2, 3], 'B': ['x', 'y', 'z']})\n        with self.assertRaises(TypeError):\n            task_func(df)\n\n    def test_single_column(self):\n        df = pd.DataFrame({'A': [1, 2, 3, 4]})\n        result = task_func(df)\n        cumsum = df.cumsum()\n        scaler = MinMaxScaler()\n        expected_array = scaler.fit_transform(cumsum)\n        expected = pd.DataFrame(expected_array, columns=['A'])\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_multiple_rows_and_columns(self):\n        df = pd.DataFrame({\n            'X': [10, 20, 30, 40],\n            'Y': [5, 15, 25, 35],\n            'Z': [2, 4, 6, 8]\n        })\n        result = task_func(df)\n        cumsum = df.cumsum()\n        scaler = MinMaxScaler()\n        expected_array = scaler.fit_transform(cumsum)\n        expected = pd.DataFrame(expected_array, columns=['X', 'Y', 'Z'])\n        pd.testing.assert_frame_equal(result, expected)\n",
        "code": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty:\n        raise ValueError('DataFrame is empty')\n    if df.isnull().values.any():\n        raise ValueError('DataFrame contains NaN values')\n    if not all(dtype.kind in 'biufc' for dtype in df.dtypes):\n        raise TypeError('DataFrame contains non-numeric data types')\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    cumsum_df = df[numeric_cols].cumsum()\n    scaler = MinMaxScaler()\n    normalized_array = scaler.fit_transform(cumsum_df)\n    normalized_df = pd.DataFrame(normalized_array, columns=numeric_cols, index=df.index)\n    return normalized_df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 123,
    "task_id": "BigCodeBench/971",
    "mt_data": [
      {
        "task_id": "BigCodeBench/971_1",
        "turn": "1",
        "instruct_prompt": "Write a function named task_func that takes a directory path as a string and returns a list of tuples, each containing the file name and file size in bytes for every file in the given directory. You should write self-contained code starting with:\n```\nimport os\nfrom pathlib import Path\ndef task_func(directory_path: str):\n```",
        "test": "import unittest\nimport tempfile\nimport os\nfrom pathlib import Path\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_with_files(self):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            # Create files with known content\n            file1 = Path(tmpdirname) / 'file1.txt'\n            file1.write_text('hello')  # 5 bytes\n            file2 = Path(tmpdirname) / 'file2.bin'\n            file2.write_bytes(b'\\x00\\x01\\x02')  # 3 bytes\n\n            expected = [(file1.name, 5), (file2.name, 3)]\n            result = task_func(tmpdirname)\n            # Sort results for comparison\n            self.assertEqual(sorted(result), sorted(expected))\n\n    def test_task_func_with_no_files(self):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            # Empty directory\n            result = task_func(tmpdirname)\n            self.assertEqual(result, [])\n\n    def test_task_func_ignores_subdirectories(self):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            subdir = Path(tmpdirname) / 'subdir'\n            subdir.mkdir()\n            file1 = Path(tmpdirname) / 'file1.txt'\n            file1.write_text('data')  # 4 bytes\n            (subdir / 'file2.txt').write_text('more data')  # Should be ignored\n\n            expected = [(file1.name, 4)]\n            result = task_func(tmpdirname)\n            self.assertEqual(result, expected)\n",
        "code": "import os\nfrom pathlib import Path\n\ndef task_func(directory_path: str):\n    result = []\n    p = Path(directory_path)\n    for file in p.iterdir():\n        if file.is_file():\n            result.append((file.name, file.stat().st_size))\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/971_2",
        "turn": "2",
        "instruct_prompt": "Make sure the function raises a ValueError if the provided directory path does not exist or is not a directory.",
        "test": "import unittest\nimport tempfile\nimport os\nfrom pathlib import Path\n\nclass TestCases(unittest.TestCase):\n    def test_valid_directory_files(self):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            # create some files\n            file1 = Path(tmpdirname) / \"file1.txt\"\n            file1.write_text(\"hello\")\n            file2 = Path(tmpdirname) / \"file2.txt\"\n            file2.write_text(\"world\")\n            # create a subdirectory\n            subdir = Path(tmpdirname) / \"subdir\"\n            subdir.mkdir()\n\n            result = task_func(tmpdirname)\n            expected = [(\"file1.txt\", 5), (\"file2.txt\", 5)]\n            self.assertCountEqual(result, expected)\n\n    def test_nonexistent_directory(self):\n        with self.assertRaises(ValueError):\n            task_func(\"/path/does/not/exist\")\n\n    def test_path_is_file_not_directory(self):\n        with tempfile.NamedTemporaryFile() as tmpfile:\n            with self.assertRaises(ValueError):\n                task_func(tmpfile.name)\n",
        "code": "import os\nfrom pathlib import Path\n\ndef task_func(directory_path: str):\n    p = Path(directory_path)\n    if not p.exists() or not p.is_dir():\n        raise ValueError(f\"The path '{directory_path}' does not exist or is not a directory.\")\n    result = []\n    for file in p.iterdir():\n        if file.is_file():\n            result.append((file.name, file.stat().st_size))\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/971_3",
        "turn": "3",
        "instruct_prompt": "Extend the function to also retrieve the creation time and last modification time of each file, and include these times in ISO 8601 format (UTC timezone) in each tuple returned, so each tuple contains (file name, file size in bytes, creation time ISO string, modification time ISO string).",
        "test": "import unittest\nimport tempfile\nimport os\nimport time\nfrom datetime import datetime, timezone\n\nclass TestCases(unittest.TestCase):\n    def test_file_info_with_times(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            file_path = os.path.join(tmpdir, \"testfile.txt\")\n            with open(file_path, \"w\") as f:\n                f.write(\"hello world\")\n            # Get times after writing file\n            stat = os.stat(file_path)\n            expected_name = \"testfile.txt\"\n            expected_size = stat.st_size\n            expected_ctime = datetime.fromtimestamp(stat.st_ctime, timezone.utc).isoformat()\n            expected_mtime = datetime.fromtimestamp(stat.st_mtime, timezone.utc).isoformat()\n\n            result = task_func(tmpdir)\n            self.assertEqual(len(result), 1)\n            self.assertEqual(result[0][0], expected_name)\n            self.assertEqual(result[0][1], expected_size)\n            self.assertEqual(result[0][2], expected_ctime)\n            self.assertEqual(result[0][3], expected_mtime)\n\n    def test_empty_directory(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            result = task_func(tmpdir)\n            self.assertEqual(result, [])\n\n    def test_invalid_directory(self):\n        with self.assertRaises(ValueError):\n            task_func(\"/non/existent/directory/path\")\n",
        "code": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\n\ndef task_func(directory_path: str):\n    p = Path(directory_path)\n    if not p.exists() or not p.is_dir():\n        raise ValueError(f\"The path '{directory_path}' does not exist or is not a directory.\")\n    result = []\n    for file in p.iterdir():\n        if file.is_file():\n            stat = file.stat()\n            # Convert timestamps to ISO 8601 UTC strings\n            ctime = datetime.fromtimestamp(stat.st_ctime, timezone.utc).isoformat()\n            mtime = datetime.fromtimestamp(stat.st_mtime, timezone.utc).isoformat()\n            result.append((file.name, stat.st_size, ctime, mtime))\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/971_4",
        "turn": "4",
        "instruct_prompt": "Ensure the function does not recurse into subdirectories and only processes files directly inside the given directory.",
        "test": "import unittest\nimport tempfile\nfrom pathlib import Path\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_files_only_in_given_directory(self):\n        with tempfile.TemporaryDirectory() as temp_dir:\n            # Create files directly in temp_dir\n            file1 = Path(temp_dir) / 'file1.txt'\n            file1.write_text('abc')\n            file2 = Path(temp_dir) / 'file2.txt'\n            file2.write_text('defg')\n\n            # Create a subdirectory with a file inside\n            subdir = Path(temp_dir) / 'subdir'\n            subdir.mkdir()\n            subfile = subdir / 'subfile.txt'\n            subfile.write_text('hijkl')\n\n            # Create a symlink to a file inside temp_dir\n            symlink_path = Path(temp_dir) / 'link_to_file1'\n            try:\n                symlink_path.symlink_to(file1)\n            except (OSError, NotImplementedError):\n                # Symlink creation may fail on some platforms or filesystems\n                pass\n\n            # Call task_func\n            results = task_func(temp_dir)\n\n            # Extract file names returned\n            returned_files = {item[0] for item in results}\n\n            # The files directly in temp_dir should be present\n            self.assertIn('file1.txt', returned_files)\n            self.assertIn('file2.txt', returned_files)\n\n            # The file inside subdirectory should NOT be present\n            self.assertNotIn('subfile.txt', returned_files)\n\n            # The symlink to a file should NOT be present (because solution excludes symlinks)\n            self.assertNotIn('link_to_file1', returned_files)\n\n            # Check sizes for files directly in directory\n            for name, size, ctime, mtime in results:\n                if name == 'file1.txt':\n                    self.assertEqual(size, 3)  # 'abc'\n                elif name == 'file2.txt':\n                    self.assertEqual(size, 4)  # 'defg'\n\n    def test_empty_directory(self):\n        with tempfile.TemporaryDirectory() as temp_dir:\n            results = task_func(temp_dir)\n            self.assertEqual(results, [])\n\n    def test_invalid_directory_raises(self):\n        with self.assertRaises(ValueError):\n            task_func('/path/does/not/exist')\n",
        "code": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\n\ndef task_func(directory_path: str):\n    p = Path(directory_path)\n    if not p.exists() or not p.is_dir():\n        raise ValueError(f\"The path '{directory_path}' does not exist or is not a directory.\")\n    result = []\n    for file in p.iterdir():\n        # Only process regular files, do not follow symlinks\n        if file.is_file() and not file.is_symlink():\n            stat = file.stat()\n            ctime = datetime.fromtimestamp(stat.st_ctime, timezone.utc).isoformat()\n            mtime = datetime.fromtimestamp(stat.st_mtime, timezone.utc).isoformat()\n            result.append((file.name, stat.st_size, ctime, mtime))\n    return result\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 124,
    "task_id": "BigCodeBench/985",
    "mt_data": [
      {
        "task_id": "BigCodeBench/985_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes JSON data containing country population information and outputs a pandas DataFrame with columns \"Country\" and \"Population\". The function signature is:\n```python\nimport pandas as pd\nimport json\nimport os\nimport math\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n```",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_basic(self):\n        json_data = '[{\"Country\": \"USA\", \"Population\": 331002651}, {\"Country\": \"India\", \"Population\": 1380004385}, {\"Country\": \"China\", \"Population\": 1439323776}]'\n        df = task_func(json_data)\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertListEqual(list(df.columns), [\"Country\", \"Population\"])\n        self.assertEqual(len(df), 3)\n        self.assertEqual(df.iloc[0][\"Country\"], \"USA\")\n        self.assertEqual(df.iloc[1][\"Population\"], 1380004385)\n\n    def test_task_func_empty(self):\n        json_data = '[]'\n        df = task_func(json_data)\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertListEqual(list(df.columns), [\"Country\", \"Population\"])\n        self.assertEqual(len(df), 0)\n\n    def test_task_func_missing_keys(self):\n        json_data = '[{\"Country\": \"USA\"}, {\"Population\": 1380004385}, {\"Country\": \"China\", \"Population\": 1439323776}]'\n        df = task_func(json_data)\n        # For missing Population (numeric), pandas stores NaN, so check with pd.isna\n        self.assertTrue(pd.isna(df.iloc[0][\"Population\"]))\n        # For missing Country (string), pandas stores None or NaN, check with pd.isna or None\n        self.assertTrue(pd.isna(df.iloc[1][\"Country\"]))\n        self.assertEqual(df.iloc[2][\"Country\"], \"China\")\n        self.assertEqual(df.iloc[2][\"Population\"], 1439323776)\n",
        "code": "import pandas as pd\nimport json\nimport os\nimport math\n\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    # Parse the JSON data\n    data = json.loads(json_data)\n    \n    # Extract country and population info assuming data is a list of dicts with keys 'Country' and 'Population'\n    countries = []\n    populations = []\n    for entry in data:\n        countries.append(entry.get('Country'))\n        populations.append(entry.get('Population'))\n    \n    # Create the DataFrame\n    df = pd.DataFrame({\"Country\": countries, \"Population\": populations})\n    \n    # Return the DataFrame\n    return df",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/985_2",
        "turn": "2",
        "instruct_prompt": "Ensure the function validates the JSON input and raises a ValueError if the JSON is malformed, empty, or missing the expected country data.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_valid_input(self):\n        json_data = '[{\"Country\": \"USA\", \"Population\": 331000000}, {\"Country\": \"Canada\", \"Population\": 37700000}]'\n        df = task_func(json_data)\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertEqual(list(df.columns), [\"Country\", \"Population\"])\n        self.assertEqual(len(df), 2)\n        self.assertEqual(df.iloc[0][\"Country\"], \"USA\")\n        self.assertEqual(df.iloc[1][\"Population\"], 37700000)\n\n    def test_empty_string(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(\"\")\n        self.assertIn(\"empty or whitespace\", str(cm.exception))\n\n    def test_whitespace_string(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(\"   \\n  \")\n        self.assertIn(\"empty or whitespace\", str(cm.exception))\n\n    def test_malformed_json(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func(\"{bad json}\")\n        self.assertIn(\"Malformed JSON\", str(cm.exception))\n\n    def test_not_a_list(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func('{\"Country\": \"USA\", \"Population\": 331000000}')\n        self.assertIn(\"must be a non-empty list\", str(cm.exception))\n\n    def test_empty_list(self):\n        with self.assertRaises(ValueError) as cm:\n            task_func('[]')\n        self.assertIn(\"must be a non-empty list\", str(cm.exception))\n\n    def test_missing_country_key(self):\n        json_data = '[{\"Population\": 331000000}]'\n        with self.assertRaises(ValueError) as cm:\n            task_func(json_data)\n        self.assertIn(\"containing 'Country' and 'Population' keys\", str(cm.exception))\n\n    def test_missing_population_key(self):\n        json_data = '[{\"Country\": \"USA\"}]'\n        with self.assertRaises(ValueError) as cm:\n            task_func(json_data)\n        self.assertIn(\"containing 'Country' and 'Population' keys\", str(cm.exception))\n\n    def test_entry_not_dict(self):\n        json_data = '[\"USA\", \"Canada\"]'\n        with self.assertRaises(ValueError) as cm:\n            task_func(json_data)\n        self.assertIn(\"containing 'Country' and 'Population' keys\", str(cm.exception))\n",
        "code": "import pandas as pd\nimport json\n\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    # Validate input JSON data\n    if not json_data or not json_data.strip():\n        raise ValueError(\"Input JSON data is empty or whitespace.\")\n    \n    try:\n        data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"Malformed JSON input.\")\n    \n    # Validate that data is a list and contains expected country data\n    if not isinstance(data, list) or len(data) == 0:\n        raise ValueError(\"JSON input must be a non-empty list.\")\n    \n    for entry in data:\n        if not isinstance(entry, dict) or 'Country' not in entry or 'Population' not in entry:\n            raise ValueError(\"Each entry must be a dict containing 'Country' and 'Population' keys.\")\n    \n    # Extract country and population info\n    countries = [entry['Country'] for entry in data]\n    populations = [entry['Population'] for entry in data]\n    \n    # Create the DataFrame\n    df = pd.DataFrame({\"Country\": countries, \"Population\": populations})\n    \n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/985_3",
        "turn": "3",
        "instruct_prompt": "Validate that all country names are strings, and populations are numeric and non-negative. If a population is a float, round it down to the nearest integer. Raise ValueError if validation fails.",
        "test": "import unittest\nimport pandas as pd\nfrom math import floor\n\nclass TestCases(unittest.TestCase):\n    def test_valid_input_with_int_and_float_populations(self):\n        json_data = '[{\"Country\": \"A\", \"Population\": 10}, {\"Country\": \"B\", \"Population\": 20.9}]'\n        df = task_func(json_data)\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertEqual(list(df['Country']), [\"A\", \"B\"])\n        self.assertEqual(list(df['Population']), [10, floor(20.9)])\n\n    def test_population_negative_raises_value_error(self):\n        json_data = '[{\"Country\": \"A\", \"Population\": -1}]'\n        with self.assertRaises(ValueError):\n            task_func(json_data)\n\n    def test_population_non_numeric_raises_value_error(self):\n        json_data = '[{\"Country\": \"A\", \"Population\": \"not a number\"}]'\n        with self.assertRaises(ValueError):\n            task_func(json_data)\n\n    def test_country_not_string_raises_value_error(self):\n        json_data = '[{\"Country\": 123, \"Population\": 10}]'\n        with self.assertRaises(ValueError):\n            task_func(json_data)\n\n    def test_empty_json_raises_value_error(self):\n        with self.assertRaises(ValueError):\n            task_func(\"\")\n\n    def test_malformed_json_raises_value_error(self):\n        with self.assertRaises(ValueError):\n            task_func(\"{bad json}\")\n\n    def test_json_not_list_raises_value_error(self):\n        with self.assertRaises(ValueError):\n            task_func('{\"Country\": \"A\", \"Population\": 10}')\n\n    def test_entry_missing_keys_raises_value_error(self):\n        json_data = '[{\"Country\": \"A\"}]'\n        with self.assertRaises(ValueError):\n            task_func(json_data)\n",
        "code": "import pandas as pd\nimport json\nimport math\n\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    # Validate input JSON data\n    if not json_data or not json_data.strip():\n        raise ValueError(\"Input JSON data is empty or whitespace.\")\n    \n    try:\n        data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"Malformed JSON input.\")\n    \n    # Validate that data is a list and contains expected country data\n    if not isinstance(data, list) or len(data) == 0:\n        raise ValueError(\"JSON input must be a non-empty list.\")\n    \n    for entry in data:\n        if not isinstance(entry, dict) or 'Country' not in entry or 'Population' not in entry:\n            raise ValueError(\"Each entry must be a dict containing 'Country' and 'Population' keys.\")\n        # Validate Country is string\n        if not isinstance(entry['Country'], str):\n            raise ValueError(\"Country name must be a string.\")\n        # Validate Population is numeric and non-negative\n        pop = entry['Population']\n        if not (isinstance(pop, int) or isinstance(pop, float)):\n            raise ValueError(\"Population must be numeric.\")\n        if pop < 0:\n            raise ValueError(\"Population must be non-negative.\")\n        # If float, round down\n        if isinstance(pop, float):\n            entry['Population'] = math.floor(pop)\n    \n    # Extract country and population info\n    countries = [entry['Country'] for entry in data]\n    populations = [entry['Population'] for entry in data]\n    \n    # Create the DataFrame\n    df = pd.DataFrame({\"Country\": countries, \"Population\": populations})\n    \n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/985_4",
        "turn": "4",
        "instruct_prompt": "The function should save the resulting DataFrame as a CSV file to the specified output directory and file name, without adding an extra index column. If writing the file fails, raise an IOError.",
        "test": "import unittest\nimport os\nimport tempfile\nimport pandas as pd\nfrom io import StringIO\n\nclass TestCases(unittest.TestCase):\n    def test_save_csv_success(self):\n        json_data = '[{\"Country\": \"A\", \"Population\": 100}, {\"Country\": \"B\", \"Population\": 200.9}]'\n        with tempfile.TemporaryDirectory() as tmpdir:\n            df = task_func(json_data, output_dir=tmpdir, file_name=\"output.csv\")\n            self.assertIsInstance(df, pd.DataFrame)\n            # Check file exists\n            file_path = os.path.join(tmpdir, \"output.csv\")\n            self.assertTrue(os.path.isfile(file_path))\n            # Check file content matches the DataFrame without index column\n            loaded_df = pd.read_csv(file_path)\n            pd.testing.assert_frame_equal(df, loaded_df)\n\n    def test_save_csv_ioerror(self):\n        json_data = '[{\"Country\": \"A\", \"Population\": 100}]'\n        # Provide an invalid directory to cause IOError\n        invalid_dir = '/invalid_directory_that_does_not_exist'\n        with self.assertRaises(IOError):\n            task_func(json_data, output_dir=invalid_dir, file_name=\"output.csv\")\n",
        "code": "import pandas as pd\nimport json\nimport math\nimport os\n\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    # Validate input JSON data\n    if not json_data or not json_data.strip():\n        raise ValueError(\"Input JSON data is empty or whitespace.\")\n    \n    try:\n        data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"Malformed JSON input.\")\n    \n    # Validate that data is a list and contains expected country data\n    if not isinstance(data, list) or len(data) == 0:\n        raise ValueError(\"JSON input must be a non-empty list.\")\n    \n    for entry in data:\n        if not isinstance(entry, dict) or 'Country' not in entry or 'Population' not in entry:\n            raise ValueError(\"Each entry must be a dict containing 'Country' and 'Population' keys.\")\n        # Validate Country is string\n        if not isinstance(entry['Country'], str):\n            raise ValueError(\"Country name must be a string.\")\n        # Validate Population is numeric and non-negative\n        pop = entry['Population']\n        if not (isinstance(pop, int) or isinstance(pop, float)):\n            raise ValueError(\"Population must be numeric.\")\n        if pop < 0:\n            raise ValueError(\"Population must be non-negative.\")\n        # If float, round down\n        if isinstance(pop, float):\n            entry['Population'] = math.floor(pop)\n    \n    # Extract country and population info\n    countries = [entry['Country'] for entry in data]\n    populations = [entry['Population'] for entry in data]\n    \n    # Create the DataFrame\n    df = pd.DataFrame({\"Country\": countries, \"Population\": populations})\n\n    # Prepare full output file path\n    output_path = os.path.join(output_dir, file_name)\n\n    # Attempt to save DataFrame to CSV without index\n    try:\n        df.to_csv(output_path, index=False)\n    except Exception as e:\n        raise IOError(f\"Failed to write CSV file: {e}\")\n\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/985_5",
        "turn": "5",
        "instruct_prompt": "The function should return a tuple containing the file path of the generated CSV report and the DataFrame with the country-population data.",
        "test": "import unittest\nimport os\nimport pandas as pd\nfrom io import StringIO\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Setup a temporary directory for output files\n        self.output_dir = \".\"\n        self.file_name = \"test_country_population_report.csv\"\n\n    def tearDown(self):\n        # Clean up the generated file after tests\n        output_path = os.path.join(self.output_dir, self.file_name)\n        if os.path.exists(output_path):\n            os.remove(output_path)\n\n    def test_return_tuple_and_content(self):\n        json_input = '[{\"Country\": \"USA\", \"Population\": 331002651}, {\"Country\": \"India\", \"Population\": 1380004385}]'\n        result = task_func(json_input, output_dir=self.output_dir, file_name=self.file_name)\n        # Check return type is tuple\n        self.assertIsInstance(result, tuple)\n        self.assertEqual(len(result), 2)\n        output_path, df = result\n\n        # Check output_path correctness\n        expected_path = os.path.join(self.output_dir, self.file_name)\n        self.assertEqual(output_path, expected_path)\n\n        # Check df is DataFrame and content is correct\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertListEqual(df['Country'].tolist(), [\"USA\", \"India\"])\n        self.assertListEqual(df['Population'].tolist(), [331002651, 1380004385])\n\n        # Check the CSV file exists and content matches DataFrame\n        self.assertTrue(os.path.exists(output_path))\n        df_from_csv = pd.read_csv(output_path)\n        pd.testing.assert_frame_equal(df, df_from_csv)\n\n    def test_previous_code_should_fail_return_type(self):\n        # This test ensures previous round code, which returns only DataFrame, will fail\n        # We simulate by calling task_func and checking if it returns tuple\n        json_input = '[{\"Country\": \"USA\", \"Population\": 331002651}]'\n        result = task_func(json_input, output_dir=self.output_dir, file_name=self.file_name)\n        # It must be a tuple now\n        self.assertIsInstance(result, tuple)\n        self.assertEqual(len(result), 2)\n\n    def test_population_float_round_down(self):\n        json_input = '[{\"Country\": \"CountryA\", \"Population\": 1234.56}]'\n        output_path, df = task_func(json_input, output_dir=self.output_dir, file_name=self.file_name)\n        self.assertEqual(df.loc[0, 'Population'], 1234)  # floored\n\n    def test_empty_json_raises(self):\n        with self.assertRaises(ValueError):\n            task_func(\"\")\n\n    def test_malformed_json_raises(self):\n        with self.assertRaises(ValueError):\n            task_func(\"{bad json}\")\n\n    def test_invalid_data_structure_raises(self):\n        with self.assertRaises(ValueError):\n            task_func('\"Just a string, not a list\"')\n\n    def test_missing_keys_raises(self):\n        json_input = '[{\"Country\": \"X\"}]'\n        with self.assertRaises(ValueError):\n            task_func(json_input)\n\n    def test_negative_population_raises(self):\n        json_input = '[{\"Country\": \"X\", \"Population\": -5}]'\n        with self.assertRaises(ValueError):\n            task_func(json_input)\n",
        "code": "import pandas as pd\nimport json\nimport math\nimport os\n\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    # Validate input JSON data\n    if not json_data or not json_data.strip():\n        raise ValueError(\"Input JSON data is empty or whitespace.\")\n    \n    try:\n        data = json.loads(json_data)\n    except json.JSONDecodeError:\n        raise ValueError(\"Malformed JSON input.\")\n    \n    # Validate that data is a list and contains expected country data\n    if not isinstance(data, list) or len(data) == 0:\n        raise ValueError(\"JSON input must be a non-empty list.\")\n    \n    for entry in data:\n        if not isinstance(entry, dict) or 'Country' not in entry or 'Population' not in entry:\n            raise ValueError(\"Each entry must be a dict containing 'Country' and 'Population' keys.\")\n        # Validate Country is string\n        if not isinstance(entry['Country'], str):\n            raise ValueError(\"Country name must be a string.\")\n        # Validate Population is numeric and non-negative\n        pop = entry['Population']\n        if not (isinstance(pop, int) or isinstance(pop, float)):\n            raise ValueError(\"Population must be numeric.\")\n        if pop < 0:\n            raise ValueError(\"Population must be non-negative.\")\n        # If float, round down\n        if isinstance(pop, float):\n            entry['Population'] = math.floor(pop)\n    \n    # Extract country and population info\n    countries = [entry['Country'] for entry in data]\n    populations = [entry['Population'] for entry in data]\n    \n    # Create the DataFrame\n    df = pd.DataFrame({\"Country\": countries, \"Population\": populations})\n\n    # Prepare full output file path\n    output_path = os.path.join(output_dir, file_name)\n\n    # Attempt to save DataFrame to CSV without index\n    try:\n        df.to_csv(output_path, index=False)\n    except Exception as e:\n        raise IOError(f\"Failed to write CSV file: {e}\")\n\n    return (output_path, df)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 125,
    "task_id": "BigCodeBench/988",
    "mt_data": [
      {
        "task_id": "BigCodeBench/988_1",
        "turn": "1",
        "instruct_prompt": "Write a function that lists all items (files and directories) in a given directory. You should write self-contained code starting with:```python\nimport os\nfrom pathlib import Path\ndef task_func(dir_path: str, predicates: list) -> dict:\n```",
        "test": "import unittest\nimport tempfile\nimport os\nfrom pathlib import Path\n\nclass TestCases(unittest.TestCase):\n    def test_list_items(self):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            # Create some files and directories\n            Path(tmpdirname, \"file1.txt\").write_text(\"hello\")\n            Path(tmpdirname, \"file2.txt\").write_text(\"world\")\n            os.mkdir(Path(tmpdirname, \"subdir1\"))\n\n            result = task_func(tmpdirname, [])\n            self.assertIn(\"file1.txt\", result[\"items\"])\n            self.assertIn(\"file2.txt\", result[\"items\"])\n            self.assertIn(\"subdir1\", result[\"items\"])\n            self.assertEqual(len(result[\"items\"]), 3)\n\n    def test_empty_directory(self):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            result = task_func(tmpdirname, [])\n            self.assertEqual(result[\"items\"], [])\n\n    def test_non_existing_directory(self):\n        result = task_func(\"/non/existing/path\", [])\n        self.assertEqual(result, {})\n",
        "code": "import os\nfrom pathlib import Path\n\ndef task_func(dir_path: str, predicates: list) -> dict:\n    \"\"\"List all items (files and directories) in the given directory.\"\"\"\n    p = Path(dir_path)\n    if not p.is_dir():\n        return {}\n    items = [item.name for item in p.iterdir()]\n    return {\"items\": items}",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/988_2",
        "turn": "2",
        "instruct_prompt": "Add input validation to the function: raise FileNotFoundError if the specified directory does not exist or is not a directory.",
        "test": "import unittest\nimport tempfile\nimport os\nfrom pathlib import Path\n\nclass TestCases(unittest.TestCase):\n    def test_directory_exists(self):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            # Create some files and directories\n            Path(tmpdirname, 'file1.txt').write_text('hello')\n            os.mkdir(Path(tmpdirname, 'subdir'))\n            result = task_func(tmpdirname, [])\n            self.assertIn('file1.txt', result['items'])\n            self.assertIn('subdir', result['items'])\n\n    def test_directory_not_exist(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('/non/existent/directory/path', [])\n\n    def test_path_is_file_not_directory(self):\n        with tempfile.NamedTemporaryFile() as tmpfile:\n            with self.assertRaises(FileNotFoundError):\n                task_func(tmpfile.name, [])",
        "code": "import os\nfrom pathlib import Path\n\ndef task_func(dir_path: str, predicates: list) -> dict:\n    \"\"\"List all items (files and directories) in the given directory.\"\"\"\n    p = Path(dir_path)\n    if not p.exists() or not p.is_dir():\n        raise FileNotFoundError(f\"The directory '{dir_path}' does not exist or is not a directory.\")\n    items = [item.name for item in p.iterdir()]\n    return {\"items\": items}",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/988_3",
        "turn": "3",
        "instruct_prompt": "Define a set of predicates (conditions) as functions that evaluate properties of file/directory names (not full paths). Deduplicate the predicates list by keeping only valid predicate names. Raise ValueError if no valid predicates are provided.",
        "test": "import unittest\nimport tempfile\nimport os\nfrom pathlib import Path\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Setup a temporary directory with some files\n        self.test_dir = tempfile.TemporaryDirectory()\n        dir_path = Path(self.test_dir.name)\n        # Create files and directories\n        (dir_path / '.hiddenfile').write_text('hidden')\n        (dir_path / 'script.py').write_text('print(1)')\n        (dir_path / 'readme.md').write_text('# readme')\n        (dir_path / '.anotherhidden').write_text('hidden2')\n        (dir_path / 'normal.txt').write_text('normal')\n        (dir_path / 'code.py').write_text('print(2)')\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def test_valid_predicates_deduplication_and_filtering(self):\n        # Provide predicates with duplicates and invalid names\n        predicates = ['is_hidden', 'is_python_file', 'invalid_pred', 'is_hidden']\n        result = task_func(self.test_dir.name, predicates)\n        # Should keep only 'is_hidden' and 'is_python_file'\n        # Items must satisfy both predicates (i.e., files that are hidden AND python files)\n        # So only '.hiddenfile' and '.anotherhidden' are hidden, but none ends with .py\n        # So expected empty list\n        self.assertEqual(result, {\"items\": []})\n\n    def test_only_is_hidden(self):\n        predicates = ['is_hidden']\n        result = task_func(self.test_dir.name, predicates)\n        # Should include all hidden files\n        expected = ['.hiddenfile', '.anotherhidden']\n        self.assertCountEqual(result[\"items\"], expected)\n\n    def test_only_is_python_file(self):\n        predicates = ['is_python_file']\n        result = task_func(self.test_dir.name, predicates)\n        expected = ['script.py', 'code.py']\n        self.assertCountEqual(result[\"items\"], expected)\n\n    def test_no_valid_predicates_raises(self):\n        predicates = ['invalid1', 'invalid2']\n        with self.assertRaises(ValueError):\n            task_func(self.test_dir.name, predicates)\n\n    def test_empty_predicates_raises(self):\n        predicates = []\n        with self.assertRaises(ValueError):\n            task_func(self.test_dir.name, predicates)\n",
        "code": "import os\nfrom pathlib import Path\n\n# Define predicate functions that take a file/directory name and return a boolean\n\ndef is_hidden(name: str) -> bool:\n    return name.startswith('.')\n\ndef is_python_file(name: str) -> bool:\n    return name.endswith('.py')\n\ndef is_directory(name: str) -> bool:\n    # This predicate requires the directory path to check if name is a directory, but as per requirement,\n    # predicates only evaluate the name, so this predicate cannot reliably check if name is directory without path.\n    # We will omit such predicates for now.\n    return False\n\nVALID_PREDICATES = {\n    'is_hidden': is_hidden,\n    'is_python_file': is_python_file\n}\n\ndef task_func(dir_path: str, predicates: list) -> dict:\n    \"\"\"List all items (files and directories) in the given directory, filtered by predicates.\"\"\"\n    p = Path(dir_path)\n    if not p.exists() or not p.is_dir():\n        raise FileNotFoundError(f\"The directory '{dir_path}' does not exist or is not a directory.\")\n\n    # Deduplicate predicates by keeping only valid predicate names\n    valid_predicate_names = []\n    for pred in predicates:\n        if pred in VALID_PREDICATES and pred not in valid_predicate_names:\n            valid_predicate_names.append(pred)\n\n    if not valid_predicate_names:\n        raise ValueError(\"No valid predicates provided.\")\n\n    items = []\n    for item in p.iterdir():\n        name = item.name\n        # Evaluate all predicates on the name, include item only if all predicates are True\n        if all(VALID_PREDICATES[pred](name) for pred in valid_predicate_names):\n            items.append(name)\n\n    return {\"items\": items}",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/988_4",
        "turn": "4",
        "instruct_prompt": "Evaluate each directory items name against the specified predicates and return a dictionary where each key is the item name and the value is another dictionary mapping predicate names to their boolean evaluation results.",
        "test": "import unittest\nimport tempfile\nfrom pathlib import Path\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = tempfile.TemporaryDirectory()\n        self.dir_path = self.test_dir.name\n\n        # Create files and directories\n        # .hidden_file.py (hidden and python file)\n        Path(self.dir_path, '.hidden_file.py').write_text('print(123)')\n        # visible_file.txt (visible, not python)\n        Path(self.dir_path, 'visible_file.txt').write_text('hello')\n        # script.py (visible, python file)\n        Path(self.dir_path, 'script.py').write_text('print(\"script\")')\n        # .hidden_folder (hidden, directory)\n        hidden_folder_path = Path(self.dir_path, '.hidden_folder')\n        hidden_folder_path.mkdir()\n        # visible_folder (visible directory)\n        visible_folder_path = Path(self.dir_path, 'visible_folder')\n        visible_folder_path.mkdir()\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def test_predicate_evaluations(self):\n        predicates = ['is_hidden', 'is_python_file']\n        result = task_func(self.dir_path, predicates)\n\n        expected_keys = {'.hidden_file.py', 'visible_file.txt', 'script.py', '.hidden_folder', 'visible_folder'}\n        self.assertEqual(set(result.keys()), expected_keys)\n\n        # Check individual predicate results\n        self.assertEqual(result['.hidden_file.py']['is_hidden'], True)\n        self.assertEqual(result['.hidden_file.py']['is_python_file'], True)\n\n        self.assertEqual(result['visible_file.txt']['is_hidden'], False)\n        self.assertEqual(result['visible_file.txt']['is_python_file'], False)\n\n        self.assertEqual(result['script.py']['is_hidden'], False)\n        self.assertEqual(result['script.py']['is_python_file'], True)\n\n        self.assertEqual(result['.hidden_folder']['is_hidden'], True)\n        self.assertEqual(result['.hidden_folder']['is_python_file'], False)\n\n        self.assertEqual(result['visible_folder']['is_hidden'], False)\n        self.assertEqual(result['visible_folder']['is_python_file'], False)\n\n    def test_invalid_predicate(self):\n        with self.assertRaises(ValueError):\n            task_func(self.dir_path, ['non_existing_predicate'])\n\n    def test_empty_predicates(self):\n        with self.assertRaises(ValueError):\n            task_func(self.dir_path, [])\n\n    def test_nonexistent_directory(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('/non/existent/path', ['is_hidden'])\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import os\nfrom pathlib import Path\n\n# Define predicate functions that take a file/directory name and return a boolean\n\ndef is_hidden(name: str) -> bool:\n    return name.startswith('.')\n\ndef is_python_file(name: str) -> bool:\n    return name.endswith('.py')\n\nVALID_PREDICATES = {\n    'is_hidden': is_hidden,\n    'is_python_file': is_python_file\n}\n\ndef task_func(dir_path: str, predicates: list) -> dict:\n    \"\"\"Evaluate each directory items name against the specified predicates and return a dictionary where\n    each key is the item name and the value is another dictionary mapping predicate names to their boolean evaluation results.\"\"\"\n    p = Path(dir_path)\n    if not p.exists() or not p.is_dir():\n        raise FileNotFoundError(f\"The directory '{dir_path}' does not exist or is not a directory.\")\n\n    # Deduplicate predicates by keeping only valid predicate names\n    valid_predicate_names = []\n    for pred in predicates:\n        if pred in VALID_PREDICATES and pred not in valid_predicate_names:\n            valid_predicate_names.append(pred)\n\n    if not valid_predicate_names:\n        raise ValueError(\"No valid predicates provided.\")\n\n    result = {}\n    for item in p.iterdir():\n        name = item.name\n        pred_results = {}\n        for pred in valid_predicate_names:\n            pred_results[pred] = VALID_PREDICATES[pred](name)\n        result[name] = pred_results\n\n    return result\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 126,
    "task_id": "BigCodeBench/990",
    "mt_data": [
      {
        "task_id": "BigCodeBench/990_1",
        "turn": "1",
        "instruct_prompt": "Convert a hexadecimal string to a UTF-8 decoded string. You should write self-contained code starting with:\n```\nimport binascii\nimport base64\nimport urllib.parse\nimport codecs\ndef task_func(hex_string):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic_utf8(self):\n        # 'hello' in hex\n        self.assertEqual(task_func('68656c6c6f'), 'hello')\n\n    def test_utf8_with_multibyte(self):\n        # '' in hex (UTF-8)\n        self.assertEqual(task_func('e4bda0e5a5bd'), '')\n\n    def test_empty_string(self):\n        self.assertEqual(task_func(''), '')\n\n    def test_invalid_hex(self):\n        with self.assertRaises(binascii.Error):\n            task_func('zz')\n\n    def test_incomplete_hex(self):\n        with self.assertRaises(binascii.Error):\n            task_func('a')\n",
        "code": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\n\ndef task_func(hex_string):\n    # Convert hex string to bytes\n    byte_data = binascii.unhexlify(hex_string)\n    # Decode bytes to UTF-8 string\n    return byte_data.decode('utf-8')\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/990_2",
        "turn": "2",
        "instruct_prompt": "Extend the function to encode the decoded UTF-8 string into hexadecimal and base64 formats, returning these encodings in a dictionary.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_encoding(self):\n        # Original string: 'hello'\n        hex_input = '68656c6c6f'\n        expected_hex = '68656c6c6f'\n        expected_base64 = 'aGVsbG8='\n        result = task_func(hex_input)\n        self.assertIsInstance(result, dict)\n        self.assertIn('hex', result)\n        self.assertIn('base64', result)\n        self.assertEqual(result['hex'], expected_hex)\n        self.assertEqual(result['base64'], expected_base64)\n\n    def test_encoding_unicode(self):\n        # Original string: ''\n        hex_input = 'e4bda0e5a5bd'\n        expected_hex = 'e4bda0e5a5bd'\n        expected_base64 = '5L2g5aW9'\n        result = task_func(hex_input)\n        self.assertEqual(result['hex'], expected_hex)\n        self.assertEqual(result['base64'], expected_base64)\n\n    def test_empty_string(self):\n        hex_input = ''\n        expected_hex = ''\n        expected_base64 = ''\n        result = task_func(hex_input)\n        self.assertEqual(result['hex'], expected_hex)\n        self.assertEqual(result['base64'], expected_base64)\n\n    def test_invalid_hex(self):\n        hex_input = 'zz'\n        with self.assertRaises(binascii.Error):\n            task_func(hex_input)\n",
        "code": "import binascii\nimport base64\n\ndef task_func(hex_string):\n    # Convert hex string to bytes\n    byte_data = binascii.unhexlify(hex_string)\n    # Decode bytes to UTF-8 string\n    decoded_str = byte_data.decode('utf-8')\n    # Encode decoded string to hexadecimal\n    hex_encoded = binascii.hexlify(decoded_str.encode('utf-8')).decode('utf-8')\n    # Encode decoded string to base64\n    base64_encoded = base64.b64encode(decoded_str.encode('utf-8')).decode('utf-8')\n    # Return dictionary with both encodings\n    return {\"hex\": hex_encoded, \"base64\": base64_encoded}",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/990_3",
        "turn": "3",
        "instruct_prompt": "Add UTF-8, UTF-16, and UTF-32 encodings of the decoded string to the dictionary.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_encodings(self):\n        # 'hello' in hex (UTF-8)\n        input_hex = '68656c6c6f'\n        result = task_func(input_hex)\n        expected_utf8 = '68656c6c6f'\n        expected_utf16 = 'fffe680065006c006c006f00'\n        expected_utf32 = 'fffe000068000000650000006c0000006c0000006f000000'\n        self.assertEqual(result['hex'], expected_utf8)\n        self.assertEqual(result['base64'], 'aGVsbG8=')\n        self.assertEqual(result['utf8'], expected_utf8)\n        self.assertEqual(result['utf16'], expected_utf16)\n        self.assertEqual(result['utf32'], expected_utf32)\n\n    def test_utf8_multibyte(self):\n        # '' in hex (UTF-8)\n        input_hex = 'e4bda0e5a5bd'\n        result = task_func(input_hex)\n        # UTF-8 hex should be same as input\n        self.assertEqual(result['utf8'], input_hex)\n        # Base64 of UTF-8\n        self.assertEqual(result['base64'], '5L2g5aW9')\n        # UTF-16 encoding check (with BOM)\n        expected_utf16 = 'fffe60597d7d59'\n        # Since BOM + utf-16le bytes for ''(0x4f60), ''(0x597d)\n        # Let's compute actual expected utf16 hex bytes\n        # BOM: ff fe\n        # '' U+4F60 => 60 4f in little endian\n        # '' U+597d => 7d 59 in little endian\n        expected_utf16 = 'fffe604f7d59'\n        self.assertEqual(result['utf16'], expected_utf16)\n        # UTF-32 encoding check (with BOM)\n        # BOM: ff fe 00 00\n        # '' U+4F60 => 60 4f 00 00\n        # '' U+597d => 7d 59 00 00\n        expected_utf32 = 'fffe0000604f00007d590000'\n        self.assertEqual(result['utf32'], expected_utf32)\n\n    def test_empty_string(self):\n        input_hex = ''\n        result = task_func(input_hex)\n        self.assertEqual(result['hex'], '')\n        self.assertEqual(result['base64'], '')\n        self.assertEqual(result['utf8'], '')\n        # UTF-16 BOM only\n        self.assertEqual(result['utf16'], 'fffe')\n        # UTF-32 BOM only\n        self.assertEqual(result['utf32'], 'fffe0000')\n",
        "code": "import binascii\nimport base64\n\ndef task_func(hex_string):\n    # Convert hex string to bytes\n    byte_data = binascii.unhexlify(hex_string)\n    # Decode bytes to UTF-8 string\n    decoded_str = byte_data.decode('utf-8')\n    # Encode decoded string to hexadecimal (UTF-8)\n    hex_encoded = binascii.hexlify(decoded_str.encode('utf-8')).decode('utf-8')\n    # Encode decoded string to base64 (UTF-8)\n    base64_encoded = base64.b64encode(decoded_str.encode('utf-8')).decode('utf-8')\n    # Encode decoded string to UTF-8 bytes\n    utf8_bytes = decoded_str.encode('utf-8')\n    # Encode decoded string to UTF-16 bytes (with BOM)\n    utf16_bytes = decoded_str.encode('utf-16')\n    # Encode decoded string to UTF-32 bytes (with BOM)\n    utf32_bytes = decoded_str.encode('utf-32')\n    # Encode these byte sequences to hex strings\n    utf8_hex = binascii.hexlify(utf8_bytes).decode('utf-8')\n    utf16_hex = binascii.hexlify(utf16_bytes).decode('utf-8')\n    utf32_hex = binascii.hexlify(utf32_bytes).decode('utf-8')\n    \n    return {\n        \"hex\": hex_encoded,\n        \"base64\": base64_encoded,\n        \"utf8\": utf8_hex,\n        \"utf16\": utf16_hex,\n        \"utf32\": utf32_hex\n    }\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/990_4",
        "turn": "4",
        "instruct_prompt": "Include ASCII encoding of the decoded string if representable; otherwise, set the value to 'Not representable in ASCII'. Also add URL encoding and ROT13 encoding of the decoded string to the dictionary.",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_ascii_representable(self):\n        # 'hello' is ASCII representable\n        hex_input = '68656c6c6f'\n        result = task_func(hex_input)\n        self.assertEqual(result['ascii'], 'hello')\n        self.assertEqual(result['url'], 'hello')\n        self.assertEqual(result['rot13'], 'uryyb')\n\n    def test_ascii_not_representable(self):\n        # '' in hex (UTF-8) is not ASCII representable\n        # \n        hex_input = 'e38193e38293e381abe381a1e381af'\n        result = task_func(hex_input)\n        self.assertEqual(result['ascii'], 'Not representable in ASCII')\n        # URL encoding should be percent encoded\n        self.assertTrue(result['url'].startswith('%'))\n        # ROT13 encoding on non-ascii characters returns the same string\n        self.assertEqual(result['rot13'], '')\n\n    def test_empty_string(self):\n        hex_input = ''\n        result = task_func(hex_input)\n        self.assertEqual(result['ascii'], '')\n        self.assertEqual(result['url'], '')\n        self.assertEqual(result['rot13'], '')\n\n    def test_url_encoding_special_chars(self):\n        # String with spaces and symbols\n        hex_input = '48656c6c6f20576f726c6421'  # 'Hello World!'\n        result = task_func(hex_input)\n        self.assertEqual(result['ascii'], 'Hello World!')\n        self.assertEqual(result['url'], 'Hello%20World%21')\n        self.assertEqual(result['rot13'], 'Uryyb Jbeyq!')\n",
        "code": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\n\ndef task_func(hex_string):\n    # Convert hex string to bytes\n    byte_data = binascii.unhexlify(hex_string)\n    # Decode bytes to UTF-8 string\n    decoded_str = byte_data.decode('utf-8')\n    # Encode decoded string to hexadecimal (UTF-8)\n    hex_encoded = binascii.hexlify(decoded_str.encode('utf-8')).decode('utf-8')\n    # Encode decoded string to base64 (UTF-8)\n    base64_encoded = base64.b64encode(decoded_str.encode('utf-8')).decode('utf-8')\n    # Encode decoded string to UTF-8 bytes\n    utf8_bytes = decoded_str.encode('utf-8')\n    # Encode decoded string to UTF-16 bytes (with BOM)\n    utf16_bytes = decoded_str.encode('utf-16')\n    # Encode decoded string to UTF-32 bytes (with BOM)\n    utf32_bytes = decoded_str.encode('utf-32')\n    # Encode these byte sequences to hex strings\n    utf8_hex = binascii.hexlify(utf8_bytes).decode('utf-8')\n    utf16_hex = binascii.hexlify(utf16_bytes).decode('utf-8')\n    utf32_hex = binascii.hexlify(utf32_bytes).decode('utf-8')\n\n    # ASCII encoding if representable\n    try:\n        ascii_encoded = decoded_str.encode('ascii').decode('ascii')\n    except UnicodeEncodeError:\n        ascii_encoded = 'Not representable in ASCII'\n\n    # URL encoding\n    url_encoded = urllib.parse.quote(decoded_str)\n\n    # ROT13 encoding\n    rot13_encoded = codecs.encode(decoded_str, 'rot_13')\n\n    return {\n        \"hex\": hex_encoded,\n        \"base64\": base64_encoded,\n        \"utf8\": utf8_hex,\n        \"utf16\": utf16_hex,\n        \"utf32\": utf32_hex,\n        \"ascii\": ascii_encoded,\n        \"url\": url_encoded,\n        \"rot13\": rot13_encoded\n    }\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 127,
    "task_id": "BigCodeBench/998",
    "mt_data": [
      {
        "task_id": "BigCodeBench/998_1",
        "turn": "1",
        "instruct_prompt": "Write a function that downloads a file from a given URL and saves it locally. You should write self-contained code starting with:\n```\nimport urllib.request\n# Constants\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\ndef task_func(url):\n```",
        "test": "import unittest\nimport os\nfrom unittest import mock\nimport urllib.request\n\nclass TestCases(unittest.TestCase):\n    @mock.patch('urllib.request.urlretrieve')\n    def test_download_called_with_correct_args(self, mock_urlretrieve):\n        test_url = 'http://example.com/file.tar.gz'\n        task_func(test_url)\n        mock_urlretrieve.assert_called_once_with(test_url, TARGET_TAR_FILE)\n\n    @mock.patch('urllib.request.urlretrieve')\n    def test_file_created_after_download(self, mock_urlretrieve):\n        # Simulate file creation\n        def side_effect(url, filename):\n            with open(filename, 'w') as f:\n                f.write('dummy content')\n        mock_urlretrieve.side_effect = side_effect\n\n        # Clean up before test\n        if os.path.exists(TARGET_TAR_FILE):\n            os.remove(TARGET_TAR_FILE)\n\n        task_func('http://example.com/file.tar.gz')\n        self.assertTrue(os.path.exists(TARGET_TAR_FILE))\n\n        # Clean up after test\n        if os.path.exists(TARGET_TAR_FILE):\n            os.remove(TARGET_TAR_FILE)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import urllib.request\n# Constants\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\ndef task_func(url):\n    urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/998_2",
        "turn": "2",
        "instruct_prompt": "After downloading, verify the downloaded file's MD5 checksum matches a predefined expected checksum. If the checksum does not match, delete the downloaded file and return False.",
        "test": "import unittest\nimport os\nfrom unittest import mock\n\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5 = \"5d41402abc4b2a76b9719d911017c592\"  # MD5 of 'hello'\n\nclass TestCases(unittest.TestCase):\n    @mock.patch('urllib.request.urlretrieve')\n    def test_correct_md5(self, mock_urlretrieve):\n        # Mock urlretrieve to write 'hello' to file, matching EXPECTED_MD5\n        def side_effect(url, filename):\n            with open(filename, 'wb') as f:\n                f.write(b'hello')\n        mock_urlretrieve.side_effect = side_effect\n\n        result = task_func('http://fakeurl.com/file.tar.gz')\n\n        # Should return True and file should exist\n        self.assertTrue(result)\n        self.assertTrue(os.path.exists(TARGET_TAR_FILE))\n\n        # Cleanup\n        os.remove(TARGET_TAR_FILE)\n\n    @mock.patch('urllib.request.urlretrieve')\n    def test_incorrect_md5(self, mock_urlretrieve):\n        # Mock urlretrieve to write content not matching EXPECTED_MD5\n        def side_effect(url, filename):\n            with open(filename, 'wb') as f:\n                f.write(b'incorrect content')\n        mock_urlretrieve.side_effect = side_effect\n\n        result = task_func('http://fakeurl.com/file.tar.gz')\n\n        # Should return False and file should be deleted\n        self.assertFalse(result)\n        self.assertFalse(os.path.exists(TARGET_TAR_FILE))\n",
        "code": "import urllib.request\nimport hashlib\nimport os\n\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5 = \"5d41402abc4b2a76b9719d911017c592\"  # MD5 of 'hello'\n\ndef task_func(url):\n    urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n\n    md5_hash = hashlib.md5()\n    with open(TARGET_TAR_FILE, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            md5_hash.update(chunk)\n    downloaded_md5 = md5_hash.hexdigest()\n\n    if downloaded_md5 != EXPECTED_MD5:\n        os.remove(TARGET_TAR_FILE)\n        return False\n    return True\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/998_3",
        "turn": "3",
        "instruct_prompt": "If the checksum matches, extract the contents of the downloaded tar.gz file, then delete the tar.gz file and return True.",
        "test": "import unittest\nimport os\nimport tarfile\nimport hashlib\nimport tempfile\nimport shutil\nfrom io import BytesIO\n\nimport urllib.request\n\nfrom unittest import mock\n\n# Import the task_func and constants from the solution\n# Since we are in the same code block, assume task_func is already defined\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory to work in\n        self.test_dir = tempfile.mkdtemp()\n        self.original_cwd = os.getcwd()\n        os.chdir(self.test_dir)\n\n    def tearDown(self):\n        # Return to original directory and clean up\n        os.chdir(self.original_cwd)\n        shutil.rmtree(self.test_dir)\n\n    def _create_tar_gz_file(self, filename, file_contents):\n        # Create a tar.gz file with one file inside\n        with tarfile.open(filename, \"w:gz\") as tar:\n            data = file_contents.encode('utf-8')\n            fileobj = BytesIO(data)\n            tarinfo = tarfile.TarInfo(name=\"testfile.txt\")\n            tarinfo.size = len(data)\n            tar.addfile(tarinfo, fileobj)\n\n    def _calculate_md5(self, filename):\n        md5_hash = hashlib.md5()\n        with open(filename, \"rb\") as f:\n            for chunk in iter(lambda: f.read(4096), b\"\"):\n                md5_hash.update(chunk)\n        return md5_hash.hexdigest()\n\n    @mock.patch('urllib.request.urlretrieve')\n    def test_checksum_match_extract_and_delete(self, mock_urlretrieve):\n        # Prepare tar.gz file with content \"hello\" inside\n        self._create_tar_gz_file(\"test.tar.gz\", \"hello\")\n        # Calculate its md5\n        md5 = self._calculate_md5(\"test.tar.gz\")\n\n        # Patch EXPECTED_MD5 to match this md5\n        global EXPECTED_MD5\n        EXPECTED_MD5 = md5\n\n        # Mock urlretrieve to copy our test.tar.gz to TARGET_TAR_FILE\n        def fake_urlretrieve(url, filename):\n            shutil.copyfile(\"test.tar.gz\", filename)\n        mock_urlretrieve.side_effect = fake_urlretrieve\n\n        url = \"http://example.com/fake.tar.gz\"\n\n        result = task_func(url)\n\n        # Check function returns True\n        self.assertTrue(result)\n\n        # Check tar.gz file is deleted\n        self.assertFalse(os.path.exists(TARGET_TAR_FILE))\n\n        # Check extracted file exists with correct content\n        self.assertTrue(os.path.exists(\"testfile.txt\"))\n        with open(\"testfile.txt\", \"r\") as f:\n            content = f.read()\n        self.assertEqual(content, \"hello\")\n\n    @mock.patch('urllib.request.urlretrieve')\n    def test_checksum_mismatch_deletes_file_and_returns_false(self, mock_urlretrieve):\n        # Prepare tar.gz file with content \"hello\" inside\n        self._create_tar_gz_file(\"test.tar.gz\", \"hello\")\n\n        # Set EXPECTED_MD5 to a different value\n        global EXPECTED_MD5\n        EXPECTED_MD5 = \"00000000000000000000000000000000\"\n\n        # Mock urlretrieve to copy our test.tar.gz to TARGET_TAR_FILE\n        def fake_urlretrieve(url, filename):\n            shutil.copyfile(\"test.tar.gz\", filename)\n        mock_urlretrieve.side_effect = fake_urlretrieve\n\n        url = \"http://example.com/fake.tar.gz\"\n\n        result = task_func(url)\n\n        # Check function returns False\n        self.assertFalse(result)\n\n        # Check tar.gz file is deleted\n        self.assertFalse(os.path.exists(TARGET_TAR_FILE))\n\n        # Check no extracted file created\n        self.assertFalse(os.path.exists(\"testfile.txt\"))\n",
        "code": "import urllib.request\nimport hashlib\nimport os\nimport tarfile\n\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5 = \"5d41402abc4b2a76b9719d911017c592\"  # MD5 of 'hello'\n\ndef task_func(url):\n    urllib.request.urlretrieve(url, TARGET_TAR_FILE)\n\n    md5_hash = hashlib.md5()\n    with open(TARGET_TAR_FILE, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            md5_hash.update(chunk)\n    downloaded_md5 = md5_hash.hexdigest()\n\n    if downloaded_md5 != EXPECTED_MD5:\n        os.remove(TARGET_TAR_FILE)\n        return False\n\n    # Extract tar.gz file\n    with tarfile.open(TARGET_TAR_FILE, \"r:gz\") as tar:\n        tar.extractall()\n\n    os.remove(TARGET_TAR_FILE)\n    return True\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 128,
    "task_id": "BigCodeBench/999",
    "mt_data": [
      {
        "task_id": "BigCodeBench/999_1",
        "turn": "1",
        "instruct_prompt": "Download a CSV file from a given URL and save it to a specified path. You should write self-contained code starting with:\n```\nimport urllib.request\nimport os\nimport csv\nimport collections\ndef task_func(url, column_name, csv_file_path):\n```",
        "test": "import unittest\nimport os\nimport tempfile\nfrom http.server import HTTPServer, SimpleHTTPRequestHandler\nimport threading\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory\n        self.test_dir = tempfile.TemporaryDirectory()\n        self.test_csv_path = os.path.join(self.test_dir.name, 'test.csv')\n\n        # Create a sample CSV content\n        self.sample_csv_content = b\"col1,col2,col3\\n1,2,3\\n4,5,6\\n\"\n\n        # Set up a simple HTTP server to serve the CSV content\n        class TestHandler(SimpleHTTPRequestHandler):\n            def do_GET(self):\n                self.send_response(200)\n                self.send_header('Content-type', 'text/csv')\n                self.end_headers()\n                self.wfile.write(self.server.csv_content)\n\n        self.httpd = HTTPServer(('localhost', 0), TestHandler)\n        self.httpd.csv_content = self.sample_csv_content\n\n        # Run the server in a separate thread\n        self.server_thread = threading.Thread(target=self.httpd.serve_forever)\n        self.server_thread.daemon = True\n        self.server_thread.start()\n\n        self.url = f'http://localhost:{self.httpd.server_port}/sample.csv'\n\n    def tearDown(self):\n        self.httpd.shutdown()\n        self.server_thread.join()\n        self.test_dir.cleanup()\n\n    def test_task_func_downloads_csv(self):\n        # Directly call the function without import\n        task_func(self.url, 'col2', self.test_csv_path)\n\n        # Check the file exists\n        self.assertTrue(os.path.exists(self.test_csv_path))\n\n        # Read the file and check content\n        with open(self.test_csv_path, 'rb') as f:\n            content = f.read()\n\n        self.assertEqual(content, self.sample_csv_content)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import urllib.request\nimport os\nimport csv\nimport collections\n\ndef task_func(url, column_name, csv_file_path):\n    # Download the CSV file from the given URL\n    with urllib.request.urlopen(url) as response:\n        content = response.read()\n\n    # Save the content to the specified path\n    with open(csv_file_path, 'wb') as f:\n        f.write(content)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/999_2",
        "turn": "2",
        "instruct_prompt": "Read the downloaded CSV file and count the occurrences of each value in the specified column_name.",
        "test": "import unittest\nimport tempfile\nimport os\nimport threading\nimport http.server\nimport socketserver\nimport time\n\nclass TestCases(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.csv_content = \"\"\"name,age,city\\nAlice,30,New York\\nBob,25,Los Angeles\\nAlice,22,New York\\nCharlie,35,Chicago\\nBob,25,Los Angeles\\n\"\"\"\n\n        class Handler(http.server.SimpleHTTPRequestHandler):\n            def do_GET(self):\n                if self.path == '/test.csv':\n                    self.send_response(200)\n                    self.send_header(\"Content-type\", \"text/csv\")\n                    self.end_headers()\n                    self.wfile.write(cls.csv_content.encode('utf-8'))\n                else:\n                    self.send_response(404)\n                    self.end_headers()\n\n        # Use port 0 to assign an ephemeral port\n        cls.httpd = socketserver.TCPServer(('localhost', 0), Handler)\n        cls.port = cls.httpd.server_address[1]\n\n        cls.thread = threading.Thread(target=cls.httpd.serve_forever)\n        cls.thread.daemon = True\n        cls.thread.start()\n\n        # Wait briefly to ensure server is ready\n        time.sleep(0.1)\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.httpd.shutdown()\n        cls.thread.join()\n\n    def test_count_occurrences(self):\n        url = f'http://localhost:{self.port}/test.csv'\n        with tempfile.TemporaryDirectory() as tmpdir:\n            csv_file_path = os.path.join(tmpdir, 'test.csv')\n            result = task_func(url, 'name', csv_file_path)\n            expected = {'Alice': 2, 'Bob': 2, 'Charlie': 1}\n            self.assertEqual(result, expected)\n\n            result_age = task_func(url, 'age', csv_file_path)\n            expected_age = {'30': 1, '25': 2, '22': 1, '35': 1}\n            self.assertEqual(result_age, expected_age)\n\n            result_city = task_func(url, 'city', csv_file_path)\n            expected_city = {'New York': 2, 'Los Angeles': 2, 'Chicago': 1}\n            self.assertEqual(result_city, expected_city)\n\n    def test_column_not_exist(self):\n        url = f'http://localhost:{self.port}/test.csv'\n        with tempfile.TemporaryDirectory() as tmpdir:\n            csv_file_path = os.path.join(tmpdir, 'test.csv')\n            result = task_func(url, 'nonexistent_column', csv_file_path)\n            self.assertEqual(result, {})\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import urllib.request\nimport csv\nimport collections\n\ndef task_func(url, column_name, csv_file_path):\n    # Download the CSV file from the given URL\n    with urllib.request.urlopen(url) as response:\n        content = response.read()\n\n    # Save the content to the specified path\n    with open(csv_file_path, 'wb') as f:\n        f.write(content)\n\n    # Read the CSV file and count occurrences of each value in the specified column\n    counts = collections.Counter()\n    with open(csv_file_path, 'r', newline='', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            value = row.get(column_name)\n            if value is not None:\n                counts[value] += 1\n    return dict(counts)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/999_3",
        "turn": "3",
        "instruct_prompt": "If the specified column_name does not exist in the CSV file, delete the downloaded file and raise a ValueError with the message: \"The provided column_name '{column_name}' does not exist in the CSV file.\"",
        "test": "import unittest\nimport os\nimport tempfile\nimport http.server\nimport socketserver\nimport threading\n\nclass TestCases(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        # Set up a simple HTTP server to serve test CSV files\n        cls.test_dir = tempfile.TemporaryDirectory()\n        cls.csv_path = os.path.join(cls.test_dir.name, 'test.csv')\n        # Create a sample CSV file\n        with open(cls.csv_path, 'w', encoding='utf-8') as f:\n            f.write('name,age,city\\nAlice,30,New York\\nBob,25,Los Angeles\\nAlice,30,New York\\n')\n\n        os.chdir(cls.test_dir.name)\n\n        handler = http.server.SimpleHTTPRequestHandler\n        cls.httpd = socketserver.TCPServer(('localhost', 0), handler)  # Bind to any free port\n        cls.port = cls.httpd.server_address[1]\n\n        cls.server_thread = threading.Thread(target=cls.httpd.serve_forever)\n        cls.server_thread.daemon = True\n        cls.server_thread.start()\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.httpd.shutdown()\n        cls.server_thread.join()\n        cls.test_dir.cleanup()\n\n    def test_column_exists(self):\n        url = f'http://localhost:{self.port}/test.csv'\n        out_file = os.path.join(self.test_dir.name, 'output.csv')\n        result = task_func(url, 'name', out_file)\n        expected = {'Alice': 2, 'Bob': 1}\n        self.assertEqual(result, expected)\n        self.assertTrue(os.path.exists(out_file))\n\n    def test_column_not_exists(self):\n        url = f'http://localhost:{self.port}/test.csv'\n        out_file = os.path.join(self.test_dir.name, 'output.csv')\n        with self.assertRaises(ValueError) as cm:\n            task_func(url, 'invalid_column', out_file)\n        self.assertEqual(str(cm.exception), \"The provided column_name 'invalid_column' does not exist in the CSV file.\")\n        # Check that the file was deleted\n        self.assertFalse(os.path.exists(out_file))\n",
        "code": "import urllib.request\nimport csv\nimport collections\nimport os\n\ndef task_func(url, column_name, csv_file_path):\n    # Download the CSV file from the given URL\n    with urllib.request.urlopen(url) as response:\n        content = response.read()\n\n    # Save the content to the specified path\n    with open(csv_file_path, 'wb') as f:\n        f.write(content)\n\n    # Read the CSV file and count occurrences of each value in the specified column\n    with open(csv_file_path, 'r', newline='', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        if column_name not in reader.fieldnames:\n            # Delete the downloaded file if column_name not found\n            f.close()\n            os.remove(csv_file_path)\n            raise ValueError(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n        counts = collections.Counter()\n        for row in reader:\n            value = row.get(column_name)\n            if value is not None:\n                counts[value] += 1\n    return dict(counts)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/999_4",
        "turn": "4",
        "instruct_prompt": "After processing, delete the downloaded CSV file regardless of success or error, and return a dictionary mapping each value in the specified column to its occurrence count.",
        "test": "import unittest\nimport os\nfrom io import BytesIO\nfrom unittest import mock\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Prepare a sample CSV content\n        self.csv_content = \"name,age,city\\nAlice,30,New York\\nBob,25,Los Angeles\\nAlice,30,New York\\nCharlie,35,Chicago\\n\"\n        self.url = \"http://example.com/sample.csv\"\n        self.csv_file_path = \"test.csv\"\n\n    class MockResponse:\n        def __init__(self, content_bytes):\n            self.content_bytes = content_bytes\n            self.closed = False\n\n        def read(self):\n            return self.content_bytes\n\n        def __enter__(self):\n            return self\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            self.closed = True\n\n    def mock_urlopen(self, url):\n        return self.MockResponse(self.csv_content.encode('utf-8'))\n\n    @mock.patch('urllib.request.urlopen')\n    def test_count_occurrences_and_file_deletion(self, mock_urlopen):\n        mock_urlopen.side_effect = self.mock_urlopen\n\n        # Directly call task_func since it's in the same file\n        result = task_func(self.url, 'name', self.csv_file_path)\n        expected = {'Alice': 2, 'Bob': 1, 'Charlie': 1}\n        self.assertEqual(result, expected)\n\n        # After function call, file should be deleted\n        self.assertFalse(os.path.exists(self.csv_file_path))\n\n    @mock.patch('urllib.request.urlopen')\n    def test_nonexistent_column_raises_and_file_deleted(self, mock_urlopen):\n        mock_urlopen.side_effect = self.mock_urlopen\n\n        with self.assertRaises(ValueError):\n            task_func(self.url, 'nonexistent_column', self.csv_file_path)\n\n        # File should be deleted even after exception\n        self.assertFalse(os.path.exists(self.csv_file_path))\n",
        "code": "import urllib.request\nimport csv\nimport collections\nimport os\n\n\ndef task_func(url, column_name, csv_file_path):\n    try:\n        # Download the CSV file from the given URL\n        with urllib.request.urlopen(url) as response:\n            content = response.read()\n\n        # Save the content to the specified path\n        with open(csv_file_path, 'wb') as f:\n            f.write(content)\n\n        # Read the CSV file and count occurrences of each value in the specified column\n        with open(csv_file_path, 'r', newline='', encoding='utf-8') as f:\n            reader = csv.DictReader(f)\n            if column_name not in reader.fieldnames:\n                raise ValueError(f\"The provided column_name '{column_name}' does not exist in the CSV file.\")\n            counts = collections.Counter()\n            for row in reader:\n                value = row.get(column_name)\n                if value is not None:\n                    counts[value] += 1\n        return dict(counts)\n    finally:\n        if os.path.exists(csv_file_path):\n            os.remove(csv_file_path)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 129,
    "task_id": "BigCodeBench/1003",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1003_1",
        "turn": "1",
        "instruct_prompt": "Write a function task_func that fetches XML content from a given URL and returns it as a string. You should write self-contained code starting with:\n```python\nimport urllib.request\ndef task_func(url):\n```",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('urllib.request.urlopen')\n    def test_task_func_returns_xml_content(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = b'<root><child>data</child></root>'\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n        \n        url = 'http://example.com/sample.xml'\n        result = task_func(url)\n        self.assertEqual(result, '<root><child>data</child></root>')\n\n    @patch('urllib.request.urlopen')\n    def test_task_func_returns_empty_string_for_empty_response(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = b''\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n        \n        url = 'http://example.com/empty.xml'\n        result = task_func(url)\n        self.assertEqual(result, '')\n",
        "code": "import urllib.request\n\ndef task_func(url):\n    with urllib.request.urlopen(url) as response:\n        return response.read().decode('utf-8')\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1003_2",
        "turn": "2",
        "instruct_prompt": "Extend the function to parse the fetched XML string using lxml.etree and raise a ValueError if the XML syntax is invalid.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('urllib.request.urlopen')\n    def test_valid_xml(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = b'<root><child>data</child></root>'\n        # Properly mock context manager __enter__ to return mock_response\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        result = task_func('http://example.com')\n        self.assertEqual(result, '<root><child>data</child></root>')\n\n    @patch('urllib.request.urlopen')\n    def test_invalid_xml(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = b'<root><child>data</root>'  # invalid XML\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        with self.assertRaises(ValueError) as context:\n            task_func('http://example.com')\n        self.assertIn('Invalid XML syntax', str(context.exception))\n",
        "code": "import urllib.request\nfrom lxml import etree\n\ndef task_func(url):\n    with urllib.request.urlopen(url) as response:\n        xml_bytes = response.read()\n        xml_str = xml_bytes.decode('utf-8')\n    try:\n        etree.fromstring(xml_str)\n    except etree.XMLSyntaxError as e:\n        raise ValueError(\"Invalid XML syntax\") from e\n    return xml_str\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1003_3",
        "turn": "3",
        "instruct_prompt": "Parse the XML tree to extract all 'item' elements, convert their child elements into dictionaries, and raise a ValueError if no 'item' elements are found (indicating the XML structure does not match the expected format).",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('urllib.request.urlopen')\n    def test_valid_xml_with_items(self, mock_urlopen):\n        xml_content = '''<?xml version=\"1.0\"?>\n<root>\n    <item>\n        <name>Item1</name>\n        <value>10</value>\n    </item>\n    <item>\n        <name>Item2</name>\n        <value>20</value>\n    </item>\n</root>'''\n        mock_response = MagicMock()\n        mock_response.read.return_value = xml_content.encode('utf-8')\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        expected = [\n            {'name': 'Item1', 'value': '10'},\n            {'name': 'Item2', 'value': '20'}\n        ]\n\n        result = task_func('http://fakeurl')\n        self.assertEqual(result, expected)\n\n    @patch('urllib.request.urlopen')\n    def test_xml_with_no_items(self, mock_urlopen):\n        xml_content = '''<?xml version=\"1.0\"?>\n<root>\n    <notitem>\n        <name>Item1</name>\n    </notitem>\n</root>'''\n        mock_response = MagicMock()\n        mock_response.read.return_value = xml_content.encode('utf-8')\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        with self.assertRaises(ValueError) as context:\n            task_func('http://fakeurl')\n        self.assertIn(\"No 'item' elements found\", str(context.exception))\n\n    @patch('urllib.request.urlopen')\n    def test_invalid_xml_syntax(self, mock_urlopen):\n        xml_content = '<root><item><name>Item1</name></item>'  # missing closing root tag\n        mock_response = MagicMock()\n        mock_response.read.return_value = xml_content.encode('utf-8')\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        with self.assertRaises(ValueError) as context:\n            task_func('http://fakeurl')\n        self.assertIn(\"Invalid XML syntax\", str(context.exception))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import urllib.request\nfrom lxml import etree\n\ndef task_func(url):\n    with urllib.request.urlopen(url) as response:\n        xml_bytes = response.read()\n        xml_str = xml_bytes.decode('utf-8')\n    try:\n        root = etree.fromstring(xml_str)\n    except etree.XMLSyntaxError as e:\n        raise ValueError(\"Invalid XML syntax\") from e\n\n    items = root.findall('.//item')\n    if not items:\n        raise ValueError(\"No 'item' elements found in XML\")\n\n    result = []\n    for item in items:\n        item_dict = {}\n        for child in item:\n            item_dict[child.tag] = child.text\n        result.append(item_dict)\n\n    return result\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1003_4",
        "turn": "4",
        "instruct_prompt": "Convert the list of dictionaries from the 'item' elements into a pandas DataFrame and return it. Raise a ValueError if fetching the XML from the URL fails.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.valid_xml = '''<root>\n            <item>\n                <name>Item1</name>\n                <value>10</value>\n            </item>\n            <item>\n                <name>Item2</name>\n                <value>20</value>\n            </item>\n        </root>'''\n\n        self.invalid_xml = \"<root><item></root>\"\n        self.no_item_xml = \"<root><data>test</data></root>\"\n\n    @patch('urllib.request.urlopen')\n    def test_valid_xml(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = self.valid_xml.encode('utf-8')\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        df = task_func('http://fakeurl.com')\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertEqual(len(df), 2)\n        self.assertIn('name', df.columns)\n        self.assertIn('value', df.columns)\n        self.assertEqual(df.iloc[0]['name'], 'Item1')\n        self.assertEqual(df.iloc[1]['value'], '20')\n\n    @patch('urllib.request.urlopen')\n    def test_fetch_fail(self, mock_urlopen):\n        mock_urlopen.side_effect = Exception(\"Network error\")\n        with self.assertRaises(ValueError) as cm:\n            task_func('http://fakeurl.com')\n        self.assertIn('Failed to fetch XML from URL', str(cm.exception))\n\n    @patch('urllib.request.urlopen')\n    def test_invalid_xml(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = self.invalid_xml.encode('utf-8')\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n        with self.assertRaises(ValueError) as cm:\n            task_func('http://fakeurl.com')\n        self.assertIn('Invalid XML syntax', str(cm.exception))\n\n    @patch('urllib.request.urlopen')\n    def test_no_item_elements(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = self.no_item_xml.encode('utf-8')\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n        with self.assertRaises(ValueError) as cm:\n            task_func('http://fakeurl.com')\n        self.assertIn(\"No 'item' elements found in XML\", str(cm.exception))\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\n\ndef task_func(url):\n    try:\n        with urllib.request.urlopen(url) as response:\n            xml_bytes = response.read()\n    except Exception as e:\n        raise ValueError(\"Failed to fetch XML from URL\") from e\n\n    try:\n        xml_str = xml_bytes.decode('utf-8')\n    except Exception as e:\n        raise ValueError(\"Failed to decode XML bytes\") from e\n\n    try:\n        root = etree.fromstring(xml_str)\n    except (etree.XMLSyntaxError, ValueError) as e:\n        raise ValueError(\"Invalid XML syntax\") from e\n\n    items = root.findall('.//item')\n    if not items:\n        raise ValueError(\"No 'item' elements found in XML\")\n\n    result = []\n    for item in items:\n        item_dict = {}\n        for child in item:\n            item_dict[child.tag] = child.text\n        result.append(item_dict)\n\n    df = pd.DataFrame(result)\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 130,
    "task_id": "BigCodeBench/1004",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1004_1",
        "turn": "1",
        "instruct_prompt": "Write a function that downloads a text file from a specified URL and returns the full text content as a string. You should write self-contained code starting with:```python\nimport urllib.request\ndef task_func(url):\n```",
        "test": "import unittest\nimport http.server\nimport socketserver\nimport threading\nimport os\n\nclass TestCases(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        # Write the test text file\n        cls.test_text = \"Hello, this is a test file.\\nLine 2 of the file.\"\n        cls.test_filename = \"testfile.txt\"\n        with open(cls.test_filename, 'w', encoding='utf-8') as f:\n            f.write(cls.test_text)\n\n        class Handler(http.server.SimpleHTTPRequestHandler):\n            def log_message(self, format, *args):\n                pass  # Suppress logging\n\n        # Bind to port 0 to get an available port\n        cls.httpd = socketserver.TCPServer((\"\", 0), Handler)\n        cls.port = cls.httpd.server_address[1]\n\n        def serve():\n            cls.httpd.serve_forever()\n\n        cls.server_thread = threading.Thread(target=serve, daemon=True)\n        cls.server_thread.start()\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.httpd.shutdown()\n        cls.server_thread.join()\n        os.remove(cls.test_filename)\n\n    def test_download_text_file(self):\n        url = f\"http://localhost:{self.port}/{self.test_filename}\"\n        content = task_func(url)\n        self.assertEqual(content, self.test_text)\n",
        "code": "import urllib.request\n\ndef task_func(url):\n    with urllib.request.urlopen(url) as response:\n        return response.read().decode('utf-8')\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1004_2",
        "turn": "2",
        "instruct_prompt": "Extend the function to process the downloaded text and count the frequency of each word using a basic regular expression that matches word characters. The function should return a collections.Counter object containing the word frequencies.",
        "test": "import unittest\nimport collections\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('urllib.request.urlopen')\n    def test_word_count(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = b\"Hello world! Hello, test.\"\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        result = task_func('http://fakeurl.com')\n\n        expected = collections.Counter({'hello': 2, 'world': 1, 'test': 1})\n        self.assertEqual(result, expected)\n\n    @patch('urllib.request.urlopen')\n    def test_empty_text(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = b\"\"\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        result = task_func('http://fakeurl.com')\n\n        expected = collections.Counter()\n        self.assertEqual(result, expected)\n",
        "code": "import urllib.request\nimport re\nimport collections\n\ndef task_func(url):\n    with urllib.request.urlopen(url) as response:\n        text = response.read().decode('utf-8')\n    words = re.findall(r'\\w+', text.lower())\n    return collections.Counter(words)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1004_3",
        "turn": "3",
        "instruct_prompt": "Modify the function to plot a bar chart displaying the ten most frequently occurring words using matplotlib. The function should return a tuple containing the Counter object and the matplotlib Axes object representing the plotted bar chart.",
        "test": "import unittest\nimport collections\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_returns_counter_and_axes(self):\n        import io\n        import urllib.request\n        from unittest.mock import patch\n\n        sample_text = 'Hello world! Hello AI. AI is the future. Future is AI.'\n        expected_words = ['hello', 'world', 'hello', 'ai', 'ai', 'is', 'the', 'future', 'future', 'is', 'ai']\n\n        class MockResponse:\n            def __enter__(self):\n                return self\n            def __exit__(self, exc_type, exc_val, exc_tb):\n                pass\n            def read(self):\n                return sample_text.encode('utf-8')\n\n        with patch('urllib.request.urlopen', return_value=MockResponse()):\n            # Directly call task_func, no import needed\n            counter, ax = task_func('http://example.com')\n\n            # Check counter is collections.Counter and counts words correctly\n            self.assertIsInstance(counter, collections.Counter)\n            for word in expected_words:\n                self.assertIn(word, counter)\n\n            # Check ax is a matplotlib Axes object\n            self.assertIsInstance(ax, Axes)\n\n            # Filter bars: matplotlib bar container patches are Rectangle, exclude background (height=0)\n            bars = [patch for patch in ax.patches if isinstance(patch, plt.Rectangle) and patch.get_height() > 0]\n            self.assertLessEqual(len(bars), 10)\n\n            # Check the labels correspond to the top words\n            top_words = [tick.get_text() for tick in ax.get_xticklabels() if tick.get_text()]\n            self.assertTrue(all(isinstance(word, str) for word in top_words))\n\n            most_common_words = [word for word, _ in counter.most_common(10)]\n            for word in top_words:\n                self.assertIn(word, most_common_words)\n",
        "code": "import urllib.request\nimport re\nimport collections\nimport matplotlib.pyplot as plt\n\ndef task_func(url):\n    with urllib.request.urlopen(url) as response:\n        text = response.read().decode('utf-8')\n    words = re.findall(r'\\w+', text.lower())\n    counter = collections.Counter(words)\n    most_common = counter.most_common(10)\n    words_top, counts_top = zip(*most_common) if most_common else ([], [])\n    fig, ax = plt.subplots()\n    ax.bar(words_top, counts_top)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Top 10 Most Frequent Words')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    return counter, ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1004_4",
        "turn": "4",
        "instruct_prompt": "Ensure that words are counted as case-sensitive and that no stopwords are removed. The function assumes the URL points to a plain text file and may not handle binary or non-text content correctly. Internet access is required to download the file.",
        "test": "import unittest\nimport collections\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('urllib.request.urlopen')\n    def test_case_sensitive_counting_and_no_stopword_removal(self, mock_urlopen):\n        test_text = \"The the THE quick brown fox jumps over the lazy dog. the THE.\"\n        mock_response = MagicMock()\n        mock_response.read.return_value = test_text.encode('utf-8')\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        counter, ax = task_func('http://dummyurl')\n\n        expected_counts = collections.Counter({\n            'The': 1,\n            'the': 3,\n            'THE': 2,\n            'quick': 1,\n            'brown': 1,\n            'fox': 1,\n            'jumps': 1,\n            'over': 1,\n            'lazy': 1,\n            'dog': 1\n        })\n\n        self.assertEqual(counter, expected_counts)\n        self.assertIn('the', counter)\n        self.assertIn('The', counter)\n        self.assertIn('THE', counter)\n\n    @patch('urllib.request.urlopen')\n    def test_empty_text(self, mock_urlopen):\n        mock_response = MagicMock()\n        mock_response.read.return_value = b''\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        counter, ax = task_func('http://dummyurl')\n        self.assertEqual(len(counter), 0)\n\n    @patch('urllib.request.urlopen')\n    def test_non_alpha_characters(self, mock_urlopen):\n        test_text = \"Hello, HELLO! hello? HeLLo.\"\n        mock_response = MagicMock()\n        mock_response.read.return_value = test_text.encode('utf-8')\n        mock_urlopen.return_value.__enter__.return_value = mock_response\n\n        counter, ax = task_func('http://dummyurl')\n\n        expected_counts = collections.Counter({\n            'Hello': 1,\n            'HELLO': 1,\n            'hello': 1,\n            'HeLLo': 1\n        })\n\n        self.assertEqual(counter, expected_counts)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import urllib.request\nimport re\nimport collections\nimport matplotlib.pyplot as plt\n\ndef task_func(url):\n    with urllib.request.urlopen(url) as response:\n        text = response.read().decode('utf-8')\n    # Case-sensitive words, do not lower case\n    words = re.findall(r'\\w+', text)\n    counter = collections.Counter(words)\n    most_common = counter.most_common(10)\n    words_top, counts_top = zip(*most_common) if most_common else ([], [])\n    fig, ax = plt.subplots()\n    ax.bar(words_top, counts_top)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Top 10 Most Frequent Words')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    return counter, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 131,
    "task_id": "BigCodeBench/1006",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1006_1",
        "turn": "1",
        "instruct_prompt": "Download a file from a specified URL and save it to a given directory.\nYou should write self-contained code starting with:```python\nimport os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n```",
        "test": "import unittest\nimport os\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_download_file(self, mock_get):\n        # Setup mock response\n        mock_response = MagicMock()\n        mock_response.iter_content = lambda chunk_size: [b'test data']\n        mock_response.__enter__.return_value = mock_response\n        mock_response.raise_for_status = lambda: None\n        mock_get.return_value = mock_response\n        \n        test_url = 'http://example.com/file.txt'\n        test_path = 'test_download_dir/'\n\n        # Cleanup before test\n        if os.path.exists(test_path):\n            for f in os.listdir(test_path):\n                os.remove(os.path.join(test_path, f))\n            os.rmdir(test_path)\n\n        # Call the function directly (no import needed)\n        downloaded_file = task_func(test_url, test_path)\n\n        # Check directory creation\n        self.assertTrue(os.path.exists(test_path))\n\n        # Check file path\n        expected_file_path = os.path.join(test_path, 'file.txt')\n        self.assertEqual(downloaded_file, expected_file_path)\n\n        # Check file content\n        with open(downloaded_file, 'rb') as f:\n            content = f.read()\n        self.assertEqual(content, b'test data')\n\n        # Cleanup after test\n        os.remove(downloaded_file)\n        os.rmdir(test_path)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\n\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    if not os.path.exists(download_path):\n        os.makedirs(download_path)\n    \n    local_filename = os.path.join(download_path, url.split('/')[-1])\n    \n    with requests.get(url, stream=True) as r:\n        r.raise_for_status()\n        with open(local_filename, 'wb') as f:\n            for chunk in r.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n    \n    return local_filename\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1006_2",
        "turn": "2",
        "instruct_prompt": "Check if the downloaded file is a ZIP file by verifying that the Content-Type header contains 'application/zip'. If not, return the error message: \"Error: The URL does not point to a ZIP file.\"",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport os\nimport tempfile\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_zip_content_type(self, mock_get):\n        # Mock response for a zip file\n        mock_response = MagicMock()\n        mock_response.headers = {'Content-Type': 'application/zip'}\n        mock_response.iter_content = lambda chunk_size: [b'PK\\x03\\x04']\n        mock_response.raise_for_status = lambda: None\n        # Setup context manager behavior\n        mock_get.return_value.__enter__.return_value = mock_response\n\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            url = 'http://example.com/file.zip'\n            result = task_func(url, download_path=tmpdirname)\n            self.assertTrue(os.path.isfile(result))\n            self.assertTrue(result.endswith('.zip'))\n\n    @patch('requests.get')\n    def test_non_zip_content_type(self, mock_get):\n        # Mock response for a non-zip file\n        mock_response = MagicMock()\n        mock_response.headers = {'Content-Type': 'text/html'}\n        mock_response.iter_content = lambda chunk_size: [b'<html></html>']\n        mock_response.raise_for_status = lambda: None\n        # Setup context manager behavior\n        mock_get.return_value.__enter__.return_value = mock_response\n\n        url = 'http://example.com/file.html'\n        result = task_func(url)\n        self.assertEqual(result, \"Error: The URL does not point to a ZIP file.\")\n",
        "code": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\n\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    if not os.path.exists(download_path):\n        os.makedirs(download_path)\n    \n    with requests.get(url, stream=True) as r:\n        r.raise_for_status()\n        content_type = r.headers.get('Content-Type', '')\n        if 'application/zip' not in content_type:\n            return \"Error: The URL does not point to a ZIP file.\"\n        local_filename = os.path.join(download_path, url.split('/')[-1])\n        with open(local_filename, 'wb') as f:\n            for chunk in r.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n    \n    return local_filename\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1006_3",
        "turn": "3",
        "instruct_prompt": "Extract the downloaded ZIP file to a directory named after the ZIP file (without extension) inside the download_path. If the ZIP file is corrupt or cannot be extracted, return the error message: \"Error: The downloaded file is not a valid ZIP file.\"",
        "test": "import unittest\nimport os\nimport shutil\nfrom unittest.mock import patch, MagicMock\nfrom io import BytesIO\nfrom zipfile import ZipFile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = \"mnt/data/downloads/\"\n        if not os.path.exists(self.test_dir):\n            os.makedirs(self.test_dir)\n\n    def tearDown(self):\n        if os.path.exists(self.test_dir):\n            shutil.rmtree(self.test_dir)\n\n    @patch('requests.get')\n    def test_valid_zip_extraction(self, mock_get):\n        # Create a simple in-memory ZIP file\n        in_memory_zip = BytesIO()\n        with ZipFile(in_memory_zip, 'w') as zipf:\n            zipf.writestr('testfile.txt', 'This is some test content')\n        in_memory_zip.seek(0)\n\n        # Mock response\n        mock_response = MagicMock()\n        mock_response.iter_content = lambda chunk_size: [in_memory_zip.read()]\n        mock_response.headers = {'Content-Type': 'application/zip'}\n        mock_response.__enter__.return_value = mock_response\n        mock_response.raise_for_status = lambda: None\n        mock_get.return_value = mock_response\n\n        url = 'http://example.com/test.zip'\n        result = task_func(url, self.test_dir)\n\n        # Check the zip file is saved\n        expected_zip_path = os.path.join(self.test_dir, 'test.zip')\n        self.assertEqual(result, expected_zip_path)\n        self.assertTrue(os.path.isfile(expected_zip_path))\n\n        # Check extraction directory and file\n        extract_dir = os.path.join(self.test_dir, 'test')\n        self.assertTrue(os.path.isdir(extract_dir))\n        extracted_file = os.path.join(extract_dir, 'testfile.txt')\n        self.assertTrue(os.path.isfile(extracted_file))\n\n        with open(extracted_file, 'r') as f:\n            content = f.read()\n        self.assertEqual(content, 'This is some test content')\n\n    @patch('requests.get')\n    def test_corrupt_zip_file(self, mock_get):\n        # Provide invalid ZIP content\n        invalid_zip_content = b'Not a zip file content'\n\n        # Mock response\n        mock_response = MagicMock()\n        mock_response.iter_content = lambda chunk_size: [invalid_zip_content]\n        mock_response.headers = {'Content-Type': 'application/zip'}\n        mock_response.__enter__.return_value = mock_response\n        mock_response.raise_for_status = lambda: None\n        mock_get.return_value = mock_response\n\n        url = 'http://example.com/corrupt.zip'\n        result = task_func(url, self.test_dir)\n\n        self.assertEqual(result, \"Error: The downloaded file is not a valid ZIP file.\")",
        "code": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\n\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    if not os.path.exists(download_path):\n        os.makedirs(download_path)\n    \n    with requests.get(url, stream=True) as r:\n        r.raise_for_status()\n        content_type = r.headers.get('Content-Type', '')\n        if 'application/zip' not in content_type:\n            return \"Error: The URL does not point to a ZIP file.\"\n        local_filename = os.path.join(download_path, url.split('/')[-1])\n        with open(local_filename, 'wb') as f:\n            for chunk in r.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n\n    extract_dir = os.path.join(download_path, os.path.splitext(os.path.basename(local_filename))[0])\n    try:\n        with ZipFile(local_filename, 'r') as zip_ref:\n            if not os.path.exists(extract_dir):\n                os.makedirs(extract_dir)\n            zip_ref.extractall(extract_dir)\n    except BadZipFile:\n        return \"Error: The downloaded file is not a valid ZIP file.\"\n\n    return local_filename",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1006_4",
        "turn": "4",
        "instruct_prompt": "Handle network issues or invalid URL errors by returning the error message: \"Error: Unable to download the file from the provided URL.\"",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport builtins\nimport os\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_network_error(self, mock_get):\n        # Simulate a network error (e.g. ConnectionError)\n        mock_get.side_effect = requests.ConnectionError()\n        result = task_func('http://example.com/file.zip')\n        self.assertEqual(result, \"Error: Unable to download the file from the provided URL.\")\n\n    @patch('requests.get')\n    def test_invalid_url_error(self, mock_get):\n        # Simulate a requests.RequestException (invalid URL)\n        mock_get.side_effect = requests.RequestException()\n        result = task_func('http://invalid-url')\n        self.assertEqual(result, \"Error: Unable to download the file from the provided URL.\")\n",
        "code": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\n\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    if not os.path.exists(download_path):\n        os.makedirs(download_path)\n    \n    try:\n        with requests.get(url, stream=True) as r:\n            r.raise_for_status()\n            content_type = r.headers.get('Content-Type', '')\n            if 'application/zip' not in content_type:\n                return \"Error: The URL does not point to a ZIP file.\"\n            local_filename = os.path.join(download_path, url.split('/')[-1])\n            with open(local_filename, 'wb') as f:\n                for chunk in r.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n    except (requests.RequestException, requests.ConnectionError, requests.Timeout):\n        return \"Error: Unable to download the file from the provided URL.\"\n\n    extract_dir = os.path.join(download_path, os.path.splitext(os.path.basename(local_filename))[0])\n    try:\n        with ZipFile(local_filename, 'r') as zip_ref:\n            if not os.path.exists(extract_dir):\n                os.makedirs(extract_dir)\n            zip_ref.extractall(extract_dir)\n    except BadZipFile:\n        return \"Error: The downloaded file is not a valid ZIP file.\"\n\n    return local_filename\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1006_5",
        "turn": "5",
        "instruct_prompt": "Catch any other exceptions during the process and return an error message formatted as: \"Error: [exception message]\"",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport tempfile\nimport shutil\nimport zipfile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_dir = tempfile.mkdtemp()\n\n    def tearDown(self):\n        shutil.rmtree(self.test_dir)\n\n    @patch('requests.get')\n    def test_other_exception_in_download(self, mock_get):\n        # Simulate a generic exception during requests.get\n        def raise_exception(*args, **kwargs):\n            raise ValueError(\"Unexpected error during request\")\n        mock_get.side_effect = raise_exception\n\n        result = task_func(\"http://example.com/file.zip\", download_path=self.test_dir)\n        self.assertEqual(result, \"Error: Unexpected error during request\")\n\n    @patch('requests.get')\n    def test_other_exception_in_zip_extract(self, mock_get):\n        # Prepare a minimal valid ZIP file content bytes\n        minimal_zip_bytes = (b'PK\\x05\\x06' + b'\\x00' * 18)  # Empty ZIP archive\n\n        mock_response = MagicMock()\n        mock_response.__enter__.return_value = mock_response\n        mock_response.iter_content = lambda chunk_size: [minimal_zip_bytes]\n        mock_response.headers = {'Content-Type': 'application/zip'}\n        mock_response.raise_for_status = MagicMock()\n        mock_get.return_value = mock_response\n\n        # Patch zipfile.ZipFile to raise an unexpected exception during extractall\n        class BadExtractZipFile(zipfile.ZipFile):\n            def extractall(self, path):\n                raise RuntimeError(\"Unexpected extraction error\")\n\n        with patch('zipfile.ZipFile', BadExtractZipFile):\n            url = \"http://example.com/test.zip\"\n            result = task_func(url, download_path=self.test_dir)\n            self.assertEqual(result, \"Error: Unexpected extraction error\")\n",
        "code": "import os\nimport requests\nimport zipfile\n\n\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    if not os.path.exists(download_path):\n        os.makedirs(download_path)\n    \n    try:\n        with requests.get(url, stream=True) as r:\n            r.raise_for_status()\n            content_type = r.headers.get('Content-Type', '')\n            if 'application/zip' not in content_type:\n                return \"Error: The URL does not point to a ZIP file.\"\n            local_filename = os.path.join(download_path, url.split('/')[-1])\n            with open(local_filename, 'wb') as f:\n                for chunk in r.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n    except (requests.RequestException, requests.ConnectionError, requests.Timeout):\n        return \"Error: Unable to download the file from the provided URL.\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    extract_dir = os.path.join(download_path, os.path.splitext(os.path.basename(local_filename))[0])\n    try:\n        with zipfile.ZipFile(local_filename, 'r') as zip_ref:\n            if not os.path.exists(extract_dir):\n                os.makedirs(extract_dir)\n            zip_ref.extractall(extract_dir)\n    except zipfile.BadZipFile:\n        return \"Error: The downloaded file is not a valid ZIP file.\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n    return local_filename\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 132,
    "task_id": "BigCodeBench/1008",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1008_1",
        "turn": "1",
        "instruct_prompt": "Extract data from an HTML table identified by 'table_id' from a given webpage URL and convert it into a Pandas DataFrame. You should write self-contained code starting with:\n```python\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\ndef task_func(url, table_id):\n```",
        "test": "import unittest\nfrom unittest.mock import patch\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_valid_table(self, mock_get):\n        html = '''\n        <html>\n        <body>\n        <table id=\"test_table\">\n          <thead>\n            <tr><th>Name</th><th>Age</th></tr>\n          </thead>\n          <tbody>\n            <tr><td>Alice</td><td>30</td></tr>\n            <tr><td>Bob</td><td>25</td></tr>\n          </tbody>\n        </table>\n        </body>\n        </html>\n        '''\n        class MockResponse:\n            def __init__(self, text):\n                self.text = text\n            def raise_for_status(self):\n                pass\n\n        mock_get.return_value = MockResponse(html)\n\n        df = task_func('http://fakeurl.com', 'test_table')\n\n        expected_df = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Age': ['30', '25']})\n        pd.testing.assert_frame_equal(df, expected_df)\n\n    @patch('requests.get')\n    def test_table_not_found(self, mock_get):\n        html = '<html><body><table id=\"other_table\"></table></body></html>'\n\n        class MockResponse:\n            def __init__(self, text):\n                self.text = text\n            def raise_for_status(self):\n                pass\n\n        mock_get.return_value = MockResponse(html)\n\n        with self.assertRaises(ValueError) as context:\n            task_func('http://fakeurl.com', 'missing_table')\n        self.assertIn(\"No table found with id 'missing_table'\", str(context.exception))\n\n    @patch('requests.get')\n    def test_empty_table(self, mock_get):\n        html = '<html><body><table id=\"empty_table\"></table></body></html>'\n\n        class MockResponse:\n            def __init__(self, text):\n                self.text = text\n            def raise_for_status(self):\n                pass\n\n        mock_get.return_value = MockResponse(html)\n\n        with self.assertRaises(ValueError) as context:\n            task_func('http://fakeurl.com', 'empty_table')\n        self.assertIn(\"Table with id 'empty_table' has no header row\", str(context.exception))",
        "code": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef task_func(url, table_id):\n    response = requests.get(url)\n    response.raise_for_status()\n    soup = BeautifulSoup(response.text, 'html.parser')\n    table = soup.find('table', id=table_id)\n    if table is None:\n        raise ValueError(f\"No table found with id '{table_id}'\")\n\n    # Extract headers\n    headers = []\n    thead = table.find('thead')\n    if thead:\n        header_rows = thead.find_all('tr')\n    else:\n        # fallback: first tr in table\n        header_rows = table.find_all('tr', limit=1)\n\n    if not header_rows:\n        raise ValueError(f\"Table with id '{table_id}' has no header row\")\n\n    # Collect headers from first header row\n    first_header_row = header_rows[0]\n    for th in first_header_row.find_all(['th', 'td']):\n        headers.append(th.get_text(strip=True))\n\n    # Extract data rows\n    rows = []\n    tbody = table.find('tbody')\n    if tbody:\n        data_rows = tbody.find_all('tr')\n    else:\n        # fallback: all tr except header\n        data_rows = table.find_all('tr')[1:]\n\n    for row in data_rows:\n        cells = row.find_all(['td', 'th'])\n        row_data = [cell.get_text(strip=True) for cell in cells]\n        if row_data:\n            rows.append(row_data)\n\n    if not rows:\n        raise ValueError(f\"No data rows found in table with id '{table_id}'\")\n\n    # Normalize rows length to headers length (trim or pad with None)\n    normalized_rows = []\n    for r in rows:\n        if len(r) > len(headers):\n            normalized_rows.append(r[:len(headers)])\n        else:\n            normalized_rows.append(r + [None]*(len(headers) - len(r)))\n\n    df = pd.DataFrame(normalized_rows, columns=headers)\n\n    return df",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1008_2",
        "turn": "2",
        "instruct_prompt": "Raise requests.exceptions.HTTPError if the HTTP request to the URL fails due to network issues or non-success status codes like 404 or 500.",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\nimport requests\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_http_error_raises_on_network_issue(self, mock_get):\n        mock_get.side_effect = requests.exceptions.ConnectionError(\"Network failure\")\n        with self.assertRaises(requests.exceptions.HTTPError):\n            task_func('http://example.com', 'table1')\n\n    @patch('requests.get')\n    def test_http_error_raises_on_404_status(self, mock_get):\n        mock_response = Mock()\n        mock_response.raise_for_status.side_effect = requests.exceptions.HTTPError(\"404 Client Error\")\n        mock_get.return_value = mock_response\n        with self.assertRaises(requests.exceptions.HTTPError):\n            task_func('http://example.com', 'table1')\n\n    @patch('requests.get')\n    def test_http_error_raises_on_500_status(self, mock_get):\n        mock_response = Mock()\n        mock_response.raise_for_status.side_effect = requests.exceptions.HTTPError(\"500 Server Error\")\n        mock_get.return_value = mock_response\n        with self.assertRaises(requests.exceptions.HTTPError):\n            task_func('http://example.com', 'table1')\n\n    @patch('requests.get')\n    def test_successful_request_and_parsing(self, mock_get):\n        html = '''\n        <html>\n        <body>\n          <table id=\"table1\">\n            <thead>\n              <tr><th>Header1</th><th>Header2</th></tr>\n            </thead>\n            <tbody>\n              <tr><td>Row1Col1</td><td>Row1Col2</td></tr>\n              <tr><td>Row2Col1</td><td>Row2Col2</td></tr>\n            </tbody>\n          </table>\n        </body>\n        </html>\n        '''\n        mock_response = Mock()\n        mock_response.raise_for_status.return_value = None\n        mock_response.text = html\n        mock_get.return_value = mock_response\n\n        df = task_func('http://example.com', 'table1')\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertEqual(list(df.columns), ['Header1', 'Header2'])\n        self.assertEqual(df.iloc[0]['Header1'], 'Row1Col1')\n        self.assertEqual(df.iloc[1]['Header2'], 'Row2Col2')\n",
        "code": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise requests.exceptions.HTTPError(f\"HTTP request failed: {e}\") from e\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    table = soup.find('table', id=table_id)\n    if table is None:\n        raise ValueError(f\"No table found with id '{table_id}'\")\n\n    # Extract headers\n    headers = []\n    thead = table.find('thead')\n    if thead:\n        header_rows = thead.find_all('tr')\n    else:\n        # fallback: first tr in table\n        header_rows = table.find_all('tr', limit=1)\n\n    if not header_rows:\n        raise ValueError(f\"Table with id '{table_id}' has no header row\")\n\n    # Collect headers from first header row\n    first_header_row = header_rows[0]\n    for th in first_header_row.find_all(['th', 'td']):\n        headers.append(th.get_text(strip=True))\n\n    # Extract data rows\n    rows = []\n    tbody = table.find('tbody')\n    if tbody:\n        data_rows = tbody.find_all('tr')\n    else:\n        # fallback: all tr except header\n        data_rows = table.find_all('tr')[1:]\n\n    for row in data_rows:\n        cells = row.find_all(['td', 'th'])\n        row_data = [cell.get_text(strip=True) for cell in cells]\n        if row_data:\n            rows.append(row_data)\n\n    if not rows:\n        raise ValueError(f\"No data rows found in table with id '{table_id}'\")\n\n    # Normalize rows length to headers length (trim or pad with None)\n    normalized_rows = []\n    for r in rows:\n        if len(r) > len(headers):\n            normalized_rows.append(r[:len(headers)])\n        else:\n            normalized_rows.append(r + [None]*(len(headers) - len(r)))\n\n    df = pd.DataFrame(normalized_rows, columns=headers)\n\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1008_3",
        "turn": "3",
        "instruct_prompt": "Raise a ValueError with the message \"Table with the specified ID not found.\" if the HTML table with the specified 'table_id' is not found in the webpage content.",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_table_not_found_raises_value_error(self, mock_get):\n        # HTML content without any table element\n        html_content = '<html><head></head><body><p>No table here</p></body></html>'\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        with self.assertRaises(ValueError) as cm:\n            task_func('http://example.com', 'missing_table')\n        self.assertEqual(str(cm.exception), \"Table with the specified ID not found.\")\n",
        "code": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise requests.exceptions.HTTPError(f\"HTTP request failed: {e}\") from e\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    table = soup.find('table', id=table_id)\n    if table is None:\n        raise ValueError(\"Table with the specified ID not found.\")\n\n    # Extract headers\n    headers = []\n    thead = table.find('thead')\n    if thead:\n        header_rows = thead.find_all('tr')\n    else:\n        # fallback: first tr in table\n        header_rows = table.find_all('tr', limit=1)\n\n    if not header_rows:\n        raise ValueError(f\"Table with id '{table_id}' has no header row\")\n\n    # Collect headers from first header row\n    first_header_row = header_rows[0]\n    for th in first_header_row.find_all(['th', 'td']):\n        headers.append(th.get_text(strip=True))\n\n    # Extract data rows\n    rows = []\n    tbody = table.find('tbody')\n    if tbody:\n        data_rows = tbody.find_all('tr')\n    else:\n        # fallback: all tr except header\n        data_rows = table.find_all('tr')[1:]\n\n    for row in data_rows:\n        cells = row.find_all(['td', 'th'])\n        row_data = [cell.get_text(strip=True) for cell in cells]\n        if row_data:\n            rows.append(row_data)\n\n    if not rows:\n        raise ValueError(f\"No data rows found in table with id '{table_id}'\")\n\n    # Normalize rows length to headers length (trim or pad with None)\n    normalized_rows = []\n    for r in rows:\n        if len(r) > len(headers):\n            normalized_rows.append(r[:len(headers)])\n        else:\n            normalized_rows.append(r + [None]*(len(headers) - len(r)))\n\n    df = pd.DataFrame(normalized_rows, columns=headers)\n\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1008_4",
        "turn": "4",
        "instruct_prompt": "If the found table contains no <tr> elements (i.e., no data rows), return an empty Pandas DataFrame.",
        "test": "import unittest\nimport pandas as pd\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.url = 'http://example.com'\n        self.table_id = 'test-table'\n\n    @patch('requests.get')\n    def test_table_with_no_tr(self, mock_get):\n        html = '''<html><body><table id=\"test-table\"><thead><tr><th>Header1</th><th>Header2</th></tr></thead></table></body></html>'''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html\n        mock_get.return_value = mock_response\n\n        df = task_func(self.url, self.table_id)\n        self.assertTrue(isinstance(df, pd.DataFrame))\n        self.assertTrue(df.empty)\n\n    @patch('requests.get')\n    def test_table_with_empty_tbody(self, mock_get):\n        html = '''<html><body><table id=\"test-table\"><thead><tr><th>H1</th><th>H2</th></tr></thead><tbody></tbody></table></body></html>'''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html\n        mock_get.return_value = mock_response\n\n        df = task_func(self.url, self.table_id)\n        self.assertTrue(isinstance(df, pd.DataFrame))\n        self.assertTrue(df.empty)\n\n    @patch('requests.get')\n    def test_table_with_tr_but_no_data_cells(self, mock_get):\n        html = '''<html><body><table id=\"test-table\"><thead><tr><th>H1</th></tr></thead><tbody><tr></tr></tbody></table></body></html>'''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html\n        mock_get.return_value = mock_response\n\n        df = task_func(self.url, self.table_id)\n        self.assertTrue(isinstance(df, pd.DataFrame))\n        self.assertTrue(df.empty)\n\n    @patch('requests.get')\n    def test_table_with_data_rows(self, mock_get):\n        html = '''<html><body><table id=\"test-table\"><thead><tr><th>Col1</th><th>Col2</th></tr></thead><tbody><tr><td>Val1</td><td>Val2</td></tr></tbody></table></body></html>'''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html\n        mock_get.return_value = mock_response\n\n        df = task_func(self.url, self.table_id)\n        self.assertEqual(list(df.columns), ['Col1', 'Col2'])\n        self.assertEqual(df.iloc[0,0], 'Val1')\n        self.assertEqual(df.iloc[0,1], 'Val2')\n\n    @patch('requests.get')\n    def test_table_not_found(self, mock_get):\n        html = '''<html><body><table id=\"other-table\"><thead><tr><th>H1</th></tr></thead></table></body></html>'''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html\n        mock_get.return_value = mock_response\n\n        with self.assertRaises(ValueError):\n            task_func(self.url, self.table_id)\n",
        "code": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise requests.exceptions.HTTPError(f\"HTTP request failed: {e}\") from e\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    table = soup.find('table', id=table_id)\n    if table is None:\n        raise ValueError(\"Table with the specified ID not found.\")\n\n    # Extract headers\n    headers = []\n    thead = table.find('thead')\n    if thead:\n        header_rows = thead.find_all('tr')\n    else:\n        # fallback: first tr in table\n        header_rows = table.find_all('tr', limit=1)\n\n    if not header_rows:\n        raise ValueError(f\"Table with id '{table_id}' has no header row\")\n\n    # Collect headers from first header row\n    first_header_row = header_rows[0]\n    for th in first_header_row.find_all(['th', 'td']):\n        headers.append(th.get_text(strip=True))\n\n    # Extract data rows\n    rows = []\n    tbody = table.find('tbody')\n    if tbody:\n        data_rows = tbody.find_all('tr')\n    else:\n        # fallback: all tr except header\n        data_rows = table.find_all('tr')[1:]\n\n    if not data_rows:\n        # No data rows, return empty DataFrame\n        return pd.DataFrame()\n\n    for row in data_rows:\n        cells = row.find_all(['td', 'th'])\n        row_data = [cell.get_text(strip=True) for cell in cells]\n        if row_data:\n            rows.append(row_data)\n\n    if not rows:\n        # No data rows with cells, return empty DataFrame\n        return pd.DataFrame()\n\n    # Normalize rows length to headers length (trim or pad with None)\n    normalized_rows = []\n    for r in rows:\n        if len(r) > len(headers):\n            normalized_rows.append(r[:len(headers)])\n        else:\n            normalized_rows.append(r + [None]*(len(headers) - len(r)))\n\n    df = pd.DataFrame(normalized_rows, columns=headers)\n\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1008_5",
        "turn": "5",
        "instruct_prompt": "Parse the found HTML table into a Pandas DataFrame and return it.",
        "test": "import unittest\nimport pandas as pd\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.html_with_table = '''\n        <html>\n        <body>\n            <table id=\"mytable\">\n                <thead>\n                    <tr><th>Name</th><th>Age</th><th>City</th></tr>\n                </thead>\n                <tbody>\n                    <tr><td>Alice</td><td>30</td><td>New York</td></tr>\n                    <tr><td>Bob</td><td>25</td><td>Los Angeles</td></tr>\n                </tbody>\n            </table>\n        </body>\n        </html>\n        '''\n\n        self.html_no_thead = '''\n        <html>\n        <body>\n            <table id=\"mytable\">\n                <tr><th>Product</th><th>Price</th></tr>\n                <tr><td>Book</td><td>12.99</td></tr>\n                <tr><td>Pen</td><td>1.5</td></tr>\n            </table>\n        </body>\n        </html>\n        '''\n\n        self.html_inconsistent_rows = '''\n        <html>\n        <body>\n            <table id=\"mytable\">\n                <thead>\n                    <tr><th>Col1</th><th>Col2</th><th>Col3</th></tr>\n                </thead>\n                <tbody>\n                    <tr><td>val1</td><td>val2</td></tr>\n                    <tr><td>val3</td><td>val4</td><td>val5</td></tr>\n                    <tr><td>val6</td></tr>\n                </tbody>\n            </table>\n        </body>\n        </html>\n        '''\n\n    @patch('requests.get')\n    def test_parse_table_with_thead(self, mock_get):\n        mock_get.return_value = Mock(status_code=200, text=self.html_with_table)\n        df = task_func('http://fakeurl.com', 'mytable')\n\n        expected_df = pd.DataFrame({\n            'Name': ['Alice', 'Bob'],\n            'Age': ['30', '25'],\n            'City': ['New York', 'Los Angeles']\n        })\n\n        pd.testing.assert_frame_equal(df, expected_df)\n\n    @patch('requests.get')\n    def test_parse_table_without_thead(self, mock_get):\n        mock_get.return_value = Mock(status_code=200, text=self.html_no_thead)\n        df = task_func('http://fakeurl.com', 'mytable')\n\n        expected_df = pd.DataFrame({\n            'Product': ['Book', 'Pen'],\n            'Price': ['12.99', '1.5']\n        })\n\n        pd.testing.assert_frame_equal(df, expected_df)\n\n    @patch('requests.get')\n    def test_table_not_found(self, mock_get):\n        mock_get.return_value = Mock(status_code=200, text='<html><body></body></html>')\n        with self.assertRaises(ValueError):\n            task_func('http://fakeurl.com', 'nonexistent')\n\n    @patch('requests.get')\n    def test_empty_table(self, mock_get):\n        html_empty_table = '''<html><body><table id=\"mytable\"></table></body></html>'''\n        mock_get.return_value = Mock(status_code=200, text=html_empty_table)\n        with self.assertRaises(ValueError):\n            task_func('http://fakeurl.com', 'mytable')\n\n    @patch('requests.get')\n    def test_no_data_rows(self, mock_get):\n        html_no_data_rows = '''\n        <html><body>\n            <table id=\"mytable\">\n                <thead><tr><th>Header1</th><th>Header2</th></tr></thead>\n            </table>\n        </body></html>\n        '''\n        mock_get.return_value = Mock(status_code=200, text=html_no_data_rows)\n        df = task_func('http://fakeurl.com', 'mytable')\n        self.assertTrue(df.empty)\n        self.assertListEqual(list(df.columns), ['Header1', 'Header2'])\n\n    @patch('requests.get')\n    def test_inconsistent_row_lengths(self, mock_get):\n        # This test is designed to fail the previous round's code if it does not pad rows properly\n        mock_get.return_value = Mock(status_code=200, text=self.html_inconsistent_rows)\n        df = task_func('http://fakeurl.com', 'mytable')\n\n        expected_df = pd.DataFrame([\n            ['val1', 'val2', None],\n            ['val3', 'val4', 'val5'],\n            ['val6', None, None]\n        ], columns=['Col1', 'Col2', 'Col3'])\n\n        pd.testing.assert_frame_equal(df, expected_df)\n\n    @patch('requests.get')\n    def test_output_type_and_columns(self, mock_get):\n        mock_get.return_value = Mock(status_code=200, text=self.html_with_table)\n        df = task_func('http://fakeurl.com', 'mytable')\n        self.assertIsInstance(df, pd.DataFrame)\n        self.assertListEqual(list(df.columns), ['Name', 'Age', 'City'])\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef task_func(url, table_id):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise requests.exceptions.HTTPError(f\"HTTP request failed: {e}\") from e\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    table = soup.find('table', id=table_id)\n    if table is None:\n        raise ValueError(\"Table with the specified ID not found.\")\n\n    headers = []\n    thead = table.find('thead')\n    if thead:\n        header_rows = thead.find_all('tr')\n    else:\n        header_rows = table.find_all('tr', limit=1)\n\n    if not header_rows:\n        raise ValueError(f\"Table with id '{table_id}' has no header row\")\n\n    first_header_row = header_rows[0]\n    for th in first_header_row.find_all(['th', 'td']):\n        headers.append(th.get_text(strip=True))\n\n    rows = []\n    tbody = table.find('tbody')\n    if tbody:\n        data_rows = tbody.find_all('tr')\n    else:\n        data_rows = table.find_all('tr')[1:]\n\n    if not data_rows:\n        return pd.DataFrame(columns=headers)\n\n    for row in data_rows:\n        cells = row.find_all(['td', 'th'])\n        row_data = [cell.get_text(strip=True) for cell in cells]\n        if row_data:\n            rows.append(row_data)\n\n    if not rows:\n        return pd.DataFrame(columns=headers)\n\n    normalized_rows = []\n    for r in rows:\n        if len(r) > len(headers):\n            normalized_rows.append(r[:len(headers)])\n        else:\n            normalized_rows.append(r + [None]*(len(headers) - len(r)))\n\n    df = pd.DataFrame(normalized_rows, columns=headers)\n\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 133,
    "task_id": "BigCodeBench/1012",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1012_1",
        "turn": "1",
        "instruct_prompt": "Write a function that downloads a file from a specified URL and saves it locally. You should write self-contained code starting with:```python\nimport requests\nfrom pathlib import Path\n# Constants\nDOWNLOAD_DIR = Path(\"downloads\")\n\ndef task_func(url, filename):\n```",
        "test": "import unittest\nfrom pathlib import Path\nfrom unittest.mock import patch, MagicMock\nimport os\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_task_func_downloads_file(self, mock_get):\n        # Setup mock response\n        mock_response = MagicMock()\n        mock_response.content = b'test content'\n        mock_response.raise_for_status = MagicMock()\n        mock_get.return_value = mock_response\n\n        url = 'http://example.com/testfile'\n        filename = 'testfile.txt'\n\n        # Remove file if it exists from previous runs\n        file_path = Path('downloads') / filename\n        if file_path.exists():\n            file_path.unlink()\n\n        # Call the function directly (no import needed)\n        task_func(url, filename)\n\n        # Check that requests.get was called with the correct URL\n        mock_get.assert_called_once_with(url)\n\n        # Check that the file was created with correct content\n        self.assertTrue(file_path.exists())\n        with open(file_path, 'rb') as f:\n            content = f.read()\n        self.assertEqual(content, b'test content')\n\n        # Cleanup\n        if file_path.exists():\n            file_path.unlink()\n        if Path('downloads').exists() and not any(Path('downloads').iterdir()):\n            Path('downloads').rmdir()\n",
        "code": "import requests\nfrom pathlib import Path\n\n# Constants\nDOWNLOAD_DIR = Path(\"downloads\")\n\ndef task_func(url, filename):\n    DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n    file_path = DOWNLOAD_DIR / filename\n    response = requests.get(url)\n    response.raise_for_status()\n    with open(file_path, 'wb') as f:\n        f.write(response.content)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1012_2",
        "turn": "2",
        "instruct_prompt": "After downloading the file, extract it as a zip archive into a separate directory.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nfrom pathlib import Path\nimport zipfile\nimport io\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_task_func_extract_zip(self, mock_get):\n        # Prepare a fake zip file in memory\n        fake_zip_bytes = io.BytesIO()\n        with zipfile.ZipFile(fake_zip_bytes, 'w') as zf:\n            zf.writestr('testfile.txt', 'hello world')\n        fake_zip_bytes.seek(0)\n\n        # Mock the requests.get to return the fake zip file content\n        mock_response = MagicMock()\n        mock_response.content = fake_zip_bytes.read()\n        mock_response.raise_for_status = MagicMock()\n        mock_get.return_value = mock_response\n\n        url = 'http://example.com/fake.zip'\n        filename = 'fake.zip'\n\n        # Run the function\n        extract_dir = task_func(url, filename)\n\n        # Check the downloaded file exists\n        downloaded_file = Path('downloads') / filename\n        self.assertTrue(downloaded_file.exists())\n\n        # Check the extracted directory exists\n        self.assertTrue(extract_dir.exists())\n        self.assertTrue(extract_dir.is_dir())\n\n        # Check the extracted file exists and contents are correct\n        extracted_file = extract_dir / 'testfile.txt'\n        self.assertTrue(extracted_file.exists())\n        with open(extracted_file, 'r') as f:\n            content = f.read()\n        self.assertEqual(content, 'hello world')\n",
        "code": "import requests\nfrom pathlib import Path\nimport zipfile\n\n# Constants\nDOWNLOAD_DIR = Path(\"downloads\")\n\n\ndef task_func(url, filename):\n    DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n    file_path = DOWNLOAD_DIR / filename\n    response = requests.get(url)\n    response.raise_for_status()\n    with open(file_path, 'wb') as f:\n        f.write(response.content)\n\n    # Extract zip archive into a separate directory\n    extract_dir = DOWNLOAD_DIR / (file_path.stem + \"_extracted\")\n    extract_dir.mkdir(parents=True, exist_ok=True)\n    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n        zip_ref.extractall(extract_dir)\n\n    return extract_dir\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1012_3",
        "turn": "3",
        "instruct_prompt": "The function should return a tuple with a status message and a list of filenames extracted from the zip file. If extraction fails, return an empty list.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport zipfile\nimport io\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_successful_extraction(self, mock_get):\n        # Prepare a simple in-memory zip file\n        zip_buffer = io.BytesIO()\n        with zipfile.ZipFile(zip_buffer, 'w') as zip_file:\n            zip_file.writestr('file1.txt', 'content1')\n            zip_file.writestr('file2.txt', 'content2')\n        zip_buffer.seek(0)\n\n        # Mock response content\n        mock_response = MagicMock()\n        mock_response.content = zip_buffer.read()\n        mock_response.raise_for_status = MagicMock()\n        mock_get.return_value = mock_response\n\n        status, files = task_func('http://example.com/test.zip', 'test.zip')\n\n        self.assertEqual(status, \"Success\")\n        self.assertIn('file1.txt', files)\n        self.assertIn('file2.txt', files)\n\n    @patch('requests.get')\n    def test_failed_download(self, mock_get):\n        # Simulate a failed HTTP request\n        mock_response = MagicMock()\n        mock_response.raise_for_status.side_effect = Exception('Download error')\n        mock_get.return_value = mock_response\n\n        status, files = task_func('http://example.com/test.zip', 'test.zip')\n\n        self.assertEqual(status, \"Failed\")\n        self.assertEqual(files, [])\n\n    @patch('requests.get')\n    def test_invalid_zip_file(self, mock_get):\n        # Mock response with invalid zip content\n        mock_response = MagicMock()\n        mock_response.content = b'not a zip file'\n        mock_response.raise_for_status = MagicMock()\n        mock_get.return_value = mock_response\n\n        status, files = task_func('http://example.com/test.zip', 'test.zip')\n\n        self.assertEqual(status, \"Failed\")\n        self.assertEqual(files, [])\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import requests\nfrom pathlib import Path\nimport zipfile\n\ndef task_func(url, filename):\n    DOWNLOAD_DIR = Path(\"downloads\")\n    DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n    file_path = DOWNLOAD_DIR / filename\n\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        with open(file_path, 'wb') as f:\n            f.write(response.content)\n\n        extract_dir = DOWNLOAD_DIR / (file_path.stem + \"_extracted\")\n        extract_dir.mkdir(parents=True, exist_ok=True)\n\n        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n            zip_ref.extractall(extract_dir)\n            extracted_files = zip_ref.namelist()\n\n        return (\"Success\", extracted_files)\n\n    except Exception:\n        return (\"Failed\", [])\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1012_4",
        "turn": "4",
        "instruct_prompt": "Handle exceptions: if a network-related error occurs during download, or if file handling or extraction raises exceptions, return a status message containing \"Error\" and an empty list.",
        "test": "import unittest\nimport tempfile\nimport os\nimport zipfile\nfrom unittest import mock\nfrom pathlib import Path\nimport builtins\n\nimport requests\n\n# Assuming the solution function is named task_func and imported here\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory for downloads\n        self.test_dir = tempfile.TemporaryDirectory()\n        self.addCleanup(self.test_dir.cleanup)\n        self.download_dir = Path(self.test_dir.name) / \"downloads\"\n        self.download_dir.mkdir(parents=True, exist_ok=True)\n\n    @mock.patch('requests.get')\n    def test_network_error(self, mock_get):\n        # Simulate network error by raising requests.ConnectionError\n        mock_get.side_effect = requests.ConnectionError()\n\n        status, files = task_func('http://fakeurl.com/fake.zip', 'fake.zip')\n        self.assertTrue(status.startswith(\"Error\"))\n        self.assertEqual(files, [])\n\n    @mock.patch('requests.get')\n    def test_file_handling_error(self, mock_get):\n        # Normal response content (a valid zip file)\n        # but simulate file write error by mocking open\n        content = self._create_test_zip_bytes(['file1.txt'])\n        mock_response = mock.Mock()\n        mock_response.content = content\n        mock_response.raise_for_status = mock.Mock()\n        mock_get.return_value = mock_response\n\n        # Mock open to raise an IOError\n        with mock.patch('builtins.open', side_effect=IOError):\n            status, files = task_func('http://fakeurl.com/fake.zip', 'fake.zip')\n            self.assertTrue(status.startswith(\"Error\"))\n            self.assertEqual(files, [])\n\n    @mock.patch('requests.get')\n    def test_extraction_error(self, mock_get):\n        # Provide a non-zip content to cause extraction error\n        mock_response = mock.Mock()\n        mock_response.content = b'not a zip file'\n        mock_response.raise_for_status = mock.Mock()\n        mock_get.return_value = mock_response\n\n        status, files = task_func('http://fakeurl.com/fake.zip', 'fake.zip')\n        self.assertTrue(status.startswith(\"Error\"))\n        self.assertEqual(files, [])\n\n    @mock.patch('requests.get')\n    def test_success(self, mock_get):\n        # Provide a valid zip content and test success\n        files_in_zip = ['file1.txt', 'file2.txt']\n        content = self._create_test_zip_bytes(files_in_zip)\n        mock_response = mock.Mock()\n        mock_response.content = content\n        mock_response.raise_for_status = mock.Mock()\n        mock_get.return_value = mock_response\n\n        status, files = task_func('http://fakeurl.com/fake.zip', 'fake.zip')\n        self.assertEqual(status, \"Success\")\n        self.assertEqual(set(files), set(files_in_zip))\n\n    def _create_test_zip_bytes(self, filenames):\n        import io\n        byte_io = io.BytesIO()\n        with zipfile.ZipFile(byte_io, 'w') as zf:\n            for filename in filenames:\n                zf.writestr(filename, 'dummy content')\n        return byte_io.getvalue()\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import requests\nfrom pathlib import Path\nimport zipfile\n\n\ndef task_func(url, filename):\n    DOWNLOAD_DIR = Path(\"downloads\")\n    DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n    file_path = DOWNLOAD_DIR / filename\n\n    try:\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n        except (requests.RequestException, requests.ConnectionError):\n            return (\"Error: Network error during download\", [])\n\n        try:\n            with open(file_path, 'wb') as f:\n                f.write(response.content)\n        except Exception:\n            return (\"Error: File handling error\", [])\n\n        extract_dir = DOWNLOAD_DIR / (file_path.stem + \"_extracted\")\n        extract_dir.mkdir(parents=True, exist_ok=True)\n\n        try:\n            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n                zip_ref.extractall(extract_dir)\n                extracted_files = zip_ref.namelist()\n        except Exception:\n            return (\"Error: Extraction error\", [])\n\n        return (\"Success\", extracted_files)\n\n    except Exception:\n        return (\"Error: Unexpected error\", [])\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 134,
    "task_id": "BigCodeBench/1013",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1013_1",
        "turn": "1",
        "instruct_prompt": "Write a function that fetches the content of a webpage given by a URL. You should write self-contained code starting with:```python\nimport requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n```",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_fetch_content_success(self, mock_get):\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = 'Hello World'\n        mock_response.raise_for_status = Mock()\n        mock_get.return_value = mock_response\n\n        length = task_func('http://test.com')\n        self.assertEqual(length, len('Hello World'))\n\n    @patch('requests.get')\n    def test_fetch_content_failure(self, mock_get):\n        mock_get.side_effect = requests.RequestException\n        length = task_func('http://test.com')\n        self.assertEqual(length, 0)\n",
        "code": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\n\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        content = response.text\n        return len(content)\n    except requests.RequestException:\n        return 0\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1013_2",
        "turn": "2",
        "instruct_prompt": "Parse the fetched webpage content using BeautifulSoup to find all hyperlinks (anchor tags with href attributes).",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\nimport requests\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_links_count(self, mock_get):\n        html_content = '''\n        <html>\n            <body>\n                <a href=\"https://link1.com\">Link 1</a>\n                <a href=\"/relative/link2\">Link 2</a>\n                <a>No href</a>\n                <a href=\"https://link3.com\">Link 3</a>\n            </body>\n        </html>\n        '''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        count = task_func('http://dummyurl.com')\n        self.assertEqual(count, 3)  # Only 3 anchors have href attribute\n\n    @patch('requests.get')\n    def test_request_exception(self, mock_get):\n        mock_get.side_effect = requests.RequestException('Failed request')\n\n        count = task_func('http://dummyurl.com')\n        self.assertEqual(count, 0)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\n\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        content = response.text\n        soup = BeautifulSoup(content, 'html.parser')\n        links = soup.find_all('a', href=True)\n        return len(links)\n    except requests.RequestException:\n        return 0\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1013_3",
        "turn": "3",
        "instruct_prompt": "Convert all extracted hyperlinks to absolute URLs using the given base_url and collect only unique links.",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_unique_absolute_links(self, mock_get):\n        html_content = '''\n        <html>\n            <body>\n                <a href=\"/page1.html\">Page 1</a>\n                <a href=\"/page2.html\">Page 2</a>\n                <a href=\"https://www.example.com/page1.html\">Page 1 Duplicate Absolute</a>\n                <a href=\"page3.html\">Page 3</a>\n                <a href=\"http://otherdomain.com/page4.html\">External Link</a>\n                <a href=\"/page2.html\">Page 2 Duplicate</a>\n            </body>\n        </html>\n        '''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        base_url = \"https://www.example.com\"\n        url = \"https://www.example.com/test\"\n\n        result = task_func(url, base_url)\n        # The unique absolute URLs should be:\n        # https://www.example.com/page1.html\n        # https://www.example.com/page2.html\n        # https://www.example.com/page3.html\n        # http://otherdomain.com/page4.html\n        # Total 4 unique links\n        self.assertEqual(result, 4)\n\n    @patch('requests.get')\n    def test_no_links(self, mock_get):\n        html_content = '<html><body><p>No links here</p></body></html>'\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        result = task_func('https://dummyurl.com')\n        self.assertEqual(result, 0)\n\n    @patch('requests.get')\n    def test_request_exception(self, mock_get):\n        mock_get.side_effect = requests.RequestException\n        result = task_func('https://dummyurl.com')\n        self.assertEqual(result, 0)\n",
        "code": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\n\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        content = response.text\n        soup = BeautifulSoup(content, 'html.parser')\n        links = soup.find_all('a', href=True)\n        unique_abs_links = set()\n        for link in links:\n            abs_url = urljoin(base_url, link['href'])\n            unique_abs_links.add(abs_url)\n        return len(unique_abs_links)\n    except requests.RequestException:\n        return 0\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1013_4",
        "turn": "4",
        "instruct_prompt": "Save all unique absolute URLs to a CSV file specified by csv_file, writing one URL per row.",
        "test": "import unittest\nimport os\nfrom unittest.mock import patch, Mock\nfrom io import StringIO\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_task_func_saves_unique_urls_to_csv(self, mock_get):\n        html_content = '''\n        <html>\n            <body>\n                <a href=\"/page1\">Page 1</a>\n                <a href=\"https://www.example.com/page2\">Page 2</a>\n                <a href=\"/page1\">Page 1 Duplicate</a>\n                <a href=\"page3\">Page 3</a>\n            </body>\n        </html>\n        '''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        csv_file = 'test_output.csv'\n        if os.path.exists(csv_file):\n            os.remove(csv_file)\n\n        count = task_func('http://dummyurl.com', csv_file=csv_file)\n\n        # Check count\n        self.assertEqual(count, 3)  # /page1, /page2, page3 resolved to absolute\n\n        # Check csv file content\n        with open(csv_file, 'r', encoding='utf-8') as f:\n            lines = f.read().strip().split('\\n')\n\n        # There should be 3 lines\n        self.assertEqual(len(lines), 3)\n\n        expected_urls = set([\n            'https://www.example.com/page1',\n            'https://www.example.com/page2',\n            'https://www.example.com/page3'\n        ])\n\n        self.assertEqual(set(lines), expected_urls)\n\n        # Clean up\n        os.remove(csv_file)\n\n    @patch('requests.get')\n    def test_task_func_handles_request_exception(self, mock_get):\n        mock_get.side_effect = requests.RequestException\n        result = task_func('http://dummyurl.com', csv_file='dummy.csv')\n        self.assertEqual(result, 0)\n        # dummy.csv should not be created\n        self.assertFalse(os.path.exists('dummy.csv'))\n",
        "code": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\n\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        content = response.text\n        soup = BeautifulSoup(content, 'html.parser')\n        links = soup.find_all('a', href=True)\n        unique_abs_links = set()\n        for link in links:\n            abs_url = urljoin(base_url, link['href'])\n            unique_abs_links.add(abs_url)\n        # Save unique URLs to CSV\n        with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n            writer = csv.writer(f)\n            for url in unique_abs_links:\n                writer.writerow([url])\n        return len(unique_abs_links)\n    except requests.RequestException:\n        return 0\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1013_5",
        "turn": "5",
        "instruct_prompt": "Return the number of unique absolute URLs scraped from the webpage as an integer.",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\nimport requests\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_unique_abs_urls_count_exclude_fragments(self, mock_get):\n        html_content = '''\n        <html>\n            <body>\n                <a href=\"/page1\">Page 1</a>\n                <a href=\"https://www.example.com/page2\">Page 2</a>\n                <a href=\"page3\">Page 3</a>\n                <a href=\"/page1\">Page 1 Duplicate</a>\n                <a href=\"#fragment\">Fragment</a>\n                <a href=\"#another-fragment\">Another Fragment</a>\n            </body>\n        </html>\n        '''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        count = task_func('https://www.example.com')\n\n        # Expected unique absolute URLs excluding fragment-only URLs:\n        # '/page1' -> 'https://www.example.com/page1'\n        # 'https://www.example.com/page2'\n        # 'page3' -> 'https://www.example.com/page3'\n        # Fragment-only URLs are excluded\n        self.assertEqual(count, 3)\n        self.assertIsInstance(count, int)\n\n    @patch('requests.get')\n    def test_request_exception(self, mock_get):\n        mock_get.side_effect = requests.RequestException('Network error')\n\n        count = task_func('https://www.example.com')\n        self.assertEqual(count, 0)\n        self.assertIsInstance(count, int)\n\n    @patch('requests.get')\n    def test_complex_relative_urls_exclude_fragments(self, mock_get):\n        html_content = '''\n        <html>\n            <body>\n                <a href=\"../up-one-level\">Up One Level</a>\n                <a href=\"./same-level\">Same Level</a>\n                <a href=\"subdir/page\">Subdir Page</a>\n                <a href=\"https://www.example.com/absolute\">Absolute</a>\n                <a href=\"/root-level\">Root Level</a>\n                <a href=\"javascript:void(0);\">Javascript Link</a>\n                <a href=\"#fragment\">Fragment</a>\n            </body>\n        </html>\n        '''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        count = task_func('https://www.example.com/dir/page.html')\n\n        # Expected unique absolute URLs excluding fragment-only URLs:\n        # '../up-one-level' -> 'https://www.example.com/up-one-level'\n        # './same-level' -> 'https://www.example.com/dir/same-level'\n        # 'subdir/page' -> 'https://www.example.com/dir/subdir/page'\n        # 'https://www.example.com/absolute'\n        # '/root-level' -> 'https://www.example.com/root-level'\n        # 'javascript:void(0);' is included as is\n        # fragment-only URL excluded\n        self.assertEqual(count, 6)\n        self.assertIsInstance(count, int)\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\n\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        content = response.text\n        soup = BeautifulSoup(content, 'html.parser')\n        links = soup.find_all('a', href=True)\n        unique_abs_links = set()\n        for link in links:\n            href = link['href']\n            # Exclude fragment-only URLs\n            if href.startswith('#'):\n                continue\n            abs_url = urljoin(base_url, href)\n            unique_abs_links.add(abs_url)\n        # Save unique URLs to CSV\n        with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n            writer = csv.writer(f)\n            for url in unique_abs_links:\n                writer.writerow([url])\n        return len(unique_abs_links)\n    except requests.RequestException:\n        return 0\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 135,
    "task_id": "BigCodeBench/1015",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1015_1",
        "turn": "1",
        "instruct_prompt": "Write a function that fetches HTML content from a given URL or reads it from a local file path starting with \"file://\", then parses the HTML content to extract all table rows (<tr> elements) and returns the number of rows found. You should write self-contained code starting with:\n```python\nimport requests\nfrom lxml import html\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n```",
        "test": "import unittest\nimport tempfile\nimport os\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    def test_file_url_with_rows(self):\n        html_content = '''<html><body><table><tr><td>1</td></tr><tr><td>2</td></tr></table></body></html>'''\n        with tempfile.NamedTemporaryFile('w', delete=False, suffix='.html', encoding='utf-8') as tmp:\n            tmp.write(html_content)\n            tmp_path = tmp.name\n        try:\n            count = task_func(f\"file://{tmp_path}\")\n            self.assertEqual(count, 2)\n        finally:\n            os.remove(tmp_path)\n\n    def test_file_url_no_rows(self):\n        html_content = '<html><body><p>No table rows here</p></body></html>'\n        with tempfile.NamedTemporaryFile('w', delete=False, suffix='.html', encoding='utf-8') as tmp:\n            tmp.write(html_content)\n            tmp_path = tmp.name\n        try:\n            count = task_func(f\"file://{tmp_path}\")\n            self.assertEqual(count, 0)\n        finally:\n            os.remove(tmp_path)\n\n    @patch('requests.get')\n    def test_http_url_with_rows(self, mock_get):\n        html_content = '''<html><body><table><tr><td>Row1</td></tr><tr><td>Row2</td></tr><tr><td>Row3</td></tr></table></body></html>'''\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        count = task_func('http://example.com')\n        self.assertEqual(count, 3)\n\n    @patch('requests.get')\n    def test_http_url_no_rows(self, mock_get):\n        html_content = '<html><body><div>No table rows</div></body></html>'\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        count = task_func('http://example.com')\n        self.assertEqual(count, 0)\n\n    @patch('requests.get')\n    def test_http_url_raises_for_status(self, mock_get):\n        mock_response = Mock()\n        mock_response.raise_for_status.side_effect = requests.HTTPError(\"Not Found\")\n        mock_get.return_value = mock_response\n\n        with self.assertRaises(requests.HTTPError):\n            task_func('http://example.com')\n",
        "code": "import requests\nfrom lxml import html\n\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    if webpage_url.startswith(\"file://\"):\n        file_path = webpage_url[7:]\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n    else:\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n        content = response.text\n\n    tree = html.fromstring(content)\n    rows = tree.xpath('//tr')\n    return len(rows)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1015_2",
        "turn": "2",
        "instruct_prompt": "Extend the function to extract the text content from each cell (<td>) within the table rows, organize this data into a pandas DataFrame, and return 0 if the table is empty or no rows are found. Add the necessary import for pandas.",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_empty_table(self):\n        html_content = '<html><body><table></table></body></html>'\n        with tempfile.NamedTemporaryFile('w', delete=False, suffix='.html', encoding='utf-8') as f:\n            f.write(html_content)\n            temp_file = f.name\n        try:\n            result = task_func(f'file://{temp_file}')\n            self.assertEqual(result, 0)\n        finally:\n            os.unlink(temp_file)\n\n    def test_table_with_no_rows(self):\n        html_content = '<html><body><table><thead><tr><th>Header</th></tr></thead></table></body></html>'\n        with tempfile.NamedTemporaryFile('w', delete=False, suffix='.html', encoding='utf-8') as f:\n            f.write(html_content)\n            temp_file = f.name\n        try:\n            result = task_func(f'file://{temp_file}')\n            self.assertEqual(result, 0)\n        finally:\n            os.unlink(temp_file)\n\n    def test_table_with_rows_and_cells(self):\n        html_content = '''\n        <html><body>\n        <table>\n            <tr><td>Cell1</td><td>Cell2</td></tr>\n            <tr><td>Cell3</td><td>Cell4</td></tr>\n        </table>\n        </body></html>\n        '''\n        with tempfile.NamedTemporaryFile('w', delete=False, suffix='.html', encoding='utf-8') as f:\n            f.write(html_content)\n            temp_file = f.name\n        try:\n            result = task_func(f'file://{temp_file}')\n            self.assertEqual(result, 2)  # 2 rows with td cells\n        finally:\n            os.unlink(temp_file)\n\n    def test_table_with_rows_but_no_td_cells(self):\n        html_content = '''\n        <html><body>\n        <table>\n            <tr><th>Header1</th><th>Header2</th></tr>\n            <tr><th>Header3</th><th>Header4</th></tr>\n        </table>\n        </body></html>\n        '''\n        with tempfile.NamedTemporaryFile('w', delete=False, suffix='.html', encoding='utf-8') as f:\n            f.write(html_content)\n            temp_file = f.name\n        try:\n            result = task_func(f'file://{temp_file}')\n            self.assertEqual(result, 0)  # No td cells in rows\n        finally:\n            os.unlink(temp_file)\n",
        "code": "import requests\nfrom lxml import html\nimport pandas as pd\n\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    if webpage_url.startswith(\"file://\"):\n        file_path = webpage_url[7:]\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n    else:\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n        content = response.text\n\n    tree = html.fromstring(content)\n    rows = tree.xpath('//tr')\n\n    if not rows:\n        return 0\n\n    data = []\n    for row in rows:\n        cells = row.xpath('.//td')\n        if not cells:\n            continue\n        row_data = [cell.text_content().strip() for cell in cells]\n        data.append(row_data)\n\n    if not data:\n        return 0\n\n    df = pd.DataFrame(data)\n    # The DataFrame is created but not returned or saved as per current requirements\n\n    return len(data)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1015_3",
        "turn": "3",
        "instruct_prompt": "Modify the function to connect to an SQLite database (default name 'my_database.db'), replace the table named 'my_table' with the parsed DataFrame data, and return the number of rows stored in the database. Ensure the database connection is properly closed after the operation. Add the necessary import for sqlite3.",
        "test": "import unittest\nimport os\nimport sqlite3\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.test_db = 'test_my_database.db'\n        if os.path.exists(self.test_db):\n            os.remove(self.test_db)\n\n    def tearDown(self):\n        if os.path.exists(self.test_db):\n            os.remove(self.test_db)\n\n    def test_task_func_with_html_table(self):\n        html_content = '''\n        <html>\n          <body>\n            <table>\n              <tr><td>val1</td><td>val2</td></tr>\n              <tr><td>val3</td><td>val4</td></tr>\n            </table>\n          </body>\n        </html>\n        '''\n\n        with patch('requests.get') as mock_get:\n            mock_get.return_value.status_code = 200\n            mock_get.return_value.text = html_content\n\n            count = task_func('http://fakeurl.com', database_name=self.test_db)\n\n            self.assertEqual(count, 2)\n\n            conn = sqlite3.connect(self.test_db)\n            cursor = conn.cursor()\n            cursor.execute('SELECT * FROM my_table')\n            rows = cursor.fetchall()\n            conn.close()\n\n            self.assertEqual(len(rows), 2)\n            self.assertEqual(rows[0], ('val1', 'val2'))\n            self.assertEqual(rows[1], ('val3', 'val4'))\n\n    def test_task_func_with_no_rows(self):\n        html_content = '''<html><body><table></table></body></html>'''\n\n        with patch('requests.get') as mock_get:\n            mock_get.return_value.status_code = 200\n            mock_get.return_value.text = html_content\n\n            count = task_func('http://fakeurl.com', database_name=self.test_db)\n            self.assertEqual(count, 0)\n\n    def test_task_func_with_file_url(self):\n        html_content = '''\n        <html>\n          <body>\n            <table>\n              <tr><td>a</td><td>b</td></tr>\n              <tr><td>c</td><td>d</td></tr>\n              <tr><td>e</td><td>f</td></tr>\n            </table>\n          </body>\n        </html>\n        '''\n        file_name = 'test_file.html'\n        with open(file_name, 'w', encoding='utf-8') as f:\n            f.write(html_content)\n\n        try:\n            count = task_func(f'file://{file_name}', database_name=self.test_db)\n            self.assertEqual(count, 3)\n\n            conn = sqlite3.connect(self.test_db)\n            cursor = conn.cursor()\n            cursor.execute('SELECT COUNT(*) FROM my_table')\n            rows_count = cursor.fetchone()[0]\n            conn.close()\n\n            self.assertEqual(rows_count, 3)\n        finally:\n            if os.path.exists(file_name):\n                os.remove(file_name)\n",
        "code": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\n\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    if webpage_url.startswith(\"file://\"):\n        file_path = webpage_url[7:]\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n    else:\n        response = requests.get(webpage_url)\n        response.raise_for_status()\n        content = response.text\n\n    tree = html.fromstring(content)\n    rows = tree.xpath('//tr')\n\n    if not rows:\n        return 0\n\n    data = []\n    for row in rows:\n        cells = row.xpath('.//td')\n        if not cells:\n            continue\n        row_data = [cell.text_content().strip() for cell in cells]\n        data.append(row_data)\n\n    if not data:\n        return 0\n\n    df = pd.DataFrame(data)\n\n    conn = sqlite3.connect(database_name)\n    try:\n        df.to_sql('my_table', conn, if_exists='replace', index=False)\n        cursor = conn.cursor()\n        cursor.execute('SELECT COUNT(*) FROM my_table')\n        count = cursor.fetchone()[0]\n    finally:\n        conn.close()\n\n    return count\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1015_4",
        "turn": "4",
        "instruct_prompt": "Add error handling to the function: raise requests.RequestException with a descriptive message if there is a network-related error when accessing the URL; raise sqlite3.DatabaseError with a descriptive message if there is any issue connecting to or writing to the SQLite database.",
        "test": "import unittest\nimport os\nimport tempfile\nimport sqlite3\nimport requests\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    def test_network_error_raises_request_exception(self):\n        with patch('requests.get', side_effect=requests.ConnectionError('Failed to connect')):\n            with self.assertRaises(requests.RequestException) as cm:\n                task_func('http://example.com')\n            self.assertIn('Network error when accessing URL', str(cm.exception))\n\n    def test_database_error_raises_database_error(self):\n        # Create a valid HTML table content\n        html_content = '''<html><body><table><tr><td>data1</td><td>data2</td></tr></table></body></html>'''\n\n        # Create a temporary file with the HTML content\n        with tempfile.NamedTemporaryFile('w', delete=False, suffix='.html', encoding='utf-8') as tmpfile:\n            tmpfile.write(html_content)\n            tmpfile_path = tmpfile.name\n\n        # Use the tmpfile (which is an HTML file) as database name to cause error\n        with self.assertRaises(sqlite3.DatabaseError) as cm:\n            task_func(f'file://{tmpfile_path}', database_name=tmpfile_path)  # passing file path as database name to cause error\n        self.assertIn('Database error with', str(cm.exception))\n\n        os.unlink(tmpfile_path)\n\n    def test_valid_file_input_returns_correct_count(self):\n        html_content = '''<html><body><table>\n<tr><td>val1</td><td>val2</td></tr>\n<tr><td>val3</td><td>val4</td></tr>\n</table></body></html>'''\n        with tempfile.NamedTemporaryFile('w', delete=False, suffix='.html', encoding='utf-8') as tmpfile:\n            tmpfile.write(html_content)\n            tmpfile_path = tmpfile.name\n\n        count = task_func(f'file://{tmpfile_path}')\n        self.assertEqual(count, 2)\n\n        os.unlink(tmpfile_path)\n\n    def test_valid_http_input_returns_correct_count(self):\n        html_content = '''<html><body><table>\n<tr><td>a</td><td>b</td></tr>\n<tr><td>c</td><td>d</td></tr>\n<tr><td>e</td><td>f</td></tr>\n</table></body></html>'''\n\n        mock_response = Mock()\n        mock_response.raise_for_status = Mock()\n        mock_response.text = html_content\n\n        with patch('requests.get', return_value=mock_response):\n            count = task_func('http://fakeurl.com')\n            self.assertEqual(count, 3)\n",
        "code": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\nimport pandas.errors\n\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    try:\n        if webpage_url.startswith(\"file://\"):\n            file_path = webpage_url[7:]\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n        else:\n            try:\n                response = requests.get(webpage_url)\n                response.raise_for_status()\n                content = response.text\n            except requests.RequestException as e:\n                raise requests.RequestException(f\"Network error when accessing URL {webpage_url}: {e}\")\n\n        tree = html.fromstring(content)\n        rows = tree.xpath('//tr')\n\n        if not rows:\n            return 0\n\n        data = []\n        for row in rows:\n            cells = row.xpath('.//td')\n            if not cells:\n                continue\n            row_data = [cell.text_content().strip() for cell in cells]\n            data.append(row_data)\n\n        if not data:\n            return 0\n\n        df = pd.DataFrame(data)\n\n        try:\n            conn = sqlite3.connect(database_name)\n            df.to_sql('my_table', conn, if_exists='replace', index=False)\n            cursor = conn.cursor()\n            cursor.execute('SELECT COUNT(*) FROM my_table')\n            count = cursor.fetchone()[0]\n        except (sqlite3.DatabaseError, pandas.errors.DatabaseError) as e:\n            raise sqlite3.DatabaseError(f\"Database error with {database_name}: {e}\")\n        finally:\n            conn.close()\n\n        return count\n\n    except Exception:\n        raise",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 136,
    "task_id": "BigCodeBench/1019",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1019_1",
        "turn": "1",
        "instruct_prompt": "Open an image file and extract text from it using OCR. You should write self-contained code starting with:\n```python\nfrom PIL import Image\nimport pytesseract\nIMAGE_PATH = \"image.png\"\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n```",
        "test": "import unittest\nimport os\nfrom PIL import Image, ImageDraw, ImageFont\nimport pytesseract\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Skip tests if Tesseract OCR is not installed\n        try:\n            _ = pytesseract.get_tesseract_version()\n        except (EnvironmentError, pytesseract.pytesseract.TesseractNotFoundError):\n            self.skipTest(\"Tesseract OCR is not installed or not found in PATH.\")\n\n        self.test_image_path = \"test_image.png\"\n        # Create a larger image with clearer text for OCR\n        img = Image.new('RGB', (200, 60), color=(255, 255, 255))\n        d = ImageDraw.Draw(img)\n        # Use default font; if available, a truetype font could be used for better clarity\n        d.text((10, 10), \"Hello\", fill=(0, 0, 0))\n        img.save(self.test_image_path)\n\n    def tearDown(self):\n        if os.path.exists(self.test_image_path):\n            os.remove(self.test_image_path)\n\n    def test_task_func_returns_text(self):\n        extracted_text = task_func(filename=self.test_image_path)\n        self.assertTrue(len(extracted_text) > 0, \"OCR returned empty string\")\n        self.assertIn('hello', extracted_text.lower())\n\n    def test_task_func_file_not_found(self):\n        # When file does not exist, function should return empty string without error\n        result = task_func(filename=\"non_existent_file.png\")\n        self.assertEqual(result, \"\")\n",
        "code": "from PIL import Image\nimport pytesseract\n\nIMAGE_PATH = \"image.png\"\n\ndef task_func(filename=IMAGE_PATH):\n    try:\n        img = Image.open(filename)\n        text = pytesseract.image_to_string(img)\n        return text\n    except (pytesseract.pytesseract.TesseractNotFoundError, FileNotFoundError):\n        return \"\"",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1019_2",
        "turn": "2",
        "instruct_prompt": "Convert the extracted text encoding from the given from_encoding to to_encoding and return it as a string.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport pytesseract\n\nclass TestCases(unittest.TestCase):\n    @patch('pytesseract.image_to_string')\n    @patch('PIL.Image.open')\n    def test_encoding_conversion_utf8_to_utf8(self, mock_open, mock_ocr):\n        mock_open.return_value = MagicMock()\n        mock_ocr.return_value = 'hello'\n        result = task_func(from_encoding='utf-8', to_encoding='utf-8')\n        self.assertEqual(result, 'hello')\n\n    @patch('pytesseract.image_to_string')\n    @patch('PIL.Image.open')\n    def test_encoding_conversion_utf8_to_ascii(self, mock_open, mock_ocr):\n        mock_open.return_value = MagicMock()\n        mock_ocr.return_value = 'hello'\n        # 'hello' can be encoded in utf-8 and decoded in ascii without error\n        result = task_func(from_encoding='utf-8', to_encoding='ascii')\n        self.assertEqual(result, 'hello')\n\n    @patch('pytesseract.image_to_string')\n    @patch('PIL.Image.open')\n    def test_encoding_conversion_utf8_to_ascii_fail(self, mock_open, mock_ocr):\n        mock_open.return_value = MagicMock()\n        mock_ocr.return_value = 'hllo'  # contains '' which ascii cannot decode\n        result = task_func(from_encoding='utf-8', to_encoding='ascii')\n        self.assertEqual(result, '')\n\n    @patch('pytesseract.image_to_string')\n    @patch('PIL.Image.open')\n    def test_file_not_found(self, mock_open, mock_ocr):\n        mock_open.side_effect = FileNotFoundError\n        result = task_func()\n        self.assertEqual(result, '')\n\n    @patch('pytesseract.image_to_string')\n    @patch('PIL.Image.open')\n    def test_tesseract_not_found(self, mock_open, mock_ocr):\n        mock_ocr.side_effect = pytesseract.pytesseract.TesseractNotFoundError\n        result = task_func()\n        self.assertEqual(result, '')",
        "code": "from PIL import Image\nimport pytesseract\n\nIMAGE_PATH = \"image.png\"\n\ndef task_func(filename=IMAGE_PATH, from_encoding='utf-8', to_encoding='utf-8'):\n    try:\n        img = Image.open(filename)\n        text = pytesseract.image_to_string(img)\n        # If encodings are the same, return text directly\n        if from_encoding == to_encoding:\n            return text\n        # Convert text to bytes using from_encoding\n        text_bytes = text.encode(from_encoding)\n        # Decode bytes to string using to_encoding\n        text_converted = text_bytes.decode(to_encoding)\n        return text_converted\n    except (pytesseract.pytesseract.TesseractNotFoundError, FileNotFoundError, UnicodeEncodeError, UnicodeDecodeError):\n        return \"\"",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1019_3",
        "turn": "3",
        "instruct_prompt": "If OCR extraction fails or returns no text, extract the image comment instead and convert its encoding from from_encoding to to_encoding, then return it as a string.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nfrom io import BytesIO\nfrom PIL import Image\n\nclass TestCases(unittest.TestCase):\n    @patch('pytesseract.image_to_string')\n    @patch('PIL.Image.open')\n    def test_ocr_success(self, mock_open, mock_ocr):\n        # Setup mock image\n        mock_img = MagicMock()\n        mock_img.info = {}\n        mock_open.return_value = mock_img\n        mock_ocr.return_value = 'Test OCR Text'\n\n        result = task_func('dummy.png')\n        self.assertEqual(result, 'Test OCR Text')\n\n    @patch('pytesseract.image_to_string')\n    @patch('PIL.Image.open')\n    def test_ocr_empty_comment_present(self, mock_open, mock_ocr):\n        mock_img = MagicMock()\n        comment_text = 'comment text'\n        mock_img.info = {'comment': comment_text.encode('utf-8')}\n        mock_open.return_value = mock_img\n        mock_ocr.return_value = '   '  # OCR returns whitespace only\n\n        # Same encoding\n        result = task_func('dummy.png', from_encoding='utf-8', to_encoding='utf-8')\n        self.assertEqual(result, comment_text)\n\n        # Different encoding utf-8 -> utf-16\n        result2 = task_func('dummy.png', from_encoding='utf-8', to_encoding='utf-16')\n        # The result2 should be a string, possibly different content, but not empty\n        self.assertIsInstance(result2, str)\n        self.assertNotEqual(result2, '')\n\n    @patch('pytesseract.image_to_string')\n    @patch('PIL.Image.open')\n    def test_ocr_empty_comment_absent(self, mock_open, mock_ocr):\n        mock_img = MagicMock()\n        mock_img.info = {}\n        mock_open.return_value = mock_img\n        mock_ocr.return_value = ''  # OCR returns empty\n\n        result = task_func('dummy.png')\n        self.assertEqual(result, '')\n\n    def test_exception_handling(self):\n        # Pass a filename that will cause FileNotFoundError\n        result = task_func('non_existent_file.png')\n        self.assertEqual(result, '')\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "from PIL import Image\nimport pytesseract\n\ndef task_func(filename=\"image.png\", from_encoding='utf-8', to_encoding='utf-8'):\n    try:\n        img = Image.open(filename)\n        text = pytesseract.image_to_string(img)\n        if not text.strip():  # OCR failed or returned no text\n            comment = img.info.get('comment', b'')\n            if comment:\n                # comment can be bytes or str\n                if isinstance(comment, bytes):\n                    comment_decoded = comment.decode(from_encoding)\n                else:\n                    comment_decoded = str(comment)\n                if from_encoding == to_encoding:\n                    return comment_decoded\n                # Convert encoding\n                comment_bytes = comment_decoded.encode(from_encoding)\n                return comment_bytes.decode(to_encoding)\n            else:\n                return \"\"\n        else:\n            if from_encoding == to_encoding:\n                return text\n            text_bytes = text.encode(from_encoding)\n            return text_bytes.decode(to_encoding)\n    except (pytesseract.pytesseract.TesseractNotFoundError, FileNotFoundError, UnicodeEncodeError, UnicodeDecodeError):\n        return \"\"",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1019_4",
        "turn": "4",
        "instruct_prompt": "If UnicodeDecodeError or LookupError occurs during encoding conversion, raise a ValueError indicating incorrect encoding. If both OCR and comment extraction fail, return an empty string.",
        "test": "import unittest\nfrom PIL import Image\nimport pytesseract\n\nclass DummyImage:\n    def __init__(self, info=None):\n        self.info = info or {}\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.orig_image_to_string = pytesseract.image_to_string\n        self.orig_image_open = Image.open\n\n    def tearDown(self):\n        pytesseract.image_to_string = self.orig_image_to_string\n        Image.open = self.orig_image_open\n\n    def test_unicode_encode_error_raises_value_error(self):\n        # OCR returns text with a character not encodable in ascii\n        pytesseract.image_to_string = lambda img: \"\\u20ac\"  # Euro sign\n        Image.open = lambda filename: DummyImage()\n        with self.assertRaises(ValueError) as cm:\n            task_func(\"dummy.png\", from_encoding=\"utf-8\", to_encoding=\"ascii\")\n        self.assertEqual(str(cm.exception), \"Incorrect encoding\")\n\n    def test_lookup_error_raises_value_error(self):\n        # OCR returns text, but to_encoding invalid to cause LookupError\n        pytesseract.image_to_string = lambda img: \"test\"\n        Image.open = lambda filename: DummyImage()\n        with self.assertRaises(ValueError) as cm:\n            task_func(\"dummy.png\", from_encoding=\"utf-8\", to_encoding=\"invalid-enc\")\n        self.assertEqual(str(cm.exception), \"Incorrect encoding\")\n\n    def test_comment_unicode_decode_error_raises_value_error(self):\n        # OCR empty, comment bytes invalid for decoding with from_encoding\n        pytesseract.image_to_string = lambda img: \"\"\n        Image.open = lambda filename: DummyImage(info={'comment': b'\\xff\\xff'})\n        with self.assertRaises(ValueError) as cm:\n            task_func(\"dummy.png\", from_encoding=\"utf-8\", to_encoding=\"utf-8\")\n        self.assertEqual(str(cm.exception), \"Incorrect encoding\")\n\n    def test_comment_unicode_encode_error_raises_value_error(self):\n        # OCR empty, comment string with char not encodable in ascii\n        pytesseract.image_to_string = lambda img: \"\"\n        Image.open = lambda filename: DummyImage(info={'comment': \"\\u20ac\"})  # Euro sign\n        with self.assertRaises(ValueError) as cm:\n            task_func(\"dummy.png\", from_encoding=\"utf-8\", to_encoding=\"ascii\")\n        self.assertEqual(str(cm.exception), \"Incorrect encoding\")\n\n    def test_comment_lookup_error_raises_value_error(self):\n        # OCR empty, comment bytes, but to_encoding invalid\n        pytesseract.image_to_string = lambda img: \"\"\n        Image.open = lambda filename: DummyImage(info={'comment': b'test'})\n        with self.assertRaises(ValueError) as cm:\n            task_func(\"dummy.png\", from_encoding=\"utf-8\", to_encoding=\"invalid-enc\")\n        self.assertEqual(str(cm.exception), \"Incorrect encoding\")\n\n    def test_both_ocr_and_comment_fail_returns_empty_string(self):\n        # OCR empty, no comment\n        pytesseract.image_to_string = lambda img: \"\"\n        Image.open = lambda filename: DummyImage(info={})\n        result = task_func(\"dummy.png\")\n        self.assertEqual(result, \"\")\n\n    def test_ocr_success_returns_text(self):\n        pytesseract.image_to_string = lambda img: \"hello\"\n        Image.open = lambda filename: DummyImage()\n        result = task_func(\"dummy.png\", from_encoding='utf-8', to_encoding='utf-8')\n        self.assertEqual(result, \"hello\")\n\n    def test_comment_success_returns_comment(self):\n        pytesseract.image_to_string = lambda img: \"\"\n        Image.open = lambda filename: DummyImage(info={'comment': b'hello'})\n        result = task_func(\"dummy.png\", from_encoding='utf-8', to_encoding='utf-8')\n        self.assertEqual(result, \"hello\")\n\n    def test_tesseract_not_found_returns_empty_string(self):\n        def raise_tesseract_not_found(img):\n            raise pytesseract.pytesseract.TesseractNotFoundError()\n        pytesseract.image_to_string = raise_tesseract_not_found\n        Image.open = lambda filename: DummyImage()\n        result = task_func(\"dummy.png\")\n        self.assertEqual(result, \"\")\n\n    def test_file_not_found_returns_empty_string(self):\n        def raise_file_not_found(filename):\n            raise FileNotFoundError()\n        Image.open = raise_file_not_found\n        result = task_func(\"dummy.png\")\n        self.assertEqual(result, \"\")",
        "code": "from PIL import Image\nimport pytesseract\n\ndef task_func(filename=\"image.png\", from_encoding='utf-8', to_encoding='utf-8'):\n    try:\n        img = Image.open(filename)\n        text = pytesseract.image_to_string(img)\n        if not text.strip():  # OCR failed or empty\n            comment = img.info.get('comment', b'')\n            if comment:\n                try:\n                    if isinstance(comment, bytes):\n                        # decode bytes with from_encoding\n                        comment_decoded = comment.decode(from_encoding)\n                    else:\n                        comment_decoded = comment\n                    if from_encoding == to_encoding:\n                        return comment_decoded\n                    # convert encoding: encode unicode string to bytes with to_encoding, decode back to string\n                    try:\n                        comment_bytes = comment_decoded.encode(to_encoding)\n                        comment_converted = comment_bytes.decode(to_encoding)\n                    except (UnicodeEncodeError, UnicodeDecodeError, LookupError) as e:\n                        raise ValueError(\"Incorrect encoding\") from e\n                    return comment_converted\n                except (UnicodeDecodeError, LookupError) as e:\n                    raise ValueError(\"Incorrect encoding\") from e\n            else:\n                return \"\"\n        else:\n            if from_encoding == to_encoding:\n                return text\n            try:\n                # Convert encoding: encode text (unicode) to bytes with to_encoding, decode back to string\n                text_bytes = text.encode(to_encoding)\n                text_converted = text_bytes.decode(to_encoding)\n                return text_converted\n            except (UnicodeEncodeError, UnicodeDecodeError, LookupError) as e:\n                raise ValueError(\"Incorrect encoding\") from e\n    except (pytesseract.pytesseract.TesseractNotFoundError, FileNotFoundError):\n        return \"\"",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 137,
    "task_id": "BigCodeBench/1020",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1020_1",
        "turn": "1",
        "instruct_prompt": "Write a function that fetches data from a specified REST API URL using an HTTP GET request with a 5-second timeout, then returns the raw response content as bytes. You should write self-contained code starting with:```import requests\n# Constants\nAPI_URL = \"http://api.example.com/data\"\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    response = requests.get(url, timeout=5)\n    content = response.content\n    return content\n```",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\nimport requests\n\n# Import the task_func from the solution code above or assume it is in the same module\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_task_func_returns_bytes(self, mock_get):\n        # Prepare mock response\n        mock_response = Mock()\n        mock_response.content = b'Test content'\n        mock_get.return_value = mock_response\n\n        result = task_func(url=\"http://fakeurl.com\")\n\n        # Check that requests.get was called with the correct timeout\n        mock_get.assert_called_with(\"http://fakeurl.com\", timeout=5)\n\n        # Check that the result is bytes and equals the mocked content\n        self.assertIsInstance(result, bytes)\n        self.assertEqual(result, b'Test content')\n\n    @patch('requests.get')\n    def test_task_func_default_url(self, mock_get):\n        mock_response = Mock()\n        mock_response.content = b'Default URL content'\n        mock_get.return_value = mock_response\n\n        result = task_func()\n\n        mock_get.assert_called_with(\"http://api.example.com/data\", timeout=5)\n        self.assertEqual(result, b'Default URL content')\n\n    @patch('requests.get')\n    def test_task_func_timeout(self, mock_get):\n        # Simulate a timeout exception\n        mock_get.side_effect = requests.exceptions.Timeout\n\n        with self.assertRaises(requests.exceptions.Timeout):\n            task_func(url=\"http://slowurl.com\")\n",
        "code": "import requests\n\n# Constants\nAPI_URL = \"http://api.example.com/data\"\n\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    response = requests.get(url, timeout=5)\n    content = response.content\n    return content\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1020_2",
        "turn": "2",
        "instruct_prompt": "Decode the fetched raw byte content to a string. If the parameter from_encoding is None, detect the encoding using chardet.detect. If encoding cannot be detected and content is non-empty, raise ValueError(\"Unable to detect encoding for non-empty content\"). If content is empty, return an empty dictionary. If from_encoding is provided, decode using that encoding.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport builtins\n\nimport chardet\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_empty_content_returns_empty_dict(self, mock_get):\n        mock_response = MagicMock()\n        mock_response.content = b''\n        mock_get.return_value = mock_response\n\n        result = task_func()\n        self.assertEqual(result, {})\n\n    @patch('requests.get')\n    def test_from_encoding_provided_decodes_correctly(self, mock_get):\n        original_text = 'hello'\n        encoded = original_text.encode('utf-16')\n        mock_response = MagicMock()\n        mock_response.content = encoded\n        mock_get.return_value = mock_response\n\n        result = task_func(from_encoding='utf-16')\n        self.assertEqual(result, original_text)\n\n    @patch('requests.get')\n    def test_detect_encoding_and_decode(self, mock_get):\n        original_text = 'hello'\n        encoded = original_text.encode('utf-8')\n        mock_response = MagicMock()\n        mock_response.content = encoded\n        mock_get.return_value = mock_response\n\n        # Patch chardet.detect to return utf-8\n        with patch('chardet.detect', return_value={'encoding': 'utf-8', 'confidence': 1.0}):\n            result = task_func(from_encoding=None)\n            self.assertEqual(result, original_text)\n\n    @patch('requests.get')\n    def test_detect_encoding_none_raises_valueerror(self, mock_get):\n        mock_response = MagicMock()\n        mock_response.content = b'non-empty content'\n        mock_get.return_value = mock_response\n\n        # Patch chardet.detect to return no encoding\n        with patch('chardet.detect', return_value={'encoding': None, 'confidence': 0.0}):\n            with self.assertRaises(ValueError) as context:\n                task_func(from_encoding=None)\n            self.assertEqual(str(context.exception), \"Unable to detect encoding for non-empty content\")\n",
        "code": "import requests\nimport chardet\n\n# Constants\nAPI_URL = \"http://api.example.com/data\"\n\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    response = requests.get(url, timeout=5)\n    content = response.content\n\n    if not content:\n        return {}\n\n    if from_encoding is None:\n        detection = chardet.detect(content)\n        encoding = detection.get('encoding')\n        if not encoding:\n            raise ValueError(\"Unable to detect encoding for non-empty content\")\n    else:\n        encoding = from_encoding\n\n    decoded_str = content.decode(encoding)\n    return decoded_str\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1020_3",
        "turn": "3",
        "instruct_prompt": "Re-encode the decoded string content to bytes using the to_encoding parameter, then decode it back to a string using the same to_encoding to ensure compatibility with various data formats.",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_reencode_utf8(self, mock_get):\n        original_str = 'caf'\n        content = original_str.encode('latin1')\n        mock_response = Mock()\n        mock_response.content = content\n        mock_get.return_value = mock_response\n\n        result = task_func(from_encoding='latin1', to_encoding='utf8')\n        self.assertEqual(result, original_str)\n\n    @patch('requests.get')\n    def test_reencode_same_encoding(self, mock_get):\n        original_str = 'hello world'\n        content = original_str.encode('utf-8')\n        mock_response = Mock()\n        mock_response.content = content\n        mock_get.return_value = mock_response\n\n        result = task_func(from_encoding='utf-8', to_encoding='utf-8')\n        self.assertEqual(result, original_str)\n\n    @patch('requests.get')\n    def test_detect_encoding_and_reencode(self, mock_get):\n        original_str = 'test string'\n        content = original_str.encode('utf-16')\n        mock_response = Mock()\n        mock_response.content = content\n        mock_get.return_value = mock_response\n\n        result = task_func(from_encoding=None, to_encoding='utf-8')\n        self.assertEqual(result, original_str)\n\n    @patch('requests.get')\n    def test_empty_content_returns_dict(self, mock_get):\n        mock_response = Mock()\n        mock_response.content = b''\n        mock_get.return_value = mock_response\n\n        result = task_func()\n        self.assertEqual(result, {})\n\n    @patch('requests.get')\n    def test_encoding_error_raises_for_ascii(self, mock_get):\n        # String with non-ascii character\n        original_str = 'caf'\n        content = original_str.encode('latin1')\n        mock_response = Mock()\n        mock_response.content = content\n        mock_get.return_value = mock_response\n\n        # Expect UnicodeEncodeError when encoding to ascii\n        with self.assertRaises(UnicodeEncodeError):\n            task_func(from_encoding='latin1', to_encoding='ascii')\n\n    @patch('chardet.detect')\n    @patch('requests.get')\n    def test_undetectable_encoding_raises(self, mock_get, mock_chardet_detect):\n        mock_chardet_detect.return_value = {'encoding': None}\n\n        mock_response = Mock()\n        mock_response.content = b'\\xff\\xff\\xff\\xff'\n        mock_get.return_value = mock_response\n\n        with self.assertRaises(ValueError):\n            task_func(from_encoding=None)\n",
        "code": "import requests\nimport chardet\n\n# Constants\nAPI_URL = \"http://api.example.com/data\"\n\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    response = requests.get(url, timeout=5)\n    content = response.content\n\n    if not content:\n        return {}\n\n    if from_encoding is None:\n        detection = chardet.detect(content)\n        encoding = detection.get('encoding')\n        if not encoding:\n            raise ValueError(\"Unable to detect encoding for non-empty content\")\n    else:\n        encoding = from_encoding\n\n    decoded_str = content.decode(encoding)\n    reencoded_bytes = decoded_str.encode(to_encoding)  # May raise UnicodeEncodeError if chars not representable\n    final_str = reencoded_bytes.decode(to_encoding)\n    return final_str\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1020_4",
        "turn": "4",
        "instruct_prompt": "Parse the final decoded string content as JSON and return the resulting dictionary.",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\nimport json\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_empty_content(self, mock_get):\n        mock_get.return_value.content = b''\n        result = task_func()\n        self.assertEqual(result, {})\n\n    @patch('requests.get')\n    def test_valid_json_utf8(self, mock_get):\n        data = {'key': 'value', 'num': 123}\n        json_bytes = json.dumps(data).encode('utf-8')\n        mock_get.return_value.content = json_bytes\n        result = task_func()\n        self.assertEqual(result, data)\n\n    @patch('requests.get')\n    def test_valid_json_different_encoding(self, mock_get):\n        data = {'hello': 'world', 'list': [1, 2, 3]}\n        # Encode JSON string in latin1\n        json_str = json.dumps(data)\n        json_bytes = json_str.encode('latin1')\n        mock_get.return_value.content = json_bytes\n\n        # Provide from_encoding explicitly\n        result = task_func(from_encoding='latin1')\n        self.assertEqual(result, data)\n\n    @patch('requests.get')\n    def test_invalid_json_raises(self, mock_get):\n        # Content decodes to non-JSON string\n        mock_get.return_value.content = b'not a json string'\n        with self.assertRaises(json.JSONDecodeError):\n            task_func()\n\n    @patch('requests.get')\n    def test_encoding_detection_failure(self, mock_get):\n        # Provide content that chardet cannot detect encoding for\n        mock_get.return_value.content = b'\\xff\\xff\\xff\\xff'\n        with self.assertRaises(ValueError):\n            task_func()\n",
        "code": "import requests\nimport chardet\nimport json\n\n# Constants\nAPI_URL = \"http://api.example.com/data\"\n\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    response = requests.get(url, timeout=5)\n    content = response.content\n\n    if not content:\n        return {}\n\n    if from_encoding is None:\n        detection = chardet.detect(content)\n        encoding = detection.get('encoding')\n        if not encoding:\n            raise ValueError(\"Unable to detect encoding for non-empty content\")\n    else:\n        encoding = from_encoding\n\n    decoded_str = content.decode(encoding)\n    reencoded_bytes = decoded_str.encode(to_encoding)  # May raise UnicodeEncodeError if chars not representable\n    final_str = reencoded_bytes.decode(to_encoding)\n\n    # Parse the final string as JSON and return the dictionary\n    return json.loads(final_str)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 138,
    "task_id": "BigCodeBench/1022",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1022_1",
        "turn": "1",
        "instruct_prompt": "Write a function named task_func that reads a CSV file from a given path into a pandas DataFrame. You should write self-contained code starting with:\n```python\nimport pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n```",
        "test": "import unittest\nimport tempfile\nimport os\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory for test CSV files\n        self.test_dir = tempfile.TemporaryDirectory()\n\n    def tearDown(self):\n        self.test_dir.cleanup()\n\n    def test_valid_csv_and_column(self):\n        csv_content = \"date,value\\n2023-01-01,10\\n2023-01-02,20\"\n        file_path = os.path.join(self.test_dir.name, \"test.csv\")\n        with open(file_path, 'w') as f:\n            f.write(csv_content)\n        df = task_func(file_path, 'date', '%Y-%m-%d')\n        self.assertIn('date', df.columns)\n        self.assertTrue(pd.api.types.is_datetime64_any_dtype(df['date']))\n        self.assertEqual(len(df), 2)\n\n    def test_file_not_found(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('non_existent_file.csv', 'date')\n\n    def test_empty_csv(self):\n        file_path = os.path.join(self.test_dir.name, \"empty.csv\")\n        with open(file_path, 'w') as f:\n            f.write(\"\")\n        with self.assertRaises(ValueError) as context:\n            task_func(file_path, 'date')\n        self.assertIn(\"CSV file is empty\", str(context.exception))\n\n    def test_missing_column(self):\n        csv_content = \"date,value\\n2023-01-01,10\"\n        file_path = os.path.join(self.test_dir.name, \"test_missing_col.csv\")\n        with open(file_path, 'w') as f:\n            f.write(csv_content)\n        with self.assertRaises(ValueError) as context:\n            task_func(file_path, 'nonexistent_column')\n        self.assertIn(\"Column 'nonexistent_column' not found in CSV\", str(context.exception))\n\n    def test_invalid_date_format(self):\n        csv_content = \"date,value\\n01-2023-01,10\"\n        file_path = os.path.join(self.test_dir.name, \"test_invalid_date.csv\")\n        with open(file_path, 'w') as f:\n            f.write(csv_content)\n        with self.assertRaises(ValueError) as context:\n            task_func(file_path, 'date', '%Y-%m-%d')\n        self.assertIn(\"Error parsing dates in column 'date'\", str(context.exception))\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\n\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    if not os.path.exists(csv_file_path):\n        raise FileNotFoundError(f\"File not found: {csv_file_path}\")\n    try:\n        df = pd.read_csv(csv_file_path)\n    except EmptyDataError:\n        raise ValueError(\"CSV file is empty\")\n    if column_name not in df.columns:\n        raise ValueError(f\"Column '{column_name}' not found in CSV\")\n    # Try to parse the column as datetime using the given date_format\n    try:\n        df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n    except Exception as e:\n        raise ValueError(f\"Error parsing dates in column '{column_name}': {e}\")\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1022_2",
        "turn": "2",
        "instruct_prompt": "Make the function check if the CSV file exists at the given path. If the file does not exist, raise a FileNotFoundError with an appropriate message.",
        "test": "import unittest\nimport tempfile\nimport os\nimport shutil\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_file_not_found_with_directory(self):\n        # Create a directory with the name of the csv file\n        temp_dir = tempfile.mkdtemp()\n        fake_file_path = os.path.join(temp_dir, \"fakefile.csv\")\n        os.mkdir(fake_file_path)  # create directory with the csv file name\n        try:\n            with self.assertRaises(FileNotFoundError) as context:\n                task_func(fake_file_path, \"date\")\n            self.assertIn(\"File not found\", str(context.exception))\n        finally:\n            shutil.rmtree(temp_dir)\n\n    def test_file_not_found_with_nonexistent_path(self):\n        with self.assertRaises(FileNotFoundError) as context:\n            task_func(\"definitely_not_exist_12345.csv\", \"date\")\n        self.assertIn(\"File not found\", str(context.exception))\n\n    def test_existing_file(self):\n        import pandas as pd\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as tmp:\n            tmp.write(\"date,value\\n2023-01-01,10\\n2023-01-02,20\\n\")\n            tmp_path = tmp.name\n        try:\n            df = task_func(tmp_path, \"date\")\n            self.assertIsInstance(df, pd.DataFrame)\n            self.assertIn(\"date\", df.columns)\n        finally:\n            os.remove(tmp_path)\n",
        "code": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\n\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    if not os.path.isfile(csv_file_path):\n        raise FileNotFoundError(f\"File not found: {csv_file_path}\")\n    try:\n        df = pd.read_csv(csv_file_path)\n    except EmptyDataError:\n        raise ValueError(\"CSV file is empty\")\n    if column_name not in df.columns:\n        raise ValueError(f\"Column '{column_name}' not found in CSV\")\n    # Try to parse the column as datetime using the given date_format\n    try:\n        df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n    except Exception as e:\n        raise ValueError(f\"Error parsing dates in column '{column_name}': {e}\")\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1022_3",
        "turn": "3",
        "instruct_prompt": "Modify the function to handle the case where the CSV file is empty by catching pandas.errors.EmptyDataError and returning an empty DataFrame.",
        "test": "import unittest\nimport tempfile\nimport os\nimport pandas as pd\nfrom pandas.errors import EmptyDataError\n\nclass TestCases(unittest.TestCase):\n    def test_empty_csv_returns_empty_dataframe(self):\n        with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp:\n            tmp_path = tmp.name\n            # Write nothing to create an empty file\n        try:\n            df = task_func(tmp_path, 'date')\n            self.assertTrue(isinstance(df, pd.DataFrame))\n            self.assertTrue(df.empty)\n        finally:\n            os.remove(tmp_path)\n\n    def test_nonexistent_file_raises_file_not_found(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('nonexistent_file.csv', 'date')\n\n    def test_missing_column_raises_value_error(self):\n        with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp:\n            tmp.write('a,b,c\\n1,2,3\\n')\n            tmp_path = tmp.name\n        try:\n            with self.assertRaises(ValueError) as cm:\n                task_func(tmp_path, 'date')\n            self.assertIn(\"Column 'date' not found\", str(cm.exception))\n        finally:\n            os.remove(tmp_path)\n\n    def test_date_parsing_error_raises_value_error(self):\n        with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp:\n            tmp.write('date\\nnot_a_date\\n')\n            tmp_path = tmp.name\n        try:\n            with self.assertRaises(ValueError) as cm:\n                task_func(tmp_path, 'date', date_format=\"%Y-%m-%d\")\n            self.assertIn(\"Error parsing dates\", str(cm.exception))\n        finally:\n            os.remove(tmp_path)\n\n    def test_valid_csv_parses_dates_correctly(self):\n        with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp:\n            tmp.write('date,value\\n2023-01-01,10\\n2023-02-01,20\\n')\n            tmp_path = tmp.name\n        try:\n            df = task_func(tmp_path, 'date', date_format=\"%Y-%m-%d\")\n            self.assertTrue(pd.api.types.is_datetime64_any_dtype(df['date']))\n            self.assertEqual(len(df), 2)\n        finally:\n            os.remove(tmp_path)\n",
        "code": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\n\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    if not os.path.isfile(csv_file_path):\n        raise FileNotFoundError(f\"File not found: {csv_file_path}\")\n    try:\n        df = pd.read_csv(csv_file_path)\n    except EmptyDataError:\n        return pd.DataFrame()\n    if column_name not in df.columns:\n        raise ValueError(f\"Column '{column_name}' not found in CSV\")\n    # Try to parse the column as datetime using the given date_format\n    try:\n        df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n    except Exception as e:\n        raise ValueError(f\"Error parsing dates in column '{column_name}': {e}\")\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1022_4",
        "turn": "4",
        "instruct_prompt": "Add a check that the specified column_name exists in the DataFrame's columns. If the column is missing, raise a ValueError with a clear message.",
        "test": "import unittest\nimport pandas as pd\nimport os\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.temp_files = []\n\n    def tearDown(self):\n        for f in self.temp_files:\n            try:\n                os.remove(f.name)\n            except Exception:\n                pass\n\n    def create_temp_csv(self, content):\n        temp_file = NamedTemporaryFile(mode='w', delete=False, suffix='.csv')\n        temp_file.write(content)\n        temp_file.flush()\n        self.temp_files.append(temp_file)\n        return temp_file.name\n\n    def test_column_missing_raises_value_error(self):\n        csv_content = \"id,name,age\\n1,Alice,30\\n2,Bob,25\"\n        csv_path = self.create_temp_csv(csv_content)\n        with self.assertRaises(ValueError) as cm:\n            task_func(csv_path, 'missing_column')\n        # Check that the error message matches the new format\n        self.assertTrue(str(cm.exception).startswith(\"Missing column:\"))\n\n    def test_column_exists_parsing_success(self):\n        csv_content = \"id,date\\n1,2023-01-01\\n2,2023-01-02\"\n        csv_path = self.create_temp_csv(csv_content)\n        df = task_func(csv_path, 'date')\n        self.assertIn('date', df.columns)\n        self.assertTrue(pd.api.types.is_datetime64_any_dtype(df['date']))\n\n    def test_file_not_found(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('non_existing_file.csv', 'date')\n\n    def test_empty_csv_returns_empty_df(self):\n        csv_path = self.create_temp_csv(\"\")\n        df = task_func(csv_path, 'any_column')\n        self.assertTrue(df.empty)\n\n    def test_date_parsing_error_raises_value_error(self):\n        csv_content = \"id,date\\n1,not_a_date\\n2,2023-01-02\"\n        csv_path = self.create_temp_csv(csv_content)\n        with self.assertRaises(ValueError) as cm:\n            task_func(csv_path, 'date', date_format=\"%Y-%m-%d\")\n        self.assertIn(\"Error parsing dates in column 'date'\", str(cm.exception))\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\n\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    if not os.path.isfile(csv_file_path):\n        raise FileNotFoundError(f\"File not found: {csv_file_path}\")\n    try:\n        df = pd.read_csv(csv_file_path)\n    except EmptyDataError:\n        return pd.DataFrame()\n    if column_name not in df.columns:\n        # Changed error message to differentiate from previous rounds\n        raise ValueError(f\"Missing column: '{column_name}' in CSV file\")\n    try:\n        df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n    except Exception as e:\n        raise ValueError(f\"Error parsing dates in column '{column_name}': {e}\")\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1022_5",
        "turn": "5",
        "instruct_prompt": "Convert the values in the specified column_name to datetime objects using the given date_format. Then filter the DataFrame to only include rows where the date in that column is greater than or equal to the current date (based on datetime.now()). Finally, sort the filtered DataFrame by the date column in ascending order and return it.",
        "test": "import unittest\nimport pandas as pd\nimport tempfile\nimport os\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.temp_files = []\n\n    def tearDown(self):\n        for f in self.temp_files:\n            if os.path.exists(f):\n                os.remove(f)\n\n    def _write_csv(self, content):\n        tmp_file = tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.csv')\n        tmp_file.write(content)\n        tmp_file.close()\n        self.temp_files.append(tmp_file.name)\n        return tmp_file.name\n\n    def test_filter_and_sort_dates(self):\n        now = datetime.now()\n        past_date = (now - timedelta(days=2)).strftime('%Y-%m-%d')\n        future_date1 = (now + timedelta(days=1)).strftime('%Y-%m-%d')\n        future_date2 = (now + timedelta(days=3)).strftime('%Y-%m-%d')\n\n        csv_content = f\"\"\"id,date\n1,{past_date}\n2,{future_date2}\n3,{future_date1}\n\"\"\"\n        csv_path = self._write_csv(csv_content)\n\n        result_df = task_func(csv_path, 'date', '%Y-%m-%d')\n\n        self.assertEqual(len(result_df), 2)\n        self.assertTrue(all(result_df['date'] >= now))\n        self.assertLessEqual(result_df['date'].iloc[0], result_df['date'].iloc[1])\n\n    def test_empty_after_filter(self):\n        now = datetime.now()\n        past_date1 = (now - timedelta(days=5)).strftime('%Y-%m-%d')\n        past_date2 = (now - timedelta(days=1)).strftime('%Y-%m-%d')\n\n        csv_content = f\"\"\"id,date\n1,{past_date1}\n2,{past_date2}\n\"\"\"\n        csv_path = self._write_csv(csv_content)\n\n        result_df = task_func(csv_path, 'date', '%Y-%m-%d')\n\n        self.assertTrue(result_df.empty)\n\n    def test_invalid_date_format(self):\n        csv_content = \"id,date\\n1,2023/01/01\\n2,2023/02/02\\n\"\n        csv_path = self._write_csv(csv_content)\n\n        with self.assertRaises(ValueError) as context:\n            task_func(csv_path, 'date', '%Y-%m-%d')\n        self.assertIn('Error parsing dates', str(context.exception))\n\n    def test_missing_column(self):\n        csv_content = \"id,name\\n1,Alice\\n2,Bob\\n\"\n        csv_path = self._write_csv(csv_content)\n\n        with self.assertRaises(ValueError) as context:\n            task_func(csv_path, 'date', '%Y-%m-%d')\n        self.assertIn(\"Missing column\", str(context.exception))\n\n    def test_file_not_found(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('non_existent_file.csv', 'date')\n",
        "code": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\n\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    if not os.path.isfile(csv_file_path):\n        raise FileNotFoundError(f\"File not found: {csv_file_path}\")\n    try:\n        df = pd.read_csv(csv_file_path)\n    except EmptyDataError:\n        return pd.DataFrame()\n    if column_name not in df.columns:\n        raise ValueError(f\"Missing column: '{column_name}' in CSV file\")\n    try:\n        df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n    except Exception as e:\n        raise ValueError(f\"Error parsing dates in column '{column_name}': {e}\")\n\n    now = datetime.now()\n    df_filtered = df[df[column_name] >= now]\n    df_sorted = df_filtered.sort_values(by=column_name, ascending=True).reset_index(drop=True)\n    return df_sorted\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 139,
    "task_id": "BigCodeBench/1039",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1039_1",
        "turn": "1",
        "instruct_prompt": "Write a function that reads a file path sent by a client through a socket and returns the SHA256 hash of the file content if the file exists, or 'File not found' otherwise. You should write self-contained code starting with:\n```python\nimport os\nimport hashlib\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n```",
        "test": "import unittest\nimport socket\nimport tempfile\nimport os\nimport hashlib\n\nclass DummySocket:\n    def __init__(self, data_chunks):\n        self.data_chunks = data_chunks\n        self.index = 0\n    def recv(self, buffer_size):\n        if self.index < len(self.data_chunks):\n            chunk = self.data_chunks[self.index]\n            self.index += 1\n            return chunk\n        else:\n            return b''\n\nclass TestCases(unittest.TestCase):\n    def test_file_exists(self):\n        # Create a temporary file with known content\n        with tempfile.NamedTemporaryFile(delete=False) as tmp:\n            tmp.write(b'Test content for hashing')\n            tmp_path = tmp.name\n\n        # Compute expected SHA256\n        expected_hash = hashlib.sha256(b'Test content for hashing').hexdigest()\n\n        # Prepare dummy socket to send file path\n        dummy_socket = DummySocket([tmp_path.encode('utf-8') + b'\\n'])\n\n        # Call task_func\n        result = task_func(dummy_socket, None, None)\n\n        # Clean up\n        os.unlink(tmp_path)\n\n        self.assertEqual(result, expected_hash)\n\n    def test_file_not_found(self):\n        non_existent_path = '/path/to/nonexistent/file.txt'\n        dummy_socket = DummySocket([non_existent_path.encode('utf-8') + b'\\n'])\n        result = task_func(dummy_socket, None, None)\n        self.assertEqual(result, 'File not found')\n",
        "code": "import os\nimport hashlib\n\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    # Receive file path from client\n    file_path = b''\n    while True:\n        chunk = client_socket.recv(buffer_size)\n        if not chunk:\n            break\n        file_path += chunk\n        if b'\\n' in chunk:\n            break\n    file_path = file_path.strip().decode('utf-8')\n\n    if not os.path.isfile(file_path):\n        return 'File not found'\n\n    sha256_hash = hashlib.sha256()\n    with open(file_path, 'rb') as f:\n        for chunk in iter(lambda: f.read(buffer_size), b''):\n            sha256_hash.update(chunk)\n    return sha256_hash.hexdigest()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1039_2",
        "turn": "2",
        "instruct_prompt": "Secure the client socket using SSL/TLS with the provided certificate and key files before receiving the file path from the client.",
        "test": "import unittest\nimport socket\nimport threading\nimport ssl\nimport tempfile\nimport os\nfrom hashlib import sha256\nfrom cryptography import x509\nfrom cryptography.x509.oid import NameOID\nfrom cryptography.hazmat.primitives import hashes, serialization\nfrom cryptography.hazmat.primitives.asymmetric import rsa\nfrom cryptography.hazmat.backends import default_backend\nfrom datetime import datetime, timedelta\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Generate self-signed certificate and key for testing\n        key = rsa.generate_private_key(\n            public_exponent=65537,\n            key_size=2048,\n            backend=default_backend()\n        )\n\n        subject = issuer = x509.Name([\n            x509.NameAttribute(NameOID.COUNTRY_NAME, u\"US\"),\n            x509.NameAttribute(NameOID.STATE_OR_PROVINCE_NAME, u\"California\"),\n            x509.NameAttribute(NameOID.LOCALITY_NAME, u\"San Francisco\"),\n            x509.NameAttribute(NameOID.ORGANIZATION_NAME, u\"Test Org\"),\n            x509.NameAttribute(NameOID.COMMON_NAME, u\"localhost\"),\n        ])\n\n        cert = x509.CertificateBuilder().subject_name(\n            subject\n        ).issuer_name(\n            issuer\n        ).public_key(\n            key.public_key()\n        ).serial_number(\n            x509.random_serial_number()\n        ).not_valid_before(\n            datetime.utcnow() - timedelta(days=1)\n        ).not_valid_after(\n            datetime.utcnow() + timedelta(days=10)\n        ).add_extension(\n            x509.SubjectAlternativeName([x509.DNSName(u\"localhost\")]),\n            critical=False,\n        ).sign(key, hashes.SHA256(), default_backend())\n\n        # Write key and cert to temp files\n        self.keyfile = tempfile.NamedTemporaryFile(delete=False)\n        self.certfile = tempfile.NamedTemporaryFile(delete=False)\n\n        self.keyfile.write(\n            key.private_bytes(\n                encoding=serialization.Encoding.PEM,\n                format=serialization.PrivateFormat.TraditionalOpenSSL,\n                encryption_algorithm=serialization.NoEncryption()\n            )\n        )\n        self.keyfile.close()\n\n        self.certfile.write(\n            cert.public_bytes(serialization.Encoding.PEM)\n        )\n        self.certfile.close()\n\n        # Create a temporary file for testing\n        self.test_file = tempfile.NamedTemporaryFile(delete=False)\n        self.test_file.write(b\"hello world\")\n        self.test_file.close()\n\n    def tearDown(self):\n        os.unlink(self.keyfile.name)\n        os.unlink(self.certfile.name)\n        os.unlink(self.test_file.name)\n\n    def test_ssl_wrap_and_file_hash(self):\n        server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        server_socket.bind(('localhost', 0))\n        server_socket.listen(1)\n        port = server_socket.getsockname()[1]\n\n        result_container = {}\n\n        def server_task(task_func_ref):\n            try:\n                client_sock, _ = server_socket.accept()\n                context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n                context.load_cert_chain(certfile=self.certfile.name, keyfile=self.keyfile.name)\n                ssl_client_sock = context.wrap_socket(client_sock, server_side=True)\n\n                result = None\n                try:\n                    result = task_func_ref(ssl_client_sock)\n                except Exception as e:\n                    result = f'Error: {e}'\n\n                ssl_client_sock.close()\n            except Exception as e:\n                result_container['result'] = f'Error: {e}'\n            else:\n                result_container['result'] = result\n            finally:\n                server_socket.close()\n\n        server_thread = threading.Thread(target=server_task, args=(task_func,))\n        server_thread.start()\n\n        client_context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n        client_context.check_hostname = False\n        client_context.verify_mode = ssl.CERT_NONE\n\n        client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        ssl_client_sock = client_context.wrap_socket(client_sock, server_hostname='localhost')\n        ssl_client_sock.connect(('localhost', port))\n\n        ssl_client_sock.sendall((self.test_file.name + '\\n').encode('utf-8'))\n\n        ssl_client_sock.close()\n\n        server_thread.join()\n\n        with open(self.test_file.name, 'rb') as f:\n            expected_hash = sha256(f.read()).hexdigest()\n\n        self.assertIn('result', result_container)\n        self.assertEqual(result_container['result'], expected_hash)\n\n    def test_ssl_wrap_and_file_not_found(self):\n        server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        server_socket.bind(('localhost', 0))\n        server_socket.listen(1)\n        port = server_socket.getsockname()[1]\n\n        result_container = {}\n\n        def server_task(task_func_ref):\n            try:\n                client_sock, _ = server_socket.accept()\n                context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n                context.load_cert_chain(certfile=self.certfile.name, keyfile=self.keyfile.name)\n                ssl_client_sock = context.wrap_socket(client_sock, server_side=True)\n\n                result = None\n                try:\n                    result = task_func_ref(ssl_client_sock)\n                except Exception as e:\n                    result = f'Error: {e}'\n\n                ssl_client_sock.close()\n            except Exception as e:\n                result_container['result'] = f'Error: {e}'\n            else:\n                result_container['result'] = result\n            finally:\n                server_socket.close()\n\n        server_thread = threading.Thread(target=server_task, args=(task_func,))\n        server_thread.start()\n\n        client_context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n        client_context.check_hostname = False\n        client_context.verify_mode = ssl.CERT_NONE\n\n        client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        ssl_client_sock = client_context.wrap_socket(client_sock, server_hostname='localhost')\n        ssl_client_sock.connect(('localhost', port))\n\n        ssl_client_sock.sendall(b'/non/existent/file/path\\n')\n\n        ssl_client_sock.close()\n\n        server_thread.join()\n\n        self.assertIn('result', result_container)\n        self.assertEqual(result_container['result'], 'File not found')\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import os\nimport hashlib\n\ndef task_func(client_socket, buffer_size=1024):\n    # Receive file path from client over the secured socket\n    file_path = b''\n    while True:\n        chunk = client_socket.recv(buffer_size)\n        if not chunk:\n            break\n        file_path += chunk\n        if b'\\n' in chunk:\n            break\n    file_path = file_path.strip().decode('utf-8')\n\n    if not os.path.isfile(file_path):\n        return 'File not found'\n\n    sha256_hash = hashlib.sha256()\n    with open(file_path, 'rb') as f:\n        for chunk in iter(lambda: f.read(buffer_size), b''):\n            sha256_hash.update(chunk)\n\n    return sha256_hash.hexdigest()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1039_3",
        "turn": "3",
        "instruct_prompt": "Send the resulting SHA256 hash or 'File not found' message back to the client through the secured socket.",
        "test": "import unittest\nimport tempfile\nimport os\nimport hashlib\nfrom io import BytesIO\n\nclass DummySocket:\n    def __init__(self, recv_data):\n        self._recv_buffer = BytesIO(recv_data)\n        self._sent_data = b''\n\n    def recv(self, buffer_size):\n        return self._recv_buffer.read(buffer_size)\n\n    def sendall(self, data):\n        self._sent_data += data\n\n    def get_sent_data(self):\n        return self._sent_data\n\nclass TestCases(unittest.TestCase):\n    def test_send_hash_for_existing_file(self):\n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n            tmp_file.write(b'hello world')\n            tmp_file_path = tmp_file.name\n        try:\n            dummy_socket = DummySocket((tmp_file_path + '\\n').encode('utf-8'))\n\n            # Directly call task_func without import\n            task_func(dummy_socket)\n\n            expected_hash = hashlib.sha256(b'hello world').hexdigest().encode('utf-8')\n            self.assertEqual(dummy_socket.get_sent_data(), expected_hash)\n        finally:\n            os.remove(tmp_file_path)\n\n    def test_send_file_not_found_for_nonexistent_file(self):\n        non_exist_path = '/path/to/nonexistent/file.txt'\n        dummy_socket = DummySocket((non_exist_path + '\\n').encode('utf-8'))\n\n        # Directly call task_func without import\n        task_func(dummy_socket)\n\n        self.assertEqual(dummy_socket.get_sent_data(), b'File not found')\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "code": "import os\nimport hashlib\n\ndef task_func(client_socket, buffer_size=1024):\n    # Receive file path from client over the secured socket\n    file_path = b''\n    while True:\n        chunk = client_socket.recv(buffer_size)\n        if not chunk:\n            break\n        file_path += chunk\n        if b'\\n' in chunk:\n            break\n    file_path = file_path.strip().decode('utf-8')\n\n    if not os.path.isfile(file_path):\n        client_socket.sendall(b'File not found')\n        return\n\n    sha256_hash = hashlib.sha256()\n    with open(file_path, 'rb') as f:\n        for chunk in iter(lambda: f.read(buffer_size), b''):\n            sha256_hash.update(chunk)\n\n    client_socket.sendall(sha256_hash.hexdigest().encode('utf-8'))\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1039_4",
        "turn": "4",
        "instruct_prompt": "Add basic error handling that catches exceptions during processing and returns an error message string instead of raising exceptions.",
        "test": "import unittest\nfrom unittest.mock import MagicMock\nimport builtins\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary file for testing\n        self.temp_file = tempfile.NamedTemporaryFile(delete=False)\n        self.temp_file.write(b'Test content for hashing')\n        self.temp_file.flush()\n        self.temp_file.close()\n\n    def tearDown(self):\n        # Remove the temporary file\n        os.unlink(self.temp_file.name)\n\n    def test_send_correct_hash(self):\n        # Setup mock socket\n        mock_socket = MagicMock()\n\n        # Simulate recv to return file path with newline, then empty bytes\n        mock_socket.recv = MagicMock(side_effect=[self.temp_file.name.encode('utf-8') + b'\\n', b''])\n\n        # Call the function\n        task_func(mock_socket)\n\n        # Calculate expected hash\n        import hashlib\n        expected_hash = hashlib.sha256(b'Test content for hashing').hexdigest().encode('utf-8')\n\n        # Check sendall called with expected hash\n        mock_socket.sendall.assert_called_with(expected_hash)\n\n    def test_file_not_found(self):\n        mock_socket = MagicMock()\n        fake_path = '/non/existent/file/path.txt'\n        mock_socket.recv = MagicMock(side_effect=[fake_path.encode('utf-8') + b'\\n', b''])\n\n        task_func(mock_socket)\n\n        mock_socket.sendall.assert_called_with(b'File not found')\n\n    def test_error_handling_on_recv_exception(self):\n        mock_socket = MagicMock()\n        # Simulate recv raising an exception\n        mock_socket.recv = MagicMock(side_effect=Exception('recv error'))\n        mock_socket.sendall = MagicMock()\n\n        task_func(mock_socket)\n\n        # It should send an error message containing 'recv error'\n        args, _ = mock_socket.sendall.call_args\n        self.assertIn(b'Error: recv error', args[0])\n\n    def test_error_handling_on_file_open_exception(self):\n        mock_socket = MagicMock()\n        # Provide a valid path but patch open to raise an exception\n        mock_socket.recv = MagicMock(side_effect=[self.temp_file.name.encode('utf-8') + b'\\n', b''])\n\n        original_open = open\n\n        def open_raiser(*args, **kwargs):\n            raise IOError('file open error')\n\n        try:\n            # Patch open to raise error\n            builtins.open = open_raiser\n            mock_socket.sendall = MagicMock()\n\n            task_func(mock_socket)\n\n            args, _ = mock_socket.sendall.call_args\n            self.assertIn(b'Error: file open error', args[0])\n        finally:\n            builtins.open = original_open\n\n    def test_error_handling_on_sendall_exception(self):\n        mock_socket = MagicMock()\n        # Simulate recv raising an exception\n        mock_socket.recv = MagicMock(side_effect=Exception('recv error'))\n        # Simulate sendall raising exception when sending error message\n        mock_socket.sendall = MagicMock(side_effect=Exception('sendall error'))\n\n        # Should not raise despite sendall failing\n        try:\n            task_func(mock_socket)\n        except Exception:\n            self.fail('task_func raised Exception unexpectedly when sendall failed')\n",
        "code": "import os\nimport hashlib\n\ndef task_func(client_socket, buffer_size=1024):\n    try:\n        # Receive file path from client over the secured socket\n        file_path = b''\n        while True:\n            chunk = client_socket.recv(buffer_size)\n            if not chunk:\n                break\n            file_path += chunk\n            if b'\\n' in chunk:\n                break\n        file_path = file_path.strip().decode('utf-8')\n\n        if not os.path.isfile(file_path):\n            client_socket.sendall(b'File not found')\n            return\n\n        sha256_hash = hashlib.sha256()\n        with open(file_path, 'rb') as f:\n            for chunk in iter(lambda: f.read(buffer_size), b''):\n                sha256_hash.update(chunk)\n\n        client_socket.sendall(sha256_hash.hexdigest().encode('utf-8'))\n\n    except Exception as e:\n        error_message = f'Error: {str(e)}'\n        try:\n            client_socket.sendall(error_message.encode('utf-8'))\n        except Exception:\n            # If sending error message fails, silently pass\n            pass\n        return\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1039_5",
        "turn": "5",
        "instruct_prompt": "Ensure that the secured socket is properly closed after the operation completes, regardless of success or failure.",
        "test": "import unittest\nimport socket\nimport tempfile\nimport os\nfrom threading import Thread\nimport time\n\n# Import the task_func from the solution\n# Since we are in a single block, assume task_func is defined above\n\nclass DummyClientSocket:\n    def __init__(self, inputs):\n        self._inputs = inputs  # list of bytes to return on recv calls\n        self._recv_calls = 0\n        self.sent_data = b''\n        self.closed = False\n\n    def recv(self, buffer_size):\n        if self._recv_calls < len(self._inputs):\n            data = self._inputs[self._recv_calls]\n            self._recv_calls += 1\n            return data\n        return b''\n\n    def sendall(self, data):\n        self.sent_data += data\n\n    def close(self):\n        self.closed = True\n\nclass TestCases(unittest.TestCase):\n    def test_socket_closed_after_success(self):\n        # Create a temporary file with known content\n        with tempfile.NamedTemporaryFile(delete=False) as tmp:\n            tmp.write(b\"hello world\")\n            tmp_path = tmp.name\n\n        # Prepare input to send the file path followed by newline\n        input_bytes = [tmp_path.encode('utf-8') + b'\\n']\n        dummy_socket = DummyClientSocket(input_bytes)\n\n        task_func(dummy_socket)\n\n        # Check that the socket is closed\n        self.assertTrue(dummy_socket.closed)\n\n        # Check that the sent data is the SHA256 of \"hello world\"\n        import hashlib\n        expected_hash = hashlib.sha256(b\"hello world\").hexdigest().encode('utf-8')\n        self.assertEqual(dummy_socket.sent_data, expected_hash)\n\n        os.remove(tmp_path)\n\n    def test_socket_closed_after_file_not_found(self):\n        input_bytes = [b'/non/existent/file/path\\n']\n        dummy_socket = DummyClientSocket(input_bytes)\n\n        task_func(dummy_socket)\n\n        self.assertTrue(dummy_socket.closed)\n        self.assertEqual(dummy_socket.sent_data, b'File not found')\n\n    def test_socket_closed_after_exception_in_send(self):\n        # This dummy socket raises exception on sendall\n        class BadSendSocket(DummyClientSocket):\n            def sendall(self, data):\n                raise RuntimeError(\"sendall failed\")\n\n        with tempfile.NamedTemporaryFile(delete=False) as tmp:\n            tmp.write(b'test')\n            tmp_path = tmp.name\n\n        input_bytes = [tmp_path.encode('utf-8') + b'\\n']\n        bad_socket = BadSendSocket(input_bytes)\n\n        task_func(bad_socket)\n\n        self.assertTrue(bad_socket.closed)\n\n        os.remove(tmp_path)\n\n    def test_socket_closed_after_exception_in_recv(self):\n        # This dummy socket raises exception on recv\n        class BadRecvSocket(DummyClientSocket):\n            def recv(self, buffer_size):\n                raise RuntimeError(\"recv failed\")\n\n        bad_socket = BadRecvSocket([])\n\n        task_func(bad_socket)\n\n        self.assertTrue(bad_socket.closed)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import os\nimport hashlib\n\ndef task_func(client_socket, buffer_size=1024):\n    try:\n        # Receive file path from client over the secured socket\n        file_path = b''\n        while True:\n            chunk = client_socket.recv(buffer_size)\n            if not chunk:\n                break\n            file_path += chunk\n            if b'\\n' in chunk:\n                break\n        file_path = file_path.strip().decode('utf-8')\n\n        if not os.path.isfile(file_path):\n            client_socket.sendall(b'File not found')\n            return\n\n        sha256_hash = hashlib.sha256()\n        with open(file_path, 'rb') as f:\n            for chunk in iter(lambda: f.read(buffer_size), b''):\n                sha256_hash.update(chunk)\n\n        client_socket.sendall(sha256_hash.hexdigest().encode('utf-8'))\n\n    except Exception as e:\n        error_message = f'Error: {str(e)}'\n        try:\n            client_socket.sendall(error_message.encode('utf-8'))\n        except Exception:\n            # If sending error message fails, silently pass\n            pass\n    finally:\n        try:\n            client_socket.close()\n        except Exception:\n            pass\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 140,
    "task_id": "BigCodeBench/1040",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1040_1",
        "turn": "1",
        "instruct_prompt": "Write a basic TCP echo server that receives data from clients and sends the same data back to them. You should write self-contained code starting with:\n```\nimport socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n```",
        "test": "import unittest\nimport threading\nimport socket\nimport time\nfrom contextlib import closing\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.server_address = '127.0.0.1'\n        self.server_port = 23456\n        self.buffer_size = 1024\n        self.run_duration = 2\n        self.server_thread = threading.Thread(\n            target=task_func,\n            kwargs={\n                'server_address': self.server_address,\n                'server_port': self.server_port,\n                'buffer_size': self.buffer_size,\n                'run_duration': self.run_duration\n            },\n            daemon=True\n        )\n        self.server_thread.start()\n        # Wait a bit for the server to start\n        time.sleep(0.2)\n\n    def tearDown(self):\n        # Wait for server to finish\n        self.server_thread.join(timeout=self.run_duration + 1)\n\n    def test_echo(self):\n        with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:\n            sock.settimeout(1)\n            sock.connect((self.server_address, self.server_port))\n            test_data = b'hello, echo!'\n            sock.sendall(test_data)\n            received = b''\n            while len(received) < len(test_data):\n                chunk = sock.recv(self.buffer_size)\n                if not chunk:\n                    break\n                received += chunk\n            self.assertEqual(received, test_data)\n\n    def test_multiple_clients(self):\n        clients = []\n        num_clients = 3\n        test_datas = [f\"msg{i}\".encode() for i in range(num_clients)]\n        responses = [b'' for _ in range(num_clients)]\n        try:\n            for i in range(num_clients):\n                s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                s.settimeout(1)\n                s.connect((self.server_address, self.server_port))\n                clients.append(s)\n            for i, s in enumerate(clients):\n                s.sendall(test_datas[i])\n            for i, s in enumerate(clients):\n                while len(responses[i]) < len(test_datas[i]):\n                    chunk = s.recv(self.buffer_size)\n                    if not chunk:\n                        break\n                    responses[i] += chunk\n                self.assertEqual(responses[i], test_datas[i])\n        finally:\n            for s in clients:\n                s.close()\n",
        "code": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    \"\"\"\n    Basic TCP echo server. Listens on server_address:server_port, echoes received data.\n    Runs for run_duration seconds then stops.\n    \"\"\"\n    server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_sock.bind((server_address, server_port))\n    server_sock.listen(5)\n    server_sock.setblocking(False)\n\n    inputs = [server_sock]\n    outputs = []\n    message_queues = {}\n\n    end_time = datetime.now() + timedelta(seconds=run_duration)\n\n    while datetime.now() < end_time:\n        readable, writable, exceptional = select.select(inputs, outputs, inputs, 0.5)\n        for s in readable:\n            if s is server_sock:\n                client_sock, addr = s.accept()\n                client_sock.setblocking(False)\n                inputs.append(client_sock)\n                message_queues[client_sock] = queue.Queue()\n            else:\n                data = s.recv(buffer_size)\n                if data:\n                    message_queues[s].put(data)\n                    if s not in outputs:\n                        outputs.append(s)\n                else:\n                    if s in outputs:\n                        outputs.remove(s)\n                    inputs.remove(s)\n                    s.close()\n                    del message_queues[s]\n        for s in writable:\n            try:\n                next_msg = message_queues[s].get_nowait()\n            except queue.Empty:\n                outputs.remove(s)\n            else:\n                s.send(next_msg)\n        for s in exceptional:\n            if s in outputs:\n                outputs.remove(s)\n            if s in inputs:\n                inputs.remove(s)\n            s.close()\n            if s in message_queues:\n                del message_queues[s]\n    # Cleanup\n    for s in inputs:\n        s.close()\n    for s in outputs:\n        s.close()\n    server_sock.close()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1040_2",
        "turn": "2",
        "instruct_prompt": "Make the echo server non-blocking and able to handle multiple clients simultaneously using select.",
        "test": "import unittest\nimport socket\nimport threading\nimport time\nfrom contextlib import closing\n\ndef run_server_in_thread(*args, **kwargs):\n    t = threading.Thread(target=task_func, args=args, kwargs=kwargs)\n    t.daemon = True\n    t.start()\n    return t\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.server_address = 'localhost'\n        self.server_port = 12402\n        self.buffer_size = 1024\n        self.run_duration = 4\n        self.server_thread = run_server_in_thread(\n            self.server_address, self.server_port, self.buffer_size, self.run_duration\n        )\n        time.sleep(0.3)\n\n    def tearDown(self):\n        self.server_thread.join(timeout=6)\n\n    def test_nonblocking_multi_client_with_slow_client(self):\n        # One slow client holds connection open, two fast clients send/receive quickly\n        ready = threading.Event()\n        results = {}\n        slow_started = threading.Event()\n        # Slow client: connects, does not send, holds for 3s\n        def slow_client():\n            with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:\n                s.settimeout(1)\n                s.connect((self.server_address, self.server_port))\n                slow_started.set()\n                ready.wait(timeout=2)\n                time.sleep(3.0)\n        # Fast clients: connect, send, expect echo very quickly\n        def fast_client(idx):\n            slow_started.wait(timeout=2)\n            with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:\n                s.settimeout(0.4)\n                s.connect((self.server_address, self.server_port))\n                t0 = time.time()\n                msg = f'fast{idx}'.encode()\n                s.sendall(msg)\n                total_data = b''\n                for _ in range(8):\n                    try:\n                        data = s.recv(1024)\n                        if data:\n                            total_data += data\n                            break\n                    except socket.timeout:\n                        pass\n                    time.sleep(0.02)\n                t1 = time.time()\n                results[f'echo{idx}'] = total_data\n                results[f'elapsed{idx}'] = t1 - t0\n        t1 = threading.Thread(target=slow_client)\n        t2 = threading.Thread(target=fast_client, args=(1,))\n        t3 = threading.Thread(target=fast_client, args=(2,))\n        t1.start()\n        t2.start()\n        t3.start()\n        slow_started.wait(timeout=2)\n        ready.set()  # Allow fast clients to proceed\n        t1.join()\n        t2.join()\n        t3.join()\n        # If server is blocking, echo will be None or elapsed will be high\n        self.assertEqual(results['echo1'], b'fast1', msg='Echo1 not received (likely blocking server)')\n        self.assertEqual(results['echo2'], b'fast2', msg='Echo2 not received (likely blocking server)')\n        # If server is blocking, elapsed will be >2s\n        self.assertLess(results['elapsed1'], 0.5, msg='Echo1 took too long (likely blocking server)')\n        self.assertLess(results['elapsed2'], 0.5, msg='Echo2 took too long (likely blocking server)')\n\n    def test_echo_many_clients_parallel(self):\n        # 8 clients send and receive in parallel\n        num_clients = 8\n        results = [None] * num_clients\n        def client(idx):\n            with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:\n                s.settimeout(0.5)\n                s.connect((self.server_address, self.server_port))\n                msg = f'client{idx}'.encode()\n                s.sendall(msg)\n                total_data = b''\n                for _ in range(8):\n                    try:\n                        data = s.recv(1024)\n                        if data:\n                            total_data += data\n                            break\n                    except socket.timeout:\n                        pass\n                    time.sleep(0.02)\n                results[idx] = total_data\n        threads = [threading.Thread(target=client, args=(i,)) for i in range(num_clients)]\n        for t in threads:\n            t.start()\n        for t in threads:\n            t.join()\n        for i in range(num_clients):\n            self.assertEqual(results[i], f'client{i}'.encode())\n",
        "code": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    \"\"\"\n    Non-blocking TCP echo server using select. Handles multiple clients simultaneously.\n    Listens on server_address:server_port, echoes received data.\n    Runs for run_duration seconds then stops.\n    \"\"\"\n    server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_sock.bind((server_address, server_port))\n    server_sock.listen(5)\n    server_sock.setblocking(False)\n\n    inputs = [server_sock]\n    outputs = []\n    message_queues = {}\n    to_close = set()\n\n    end_time = datetime.now() + timedelta(seconds=run_duration)\n\n    while datetime.now() < end_time:\n        try:\n            readable, writable, exceptional = select.select(inputs, outputs, inputs, 0.2)\n        except ValueError:\n            break\n        for s in readable:\n            if s is server_sock:\n                try:\n                    client_sock, addr = s.accept()\n                    client_sock.setblocking(False)\n                    inputs.append(client_sock)\n                    message_queues[client_sock] = queue.Queue()\n                except BlockingIOError:\n                    continue\n            else:\n                try:\n                    data = s.recv(buffer_size)\n                except BlockingIOError:\n                    continue\n                if data:\n                    message_queues[s].put(data)\n                    if s not in outputs:\n                        outputs.append(s)\n                else:\n                    if s in inputs:\n                        inputs.remove(s)\n                    to_close.add(s)\n        for s in writable:\n            try:\n                next_msg = message_queues[s].get_nowait()\n            except queue.Empty:\n                if s in outputs:\n                    outputs.remove(s)\n                if s in to_close:\n                    if s in outputs:\n                        outputs.remove(s)\n                    s.close()\n                    if s in message_queues:\n                        del message_queues[s]\n                    to_close.discard(s)\n            else:\n                try:\n                    sent = s.send(next_msg)\n                    if sent < len(next_msg):\n                        message_queues[s].put(next_msg[sent:])\n                except BlockingIOError:\n                    message_queues[s].put(next_msg)\n                    continue\n        for s in exceptional:\n            if s in outputs:\n                outputs.remove(s)\n            if s in inputs:\n                inputs.remove(s)\n            s.close()\n            if s in message_queues:\n                del message_queues[s]\n            to_close.discard(s)\n    # Cleanup\n    for s in inputs:\n        try:\n            s.close()\n        except Exception:\n            pass\n    for s in outputs:\n        try:\n            s.close()\n        except Exception:\n            pass\n    try:\n        server_sock.close()\n    except Exception:\n        pass\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1040_3",
        "turn": "3",
        "instruct_prompt": "Modify the server so that it appends the server's current time to the received data before sending it back to the client.",
        "test": "import unittest\nimport socket\nimport threading\nimport time\nfrom datetime import datetime\nimport re\n\nfrom contextlib import closing\n\ndef find_free_port():\n    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:\n        s.bind((\"localhost\", 0))\n        return s.getsockname()[1]\n\nclass TestCases(unittest.TestCase):\n    def test_echo_with_time_appended(self):\n        import sys\n        # Find a free port\n        port = find_free_port()\n        # Start the server in a thread\n        from time import sleep\n        from types import ModuleType\n        import importlib.util\n        # Import the solution function\n        global task_func\n        try:\n            task_func\n        except NameError:\n            pass # already imported\n        # Start server\n        server_thread = threading.Thread(\n            target=task_func,\n            kwargs={\n                'server_address': 'localhost',\n                'server_port': port,\n                'buffer_size': 1024,\n                'run_duration': 2\n            },\n            daemon=True\n        )\n        server_thread.start()\n        time.sleep(0.2)  # Give server time to start\n        # Connect as client\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as client:\n            client.settimeout(2)\n            client.connect(('localhost', port))\n            msg = 'hello world'\n            client.sendall(msg.encode('utf-8'))\n            data = client.recv(1024)\n            self.assertTrue(data)\n            # Should be 'hello world|<iso8601 time>'\n            parts = data.decode('utf-8').split('|')\n            self.assertEqual(parts[0], msg)\n            # Check if the appended part is a valid ISO8601 time string\n            try:\n                dt = datetime.fromisoformat(parts[1])\n            except Exception:\n                self.fail('Appended part is not a valid ISO8601 datetime string')\n        server_thread.join(3)\n\n    def test_echo_with_non_ascii(self):\n        port = find_free_port()\n        server_thread = threading.Thread(\n            target=task_func,\n            kwargs={\n                'server_address': 'localhost',\n                'server_port': port,\n                'buffer_size': 1024,\n                'run_duration': 2\n            },\n            daemon=True\n        )\n        server_thread.start()\n        time.sleep(0.2)\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as client:\n            client.settimeout(2)\n            client.connect(('localhost', port))\n            msg = ''  # Chinese for Hello, World\n            client.sendall(msg.encode('utf-8'))\n            data = client.recv(1024)\n            self.assertTrue(data)\n            parts = data.decode('utf-8').split('|')\n            self.assertEqual(parts[0], msg)\n            try:\n                dt = datetime.fromisoformat(parts[1])\n            except Exception:\n                self.fail('Appended part is not a valid ISO8601 datetime string')\n        server_thread.join(3)\n",
        "code": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    \"\"\"\n    Non-blocking TCP echo server using select. Handles multiple clients simultaneously.\n    Listens on server_address:server_port, echoes received data with server's current time appended.\n    Runs for run_duration seconds then stops.\n    \"\"\"\n    server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_sock.bind((server_address, server_port))\n    server_sock.listen(5)\n    server_sock.setblocking(False)\n\n    inputs = [server_sock]\n    outputs = []\n    message_queues = {}\n    to_close = set()\n\n    end_time = datetime.now() + timedelta(seconds=run_duration)\n\n    while datetime.now() < end_time:\n        try:\n            readable, writable, exceptional = select.select(inputs, outputs, inputs, 0.2)\n        except ValueError:\n            break\n        for s in readable:\n            if s is server_sock:\n                try:\n                    client_sock, addr = s.accept()\n                    client_sock.setblocking(False)\n                    inputs.append(client_sock)\n                    message_queues[client_sock] = queue.Queue()\n                except BlockingIOError:\n                    continue\n            else:\n                try:\n                    data = s.recv(buffer_size)\n                except BlockingIOError:\n                    continue\n                if data:\n                    # Append server's current time to the received data before echoing\n                    now_str = datetime.now().isoformat()\n                    if isinstance(data, bytes):\n                        try:\n                            data_str = data.decode('utf-8')\n                        except UnicodeDecodeError:\n                            data_str = data.decode('latin1')\n                        appended = (data_str + '|' + now_str).encode('utf-8')\n                    else:\n                        appended = (str(data) + '|' + now_str).encode('utf-8')\n                    message_queues[s].put(appended)\n                    if s not in outputs:\n                        outputs.append(s)\n                else:\n                    if s in inputs:\n                        inputs.remove(s)\n                    to_close.add(s)\n        for s in writable:\n            try:\n                next_msg = message_queues[s].get_nowait()\n            except queue.Empty:\n                if s in outputs:\n                    outputs.remove(s)\n                if s in to_close:\n                    if s in outputs:\n                        outputs.remove(s)\n                    s.close()\n                    if s in message_queues:\n                        del message_queues[s]\n                    to_close.discard(s)\n            else:\n                try:\n                    sent = s.send(next_msg)\n                    if sent < len(next_msg):\n                        message_queues[s].put(next_msg[sent:])\n                except BlockingIOError:\n                    message_queues[s].put(next_msg)\n                    continue\n        for s in exceptional:\n            if s in outputs:\n                outputs.remove(s)\n            if s in inputs:\n                inputs.remove(s)\n            s.close()\n            if s in message_queues:\n                del message_queues[s]\n            to_close.discard(s)\n    # Cleanup\n    for s in inputs:\n        try:\n            s.close()\n        except Exception:\n            pass\n    for s in outputs:\n        try:\n            s.close()\n        except Exception:\n            pass\n    try:\n        server_sock.close()\n    except Exception:\n        pass\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1040_4",
        "turn": "4",
        "instruct_prompt": "Ensure the server handles exceptional conditions for each socket, such as client disconnects or errors, and cleans up resources accordingly.",
        "test": "import unittest\nimport socket\nimport threading\nimport time\n\ndef find_free_port():\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.bind(('localhost', 0))\n    addr, port = s.getsockname()\n    s.close()\n    return port\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        self.server_port = find_free_port()\n        self.server_thread = None\n        self.server_run_time = 3\n        self.server_state = {}\n\n    def start_server(self):\n        self.server_thread = threading.Thread(\n            target=task_func,\n            kwargs={\n                'server_address': 'localhost',\n                'server_port': self.server_port,\n                'buffer_size': 1024,\n                'run_duration': self.server_run_time,\n                'server_state': self.server_state\n            },\n            daemon=True\n        )\n        self.server_thread.start()\n        time.sleep(0.3)\n\n    def test_server_resource_cleanup_on_client_disconnect(self):\n        self.start_server()\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.connect(('localhost', self.server_port))\n        s.sendall(b'hello')\n        data = s.recv(1024)\n        self.assertIn(b'hello', data)\n        # Save the socket fd for later check\n        client_fd = s.fileno()\n        s.close()\n        # Wait for server to process disconnect\n        time.sleep(0.7)\n        # The server_state should not contain the closed socket in any of its lists\n        # (We can't compare by fd directly, but we can check that the number of message_queues is 0)\n        # There should be only the server socket in inputs, and no outputs\n        # (server socket is always present in inputs)\n        # There should be no message_queues left\n        self.assertEqual(len(self.server_state.get('message_queues', [])), 0,\n            msg=f\"Message queues not cleaned up: {self.server_state.get('message_queues')}\")\n        self.assertTrue(all(\n            (getattr(sock, 'family', None) == socket.AF_INET and sock.getsockname()[1] == self.server_port)\n            or getattr(sock, 'family', None) != socket.AF_INET\n            for sock in self.server_state.get('inputs', [])),\n            msg=f\"Unexpected sockets in inputs: {self.server_state.get('inputs')}\")\n        self.assertEqual(len(self.server_state.get('outputs', [])), 0,\n            msg=f\"Outputs not cleaned up: {self.server_state.get('outputs')}\")\n\n    def test_server_resource_cleanup_on_invalid_data(self):\n        self.start_server()\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.connect(('localhost', self.server_port))\n        # Send bytes that can't be decoded as utf-8\n        s.sendall(b'\\xff\\xfe\\xfd\\xfc')\n        data = s.recv(1024)\n        self.assertIn(b'|', data)  # Should still echo with timestamp\n        s.close()\n        time.sleep(0.7)\n        # After disconnect, message_queues should be empty\n        self.assertEqual(len(self.server_state.get('message_queues', [])), 0)\n\n    def tearDown(self):\n        if self.server_thread:\n            self.server_thread.join(timeout=self.server_run_time + 1)\n",
        "code": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\nimport threading\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5, server_state=None\n):\n    \"\"\"\n    Non-blocking TCP echo server using select. Handles multiple clients simultaneously.\n    Listens on server_address:server_port, echoes received data with server's current time appended.\n    Runs for run_duration seconds then stops.\n    Handles exceptional conditions for each socket, such as client disconnects or errors, and cleans up resources accordingly.\n    Optionally updates server_state dict with resource tracking info for testing.\n    \"\"\"\n    server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_sock.bind((server_address, server_port))\n    server_sock.listen(5)\n    server_sock.setblocking(False)\n\n    inputs = [server_sock]\n    outputs = []\n    message_queues = {}\n\n    end_time = datetime.now() + timedelta(seconds=run_duration)\n\n    def update_state():\n        if server_state is not None:\n            server_state['inputs'] = list(inputs)\n            server_state['outputs'] = list(outputs)\n            server_state['message_queues'] = list(message_queues.keys())\n\n    while datetime.now() < end_time:\n        update_state()\n        try:\n            readable, writable, exceptional = select.select(inputs, outputs, inputs, 0.2)\n        except ValueError:\n            break\n        # Handle readable sockets\n        for s in readable:\n            if s is server_sock:\n                try:\n                    client_sock, addr = s.accept()\n                    client_sock.setblocking(False)\n                    inputs.append(client_sock)\n                    message_queues[client_sock] = queue.Queue()\n                except (BlockingIOError, OSError):\n                    continue\n                except Exception:\n                    continue\n            else:\n                try:\n                    data = s.recv(buffer_size)\n                except (BlockingIOError, OSError):\n                    continue\n                except Exception:\n                    # Treat as error/exceptional\n                    if s in inputs:\n                        inputs.remove(s)\n                    if s in outputs:\n                        outputs.remove(s)\n                    try:\n                        s.close()\n                    except Exception:\n                        pass\n                    if s in message_queues:\n                        del message_queues[s]\n                    update_state()\n                    continue\n                if data:\n                    # Append server's current time to the received data before echoing\n                    now_str = datetime.now().isoformat()\n                    if isinstance(data, bytes):\n                        try:\n                            data_str = data.decode('utf-8')\n                        except UnicodeDecodeError:\n                            data_str = data.decode('latin1')\n                        appended = (data_str + '|' + now_str).encode('utf-8')\n                    else:\n                        appended = (str(data) + '|' + now_str).encode('utf-8')\n                    message_queues[s].put(appended)\n                    if s not in outputs:\n                        outputs.append(s)\n                else:\n                    # Client disconnected\n                    if s in inputs:\n                        inputs.remove(s)\n                    if s in outputs:\n                        outputs.remove(s)\n                    try:\n                        s.close()\n                    except Exception:\n                        pass\n                    if s in message_queues:\n                        del message_queues[s]\n                    update_state()\n        # Handle writable sockets\n        for s in writable:\n            try:\n                next_msg = message_queues[s].get_nowait()\n            except queue.Empty:\n                if s in outputs:\n                    outputs.remove(s)\n            else:\n                try:\n                    sent = s.send(next_msg)\n                    if sent < len(next_msg):\n                        message_queues[s].put(next_msg[sent:])\n                except (BlockingIOError, OSError):\n                    message_queues[s].put(next_msg)\n                    continue\n                except Exception:\n                    if s in outputs:\n                        outputs.remove(s)\n                    if s in inputs:\n                        inputs.remove(s)\n                    try:\n                        s.close()\n                    except Exception:\n                        pass\n                    if s in message_queues:\n                        del message_queues[s]\n                    update_state()\n                    continue\n        # Handle exceptional sockets\n        for s in exceptional:\n            if s in outputs:\n                outputs.remove(s)\n            if s in inputs:\n                inputs.remove(s)\n            try:\n                s.close()\n            except Exception:\n                pass\n            if s in message_queues:\n                del message_queues[s]\n            update_state()\n    # Cleanup\n    for s in inputs:\n        try:\n            s.close()\n        except Exception:\n            pass\n    for s in outputs:\n        try:\n            s.close()\n        except Exception:\n            pass\n    try:\n        server_sock.close()\n    except Exception:\n        pass\n    update_state()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1040_5",
        "turn": "5",
        "instruct_prompt": "Return a status message as a string indicating the server's operation and run duration after the server stops.",
        "test": "import unittest\nimport socket\nimport time\nfrom contextlib import closing\n\n# Helper to get a free port\ndef get_free_port():\n    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:\n        s.bind((\"localhost\", 0))\n        return s.getsockname()[1]\n\nclass TestCases(unittest.TestCase):\n    def test_returns_status_message(self):\n        port = get_free_port()\n        run_duration = 1.2\n        start = time.time()\n        result = task_func(server_address='localhost', server_port=port, run_duration=run_duration)\n        end = time.time()\n        # The function must return a string\n        self.assertIsInstance(result, str, \"task_func must return a string status message\")\n        self.assertGreater(len(result.strip()), 0, \"Returned status message must not be empty\")\n        self.assertIn('Server stopped after running for', result, \"Returned message must indicate server stopped and duration\")\n        import re\n        m = re.match(r\"^Server stopped after running for ([0-9]+\\.[0-9]{2}) seconds\\.$\", result.strip())\n        self.assertIsNotNone(m, \"Returned message must match the required format\")\n        reported = float(m.group(1))\n        wall_elapsed = end - start\n        # The reported duration must be at least the requested run_duration\n        self.assertGreaterEqual(reported, run_duration, \"Reported duration must be at least the requested run_duration\")\n        # The reported duration must not be zero or a fixed value\n        self.assertNotEqual(reported, 0.00, \"Reported duration must not be zero!\")\n        self.assertNotEqual(reported, 5.00, \"Reported duration must not be hardcoded!\")\n        # The reported duration must not overshoot wall time by more than 0.2s\n        self.assertLessEqual(reported, wall_elapsed + 0.2, \"Reported duration must not overshoot wall time elapsed\")\n",
        "code": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5, server_state=None\n):\n    \"\"\"\n    Non-blocking TCP echo server using select. Handles multiple clients simultaneously.\n    Listens on server_address:server_port, echoes received data with server's current time appended.\n    Runs for run_duration seconds then stops.\n    Handles exceptional conditions for each socket, such as client disconnects or errors, and cleans up resources accordingly.\n    Optionally updates server_state dict with resource tracking info for testing.\n    Returns a status message as a string indicating the server's operation and run duration after the server stops.\n    \"\"\"\n    server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_sock.bind((server_address, server_port))\n    server_sock.listen(5)\n    server_sock.setblocking(False)\n\n    inputs = [server_sock]\n    outputs = []\n    message_queues = {}\n\n    start_time = datetime.now()\n    end_time = start_time + timedelta(seconds=run_duration)\n\n    def update_state():\n        if server_state is not None:\n            server_state['inputs'] = list(inputs)\n            server_state['outputs'] = list(outputs)\n            server_state['message_queues'] = list(message_queues.keys())\n\n    while datetime.now() < end_time:\n        update_state()\n        try:\n            readable, writable, exceptional = select.select(inputs, outputs, inputs, 0.2)\n        except ValueError:\n            break\n        # Handle readable sockets\n        for s in readable:\n            if s is server_sock:\n                try:\n                    client_sock, addr = s.accept()\n                    client_sock.setblocking(False)\n                    inputs.append(client_sock)\n                    message_queues[client_sock] = queue.Queue()\n                except (BlockingIOError, OSError):\n                    continue\n                except Exception:\n                    continue\n            else:\n                try:\n                    data = s.recv(buffer_size)\n                except (BlockingIOError, OSError):\n                    continue\n                except Exception:\n                    # Treat as error/exceptional\n                    if s in inputs:\n                        inputs.remove(s)\n                    if s in outputs:\n                        outputs.remove(s)\n                    try:\n                        s.close()\n                    except Exception:\n                        pass\n                    if s in message_queues:\n                        del message_queues[s]\n                    update_state()\n                    continue\n                if data:\n                    # Append server's current time to the received data before echoing\n                    now_str = datetime.now().isoformat()\n                    if isinstance(data, bytes):\n                        try:\n                            data_str = data.decode('utf-8')\n                        except UnicodeDecodeError:\n                            data_str = data.decode('latin1')\n                        appended = (data_str + '|' + now_str).encode('utf-8')\n                    else:\n                        appended = (str(data) + '|' + now_str).encode('utf-8')\n                    message_queues[s].put(appended)\n                    if s not in outputs:\n                        outputs.append(s)\n                else:\n                    # Client disconnected\n                    if s in inputs:\n                        inputs.remove(s)\n                    if s in outputs:\n                        outputs.remove(s)\n                    try:\n                        s.close()\n                    except Exception:\n                        pass\n                    if s in message_queues:\n                        del message_queues[s]\n                    update_state()\n        # Handle writable sockets\n        for s in writable:\n            try:\n                next_msg = message_queues[s].get_nowait()\n            except queue.Empty:\n                if s in outputs:\n                    outputs.remove(s)\n            else:\n                try:\n                    sent = s.send(next_msg)\n                    if sent < len(next_msg):\n                        message_queues[s].put(next_msg[sent:])\n                except (BlockingIOError, OSError):\n                    message_queues[s].put(next_msg)\n                    continue\n                except Exception:\n                    if s in outputs:\n                        outputs.remove(s)\n                    if s in inputs:\n                        inputs.remove(s)\n                    try:\n                        s.close()\n                    except Exception:\n                        pass\n                    if s in message_queues:\n                        del message_queues[s]\n                    update_state()\n                    continue\n        # Handle exceptional sockets\n        for s in exceptional:\n            if s in outputs:\n                outputs.remove(s)\n            if s in inputs:\n                inputs.remove(s)\n            try:\n                s.close()\n            except Exception:\n                pass\n            if s in message_queues:\n                del message_queues[s]\n            update_state()\n    # Cleanup\n    for s in inputs:\n        try:\n            s.close()\n        except Exception:\n            pass\n    for s in outputs:\n        try:\n            s.close()\n        except Exception:\n            pass\n    try:\n        server_sock.close()\n    except Exception:\n        pass\n    update_state()\n    actual_duration = (datetime.now() - start_time).total_seconds()\n    return f\"Server stopped after running for {actual_duration:.2f} seconds.\"\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 141,
    "task_id": "BigCodeBench/1042",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1042_1",
        "turn": "1",
        "instruct_prompt": "Receive a message from a client socket and print it. You should write self-contained code starting with:\n```python\nimport getpass\nSERVER_ADDRESS = \"localhost\"\nSERVER_PORT = 25\nBUFFER_SIZE = 1024\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\ndef task_func(client_socket):\n```",
        "test": "import unittest\nfrom unittest.mock import Mock, patch\n\nclass TestCases(unittest.TestCase):\n    @patch('builtins.print')\n    def test_receive_and_print_message(self, mock_print):\n        mock_socket = Mock()\n        message = 'Hello, World!'\n        mock_socket.recv.return_value = message.encode('utf-8')\n        task_func(mock_socket)\n        mock_socket.recv.assert_called_once_with(BUFFER_SIZE)\n        mock_print.assert_called_once_with(message)\n",
        "code": "import getpass\nSERVER_ADDRESS = \"localhost\"\nSERVER_PORT = 25\nBUFFER_SIZE = 1024\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\ndef task_func(client_socket):\n    data = client_socket.recv(BUFFER_SIZE)\n    print(data.decode('utf-8'))",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1042_2",
        "turn": "2",
        "instruct_prompt": "After receiving the message, create an EmailMessage object with the received message as the email content. Prompt the user to input the sender's email and recipient's email using getpass.getpass(). Set the email subject to \"Message from socket client\".",
        "test": "import unittest\nfrom unittest.mock import Mock, patch\nfrom email.message import EmailMessage\n\nclass TestCases(unittest.TestCase):\n    @patch('getpass.getpass', side_effect=['sender@example.com', 'recipient@example.com'])\n    def test_email_message_creation(self, mock_getpass):\n        # Prepare a mock socket\n        mock_socket = Mock()\n        test_message = b'Hello, this is a test message.'\n        mock_socket.recv.return_value = test_message\n\n        # Patch print to capture output\n        with patch('builtins.print') as mock_print:\n            task_func(mock_socket)\n            # The EmailMessage object should be printed\n            printed_args = mock_print.call_args[0][0]\n            self.assertIn('Subject: Message from socket client', str(printed_args))\n            self.assertIn('From: sender@example.com', str(printed_args))\n            self.assertIn('To: recipient@example.com', str(printed_args))\n            self.assertIn('Hello, this is a test message.', str(printed_args))\n",
        "code": "import getpass\nfrom email.message import EmailMessage\nSERVER_ADDRESS = \"localhost\"\nSERVER_PORT = 25\nBUFFER_SIZE = 1024\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\n\ndef task_func(client_socket):\n    data = client_socket.recv(BUFFER_SIZE)\n    message_content = data.decode('utf-8')\n    sender = getpass.getpass(prompt='Enter sender email: ')\n    recipient = getpass.getpass(prompt='Enter recipient email: ')\n    msg = EmailMessage()\n    msg.set_content(message_content)\n    msg['Subject'] = 'Message from socket client'\n    msg['From'] = sender\n    msg['To'] = recipient\n    # For this round, just create the EmailMessage object as required\n    print(msg)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1042_3",
        "turn": "3",
        "instruct_prompt": "Connect to the SMTP server using smtplib.SMTP with the given SMTP_SERVER and SMTP_PORT. Start TLS encryption, then prompt the user for the sender's email password using getpass.getpass(), and login to the SMTP server using the sender's email and password. Send the email message through the SMTP server.",
        "test": "import unittest\nfrom unittest.mock import patch, MagicMock\n\nclass TestCases(unittest.TestCase):\n    @patch('getpass.getpass')\n    @patch('smtplib.SMTP')\n    def test_email_sent_via_smtp(self, mock_smtp_cls, mock_getpass):\n        # Setup mocks\n        mock_socket = MagicMock()\n        test_message = b\"Hello, this is a test email.\"\n        mock_socket.recv.return_value = test_message\n        # getpass returns sender, recipient, password in order\n        mock_getpass.side_effect = ['sender@example.com', 'recipient@example.com', 'password123']\n        mock_smtp = MagicMock()\n        mock_smtp_cls.return_value.__enter__.return_value = mock_smtp\n\n        # Import the function from the solution\n        task_func(mock_socket)\n\n        # Check that SMTP was called with correct server and port\n        mock_smtp_cls.assert_called_with('smtp.gmail.com', 587)\n        # TLS started\n        mock_smtp.starttls.assert_called_once()\n        # Login called with sender and password\n        mock_smtp.login.assert_called_once_with('sender@example.com', 'password123')\n        # Email message was sent\n        sent_msg = mock_smtp.send_message.call_args[0][0]\n        self.assertEqual(sent_msg['From'], 'sender@example.com')\n        self.assertEqual(sent_msg['To'], 'recipient@example.com')\n        self.assertEqual(sent_msg['Subject'], 'Message from socket client')\n        self.assertIn('Hello, this is a test email.', sent_msg.get_content())\n",
        "code": "import getpass\nfrom email.message import EmailMessage\nimport smtplib\nSERVER_ADDRESS = \"localhost\"\nSERVER_PORT = 25\nBUFFER_SIZE = 1024\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\n\ndef task_func(client_socket):\n    data = client_socket.recv(BUFFER_SIZE)\n    message_content = data.decode('utf-8')\n    sender = getpass.getpass(prompt='Enter sender email: ')\n    recipient = getpass.getpass(prompt='Enter recipient email: ')\n    msg = EmailMessage()\n    msg.set_content(message_content)\n    msg['Subject'] = 'Message from socket client'\n    msg['From'] = sender\n    msg['To'] = recipient\n    password = getpass.getpass(prompt='Enter sender email password: ')\n    with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as smtp:\n        smtp.starttls()\n        smtp.login(sender, password)\n        smtp.send_message(msg)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1042_4",
        "turn": "4",
        "instruct_prompt": "After sending the email, send a confirmation response message \"Message sent.\" back to the client socket encoded as utf-8, then close the client socket.",
        "test": "import unittest\nfrom unittest.mock import Mock, patch, call\n\nclass TestCases(unittest.TestCase):\n    @patch('getpass.getpass', side_effect=['sender@example.com', 'recipient@example.com', 'password'])\n    @patch('smtplib.SMTP')\n    def test_confirmation_response_and_close(self, mock_smtp, mock_getpass):\n        # Setup mock socket\n        mock_socket = Mock()\n        mock_socket.recv.return_value = b'Hello, this is a test email.'\n        # Setup mock SMTP\n        smtp_instance = mock_smtp.return_value.__enter__.return_value\n        # Call the function\n        task_func(mock_socket)\n        # After sending, should send confirmation\n        mock_socket.sendall.assert_called_once_with(b'Message sent.')\n        # Should close the socket\n        mock_socket.close.assert_called_once()\n        # Email sending should still occur\n        smtp_instance.starttls.assert_called_once()\n        smtp_instance.login.assert_called_once_with('sender@example.com', 'password')\n        smtp_instance.send_message.assert_called_once()\n",
        "code": "import getpass\nfrom email.message import EmailMessage\nimport smtplib\nSERVER_ADDRESS = \"localhost\"\nSERVER_PORT = 25\nBUFFER_SIZE = 1024\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\n\ndef task_func(client_socket):\n    data = client_socket.recv(BUFFER_SIZE)\n    message_content = data.decode('utf-8')\n    sender = getpass.getpass(prompt='Enter sender email: ')\n    recipient = getpass.getpass(prompt='Enter recipient email: ')\n    msg = EmailMessage()\n    msg.set_content(message_content)\n    msg['Subject'] = 'Message from socket client'\n    msg['From'] = sender\n    msg['To'] = recipient\n    password = getpass.getpass(prompt='Enter sender email password: ')\n    with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as smtp:\n        smtp.starttls()\n        smtp.login(sender, password)\n        smtp.send_message(msg)\n    client_socket.sendall(\"Message sent.\".encode('utf-8'))\n    client_socket.close()\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 142,
    "task_id": "BigCodeBench/1053",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1053_1",
        "turn": "1",
        "instruct_prompt": "Process a CSV file containing a single column of text data and read it into a pandas DataFrame. You should write self-contained code starting with:```python\nimport pandas as pd\n\ndef task_func(file_path, save_path=None):\n    pass\n```",
        "test": "import unittest\nimport pandas as pd\nimport os\nfrom io import StringIO\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def test_read_single_column_csv(self):\n        data = \"\"\"hello\\nworld\\nthis\\nis\\na\\ntest\"\"\"\n        with NamedTemporaryFile(mode='w+', delete=False) as tmp:\n            tmp.write(data)\n            tmp_path = tmp.name\n        \n        df = task_func(tmp_path)\n        os.unlink(tmp_path)\n        expected = pd.DataFrame({\"text\": [\"hello\", \"world\", \"this\", \"is\", \"a\", \"test\"]})\n        pd.testing.assert_frame_equal(df, expected)\n\n    def test_save_path_writes_file(self):\n        data = \"a\\nb\\nc\"\n        with NamedTemporaryFile(mode='w+', delete=False) as tmp:\n            tmp.write(data)\n            tmp_path = tmp.name\n\n        with NamedTemporaryFile(mode='w+', delete=False) as save_tmp:\n            save_path = save_tmp.name\n\n        df = task_func(tmp_path, save_path=save_path)\n\n        df_saved = pd.read_csv(save_path)\n\n        os.unlink(tmp_path)\n        os.unlink(save_path)\n\n        expected = pd.DataFrame({\"text\": [\"a\", \"b\", \"c\"]})\n        pd.testing.assert_frame_equal(df, expected)\n        pd.testing.assert_frame_equal(df_saved, expected)\n",
        "code": "import pandas as pd\n\ndef task_func(file_path, save_path=None):\n    df = pd.read_csv(file_path, header=None, names=[\"text\"] )\n    if save_path is not None:\n        df.to_csv(save_path, index=False)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1053_2",
        "turn": "2",
        "instruct_prompt": "Split the text data into words and count the frequency of each word, excluding a predefined list of stopwords: [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]. Use sklearn's CountVectorizer for this.",
        "test": "import unittest\nimport os\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def test_word_count_excludes_stopwords(self):\n        text_data = [\n            \"The cat and the dog\",\n            \"A dog in the park\",\n            \"Birds on the tree and a cat\"\n        ]\n        with NamedTemporaryFile(mode='w+', delete=False, suffix='.csv') as f:\n            for line in text_data:\n                f.write(line + '\\n')\n            f_path = f.name\n\n        # Directly call task_func without import\n        word_counts = task_func(f_path)\n\n        # Check that stopwords are excluded\n        for stopword in [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]:\n            self.assertNotIn(stopword, word_counts)\n\n        # Check counts for some words\n        self.assertEqual(word_counts.get(\"cat\"), 2)\n        self.assertEqual(word_counts.get(\"dog\"), 2)\n        self.assertEqual(word_counts.get(\"park\"), 1)\n        self.assertEqual(word_counts.get(\"birds\"), 1)\n        self.assertEqual(word_counts.get(\"tree\"), 1)\n\n        os.remove(f_path)\n",
        "code": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nSTOPWORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\n\ndef task_func(file_path, save_path=None):\n    df = pd.read_csv(file_path, header=None, names=[\"text\"])\n    vectorizer = CountVectorizer(stop_words=STOPWORDS)\n    X = vectorizer.fit_transform(df[\"text\"])\n    word_counts = dict(zip(vectorizer.get_feature_names_out(), X.toarray().sum(axis=0)))\n    if save_path is not None:\n        pd.DataFrame(list(word_counts.items()), columns=[\"word\", \"count\"]).to_csv(save_path, index=False)\n    return word_counts\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1053_3",
        "turn": "3",
        "instruct_prompt": "Generate a histogram bar plot of the ten most common words from the counted frequencies using matplotlib.",
        "test": "import unittest\nimport os\nimport tempfile\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.pyplot as plt\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary file with sample text data\n        self.test_file = tempfile.NamedTemporaryFile(delete=False, mode='w', encoding='utf-8')\n        self.test_file.write(\"\"\"\napple banana apple orange banana apple fruit\nfruit orange banana apple grape fruit banana\n\"\"\")\n        self.test_file.close()\n\n    def tearDown(self):\n        os.unlink(self.test_file.name)\n\n    def test_task_func_returns_correct_counts(self):\n        word_counts = task_func(self.test_file.name)\n        expected_counts = {\n            'apple': 4,\n            'banana': 4,\n            'orange': 2,\n            'fruit': 3,\n            'grape': 1\n        }\n        for word, count in expected_counts.items():\n            self.assertEqual(word_counts.get(word, 0), count)\n\n    def test_task_func_plots_top_10(self):\n        calls = {}\n        def fake_show():\n            calls['show_called'] = True\n\n        original_show = plt.show\n        plt.show = fake_show\n        try:\n            task_func(self.test_file.name)\n            self.assertTrue(calls.get('show_called', False))\n        finally:\n            plt.show = original_show\n",
        "code": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n\nSTOPWORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\n\ndef task_func(file_path, save_path=None):\n    df = pd.read_csv(file_path, header=None, names=[\"text\"])\n    vectorizer = CountVectorizer(stop_words=STOPWORDS)\n    X = vectorizer.fit_transform(df[\"text\"])\n    word_counts = dict(zip(vectorizer.get_feature_names_out(), X.toarray().sum(axis=0)))\n    \n    # Sort words by count descending and take top 10\n    sorted_items = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n    top_words, top_counts = zip(*sorted_items) if sorted_items else ([], [])\n\n    # Plot histogram bar plot\n    plt.figure(figsize=(10, 6))\n    plt.bar(top_words, top_counts, color='skyblue')\n    plt.xlabel('Words')\n    plt.ylabel('Frequencies')\n    plt.title('Top 10 Most Common Words')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    if save_path is not None:\n        pd.DataFrame(list(word_counts.items()), columns=[\"word\", \"count\"]).to_csv(save_path, index=False)\n    return word_counts\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1053_4",
        "turn": "4",
        "instruct_prompt": "If a save_path is provided, save the plot to this path and return None; otherwise, display the plot and return the matplotlib Axes object.",
        "test": "import unittest\nimport os\nimport tempfile\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary CSV file with sample text data\n        self.test_data = \"\"\"apple banana apple\nbanana orange apple\norange banana apple\npear apple banana\n\"\"\"\n        self.temp_file = tempfile.NamedTemporaryFile(mode='w+', delete=False)\n        self.temp_file.write(self.test_data)\n        self.temp_file.flush()\n        self.temp_file.close()\n\n    def tearDown(self):\n        os.unlink(self.temp_file.name)\n\n    def test_return_axes_when_no_save_path(self):\n        result = task_func(self.temp_file.name)\n        self.assertIsInstance(result, Axes)\n\n    def test_save_plot_and_return_none(self):\n        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_img:\n            save_path = tmp_img.name\n        # Call function with save_path\n        result = task_func(self.temp_file.name, save_path=save_path)\n        self.assertIsNone(result)\n        self.assertTrue(os.path.exists(save_path))\n        # Clean up saved image\n        os.unlink(save_path)\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.pyplot as plt\n\nSTOPWORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\n\ndef task_func(file_path, save_path=None):\n    df = pd.read_csv(file_path, header=None, names=[\"text\"])\n    vectorizer = CountVectorizer(stop_words=STOPWORDS)\n    X = vectorizer.fit_transform(df[\"text\"])\n    word_counts = dict(zip(vectorizer.get_feature_names_out(), X.toarray().sum(axis=0)))\n    \n    # Sort words by count descending and take top 10\n    sorted_items = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n    top_words, top_counts = zip(*sorted_items) if sorted_items else ([], [])\n\n    # Plot histogram bar plot\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.bar(top_words, top_counts, color='skyblue')\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('Top 10 Most Common Words')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n\n    if save_path is not None:\n        plt.savefig(save_path)\n        plt.close(fig)\n        return None\n    else:\n        plt.show()\n        return ax\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1053_5",
        "turn": "5",
        "instruct_prompt": "Handle exceptions by raising FileNotFoundError with a message if the file does not exist, and print any other exceptions while returning None.",
        "test": "import unittest\nimport os\nimport tempfile\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nfrom io import StringIO\nfrom contextlib import redirect_stdout\n\nclass TestCases(unittest.TestCase):\n    def test_file_not_found(self):\n        with self.assertRaises(FileNotFoundError) as cm:\n            _ = task_func('non_existent_file.csv')\n        self.assertIn(\"does not exist\", str(cm.exception))\n\n    def test_other_exception_print_and_return_none(self):\n        # Create a temporary file with invalid CSV content to trigger a pandas error\n        with tempfile.NamedTemporaryFile('w', delete=False) as tmp:\n            tmp.write('\"unclosed_quote\\n')\n            tmp_path = tmp.name\n        f = StringIO()\n        with redirect_stdout(f):\n            result = task_func(tmp_path)\n        os.unlink(tmp_path)\n        output = f.getvalue()\n        self.assertIsNone(result)\n        self.assertTrue(len(output) > 0)  # Some error message printed\n\n    def test_valid_file_returns_ax(self):\n        content = \"hello world\\nhello python\\nthis is a test\\nhello test\"\n        with tempfile.NamedTemporaryFile('w', delete=False) as tmp:\n            tmp.write(content)\n            tmp_path = tmp.name\n        ax = task_func(tmp_path)\n        os.unlink(tmp_path)\n        self.assertIsNotNone(ax)\n        # Check that ax is matplotlib.axes.Axes\n        import matplotlib.axes\n        self.assertIsInstance(ax, matplotlib.axes.Axes)\n\n    def test_save_path_returns_none(self):\n        content = \"hello world\\nhello python\\nthis is a test\\nhello test\"\n        with tempfile.NamedTemporaryFile('w', delete=False) as tmp:\n            tmp.write(content)\n            tmp_path = tmp.name\n        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_img:\n            img_path = tmp_img.name\n        result = task_func(tmp_path, save_path=img_path)\n        os.unlink(tmp_path)\n        os.unlink(img_path)\n        self.assertIsNone(result)\n",
        "code": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib\nmatplotlib.use('Agg')  # Use non-interactive backend for testing\nimport matplotlib.pyplot as plt\n\nSTOPWORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\n\ndef task_func(file_path, save_path=None):\n    try:\n        df = pd.read_csv(file_path, header=None, names=[\"text\"])\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n    except Exception as e:\n        print(e)\n        return None\n\n    vectorizer = CountVectorizer(stop_words=STOPWORDS)\n    X = vectorizer.fit_transform(df[\"text\"])\n    word_counts = dict(zip(vectorizer.get_feature_names_out(), X.toarray().sum(axis=0)))\n    \n    # Sort words by count descending and take top 10\n    sorted_items = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n    top_words, top_counts = zip(*sorted_items) if sorted_items else ([], [])\n\n    # Plot histogram bar plot\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.bar(top_words, top_counts, color='skyblue')\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Frequencies')\n    ax.set_title('Top 10 Most Common Words')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n\n    if save_path is not None:\n        plt.savefig(save_path)\n        plt.close(fig)\n        return None\n    else:\n        plt.show()\n        return ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 143,
    "task_id": "BigCodeBench/1057",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1057_1",
        "turn": "1",
        "instruct_prompt": "Create a DataFrame with all combinations of two lists: 'animals' and 'foods'. Each cell should contain a string formatted as 'animal:food'. You should write self-contained code starting with:```python\nimport pandas as pd\nimport itertools\nimport numpy as np\ndef task_func(animals=None, foods=None):\n```",
        "test": "import unittest\nimport pandas as pd\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        animals = ['cat', 'dog']\n        foods = ['fish', 'bone']\n        result = task_func(animals, foods)\n        expected = pd.DataFrame(\n            [['cat:fish', 'cat:bone'], ['dog:fish', 'dog:bone']],\n            index=animals,\n            columns=foods\n        )\n        pd.testing.assert_frame_equal(result, expected)\n\n    def test_empty_animals(self):\n        result = task_func([], ['fish', 'bone'])\n        self.assertTrue(result.empty)\n\n    def test_empty_foods(self):\n        result = task_func(['cat', 'dog'], [])\n        self.assertTrue(result.empty)\n\n    def test_none_inputs(self):\n        result = task_func()\n        self.assertTrue(result.empty)\n\n    def test_single_element(self):\n        animals = ['cat']\n        foods = ['fish']\n        result = task_func(animals, foods)\n        expected = pd.DataFrame([['cat:fish']], index=animals, columns=foods)\n        pd.testing.assert_frame_equal(result, expected)\n",
        "code": "import pandas as pd\nimport itertools\nimport numpy as np\ndef task_func(animals=None, foods=None):\n    if animals is None:\n        animals = []\n    if foods is None:\n        foods = []\n    combos = list(itertools.product(animals, foods))\n    df = pd.DataFrame(combos, columns=['animal', 'food'])\n    df = df.apply(lambda row: f'{row.animal}:{row.food}', axis=1)\n    n = len(animals)\n    m = len(foods)\n    if n == 0 or m == 0:\n        return pd.DataFrame()\n    df = pd.DataFrame(np.array(df).reshape(n, m), index=animals, columns=foods)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1057_2",
        "turn": "2",
        "instruct_prompt": "If either 'animals' or 'foods' is not provided (None), replace it with a predefined default list of animals or foods respectively.",
        "test": "import unittest\nimport pandas as pd\n\nclass TestCases(unittest.TestCase):\n    def test_both_none(self):\n        # When both animals and foods are None, default lists should be used\n        result = task_func()\n        expected_index = ['cat', 'dog', 'bird']\n        expected_columns = ['fish', 'meat', 'seeds']\n        self.assertListEqual(list(result.index), expected_index)\n        self.assertListEqual(list(result.columns), expected_columns)\n        self.assertEqual(result.loc['cat', 'fish'], 'cat:fish')\n\n    def test_animals_none(self):\n        # animals is None, foods provided\n        foods = ['apple', 'banana']\n        result = task_func(animals=None, foods=foods)\n        expected_index = ['cat', 'dog', 'bird']\n        expected_columns = foods\n        self.assertListEqual(list(result.index), expected_index)\n        self.assertListEqual(list(result.columns), expected_columns)\n        self.assertEqual(result.loc['dog', 'banana'], 'dog:banana')\n\n    def test_foods_none(self):\n        # foods is None, animals provided\n        animals = ['lion', 'tiger']\n        result = task_func(animals=animals, foods=None)\n        expected_index = animals\n        expected_columns = ['fish', 'meat', 'seeds']\n        self.assertListEqual(list(result.index), expected_index)\n        self.assertListEqual(list(result.columns), expected_columns)\n        self.assertEqual(result.loc['lion', 'meat'], 'lion:meat')\n\n    def test_neither_none(self):\n        # Both animals and foods provided\n        animals = ['ant']\n        foods = ['crumb']\n        result = task_func(animals=animals, foods=foods)\n        self.assertEqual(result.loc['ant', 'crumb'], 'ant:crumb')\n\n    def test_empty_animals(self):\n        # animals is empty list\n        foods = ['fish']\n        result = task_func(animals=[], foods=foods)\n        self.assertTrue(result.empty)\n\n    def test_empty_foods(self):\n        # foods is empty list\n        animals = ['cat']\n        result = task_func(animals=animals, foods=[])\n        self.assertTrue(result.empty)\n",
        "code": "import pandas as pd\nimport itertools\nimport numpy as np\n\ndef task_func(animals=None, foods=None):\n    default_animals = ['cat', 'dog', 'bird']\n    default_foods = ['fish', 'meat', 'seeds']\n\n    if animals is None:\n        animals = default_animals\n    if foods is None:\n        foods = default_foods\n\n    combos = list(itertools.product(animals, foods))\n    df = pd.DataFrame(combos, columns=['animal', 'food'])\n    df = df.apply(lambda row: f'{row.animal}:{row.food}', axis=1)\n    n = len(animals)\n    m = len(foods)\n    if n == 0 or m == 0:\n        return pd.DataFrame()\n    df = pd.DataFrame(np.array(df).reshape(n, m), index=animals, columns=foods)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1057_3",
        "turn": "3",
        "instruct_prompt": "If either 'animals' or 'foods' is an empty list, return an empty DataFrame.",
        "test": "import unittest\nimport pandas as pd\nfrom pandas.testing import assert_frame_equal\n\nclass TestCases(unittest.TestCase):\n    def test_empty_animals(self):\n        result = task_func(animals=[], foods=['fish', 'meat'])\n        expected = pd.DataFrame()\n        self.assertTrue(result.empty)\n        assert_frame_equal(result, expected)\n\n    def test_empty_foods(self):\n        result = task_func(animals=['cat', 'dog'], foods=[]) \n        expected = pd.DataFrame()\n        self.assertTrue(result.empty)\n        assert_frame_equal(result, expected)\n\n    def test_empty_both(self):\n        result = task_func(animals=[], foods=[]) \n        expected = pd.DataFrame()\n        self.assertTrue(result.empty)\n        assert_frame_equal(result, expected)\n\n    def test_non_empty(self):\n        result = task_func(animals=['cat'], foods=['fish'])\n        expected = pd.DataFrame([['cat:fish']], index=['cat'], columns=['fish'])\n        assert_frame_equal(result, expected)\n\n    def test_no_combinations_generated_with_empty_lists(self):\n        # This test checks that no combinations are generated when empty lists are provided\n        # It fails previous code because it generates combinations before checking emptiness\n        animals = []\n        foods = ['fish']\n        # We patch itertools.product to track if it's called\n        called = {'called': False}\n\n        import builtins\n        import itertools as it\n\n        original_product = it.product\n\n        def fake_product(*args, **kwargs):\n            called['called'] = True\n            return original_product(*args, **kwargs)\n\n        it.product = fake_product\n        try:\n            _ = task_func(animals=animals, foods=foods)\n        finally:\n            it.product = original_product\n\n        # The current solution returns early without calling itertools.product when animals is empty\n        self.assertFalse(called['called'], \"itertools.product was called despite empty input list\")\n",
        "code": "import pandas as pd\nimport itertools\nimport numpy as np\n\ndef task_func(animals=None, foods=None):\n    default_animals = ['cat', 'dog', 'bird']\n    default_foods = ['fish', 'meat', 'seeds']\n\n    if animals is None:\n        animals = default_animals\n    if foods is None:\n        foods = default_foods\n\n    # Return empty DataFrame immediately if either list is empty\n    if not animals or not foods:\n        return pd.DataFrame()\n\n    combos = list(itertools.product(animals, foods))\n    df = pd.DataFrame(combos, columns=['animal', 'food'])\n    df = df.apply(lambda row: f'{row.animal}:{row.food}', axis=1)\n    n = len(animals)\n    m = len(foods)\n    df = pd.DataFrame(np.array(df).reshape(n, m), index=animals, columns=foods)\n    return df\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1057_4",
        "turn": "4",
        "instruct_prompt": "Arrange the combinations into a DataFrame where each row corresponds to an animal and each column corresponds to a food. The DataFrame cells contain strings in 'animal:food' format. The DataFrame should be built by reshaping the list of combinations appropriately.",
        "test": "import unittest\nimport pandas as pd\nimport numpy as np\n\nclass TestCases(unittest.TestCase):\n    def test_default(self):\n        df = task_func()\n        expected_animals = ['cat', 'dog', 'bird']\n        expected_foods = ['fish', 'meat', 'seeds']\n\n        # Construct expected DataFrame by reshaping with (len(foods), len(animals)) then transpose\n        combos = [f'{animal}:{food}' for animal in expected_animals for food in expected_foods]\n        expected_array = np.array(combos, dtype=object).reshape(len(expected_foods), len(expected_animals)).T\n        expected_df = pd.DataFrame(expected_array, index=expected_animals, columns=expected_foods)\n\n        pd.testing.assert_frame_equal(df, expected_df)\n\n    def test_custom_lists(self):\n        animals = ['lion', 'tiger']\n        foods = ['beef', 'chicken']\n        df = task_func(animals, foods)\n\n        combos = [f'{animal}:{food}' for animal in animals for food in foods]\n        expected_array = np.array(combos, dtype=object).reshape(len(foods), len(animals)).T\n        expected_df = pd.DataFrame(expected_array, index=animals, columns=foods)\n\n        pd.testing.assert_frame_equal(df, expected_df)\n\n    def test_empty_animals(self):\n        df = task_func([], ['food1', 'food2'])\n        self.assertTrue(df.empty)\n\n    def test_empty_foods(self):\n        df = task_func(['animal1', 'animal2'], [])\n        self.assertTrue(df.empty)\n\n    def test_empty_both(self):\n        df = task_func([], [])\n        self.assertTrue(df.empty)\n",
        "code": "import pandas as pd\nimport itertools\nimport numpy as np\n\ndef task_func(animals=None, foods=None):\n    default_animals = ['cat', 'dog', 'bird']\n    default_foods = ['fish', 'meat', 'seeds']\n\n    if animals is None:\n        animals = default_animals\n    if foods is None:\n        foods = default_foods\n\n    # Return empty DataFrame immediately if either list is empty\n    if not animals or not foods:\n        return pd.DataFrame()\n\n    combos = list(itertools.product(animals, foods))\n    combo_strs = [f'{animal}:{food}' for animal, food in combos]\n    n = len(animals)\n    m = len(foods)\n\n    # Reshape by (m, n) and transpose to get (n, m) with animals as rows and foods as columns\n    combo_array = np.array(combo_strs, dtype=object).reshape(m, n).T\n    df = pd.DataFrame(combo_array, index=animals, columns=foods)\n    return df\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 144,
    "task_id": "BigCodeBench/1077",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1077_1",
        "turn": "1",
        "instruct_prompt": "Calculate the average absolute time difference in seconds between each consecutive pair of timestamps in a given list. You should write self-contained code starting with:\n```\nfrom datetime import datetime\ndef task_func(time_strings, timezone):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_average_diff_multiple(self):\n        # 10s, 20s, 30s differences -> avg = 20.0\n        times = ['2024-06-01 12:00:00', '2024-06-01 12:00:10', '2024-06-01 12:00:30', '2024-06-01 12:01:00']\n        self.assertEqual(task_func(times, None), 20.0)\n\n    def test_average_diff_single_pair(self):\n        times = ['2024-06-01 12:00:00', '2024-06-01 12:00:05']\n        self.assertEqual(task_func(times, None), 5.0)\n\n    def test_average_diff_no_pairs(self):\n        # Only one timestamp, no pairs\n        times = ['2024-06-01 12:00:00']\n        self.assertEqual(task_func(times, None), 0.0)\n\n    def test_average_diff_empty(self):\n        self.assertEqual(task_func([], None), 0.0)\n\n    def test_average_diff_non_uniform(self):\n        # 10s, 50s, 40s differences -> avg = 33.333...\n        times = ['2024-06-01 12:00:00', '2024-06-01 12:00:10', '2024-06-01 12:01:00', '2024-06-01 12:01:40']\n        self.assertAlmostEqual(task_func(times, None), 33.333333333333336)\n",
        "code": "from datetime import datetime\n\ndef task_func(time_strings, timezone):\n    if len(time_strings) < 2:\n        return 0.0\n    # Parse all timestamps\n    times = [datetime.strptime(ts, '%Y-%m-%d %H:%M:%S') for ts in time_strings]\n    # Calculate absolute differences in seconds between consecutive pairs\n    diffs = [abs((times[i+1] - times[i]).total_seconds()) for i in range(len(times)-1)]\n    # Calculate average\n    avg_diff = sum(diffs) / len(diffs)\n    return avg_diff\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1077_2",
        "turn": "2",
        "instruct_prompt": "Parse each timestamp string in the list as a UTC datetime object before calculating the differences.",
        "test": "import unittest\nfrom datetime import datetime, timezone\n\nclass TestCases(unittest.TestCase):\n    def test_utc_aware_objects_and_average(self):\n        times = ['2024-06-01 12:00:00', '2024-06-01 13:00:00', '2024-06-01 15:00:00']\n        expected_avg = (3600 + 7200) / 2\n        result, parsed = task_func(times, None, return_parsed=True)\n        self.assertEqual(result, expected_avg)\n        # Check that the parsed datetimes are UTC-aware\n        for dt in parsed:\n            self.assertIsNotNone(dt.tzinfo)\n            self.assertEqual(dt.tzinfo, timezone.utc)\n\n    def test_less_than_two(self):\n        times = ['2024-06-01 12:00:00']\n        result, parsed = task_func(times, None, return_parsed=True)\n        self.assertEqual(result, 0.0)\n        self.assertEqual(parsed, [])\n        times = []\n        result, parsed = task_func(times, None, return_parsed=True)\n        self.assertEqual(result, 0.0)\n        self.assertEqual(parsed, [])\n\n    def test_non_chronological(self):\n        times = ['2024-06-01 15:00:00', '2024-06-01 12:00:00', '2024-06-01 13:00:00']\n        expected_avg = (10800 + 3600) / 2\n        result, parsed = task_func(times, None, return_parsed=True)\n        self.assertEqual(result, expected_avg)\n        for dt in parsed:\n            self.assertEqual(dt.tzinfo, timezone.utc)\n\n    def test_utc_awareness(self):\n        times = ['2024-06-01 00:00:00', '2024-06-01 01:00:00']\n        result, parsed = task_func(times, None, return_parsed=True)\n        self.assertEqual(result, 3600.0)\n        for dt in parsed:\n            self.assertEqual(dt.tzinfo, timezone.utc)\n",
        "code": "from datetime import datetime, timezone\n\ndef task_func(time_strings, tz, return_parsed=False):\n    if len(time_strings) < 2:\n        return (0.0, []) if return_parsed else 0.0\n    # Parse all timestamps as UTC datetime objects\n    times = [datetime.strptime(ts, '%Y-%m-%d %H:%M:%S').replace(tzinfo=timezone.utc) for ts in time_strings]\n    diffs = [abs((times[i+1] - times[i]).total_seconds()) for i in range(len(times)-1)]\n    avg_diff = sum(diffs) / len(diffs)\n    if return_parsed:\n        return avg_diff, times\n    return avg_diff\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1077_3",
        "turn": "3",
        "instruct_prompt": "Convert each parsed UTC datetime to the specified timezone before calculating the differences.",
        "test": "import unittest\nfrom datetime import datetime\nimport zoneinfo\n\nclass TestCases(unittest.TestCase):\n    def test_basic_timezone_conversion(self):\n        # 12:00 UTC is 15:00 in Europe/Helsinki (UTC+3 in June)\n        ts = ['2024-06-01 12:00:00', '2024-06-01 13:00:00']\n        avg, parsed = task_func(ts, 'Europe/Helsinki', return_parsed=True)\n        self.assertEqual(avg, 3600.0)\n        self.assertEqual(parsed[0].hour, 15)\n        self.assertEqual(parsed[1].hour, 16)\n        self.assertEqual(parsed[0].tzinfo, zoneinfo.ZoneInfo('Europe/Helsinki'))\n\n    def test_negative_offset(self):\n        # UTC-4 (America/New_York, EDT in June)\n        ts = ['2024-06-01 10:00:00', '2024-06-01 12:00:00']\n        avg, parsed = task_func(ts, 'America/New_York', return_parsed=True)\n        self.assertEqual(avg, 7200.0)\n        self.assertEqual(parsed[0].hour, 6)  # 10:00 UTC -> 6:00 NY (EDT)\n        self.assertEqual(parsed[1].hour, 8)  # 12:00 UTC -> 8:00 NY (EDT)\n        self.assertEqual(parsed[0].tzinfo, zoneinfo.ZoneInfo('America/New_York'))\n\n    def test_dst_transition(self):\n        # Test a timezone with DST, e.g., Europe/London\n        ts = ['2024-03-31 00:30:00', '2024-03-31 02:30:00']\n        avg, parsed = task_func(ts, 'Europe/London', return_parsed=True)\n        # On 2024-03-31, DST starts at 01:00 UTC (goes from GMT to BST)\n        # 00:30 UTC -> 00:30 GMT, 02:30 UTC -> 03:30 BST\n        self.assertEqual(parsed[0].hour, 1 if parsed[0].tzname() == 'BST' else 0)\n        self.assertEqual(parsed[1].hour, 3)\n        self.assertEqual(parsed[1].tzname(), 'BST')\n\n    def test_invalid_timezone(self):\n        ts = ['2024-06-01 10:00:00', '2024-06-01 12:00:00']\n        with self.assertRaises(ValueError):\n            task_func(ts, 'Invalid/Zone')\n\n    def test_single_timestamp(self):\n        ts = ['2024-06-01 12:00:00']\n        self.assertEqual(task_func(ts, 'UTC'), 0.0)\n        self.assertEqual(task_func(ts, 'UTC', return_parsed=True), (0.0, []))\n",
        "code": "from datetime import datetime, timezone\nimport zoneinfo\n\ndef task_func(time_strings, tz, return_parsed=False):\n    if len(time_strings) < 2:\n        return (0.0, []) if return_parsed else 0.0\n    # Parse all timestamps as UTC datetime objects\n    times_utc = [datetime.strptime(ts, '%Y-%m-%d %H:%M:%S').replace(tzinfo=timezone.utc) for ts in time_strings]\n    # Convert each to the specified timezone\n    try:\n        target_tz = zoneinfo.ZoneInfo(tz)\n    except Exception:\n        raise ValueError(f\"Invalid timezone: {tz}\")\n    times = [dt.astimezone(target_tz) for dt in times_utc]\n    diffs = [abs((times[i+1] - times[i]).total_seconds()) for i in range(len(times)-1)]\n    avg_diff = sum(diffs) / len(diffs)\n    if return_parsed:\n        return avg_diff, times\n    return avg_diff\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1077_4",
        "turn": "4",
        "instruct_prompt": "If the list contains less than two timestamps, return 0.0 instead of calculating the average.",
        "test": "import unittest\nfrom datetime import datetime, timezone\nimport zoneinfo\n\nclass TestCases(unittest.TestCase):\n    def test_less_than_two_timestamps_empty(self):\n        # Should return 0.0 for empty list\n        self.assertEqual(task_func([], 'UTC'), 0.0)\n        self.assertEqual(task_func([], 'UTC', return_parsed=True), (0.0, []))\n\n    def test_less_than_two_timestamps_one(self):\n        # Should return 0.0 for single timestamp\n        self.assertEqual(task_func(['2024-06-01 12:00:00'], 'UTC'), 0.0)\n        self.assertEqual(\n            task_func(['2024-06-01 12:00:00'], 'UTC', return_parsed=True),\n            (0.0, [datetime(2024, 6, 1, 12, 0, 0, tzinfo=zoneinfo.ZoneInfo('UTC'))])\n        )\n\n    def test_two_timestamps(self):\n        # Should return the difference in seconds\n        result = task_func(['2024-06-01 12:00:00', '2024-06-01 12:01:00'], 'UTC')\n        self.assertEqual(result, 60.0)\n\n    def test_multiple_timestamps(self):\n        # Should return average difference\n        times = ['2024-06-01 12:00:00', '2024-06-01 12:01:00', '2024-06-01 12:03:00']\n        # diffs: 60, 120 -> avg: 90.0\n        self.assertEqual(task_func(times, 'UTC'), 90.0)\n\n    def test_invalid_timezone(self):\n        with self.assertRaises(ValueError):\n            task_func(['2024-06-01 12:00:00', '2024-06-01 12:01:00'], 'Invalid/Zone')\n",
        "code": "from datetime import datetime, timezone\nimport zoneinfo\n\ndef task_func(time_strings, tz, return_parsed=False):\n    # Parse all timestamps as UTC datetime objects\n    times_utc = [datetime.strptime(ts, '%Y-%m-%d %H:%M:%S').replace(tzinfo=timezone.utc) for ts in time_strings]\n    try:\n        target_tz = zoneinfo.ZoneInfo(tz)\n    except Exception:\n        raise ValueError(f\"Invalid timezone: {tz}\")\n    times = [dt.astimezone(target_tz) for dt in times_utc]\n    if len(times) < 2:\n        return (0.0, times) if return_parsed else 0.0\n    diffs = [abs((times[i+1] - times[i]).total_seconds()) for i in range(len(times)-1)]\n    avg_diff = sum(diffs) / len(diffs)\n    if return_parsed:\n        return avg_diff, times\n    return avg_diff\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1077_5",
        "turn": "5",
        "instruct_prompt": "Use numpy's mean function to calculate the average time difference, and return 0.0 if there are no time differences.",
        "test": "import unittest\nfrom datetime import datetime\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    def test_no_time_strings(self):\n        self.assertEqual(task_func([], 'UTC'), 0.0)\n\n    def test_one_time_string(self):\n        self.assertEqual(task_func(['2024-06-01 12:00:00'], 'UTC'), 0.0)\n\n    def test_two_time_strings(self):\n        t1 = '2024-06-01 12:00:00'\n        t2 = '2024-06-01 12:00:10'\n        self.assertEqual(task_func([t1, t2], 'UTC'), 10.0)\n\n    def test_multiple_time_strings(self):\n        t1 = '2024-06-01 12:00:00'\n        t2 = '2024-06-01 12:00:10'\n        t3 = '2024-06-01 12:00:30'\n        # diffs: [10, 20], mean: 15.0\n        self.assertEqual(task_func([t1, t2, t3], 'UTC'), 15.0)\n\n    def test_return_parsed(self):\n        t1 = '2024-06-01 12:00:00'\n        t2 = '2024-06-01 12:00:10'\n        avg, times = task_func([t1, t2], 'UTC', return_parsed=True)\n        self.assertEqual(avg, 10.0)\n        self.assertEqual(len(times), 2)\n        self.assertTrue(all(isinstance(dt, datetime) for dt in times))\n\n    def test_empty_diffs(self):\n        # Only one time, so diffs is empty, should return 0.0\n        avg, times = task_func(['2024-06-01 12:00:00'], 'UTC', return_parsed=True)\n        self.assertEqual(avg, 0.0)\n\n    def test_invalid_timezone(self):\n        with self.assertRaises(ValueError):\n            task_func(['2024-06-01 12:00:00'], 'NotARealTZ')\n\n    def test_numpy_mean_called(self):\n        t1 = '2024-06-01 12:00:00'\n        t2 = '2024-06-01 12:00:10'\n        t3 = '2024-06-01 12:00:30'\n        diffs = [10, 20]\n        with patch('numpy.mean', wraps=np.mean) as mock_mean:\n            result = task_func([t1, t2, t3], 'UTC')\n            mock_mean.assert_called_once_with(diffs)\n            self.assertEqual(result, 15.0)\n",
        "code": "from datetime import datetime, timezone\nimport zoneinfo\nimport numpy as np\n\ndef task_func(time_strings, tz, return_parsed=False):\n    # Parse all timestamps as UTC datetime objects\n    times_utc = [datetime.strptime(ts, '%Y-%m-%d %H:%M:%S').replace(tzinfo=timezone.utc) for ts in time_strings]\n    try:\n        target_tz = zoneinfo.ZoneInfo(tz)\n    except Exception:\n        raise ValueError(f\"Invalid timezone: {tz}\")\n    times = [dt.astimezone(target_tz) for dt in times_utc]\n    if len(times) < 2:\n        return (0.0, times) if return_parsed else 0.0\n    diffs = [abs((times[i+1] - times[i]).total_seconds()) for i in range(len(times)-1)]\n    # Use numpy's mean function directly\n    avg_diff = float(np.mean(diffs)) if diffs else 0.0\n    if return_parsed:\n        return avg_diff, times\n    return avg_diff\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 145,
    "task_id": "BigCodeBench/1085",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1085_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a string input parameter named text and returns a list of tuples of the 10 most common words and their counts after lowercasing the text and splitting it into words by whitespace. You should write self-contained code starting with:\n```python\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(text):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_basic(self):\n        text = \"apple apple banana banana banana orange\"\n        expected = [('banana', 3), ('apple', 2), ('orange', 1)]\n        self.assertEqual(task_func(text), expected)\n\n    def test_case_insensitive(self):\n        text = \"Apple apple APPLE banana BANANA orange\"\n        expected = [('apple', 3), ('banana', 2), ('orange', 1)]\n        self.assertEqual(task_func(text), expected)\n\n    def test_more_than_10_words(self):\n        text = \"one two three four five six seven eight nine ten eleven twelve thirteen\"\n        expected = [('one', 1), ('two', 1), ('three', 1), ('four', 1), ('five', 1), ('six', 1), ('seven', 1), ('eight', 1), ('nine', 1), ('ten', 1)]\n        self.assertEqual(task_func(text), expected)\n\n    def test_empty_string(self):\n        self.assertEqual(task_func(\"\") , [])\n\n    def test_whitespace_variation(self):\n        text = \"word1\\tword2\\nword1  word3\"\n        expected = [('word1', 2), ('word2', 1), ('word3', 1)]\n        self.assertEqual(task_func(text), expected)\n",
        "code": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\ndef task_func(text):\n    words = text.lower().split()\n    counter = Counter(words)\n    return counter.most_common(10)",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1085_2",
        "turn": "2",
        "instruct_prompt": "Modify the function to remove all punctuation characters from the input text before lowercasing and splitting it into words. Consider punctuation characters as all characters in the string module's punctuation.",
        "test": "import unittest\nfrom collections import Counter\nimport string\n\nclass TestCases(unittest.TestCase):\n    def test_basic_punctuation_removal(self):\n        text = \"Hello, world! Hello...\"\n        expected = [('hello', 2), ('world', 1)]\n        result = task_func(text)\n        self.assertEqual(result, expected)\n\n    def test_empty_string(self):\n        text = \"\"\n        expected = []\n        result = task_func(text)\n        self.assertEqual(result, expected)\n\n    def test_only_punctuation(self):\n        text = string.punctuation\n        expected = []\n        result = task_func(text)\n        self.assertEqual(result, expected)\n\n    def test_mixed_content(self):\n        text = \"Python's great: isn't it? Yes, it is!\"\n        expected = [('its', 1), ('great', 1), ('isnt', 1), ('it', 2), ('yes', 1), ('python', 1), ('s', 1), ('is', 1)]\n        # Note: After removing punctuation, \"Python's\" becomes \"Pythons\" which splits into \"pythons\" (single word)\n        # But the apostrophe is removed so it becomes \"Pythons\" not \"Python s\"\n        # Actually, the current code removes punctuation characters, so \"Python's\" -> \"Pythons\"\n        # So the words are: ['pythons', 'great', 'isnt', 'it', 'yes', 'it', 'is']\n        expected = [('it', 2), ('pythons', 1), ('great', 1), ('isnt', 1), ('yes', 1), ('is', 1)]\n        result = task_func(text)\n        self.assertEqual(sorted(result), sorted(expected))\n\n    def test_case_insensitivity(self):\n        text = \"Apple apple APPLE!\"\n        expected = [('apple', 3)]\n        result = task_func(text)\n        self.assertEqual(result, expected)\n",
        "code": "import string\nfrom collections import Counter\n\ndef task_func(text):\n    # Remove punctuation characters\n    translator = str.maketrans('', '', string.punctuation)\n    clean_text = text.translate(translator)\n    words = clean_text.lower().split()\n    counter = Counter(words)\n    return counter.most_common(10)\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1085_3",
        "turn": "3",
        "instruct_prompt": "Add code to plot a bar chart of the top 10 most common words using matplotlib, where the x-axis shows the words and the y-axis shows their counts.",
        "test": "import unittest\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    @patch('matplotlib.pyplot.show')\n    def test_top_10_words_and_plot(self, mock_show):\n        text = 'apple banana apple orange banana apple fruit fruit banana orange orange orange'\n        result = task_func(text)\n        expected = [('orange', 4), ('apple', 3), ('banana', 3), ('fruit', 2)]\n        self.assertEqual(result, expected)\n        mock_show.assert_called_once()  # Confirm plot was shown\n\n    @patch('matplotlib.pyplot.show')\n    def test_empty_text(self, mock_show):\n        result = task_func('')\n        self.assertEqual(result, [])\n        mock_show.assert_called_once()  # Plot still called with empty data\n\n    @patch('matplotlib.pyplot.show')\n    def test_punctuation_handling(self, mock_show):\n        text = 'Hello, hello! HELLO?'\n        result = task_func(text)\n        expected = [('hello', 3)]\n        self.assertEqual(result, expected)\n        mock_show.assert_called_once()  # Confirm plot was shown\n",
        "code": "import string\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Remove punctuation characters\n    translator = str.maketrans('', '', string.punctuation)\n    clean_text = text.translate(translator)\n    words = clean_text.lower().split()\n    counter = Counter(words)\n    top_10 = counter.most_common(10)\n\n    # Plot bar chart\n    if top_10:\n        words_plot, counts = zip(*top_10)\n    else:\n        words_plot, counts = [], []\n    plt.bar(words_plot, counts)\n    plt.xlabel('Words')\n    plt.ylabel('Counts')\n    plt.title('Top 10 Most Common Words')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    return top_10\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1085_4",
        "turn": "4",
        "instruct_prompt": "Make sure the function returns a tuple with two elements: the list of the 10 most common word-count tuples and the matplotlib Axes object of the generated bar chart.",
        "test": "import unittest\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n\nclass TestCases(unittest.TestCase):\n    def test_return_type_and_content(self):\n        text = 'apple banana apple orange banana apple pear orange banana banana'\n        result = task_func(text)\n        # Check return type is tuple\n        self.assertIsInstance(result, tuple)\n        # Check tuple length\n        self.assertEqual(len(result), 2)\n        # Check first element is list of tuples\n        top_10, ax = result\n        self.assertIsInstance(top_10, list)\n        for item in top_10:\n            self.assertIsInstance(item, tuple)\n            self.assertEqual(len(item), 2)\n            self.assertIsInstance(item[0], str)\n            self.assertIsInstance(item[1], int)\n        # Check second element is matplotlib Axes\n        self.assertIsInstance(ax, Axes)\n        # Check the top 10 words count correctness\n        expected = [('banana', 4), ('apple', 3), ('orange', 2), ('pear', 1)]\n        self.assertEqual(top_10, expected)\n\n    def test_empty_text(self):\n        result = task_func('')\n        top_10, ax = result\n        self.assertEqual(top_10, [])\n        self.assertIsInstance(ax, Axes)\n\n    def test_less_than_10_words(self):\n        text = 'hello world hello'\n        top_10, ax = task_func(text)\n        self.assertEqual(top_10, [('hello', 2), ('world', 1)])\n        self.assertIsInstance(ax, Axes)\n",
        "code": "import string\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(text):\n    # Remove punctuation characters\n    translator = str.maketrans('', '', string.punctuation)\n    clean_text = text.translate(translator)\n    words = clean_text.lower().split()\n    counter = Counter(words)\n    top_10 = counter.most_common(10)\n\n    # Plot bar chart\n    fig, ax = plt.subplots()\n    if top_10:\n        words_plot, counts = zip(*top_10)\n    else:\n        words_plot, counts = [], []\n    ax.bar(words_plot, counts)\n    ax.set_xlabel('Words')\n    ax.set_ylabel('Counts')\n    ax.set_title('Top 10 Most Common Words')\n    plt.setp(ax.get_xticklabels(), rotation=45)\n    plt.tight_layout()\n\n    return top_10, ax\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 146,
    "task_id": "BigCodeBench/1124",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1124_1",
        "turn": "1",
        "instruct_prompt": "Extract a URL from a given string and return it. If no valid URL is found, return the error message: \"No valid URL found in the provided string.\" You should write self-contained code starting with:\n```python\nimport re\nfrom urllib.parse import urlparse\n\ndef task_func(myString):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_valid_url(self):\n        self.assertEqual(task_func(\"Check this link: https://example.com/page.\"), \"https://example.com/page\")\n    \n    def test_multiple_urls(self):\n        self.assertEqual(task_func(\"Visit http://first.com and then https://second.com.\"), \"http://first.com\")\n    \n    def test_no_url(self):\n        self.assertEqual(task_func(\"There is no link here.\"), \"No valid URL found in the provided string.\")\n    \n    def test_url_with_path_and_query(self):\n        self.assertEqual(task_func(\"Here: https://example.com/path?query=1\"), \"https://example.com/path?query=1\")\n    \n    def test_url_without_http(self):\n        self.assertEqual(task_func(\"Go to www.example.com\"), \"No valid URL found in the provided string.\")\n    \n    def test_url_with_trailing_punctuation(self):\n        self.assertEqual(task_func(\"Visit https://example.com.\"), \"https://example.com\")",
        "code": "import re\nfrom urllib.parse import urlparse\n\ndef task_func(myString):\n    # Regex to find potential URLs\n    url_pattern = re.compile(r'https?://[^\\s]+')\n    matches = url_pattern.findall(myString)\n    \n    for match in matches:\n        # Strip trailing punctuation characters that are unlikely part of URL\n        cleaned_match = match.rstrip('.,!?:;')\n        parsed = urlparse(cleaned_match)\n        # Check if the URL has a scheme and netloc\n        if parsed.scheme and parsed.netloc:\n            return cleaned_match\n    \n    return \"No valid URL found in the provided string.\"",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1124_2",
        "turn": "2",
        "instruct_prompt": "Using the extracted URL, fetch the content of the webpage. If the fetch fails for any reason, return the error message: \"Unable to fetch the content of the URL: {url}\".",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    def test_fetch_success(self):\n        test_url = 'http://example.com'\n        test_string = f'Check this link: {test_url}.'\n        \n        with patch('requests.get') as mock_get:\n            mock_response = Mock()\n            mock_response.text = 'Example Domain Content'\n            mock_response.raise_for_status = Mock()\n            mock_get.return_value = mock_response\n            \n            result = task_func(test_string)\n            self.assertEqual(result, 'Example Domain Content')\n\n    def test_fetch_failure(self):\n        test_url = 'http://example.com'\n        test_string = f'Check this link: {test_url}.'\n        \n        with patch('requests.get') as mock_get:\n            mock_get.side_effect = Exception('Network error')\n            \n            result = task_func(test_string)\n            self.assertEqual(result, f'Unable to fetch the content of the URL: {test_url}')\n\n    def test_no_url(self):\n        test_string = 'This string has no URL.'\n        result = task_func(test_string)\n        self.assertEqual(result, 'No valid URL found in the provided string.')\n\n    def test_invalid_url(self):\n        test_string = 'Visit https://.'\n        result = task_func(test_string)\n        self.assertEqual(result, 'No valid URL found in the provided string.')",
        "code": "import re\nfrom urllib.parse import urlparse\nimport requests\n\ndef task_func(myString):\n    # Regex to find potential URLs\n    url_pattern = re.compile(r'https?://[^\\s]+')\n    matches = url_pattern.findall(myString)\n    \n    for match in matches:\n        # Strip trailing punctuation characters that are unlikely part of URL\n        cleaned_match = match.rstrip('.,!?:;')\n        parsed = urlparse(cleaned_match)\n        # Check if the URL has a scheme and netloc\n        if parsed.scheme and parsed.netloc:\n            # Try to fetch the content of the URL\n            try:\n                response = requests.get(cleaned_match, timeout=5)\n                response.raise_for_status()\n                return response.text\n            except Exception:\n                return f\"Unable to fetch the content of the URL: {cleaned_match}\"\n    \n    return \"No valid URL found in the provided string.\"",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1124_3",
        "turn": "3",
        "instruct_prompt": "Parse the fetched webpage content to extract and return the title of the webpage. If the page has no title tag, return the error message: \"No title tag found in the webpage.\"",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_title_present(self, mock_get):\n        html_content = '<html><head><title>Example Title</title></head><body>Content</body></html>'\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        input_str = 'Here is a link http://example.com'\n        expected = 'Example Title'\n        self.assertEqual(task_func(input_str), expected)\n\n    @patch('requests.get')\n    def test_no_title_tag(self, mock_get):\n        html_content = '<html><head></head><body>No title here</body></html>'\n        mock_response = Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_get.return_value = mock_response\n\n        input_str = 'Visit https://notitle.com'\n        expected = 'No title tag found in the webpage.'\n        self.assertEqual(task_func(input_str), expected)\n\n    def test_no_url(self):\n        input_str = 'This string has no url'\n        expected = 'No valid URL found in the provided string.'\n        self.assertEqual(task_func(input_str), expected)\n\n    @patch('requests.get')\n    def test_unable_to_fetch(self, mock_get):\n        mock_get.side_effect = requests.exceptions.RequestException\n\n        input_str = 'Broken link http://broken.url'\n        expected = 'Unable to fetch the content of the URL: http://broken.url'\n        self.assertEqual(task_func(input_str), expected)",
        "code": "import re\nfrom urllib.parse import urlparse\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef task_func(myString):\n    # Regex to find potential URLs\n    url_pattern = re.compile(r'https?://[^\\s]+')\n    matches = url_pattern.findall(myString)\n    \n    for match in matches:\n        # Strip trailing punctuation characters that are unlikely part of URL\n        cleaned_match = match.rstrip('.,!?:;')\n        parsed = urlparse(cleaned_match)\n        # Check if the URL has a scheme and netloc\n        if parsed.scheme and parsed.netloc:\n            # Try to fetch the content of the URL\n            try:\n                response = requests.get(cleaned_match, timeout=5)\n                response.raise_for_status()\n                # Parse the content to extract the title\n                soup = BeautifulSoup(response.text, 'html.parser')\n                title_tag = soup.title\n                if title_tag and title_tag.string:\n                    return title_tag.string.strip()\n                else:\n                    return \"No title tag found in the webpage.\"\n            except Exception:\n                return f\"Unable to fetch the content of the URL: {cleaned_match}\"\n    \n    return \"No valid URL found in the provided string.\"",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 147,
    "task_id": "BigCodeBench/1129",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1129_1",
        "turn": "1",
        "instruct_prompt": "Write a function that takes a JSON string and a key, parses the JSON to get the value associated with the key, and returns that value. You should write self-contained code starting with:\n```\nimport json\n\ndef task_func(json_data, unknown_key, save_dir=None):\n```",
        "test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_key_present(self):\n        json_str = '{\"name\": \"Alice\", \"age\": 30}'\n        self.assertEqual(task_func(json_str, \"name\"), \"Alice\")\n        self.assertEqual(task_func(json_str, \"age\"), 30)\n\n    def test_key_absent(self):\n        json_str = '{\"name\": \"Alice\", \"age\": 30}'\n        self.assertIsNone(task_func(json_str, \"height\"))\n\n    def test_empty_json(self):\n        json_str = '{}'\n        self.assertIsNone(task_func(json_str, \"anykey\"))\n\n    def test_nested_json(self):\n        json_str = '{\"person\": {\"name\": \"Bob\"}}'\n        # The function only fetches top-level key\n        self.assertEqual(task_func(json_str, \"person\"), {\"name\": \"Bob\"})\n        self.assertIsNone(task_func(json_str, \"name\"))\n\n    def test_non_string_key(self):\n        json_str = '{\"1\": \"one\", \"2\": \"two\"}'\n        self.assertEqual(task_func(json_str, \"1\"), \"one\")\n        self.assertIsNone(task_func(json_str, 1))\n",
        "code": "import json\n\ndef task_func(json_data, unknown_key, save_dir=None):\n    data = json.loads(json_data)\n    return data.get(unknown_key)",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1129_2",
        "turn": "2",
        "instruct_prompt": "Extend the function to treat the value retrieved from the JSON as a URL, download the file content from this URL using the requests library, and store the content in memory.",
        "test": "import unittest\nfrom unittest.mock import patch, Mock\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_valid_url_download(self, mock_get):\n        mock_response = Mock()\n        mock_response.content = b'downloaded content'\n        mock_response.raise_for_status = Mock()\n        mock_get.return_value = mock_response\n\n        json_data = '{\"file_url\": \"http://example.com/file.txt\"}'\n        result = task_func(json_data, 'file_url')\n        self.assertEqual(result, b'downloaded content')\n        mock_get.assert_called_once_with('http://example.com/file.txt')\n\n    @patch('requests.get')\n    def test_missing_key(self, mock_get):\n        json_data = '{\"other_key\": \"http://example.com/file.txt\"}'\n        result = task_func(json_data, 'file_url')\n        self.assertIsNone(result)\n        mock_get.assert_not_called()\n\n    @patch('requests.get')\n    def test_http_error_raises(self, mock_get):\n        mock_response = Mock()\n        mock_response.raise_for_status.side_effect = requests.HTTPError(\"404 Not Found\")\n        mock_get.return_value = mock_response\n\n        json_data = '{\"file_url\": \"http://example.com/file.txt\"}'\n        with self.assertRaises(requests.HTTPError):\n            task_func(json_data, 'file_url')\n",
        "code": "import json\nimport requests\n\n\ndef task_func(json_data, unknown_key, save_dir=None):\n    data = json.loads(json_data)\n    url = data.get(unknown_key)\n    if not url:\n        return None\n    response = requests.get(url)\n    response.raise_for_status()  # raise error if download failed\n    return response.content\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1129_3",
        "turn": "3",
        "instruct_prompt": "Modify the function to save the downloaded content to a file named '{unknown_key}_{timestamp}.txt', where 'timestamp' is the current datetime formatted as '%Y%m%d%H%M%S%f'. Save the file in the directory given by save_dir or the current working directory if save_dir is None. Return the absolute path of the saved file.",
        "test": "import unittest\nimport tempfile\nimport os\nimport json\nfrom unittest.mock import patch, Mock\nimport builtins\n\nclass TestCases(unittest.TestCase):\n    @patch('requests.get')\n    def test_save_file_in_specified_dir(self, mock_get):\n        content = b'Test content'\n        mock_response = Mock()\n        mock_response.content = content\n        mock_response.raise_for_status = Mock()\n        mock_get.return_value = mock_response\n\n        test_json = json.dumps({'key1': 'http://example.com/file.txt'})\n        unknown_key = 'key1'\n\n        with tempfile.TemporaryDirectory() as tmpdir:\n            filepath = task_func(test_json, unknown_key, save_dir=tmpdir)\n\n            self.assertTrue(filepath.startswith(tmpdir))\n            self.assertTrue(filepath.endswith('.txt'))\n            self.assertIn(unknown_key, os.path.basename(filepath))\n\n            with open(filepath, 'rb') as f:\n                self.assertEqual(f.read(), content)\n\n    @patch('requests.get')\n    def test_save_file_in_current_dir(self, mock_get):\n        content = b'Another test content'\n        mock_response = Mock()\n        mock_response.content = content\n        mock_response.raise_for_status = Mock()\n        mock_get.return_value = mock_response\n\n        test_json = json.dumps({'somekey': 'http://example.com/file2.txt'})\n        unknown_key = 'somekey'\n\n        # Save current working directory\n        orig_cwd = os.getcwd()\n        with tempfile.TemporaryDirectory() as tmpdir:\n            os.chdir(tmpdir)\n            try:\n                filepath = task_func(test_json, unknown_key, save_dir=None)\n                self.assertTrue(filepath.startswith(tmpdir))\n                self.assertTrue(filepath.endswith('.txt'))\n                self.assertIn(unknown_key, os.path.basename(filepath))\n\n                with open(filepath, 'rb') as f:\n                    self.assertEqual(f.read(), content)\n            finally:\n                os.chdir(orig_cwd)\n\n    @patch('requests.get')\n    def test_missing_key_returns_none(self, mock_get):\n        test_json = json.dumps({'somekey': 'http://example.com/file2.txt'})\n        unknown_key = 'nokey'\n        result = task_func(test_json, unknown_key)\n        self.assertIsNone(result)\n        mock_get.assert_not_called()\n",
        "code": "import json\nimport requests\nimport os\nfrom datetime import datetime\n\ndef task_func(json_data, unknown_key, save_dir=None):\n    data = json.loads(json_data)\n    url = data.get(unknown_key)\n    if not url:\n        return None\n    response = requests.get(url)\n    response.raise_for_status()  # raise error if download failed\n    content = response.content\n\n    if save_dir is None:\n        save_dir = os.getcwd()\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S%f')\n    filename = f\"{unknown_key}_{timestamp}.txt\"\n    filepath = os.path.join(save_dir, filename)\n\n    with open(filepath, 'wb') as f:\n        f.write(content)\n\n    return os.path.abspath(filepath)\n",
        "entry_point": "task_func"
      }
    ]
  },
  {
    "mt_id": 148,
    "task_id": "BigCodeBench/1137",
    "mt_data": [
      {
        "task_id": "BigCodeBench/1137_1",
        "turn": "1",
        "instruct_prompt": "Extract text content from a given URL or local file. You should write self-contained code starting with:\n```python\nimport requests\nimport bs4\n\ndef task_func(url: str, output_path: str) -> list:\n```",
        "test": "import unittest\nimport os\nimport tempfile\nfrom unittest.mock import patch\n\nclass TestCases(unittest.TestCase):\n    def test_local_file_extraction(self):\n        html_content = '<html><head><title>Test</title></head><body><p>Hello World!</p></body></html>'\n        with tempfile.NamedTemporaryFile('w', delete=False, encoding='utf-8') as tmpfile:\n            tmpfile.write(html_content)\n            tmpfile_path = tmpfile.name\n\n        with tempfile.NamedTemporaryFile('r', delete=False, encoding='utf-8') as out:\n            output_path = out.name\n\n        words = task_func(tmpfile_path, output_path)\n\n        # Check output file content\n        with open(output_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n\n        self.assertIn('Hello', content)\n        self.assertIn('World!', content)\n        self.assertIn('Test', content)\n        self.assertEqual(words, content.split())\n\n        os.remove(tmpfile_path)\n        os.remove(output_path)\n\n    @patch('requests.get')\n    def test_url_extraction(self, mock_get):\n        html_content = '<html><body><h1>Title</h1><p>Paragraph text.</p></body></html>'\n        mock_response = unittest.mock.Mock()\n        mock_response.status_code = 200\n        mock_response.text = html_content\n        mock_response.raise_for_status = lambda: None\n        mock_get.return_value = mock_response\n\n        with tempfile.NamedTemporaryFile('r', delete=False, encoding='utf-8') as out:\n            output_path = out.name\n\n        words = task_func('http://example.com', output_path)\n\n        with open(output_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n\n        self.assertIn('Title', content)\n        self.assertIn('Paragraph', content)\n        self.assertIn('text.', content)\n        self.assertEqual(words, content.split())\n\n        os.remove(output_path)\n\n    def test_invalid_local_file(self):\n        with self.assertRaises(FileNotFoundError):\n            task_func('non_existing_file.html', 'dummy_output.txt')\n\n    @patch('requests.get')\n    def test_url_http_error(self, mock_get):\n        mock_response = unittest.mock.Mock()\n        def raise_http_error():\n            raise requests.exceptions.HTTPError()\n        mock_response.raise_for_status = raise_http_error\n        mock_get.return_value = mock_response\n\n        with self.assertRaises(requests.exceptions.HTTPError):\n            task_func('http://example.com', 'dummy_output.txt')\n\nif __name__ == '__main__':\n    unittest.main()",
        "code": "import requests\nimport bs4\n\ndef task_func(url: str, output_path: str) -> list:\n    # Determine if the input is a URL or a local file path\n    if url.startswith(('http://', 'https://')):\n        # Fetch content from URL\n        response = requests.get(url)\n        response.raise_for_status()\n        content = response.text\n    else:\n        # Read content from local file\n        with open(url, 'r', encoding='utf-8') as f:\n            content = f.read()\n\n    # Parse HTML content and extract text\n    soup = bs4.BeautifulSoup(content, 'html.parser')\n    text = soup.get_text(separator=' ', strip=True)\n\n    # Write the extracted text to output_path\n    with open(output_path, 'w', encoding='utf-8') as f:\n        f.write(text)\n\n    # Return the extracted text as a list of words\n    return text.split()\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1137_2",
        "turn": "2",
        "instruct_prompt": "Extract phone numbers from the extracted text using a regular expression and return them as a list of strings.",
        "test": "import unittest\nimport tempfile\nimport os\n\nclass TestCases(unittest.TestCase):\n    def test_extract_phone_numbers(self):\n        html_content = '''\n        <html><body>\n        <p>Contact us at (123) 456-7890 or 987-654-3210.</p>\n        <p>International: +1 800 555 1234</p>\n        <p>No phone here!</p>\n        </body></html>\n        '''\n\n        # Write html_content to a temp file\n        with tempfile.NamedTemporaryFile('w+', delete=False, suffix='.html') as tmp:\n            tmp.write(html_content)\n            tmp_path = tmp.name\n\n        output_path = tmp_path + '_output.txt'\n\n        # Directly call task_func since it's in the same file\n        result = task_func(tmp_path, output_path)\n\n        # Clean up temp files\n        os.remove(tmp_path)\n        if os.path.exists(output_path):\n            os.remove(output_path)\n\n        expected_numbers = ['(123) 456-7890', '987-654-3210', '+1 800 555 1234']\n        self.assertCountEqual(result, expected_numbers)\n\n    def test_no_phone_numbers(self):\n        html_content = '<html><body><p>No phones here!</p></body></html>'\n\n        with tempfile.NamedTemporaryFile('w+', delete=False, suffix='.html') as tmp:\n            tmp.write(html_content)\n            tmp_path = tmp.name\n\n        output_path = tmp_path + '_output.txt'\n\n        result = task_func(tmp_path, output_path)\n\n        os.remove(tmp_path)\n        if os.path.exists(output_path):\n            os.remove(output_path)\n\n        self.assertEqual(result, [])\n",
        "code": "import requests\nimport bs4\nimport re\n\ndef task_func(url: str, output_path: str) -> list:\n    # Determine if the input is a URL or a local file path\n    if url.startswith(('http://', 'https://')):\n        # Fetch content from URL\n        response = requests.get(url)\n        response.raise_for_status()\n        content = response.text\n    else:\n        # Read content from local file\n        with open(url, 'r', encoding='utf-8') as f:\n            content = f.read()\n\n    # Parse HTML content and extract text\n    soup = bs4.BeautifulSoup(content, 'html.parser')\n    text = soup.get_text(separator=' ', strip=True)\n\n    # Write the extracted text to output_path\n    with open(output_path, 'w', encoding='utf-8') as f:\n        f.write(text)\n\n    # Extract phone numbers using regex\n    phone_pattern = re.compile(r'(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(\\d{3}\\)|\\d{3})[-.\\s]?\\d{3}[-.\\s]?\\d{4}')\n    phone_numbers = phone_pattern.findall(text)\n\n    return phone_numbers\n",
        "entry_point": "task_func"
      },
      {
        "task_id": "BigCodeBench/1137_3",
        "turn": "3",
        "instruct_prompt": "Save the extracted list of phone numbers to the specified output file in JSON format.",
        "test": "import unittest\nimport os\nimport json\nfrom tempfile import NamedTemporaryFile\n\nclass TestCases(unittest.TestCase):\n    def test_task_func_saves_json_and_returns_phones(self):\n        # Prepare a simple HTML content with phone numbers\n        html_content = '''\n        <html><body>\n        Contact us at (123) 456-7890 or +1 234-567-8901.\n        </body></html>\n        '''\n\n        # Write the HTML content to a temporary file\n        temp_html = NamedTemporaryFile('w', delete=False, suffix='.html', encoding='utf-8')\n        try:\n            temp_html.write(html_content)\n            temp_html_path = temp_html.name\n            temp_html.close()\n\n            # Prepare temporary output file path\n            temp_out = NamedTemporaryFile('w', delete=False, suffix='.json', encoding='utf-8')\n            temp_out_path = temp_out.name\n            temp_out.close()\n\n            # Run the function directly without import\n            phones = task_func(temp_html_path, temp_out_path)\n\n            # Check returned phone numbers\n            expected_phones = ['(123) 456-7890', '+1 234-567-8901']\n            self.assertEqual(phones, expected_phones)\n\n            # Check the output file content is JSON and matches expected phones\n            with open(temp_out_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n            self.assertEqual(data, expected_phones)\n\n        finally:\n            # Cleanup temporary files\n            if os.path.exists(temp_html_path):\n                os.remove(temp_html_path)\n            if os.path.exists(temp_out_path):\n                os.remove(temp_out_path)\n",
        "code": "import requests\nimport bs4\nimport re\nimport json\n\ndef task_func(url: str, output_path: str) -> list:\n    # Determine if the input is a URL or a local file path\n    if url.startswith(('http://', 'https://')):\n        # Fetch content from URL\n        response = requests.get(url)\n        response.raise_for_status()\n        content = response.text\n    else:\n        # Read content from local file\n        with open(url, 'r', encoding='utf-8') as f:\n            content = f.read()\n\n    # Parse HTML content and extract text\n    soup = bs4.BeautifulSoup(content, 'html.parser')\n    text = soup.get_text(separator=' ', strip=True)\n\n    # Extract phone numbers using regex\n    phone_pattern = re.compile(r'(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(\\d{3}\\)|\\d{3})[-.\\s]?\\d{3}[-.\\s]?\\d{4}')\n    phone_numbers = phone_pattern.findall(text)\n\n    # Save the extracted phone numbers to the output file in JSON format\n    with open(output_path, 'w', encoding='utf-8') as f:\n        json.dump(phone_numbers, f, ensure_ascii=False, indent=4)\n\n    return phone_numbers\n",
        "entry_point": "task_func"
      }
    ]
  }
]